{"pages":[{"title":"about-me","text":"ok,this is test text that something for you","link":"/about-me/index.html"}],"posts":[{"title":"C语言基础","text":"C语言基础对C语言基础只是的概括 目标文件 可执行文件 库 源文件 源文件指的是我们所编写的文件 vi xx.c#include int main(void){ printf(\"hello world\"); return 0;} 以上xx.c就是我们的源文件 在unix中编译c语言 cc xx.c 会在当前文件夹生成一个a.out的可执行文件 运行即可 整个流程就是用户输入代码生成源码文件 通过cc编译后生成可执行文件 运行输出内容cc其实是一个命令，可以用man cc 查看 也可以用cc -v查看版本信息 在linux中使用gcc编译c文件 gcc xx.c 第一个c语言程序 # include int main(void){ int nums; nums = 1; printf(\"how many dogs do you have?\\n\"); getchar(); return 0;}include是预处理器指令 main是第一个被调用的函数 func a是构造块stdio.h 是c编译器软件包的标准部分 变量类型整数 int int nums=12;int nums;nums = 12; int nums = 12 , ages = 20; 大致的执行过程为 int nums 划分出一块内存空间名为numsnums = 12 为nums赋值12的变量 错误zsh: command not found: a.outmac下无法执行cc编译后的文件因为没有确定工作路径 运行./a.out就可以了","link":"/posts/9ec06885/"},{"title":"Python报错总结","text":"Python报错总结Non-ASCIIpython出现SyntaxError: Non-ASCII character ‘\\xe6’ in file 打印日期.py on line 1, but no encoding declared; 解决方法在文件头部添加如下两行注释码： #!/usr/bin/python# -*- coding: -*- 例如，可添加# -*- coding: utf-8 -*-","link":"/posts/1d0174bc/"},{"title":"ansible总结","text":"登陆h3c交换机h3c交换机的模块支持度极低，网上大多都是思科交换机的模块，很多要用到H3c的都是自己写的，感觉很坑 问题:现在又一个问题就是命令行使用raw模块可以登陆交换机，并且输出执指令 返回结果，但是在ansible-playbook中不行 echo \"10.0.5.124\" >> ./xxansible -i xx all -m raw -a 'system-view ;dis arp ;' 如上是可以的，但是如下的playbook则不行 echo first.yml < EOF","link":"/posts/20d6cad/"},{"title":"ansible基础","text":"主机清单 inventoryansible中添加主机清单的几种形式 直接在命令行中指定ip,-k登陆时指定密码 ansible 192.168.20.1 -m ping -kansible 192.168.20.1,192.168.20.2 -m ping -k 在配置文件中指定 默认文件夹/etc/ansible/hosts [name1]192.168.20.1[name2]192.168.20.2ansible name1 -m ping -k # 指定分组ansible all -m ping -k # 指定所有 由于ansible是通过ssh访问被执行端主机的，因此没有ssh的权限是无法完成任务的，即使这里的命令是ping，但依旧要走ssh的流程这里的ping并不是linux下的ping ,而是ansible工具下面的ping模块 不使用默认文件下，自定义文件夹 echo \"192.168.20.1\" >> xxansible -i xx all -m ping -k 在配置组里面中直接确认登陆用户 echo \"192.168.20.1 ansible_ssh_user=root ansible_ssh_pass=upyun123\"ansible -i xx all -m ping 配置文件 local_tmp是本地的执行指令 remote_tmp是远程的执行指令当用户使用ansible控制被控端执行指令的时候，他会先将内容放在local_tmp文件中，然后上传到被控端并生成remote_tmp上执行。执行完成之后会删除这两个tmp文件 library = /usr/share/my_modules/ 库存放地址 forks = 5 默认并发数 sudo_user = root 默认sudo 用户 ask_sudo_pass = True 每次执行ansible是否询问ssh密码 ask_pass = True remote_port = 22 host_key_checking = False 检查对应服务器的host_key —–>建议取消注释 log_path=/var/log/ansible.log 日志文件 命令ansible-doc 说明文档ansible-doc [options] [module..]-a 显示所有模块的文档 参数尽量放在单引号里面-l –list 列出可用模块-s –snippet xxx 显示xxx模块的playbook片段 role扩展模块ansible-galaxy专门有一个网站提供不同用户上传的”角色”地址:https://galaxy.ansible.com/ # 列出所有已安装的galaxyansible-galaxy list# 安装galaxyansible-galaxy install xxx# 删除galaxyansible-galaxy remove xxx role默认安装路径为/etc/ansible/roles/下 ansible列出指定组别的host列表ansible appsevr –list-hosts列出所有列表的hostansible all –list-hostsansible all –list支持通配符匹配hostansible *serv –list多IP批量执行ansible 192.168.0.1,192.168.0.2 -m ping多组别批量执行(逻辑或关系,合并，A和B所有)ansible websevr:appsevr -m ping(逻辑与关系,区分,在A中,也在B中)ansible “websevr:&appsevr” -m ping(逻辑非,在A中不在B中,此处必须要用单引号)ansible ‘websevr:!appsevr’ -m ping ansible [-m module_name] [-a args]–version 显示版本-m module 指定模板,默认为command-v 详细过程 -vv -vvv更详细–list –list-hosts 显示主机列表，-k –ask-pass 提示输入ssh连接密码，默认为key验证-K –ask-become-pass 提示输入sudo时的口令-C –check 检查，并不执行-T –timeout=TIMEOUT 执行命令的超时时间,默认为10s-u –user=REMOTE_USER 执行远程执行的用户-b –become 代替旧版的sudo切换 (默认为ansible.cfg里面设置的用户,一般为root)-a 指定参数 ansible -m命令模块command在command中,我们可以创建文件，但是对于文件的操作,有一个专门的file模块 # 创建一个文件ansible -m command -a 'mkdir \\data'# 查看文件是否创建成功ansible -m command -a 'ls -al \\data'# 查看command帮助ansible-doc command shell如果-a 后带的参数中出现 $ < > | ; & 等字符，command是不支持的，需要用到shell 模块 # 输出主机名字ansible 192.168.1.3 -m shell -a 'echo $HOSTNAME' ansible命令执行流程1.加载自己的配置文件 默认为/etc/ansible/ansible.cfg2.加载自己对应的模块文件,如command3.通过ansible将模块或命令生成对应的临时py文件,并将文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/xxx.py文件4.增加文件的执行权限5.执行并返回结果6.删除临时py文件,sleep 0退出执行状态:绿色 执行成功并且不需要做改变的操作黄色 执行成功但是对目标主机做了修改红色 执行失败(颜色内容在/etc/ansible.cfg里面修改) 生成sshssh-keygen复制ssh密钥到其他主机ssh-copy-id 主机ip 模块由于Ansible的模块过多，将近有1378个模块数量,但是每个模块的介绍以及使用方法都存放在/usr/bin/ansible-doc当中 # 查看当前ansible模块数量ansible-doc -l | wc -l# ansible-doc的使用方法ansible-doc [options] [module..]-a 显示所有模块的文档 参数尽量放在单引号里面-l --list 列出可用模块-s --snippet xxx 显示xxx模块的playbook片段# 使用-m指定模块，默认为commandansible -m command command在command中,我们可以创建文件，但是对于文件的操作,有一个专门的file模块 # 创建一个文件ansible -m command -a 'mkdir \\data'# 查看文件是否创建成功ansible -m command -a 'ls -al \\data'# 查看command帮助ansible-doc command shell如果-a 后带的参数中出现 $ < > | ; & 等字符，command是不支持的，需要用到shell 模块 # 输出主机名字ansible 192.168.1.3 -m shell -a 'echo $HOSTNAME' script既然ansible可以对多台主机进行批量的操作，那往往我们会遇到一个场景，即需要我们在多台主机上执行一个脚本，这个场景下我们有两个方法:1.将脚本文件复制到多台主机上后,调用ansible使用2.使用script模块，仅在控制端存在脚本文件即可 # 方法一,先将文件发到对应控制端主机ansible 192.168.1.3 -m command -a '/root/ansible_test.sh'# 方法二root@DESKTOP-GT1K5L0:~# ansible 192.168.1.3 -m script -a '/root/ansible_test.sh'192.168.1.3 | SUCCESS => { \"changed\": true, \"rc\": 0, \"stderr\": \"Shared connection to 192.168.1.3 closed\", \"stdout\": \"to do it,ansible\", \"stdout_lines\": [ \"to do it,ansible\" ]} Copy在上面我们提到了从控制端传输文件到被控端,既然是批量的操作,那么在ansible中同样存在一个copy的模块,可以用来传输文件场景: 关闭多台主机的selinux流程: 复制控制端selinux的配置文件，修改后发送到被控制端 注意:这里的ho表示的是一个主机群 在/etc/ansible/hosts中已经添加了 # 查看控制端selinux状态getenforce# 查看被控端selinux状态[root@localhost ~]# ansible ho -m command -a 'getenforce'192.168.1.6 | SUCCESS | rc=0 >>Enforcing192.168.1.7 | SUCCESS | rc=0 >>Enforcing192.168.1.5 | SUCCESS | rc=0 >>Enforcing192.168.1.4 | SUCCESS | rc=0 >>Enforcing# 复制selinux配置文件，并修改配置cp /etc/selinux/config .SELINUX=disabled# 复制配置文件到被控端指定路径,并做好备份ansible ho -m copy -a'src=/root/hzj/config dest=/etc/selinux/config backup=yes'# 查看被控端是否生成备份文件ansible ho -m command -a 'ls /etc/selinux/'# 重启ansible ho -m command -a 'reboot'# 查看被控端selinux是否修改完成ansible ho -m command -a 'getenforce'[root@localhost hzj]# ansible ho -m command -a 'getenforce'192.168.1.7 | SUCCESS | rc=0 >>Disabled192.168.1.4 | SUCCESS | rc=0 >>Disabled192.168.1.5 | SUCCESS | rc=0 >>Disabled192.168.1.6 | SUCCESS | rc=0 >>Disabled fetchansible支持从被控端抓取文件到控制端,抓取后的格式为\\example.com\\destsrc表示抓取路径dest表示存放路径 # 复制所有主机的日志到控制端ansible ho -m fetch -a 'src=/var/log/messages dest=/root/data' 但是fetch仅支持单个文件的抓取，当我们想要抓取多个日志文件时，可以先进行打包 file设置文件的属性 # 创建文件ansible ho -m file -a 'name=/data/f3 state=touch'# 删除文件ansible ho -m file -a 'name=/data/f3 state=absent'# 创建文件夹ansible ho -m file -a 'name=/data/f3 state=directory'# 删除文件夹ansible ho -m file -a 'name=/data/f3 state=absent'# 创建软连接ansible ho -m file -a 'src=/root/test name=/data/fq state=link'# 但是需要注意的是如果你创建了文件f3 当你创建文件夹f3的时候会出现错误 hostname修改主机名 ansible ho -m hostname -a 'name=node'# 重启后生效 cron# 给每台主机添加任务,name为注释ansible ho -m cron -a 'minute=* weekday=1,3,5,7 job=\"usr/bin/wall message\" name=test'# 取消任务ansible ho -m cron -a 'disabled=true job=\"usr/bin/wall message\" name=test'# 重新启用ansible ho -m cron -a 'disabled=no job=\"usr/bin/wall message\" name=test'# 删除某条任务ansible ho -m corn -a 'jon=\"usr/bin/wall message\" state=absent' yum# name指定包 state指定状态ansible ho -m yum -a 'name=httpd state=latest' 安装ansible ho -m yum -a 'name=httpd state=absent' 删除 Service# 关闭服务 name指定服务名称 state指定状态ansible ho -m service -a 'name=httpd state=stopped'ansible ho -m service -a 'name=httpd state=started'ansible ho -m service -a'name=httpd state=reloaded'ansible ho -m service -a'name=httpd state=restarted' Useransible ho -m user -a 'name=user comment=\"test user\" uid=2048 home=/app/user group=root'ansible ho -m user -a 'name=sysuser system=yes home=/app/syseser1'ansible ho -m user -a 'name=user state=absent remove=yes' 删除用户以及家目录等数据 playbook的编写随着工作的增加,单条ansible命令(adhoc)已经不能满足我们的需求.于是我们可以把多条ansible命令写入playbook中,让系统根据playbook中的顺序依次执行ansible。我们把它叫做剧本 Playbook的编写方式Playbook的编写格式采用的是yaml语言url: http://www.ruanyifeng.com/blog/2016/07/yaml.htmlurl2: https://www.jianshu.com/p/97222440cd08urs3: https://yaml.org/ 多种语言实现yaml 简单的介绍一下yaml语言的使用 1. 在单一档案中,可以用连续的连字符(---)区分多个档案。另外，还有选择性的连续三个点号(...)用来表示档案结尾2. 次行开始正常写Playbook的内容，一般建议写明该playbook的功能3. 使用#号注释代码4. 缩进统一用tab5. 一个完整的代码块功能最少的元素需要包括name:task6. 一个name只能包括一个task7. yaml文件扩展名通常为yml或者yaml playbook例子 ---- hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted playbook核心元素 Hosts 执行的远程主机列表 Tasks 任务集 Varniables 内置变量或自定义变量在playbook中调用 Templates 模板,可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers 和 notity 结合使用,由特定条件触发的操作，满足条件方才执行,否则不执行 tags 标签 指定某条任务执行,用于选择运行playbook中的部分代码。ansible具有幂等性,因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会很长。因此可以使用tags跳过一些代码片段。ansible-playbook -t tagsname useradd.yml adhoc 和 playbook 对比 # adhoc 改变主机名字ansible ho -m hostname -a 'name=xxx'# playboot 修改主机名字---- host: ho remote_user: root tasks: - name: hello hostname: name=node 多条adhoc 和playbook对比 # adhoc ansible ho -m file -a 'name=/data/newfile state=touch' # 创建文件ansible ho -m user -a 'name=test2 system=yes shell=/sbin/nologin' # 创建用户ansible ho -m yum -a 'name=httpd' # 安装httpdansible ho -m copy -a 'src=/var/www/html/index.html dest=/var/www/html' # 复制文件ansible ho -m service -a 'name=httpd state=started enabled=yes' # 启动服务# playbook- hosts: ho remote_user: root tasks: - name: create file file: name=/data/newfile state=touch - name: create user file: name=test2 system=yes shell=/sbin/nologin - name: install httpd yum: name=httpd - name: copy file copy: src=/var/www/html/index.html dest=/var/www/html - name: start service service: name=httpd state=started enabled=yes shell脚本与playbook对比 # shell脚本#!/bin/bash# 安装Apacheyum install --quiet -y httpd# 复制配置文件cp /tmp/httpd.conf /etc/httpd/conf/httpd.confcp /tmp/vhosts.conf /etc/httpd/conf.d/# 启动Apache 并设置开机启动systemctl start httpd.servicechkconfig httpd on# playbook---- host: all tasks: - name: \"安装Apache\" yum: name=httpd - name: \"复制配置文件\" copy: src=/tmp/httpd.conf dest=/etc/httpd/conf/ - name: \"复制文件\" copy: src=/tmp/vhosts.conf dest=/etc/httpd/conf.d/ - name: \"启动Apache,并设置开机启动\" service: name=httpd state=started enabled=yes 执行流程play的主体部分是task list 。 task list 中的各任务按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个任务后在开始第二个，在运行自上而下某一个playbook时，如果中途发生错误，所有已执行任务都将回滚，因此，在更正playbook后重新执行一次即可 忽略错误信息 task:- name: copy file copy: src=/root/file dest=/root/ || /bin/true# 或者task:- name: copy file copy: src=/root/file dest=/root/ ignore_erros: True playbook运行方式ansible-playbook [options]--check 只检测可能会发生的改变，但不真正执行操作--list-hosts 列出运行任务的主机--limit 主机列表 只针对主机列表中的主机执行-v 显示过程 -vv -vvv显示更详细 Playbook剧本ansible-playbook是ansible中的一个工具,存放在/usr/bin/ansible-playbook 其他 模块https://www.cnblogs.com/f-ck-need-u/p/7550603.htmlhttps://docs.ansible.com/ansible/2.6/modules/list_of_all_modules.html ansible模块开发https://www.jianshu.com/p/f72b79b0d3f9","link":"/posts/ea06c230/"},{"title":"Python常用方法1","text":"python 常用方法保留小数使用字符串格式化 a = 11.234print(\"%.2f\"%a) 使用round内置函数 a = 11.234a = round(a,2)print(a) 使用decimal模块 from decimal import Decimala = 12.345Decimal(a).quantize(Decimal(\"0.00\")) 列表列表合并# 使用+号操作list1 = [1,2,3,4,5]list2 = [\"z\",\"xx\",] list3 = list1+list2# 使用extendlist4.extend(list1)# 使用切片list4[len(11):len(11)] = list5 os模块Python获取指定文件夹下的文件名模块os.walk可以遍历文件夹下的所有文件 os.walk(top, topdown=Ture, οnerrοr=None, followlinks=False)# return (dirpath dirnames filenames) dirpath: string 代表目录的路径 dirnames list 包含了当前dirpath路径下所有的子目录名字（不包含目录路径） filenames：list，包含了当前dirpath路径下所有的非目录子文件的名字（不包含目录路径）。import os def file_name(file_dir): for root, dirs, files in os.walk(file_dir): print(root) #当前目录路径 print(dirs) #当前路径下所有子目录 print(files) #当前路径下所有非目录子文件 for file in files: # os.path.splitext # 对文件名进行切割成数组 if os.path.splitext(file)[1] == \".jpeg\": print(file) else: pass 模块os.listdir()可以得到当前路径下的文件名，不包括子目录中的文件 import os# 遍历获取所有文件def listdir(path, list_name): for file in os.listdir(path): file_path = os.path.join(path, file) # os.path.isdir(file) #判断文件是否为文件夹 if os.path.isdir(file_path): listdir(file_path, list_name) elif os.path.splitext(file_path)[1]=='.jpeg': list_name.append(file_path) 判断文件类型os.path.isdir(path) # 是否为文件夹os.path.isfile(path) # 是否为文件 文件操作mode选项r 读模式，只能读 文件不存在报错，w 写模式，只能写 文件不存在则创建，以上存在存在则清空在打开 rb 二进制读模式 只能读 文件不存在报错wb 二进制写模式 只能写 文件不存在则创建，以上存在则清空再打开有二进制内容 写入则需要encode(“utf-8”) rb+ 二进制读模式 可读可写 文件不存在报错wb+ 二进制写模式 可读可写 文件不存在则创建，以上存在则清空再打开 a 追加写模式，文件存在则追加写入a+ 追加读写方式以上存在则追加写入 默认进入为文件末尾f.seek(0) 设置读写位置为开头f.truncate(0) 将文章字节阶段为0 文件头部写如文件with open(path, \"r+\") as f: old = f.read() f.seek(0) f.write(data) f.write(old) 或者 with open(path,\"a\") as f: f.seek(0) old = f.read() # 全部删除 f.truncate(0) f.write(\"---\") f.write(\"tags: xxx\") f.write(\"---\") f.close() Python-math库向上取整 math.ceil向下取整 math.floor四舍五入 round import math#向上取整print \"math.ceil---\"print \"math.ceil(2.3) => \", math.ceil(2.3)print \"math.ceil(2.6) => \", math.ceil(2.6) #向下取整print \"\\nmath.floor---\"print \"math.floor(2.3) => \", math.floor(2.3)print \"math.floor(2.6) => \", math.floor(2.6) #四舍五入print \"\\nround---\"print \"round(2.3) => \", round(2.3)print \"round(2.6) => \", round(2.6) #这三个的返回结果都是浮点型print \"\\n\\nNOTE:every result is type of float\"print \"math.ceil(2) => \", math.ceil(2)print \"math.floor(2) => \", math.floor(2)print \"round(2) => \", round(2)","link":"/posts/79b81c10/"},{"title":"任务流程-checklist","text":"任务流程-checklist 交换机下架流程 首先知道哪些机器要下架,知道以后登陆上去看一下交换机上下是不是有机器还连在上面，可以让机房帮忙看一下 查看接口的流量dis int bri xxx像这种没多少流量的基本上就是没有机器了 找到机柜 交换机型号 发给商务， 商务发工单给机房下架 完事 inventory上架流程拉取项目git clone https://gitlab.s.upyun.com/infrastructure/inventory.gigit clone https://gitlab.s.upyun.com/infrastructure/inventory.git 查看当前分支git branch 切换分支git checkout hzj 修改内容… 上传git commit -am “update”git push 到web端创建合并请求 更新首先切换到master，拉取最新git pull切换次分支 git checkout hzj合并更新分支到hzj分支 git merge origin hzj 发消息给有master权限的人，交由master来合并","link":"/posts/b3883d25/"},{"title":"django字段总结","text":"django字段的设计https://docs.djangoproject.com/zh-hans/2.2/ref/models/fields/#module-django.db.models.fieldsorm的设计模式在django的应用过程中，往往要设计model的设计，在model设计过程中要使用各种各样的关键词，这些关键词 关联到了数据库中每条记录的配置 # 引用from django.db import models 通用字段null字段如果设置为 True， 当该字段为空时，Django 会将数据库中该字段设置为NULL，默认为 False。即数据库置空 如果null=true blank=true 则数据库内容为空白字符串 blankField.blank默认blank = False ,如果设置为True，则允许该字段为空。与null不同的是,null存粹与数据库有相关，而blank与验证相关。如果blank=true,则表单验证将允许输入空值,如果blank=False 则不允许输入空值 choicesclass TaskSwitchModel(models.Model): ActionType = models.CharField(choices=[ ('snmp','_(snmp)'), (\"vlan\",\"_vlan\"), (\"sysname\",\"_sysname\"), (\"copyright-info\",\"_copyright-info\"), (\"int-vlan\",\"_int-vlan\"), (\"int\",\"_int\")],max_length=100,default=\"\") test = models.CharField(max_length=1, choices=[('A', ('Author')), ('E', ('Editor'))]), class TaskSwitchModel(model.ModelForm): choices=( ('snmp','_(snmp)'), (\"vlan\",\"_vlan\"), (\"sysname\",\"_sysname\"), (\"copyright-info\",\"_copyright-info\"), (\"int-vlan\",\"_int-vlan\"), (\"int\",\"_int\") ) ActionType = model.CharField(choices=choices,max_length=100,default=\"\") Field.choices每个元组中的第一个元素是要在模型上设置的实际值，第二个元素是人类可读的名称. select_choices =[ ('A','A_'), ('B','B_'), ('C','C_'), ('D','D_'),]choices字段迭代每个元组的第一个元素是要应用于组的名称。第二个元素是一个可迭代的2代元组select2_select1_choices=[ ('A',( ('A_/','A_movie'), ('A_+','A_video'), ('A_-','A_City'), ) ), ('Video', ( ('vhs', 'VHS Tape'), ('dvd', 'DVD'), ) ), ('unknown', 'Unknown'),] db_column设置数据库列的名称 age = models.CharFiled(db_column=”年龄”) db_indexage = models.CharFiled(db_index=true)如果设置为True，则创建数据库索引 default可以是值也可以是可调用的对象，每次实例化模型的时候 会调用这个对象或值 # 1def contact_defult(): return {\"email\":\"1097690268@qq.com\"}contact_info = JSONField(\"ContactInfo\", default=contact_default)# 2member_name = CharFiled(default=\"小明\") editable可编辑字段如果为False，则该字段将不会显示在管理员或其他任何人中 ModelForm。在模型验证期间也将跳过它们。默认值为True。 uniquename = CharFiled(unique=true)如上则会保证该字段的值为表中唯一，也就是不会出现同名的人如果存在了unique 则不再需要db_index 因为unique默认存在索引 primary_key如果设置为True，则初始设置为该模型的主键。如果您未primary_key=True在模型中指定任何字段，则Django会自动添加一个AutoField来保留主键，因此primary_key=True暗示null=False和 unique=True。一个对象只允许使用一个主键。主键字段是只读的。如果更改现有对象上的主键的值然后保存，则将在旧对象的旁边创建一个新对象。 自定义的字段https://docs.djangoproject.com/zh-hans/2.2/howto/custom-model-fields/","link":"/posts/65abc8f/"},{"title":"django内容总结","text":"django内容总结在后台对某些固定字段设置颜色# models.pyfrom django.urls.html import format_htmlclass Person(models.Model): first_name = models.CharField(max_length=50) last_name = models.CharField(max_length=50) color_code = models.CharField(max_length=6) def colored_name(self): return format_html( '{} {}', self.color_code, self.first_name, self.last_name, ) admin.pyclass PersonAdmin(admin.ModelAdmin): list_display = (‘first_name’, ‘last_name’, ‘colored_name’) DjangoAdmin Django自带后台管理模板是其一大特色，但作为后台管理很多地方需要我们去改进，当然也可以使用一些其他的后台模板 推荐模板1: xadmin xadmin在几年前是为django定制的后台管理模板，但是作者已经停止维护，但是在其分支中依旧有部分人在维护。 具体使用跳转到我的掘金https://juejin.im/post/5afd267d51882542714ff756 推荐模板2： django simple-ui 在github上的星数并不高，但是是基于饿了么element-ui所写的django后台模板，我还未使用 使用本身自带的admin模板 使用其他兼容多语言的后台模板 url :https://my.oschina.net/zhiyonghe/blog/1532030 自带的Admin模板 这里介绍一下自带的admin模板。 admin界面汉化在setting.py文件中设置语言 # setting.pyLANGUAGE_CODE = 'zh-hans'IME_ZONE = 'Asia/Shanghai' Model注册在Model.py中创建完类后，需要在admin.py中完成注册，才能在后台模板中显示，方法有二 # admin.py# 方法一from django.contrib import admin from blog.models import Blogclass BlogAdmin(admin.ModelAdmin): list_display=('xx','xx','xx') # 要显示的字段 list_per_page = 50 # 每页最多显示50条 ordering = (\"-xxx\") # 设置排序，-表示降序排序 list_editable = ['','',''] # 设置可编辑字段 list_display_links = ('','',) # 默认情况下只能点击第一个字段进入编辑，设置多个字段可点击进入编辑 list_filter = ('','','') # 筛选器 search_fields = ('','','',) # 搜索字段 date_hierarchy = 'go_time' # 详细时间筛选admin.site.register(Blog,BlogAdmin)# 方法二from djang.contrib import adminfrom blog.models import Blog@admin.register(Blog)class BlogAdmin(admin.ModelAdmin): list_display=('','','') Django for ajaxdjango 前后台传递消息内容的方法有很多种,这里我们来讲一下ajax for django # 路由地址# 项目路径下path('',include('GraphPro.urls'))# 应用路径下path('echartsdemo/',demoView.as_view(),name=\"demo\"),# 视图层class demoView(View): def get(self,request): if request.GET.get('name') == 'hzj': return HttpResponse(\"ssdsdsd\") else: print(2) return render(request,'demo.html') def post(self,request): pass# 模板层 点击 {{ data }} $(document).ready(function () { var name = $('#name').val(); var data = {\"name\":name}; $(\"#click_func\").click(function () { $.get( //请求的url '{% url 'demoecharts' %}', data, function (ret) { console.log(ret) } ) }) }) 进入页面直接请求后台数据 $(document).ready(function () { var data = {\"name\":\"hzj\"}; $.get( //请求的url '{% url 'demo' %}', data, function (ret) { console.log(ret) } ) }) 异步加载数据 $(document).ready(function () { var data = {\"name\":\"hzj\"}; $.get( //请求的url '{% url 'demo' %}', data, ).done(function(ret){ console.log(ret) }) }) 介绍Mysql在Django中的引用由于Django在初始化项目后，所使用的数据库是sqlite3,但为了扩展，我们这里计划使用Mysql,配置步骤如下 配置1.在服务器上安装Mysql数据库(Centos版)2.在django的setting.py中引用 错误类型总结由于mysql与django在配置过程中会存在很多的错误，这里总结一下 Mysql在Centos中权限不足的错误ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 原因是/var/lib/mysql的访问权限不足 1.改变权限 chown -R mysql:mysql /var/lib/mysql 2. 启动服务器 /etc/init.d/mysql start (会自动生成mysql.sock文件) 3.重新启动mysql服务 /etc/init.d/mysql start 密码类型错误1045, \"Access denied for user 'root'@'122.224.83.xxx 原因 密码错误，注意密码不能是字符串 GRANT ALL PRIVILEGES ON *.* TO root@'%' IDENTIFIED BY '123456' WITH GRANT OPTION; django setting 中的配置DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'itemids', # 数据库名字 'USER': 'root', # 数据库登录名 'PASSWORD': '12345x', # 数据库密码 'HOST': '106.14.195.xxx', 数据库IP 'POST': 3306, # 端口 }} 引用pymysql由于MySQLdb只能使用在Python2中，在python3中已经停止了维护，所以这里我们引用pymyql的库 pipenv install pymysql# 在与setting.py同级别的__init__.py中使用import pymysqlpymysql.install_as_MySQLdb() pymysql版本不符合报错内容:django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.3 or newer is required; you have 0.7.11修改Pipenv\\Lib\\site-packages\\django\\db\\backends\\mysql\\base.py注释下面内容if version < (1, 3, 3): raise ImproperlyConfigured(“mysqlclient 1.3.3 or newer is required; you have %s” % Database.version) (在Centos中，pipenv install 所生成的包 会在pipenv shell 激活环境的时候出现) 由于上面注释，还会出现的报错内容为File “C:\\Users\\Administrator\\PycharmProjects\\untitled1\\venv\\lib\\site-packages\\django\\db\\backends\\mysql\\operations.py”, line 146, in last_executed_query将operations.py中的decode改成encode mysql不能插入中文报错内容： django.db.utils.InternalError: (1366, “Incorrect string value: ‘\\xE5\\xAE\\x9A\\xE6\\x97\\xB6…’ for column ‘name’ at row 1”)解决方法: https://blog.csdn.net/tzh476/article/details/52644271删除之前的库，创建一个新的数据库，使用utf8mb64 之前默认创建的都是latin1 mysql 长度的问题django.db.utils.InternalError: (1071, ‘Specified key was too long; max key length is 767 bytes’)https://blog.csdn.net/ljfphp/article/details/80406907https://www.orcode.com/question/407126_k280b8.html 解决方法1: 升级Mysql5.6–>>Mysql5.7centos7 下 对mysql的操作 https://blog.csdn.net/xufengzhu/article/details/81110982https://blog.51cto.com/lisea/1941616 解决方法2 : 先使用utf8格式 —-> 介绍Mysql在Django中的引用由于Django在初始化项目后，所使用的数据库是sqlite3,但为了扩展，我们这里计划使用Mysql,配置步骤如下 配置1.在服务器上安装Mysql数据库(Centos版)2.在django的setting.py中引用 错误类型总结由于mysql与django在配置过程中会存在很多的错误，这里总结一下 Mysql在Centos中权限不足的错误ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 原因是/var/lib/mysql的访问权限不足 1.改变权限 chown -R mysql:mysql /var/lib/mysql 2. 启动服务器 /etc/init.d/mysql start (会自动生成mysql.sock文件) 3.重新启动mysql服务 /etc/init.d/mysql start 密码类型错误1045, \"Access denied for user 'root'@'122.224.83.xxx 原因 密码错误，注意密码不能是字符串 GRANT ALL PRIVILEGES ON *.* TO root@'%' IDENTIFIED BY '123456' WITH GRANT OPTION; django setting 中的配置DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'itemids', # 数据库名字 'USER': 'root', # 数据库登录名 'PASSWORD': '12345x', # 数据库密码 'HOST': '106.14.195.xxx', 数据库IP 'POST': 3306, # 端口 }} 引用pymysql由于MySQLdb只能使用在Python2中，在python3中已经停止了维护，所以这里我们引用pymyql的库 pipenv install pymysql# 在与setting.py同级别的__init__.py中使用import pymysqlpymysql.install_as_MySQLdb() pymysql版本不符合报错内容:django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.3 or newer is required; you have 0.7.11修改Pipenv\\Lib\\site-packages\\django\\db\\backends\\mysql\\base.py注释下面内容if version < (1, 3, 3): raise ImproperlyConfigured(“mysqlclient 1.3.3 or newer is required; you have %s” % Database.version) (在Centos中，pipenv install 所生成的包 会在pipenv shell 激活环境的时候出现) 由于上面注释，还会出现的报错内容为File “C:\\Users\\Administrator\\PycharmProjects\\untitled1\\venv\\lib\\site-packages\\django\\db\\backends\\mysql\\operations.py”, line 146, in last_executed_query将operations.py中的decode改成encode mysql不能插入中文报错内容： django.db.utils.InternalError: (1366, “Incorrect string value: ‘\\xE5\\xAE\\x9A\\xE6\\x97\\xB6…’ for column ‘name’ at row 1”)解决方法: https://blog.csdn.net/tzh476/article/details/52644271删除之前的库，创建一个新的数据库，使用utf8mb64 之前默认创建的都是latin1 mysql 长度的问题django.db.utils.InternalError: (1071, ‘Specified key was too long; max key length is 767 bytes’)https://blog.csdn.net/ljfphp/article/details/80406907https://www.orcode.com/question/407126_k280b8.html 解决方法1: 升级Mysql5.6–>>Mysql5.7centos7 下 对mysql的操作 https://blog.csdn.net/xufengzhu/article/details/81110982https://blog.51cto.com/lisea/1941616 解决方法2 : 先使用utf8格式","link":"/posts/7e91b378/"},{"title":"django错误合集","text":"错误类型总结由于mysql与django在配置过程中会存在很多的错误，这里总结一下 Mysql在Centos中权限不足的错误ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 原因是/var/lib/mysql的访问权限不足 1.改变权限 chown -R mysql:mysql /var/lib/mysql 2. 启动服务器 /etc/init.d/mysql start (会自动生成mysql.sock文件) 3.重新启动mysql服务 /etc/init.d/mysql start 密码类型错误1045, \"Access denied for user 'root'@'122.224.83.xxx 原因 密码错误，注意密码不能是字符串 GRANT ALL PRIVILEGES ON *.* TO root@'%' IDENTIFIED BY '123456' WITH GRANT OPTION; django setting 中的配置DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'itemids', # 数据库名字 'USER': 'root', # 数据库登录名 'PASSWORD': '12345x', # 数据库密码 'HOST': '106.14.195.xxx', 数据库IP 'POST': 3306, # 端口 }} 引用pymysql由于MySQLdb只能使用在Python2中，在python3中已经停止了维护，所以这里我们引用pymyql的库 pipenv install pymysql# 在与setting.py同级别的__init__.py中使用import pymysqlpymysql.install_as_MySQLdb() pymysql版本不符合报错内容:django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.3 or newer is required; you have 0.7.11修改Pipenv\\Lib\\site-packages\\django\\db\\backends\\mysql\\base.py注释下面内容if version < (1, 3, 3): raise ImproperlyConfigured(“mysqlclient 1.3.3 or newer is required; you have %s” % Database.version) (在Centos中，pipenv install 所生成的包 会在pipenv shell 激活环境的时候出现) 由于上面注释，还会出现的报错内容为File “C:\\Users\\Administrator\\PycharmProjects\\untitled1\\venv\\lib\\site-packages\\django\\db\\backends\\mysql\\operations.py”, line 146, in last_executed_query将operations.py中的decode改成encode mysql不能插入中文报错内容： django.db.utils.InternalError: (1366, “Incorrect string value: ‘\\xE5\\xAE\\x9A\\xE6\\x97\\xB6…’ for column ‘name’ at row 1”)解决方法: https://blog.csdn.net/tzh476/article/details/52644271删除之前的库，创建一个新的数据库，使用utf8mb64 之前默认创建的都是latin1不一样要删除之前的库，修改数据库的属性即可 mysql 长度的问题django.db.utils.InternalError: (1071, ‘Specified key was too long; max key length is 767 bytes’)https://blog.csdn.net/ljfphp/article/details/80406907https://www.orcode.com/question/407126_k280b8.html 解决方法1: 升级Mysql5.6–>>Mysql5.7centos7 下 对mysql的操作 https://blog.csdn.net/xufengzhu/article/details/81110982https://blog.51cto.com/lisea/1941616 解决方法2 : 先使用utf8格式 django migrate的问题出现下面这个问题，基本上就是你的model设置错误了。有些字段类型需要固定的属性如integerField字段需要default这个选项，添加完之后就Ok了 Please select a fix: 1) Provide a one-off default now (will be set on all existing rows with a null value for this column) 2) Quit, and let me add a default in models.p","link":"/posts/7f55f388/"},{"title":"django 用户","text":"django用户django为开发者提供了三种不同的用户形式，一种是自带的用户模型(User),另外两种是可以自定义的用户模型，分别是(AbstractUser)(AbstractBaseUser),他们的继承关系分别是 User 继承子AbstractUser 继承自AbstractBaseUser django自带的用户模型使用django自带的用户模型(快速实现)，该模型提供了一些开发过程中会经常使用到的参数，比如用户级别，名字，邮箱，密码等等。我们可以在$\\color{red}{from django.contrib.auth.models import User}$中查看User的使用 class User(AbstractUser): \"\"\" Users within the Django authentication system are represented by this model. Username and password are required. Other fields are optional. \"\"\" class Meta(AbstractUser.Meta): swappable = 'AUTH_USER_MODEL' 自定义User Model自定义Usermodel需要注意的是，$\\color{red}{需要在setting.py中添加AUTH_USER_MODEL}$ ，由于django寻找用户的方式是在setting.py中寻找这个标示，所以在我们自定义的时候需要添加这个内容 # pro/setting.pyfrom app.model import .AUTH_USER_MODEL=\"app.modelname\" 其他需要注意的地方，请看文章底部注意栏 方法一：扩展AbstractUser如果你觉得django自带的用户不能满足你所需要的字段，需要额外添加字段的话，你可以使用AbstractUser # pro/app/models.pyfrom django.contrib.auth.models import AbstractUserfrom django.db import modelsclass NewUser(AbstractUser): new_field = models.CharField(max_length=100)# pro/setting.pyAUTH_USER_MODEL=\"app.modelname\" 方法二：扩展AbstractBaseUserAbstractBaseUser中只含有3个field: password, last_login和is_active. 如果你对django user model默认的first_name, last_name不满意, 或者只想保留默认的密码储存方式, 则可以选择这一方式 自定义形式如AbstarctUser一样 使用AbstractBaseUser时，虽然他提供了User最核心的实现，比如password，但是我们依旧需要添加一些必须定义的关键字段和方法 USERNAME_FIELD，用户名称字段，必须设置，且 uniqe=True class UserProfile(AbstractBaseUser): author = models.CharField(max_length=40,unique=True) USERNAME_FIELD = 'author' REQUIRED_FIELDS，当通过createsuperuser管理命令创建一个用户时，用于提示一个字段名称列表,不能包含USERNAME_FIELD以及password字段 # pro/models.pyclass UserProfile(AbstractBaseUser) date_of_birth = models.DateField() height = models.FloatField() REQUIRED_FIELDS=['date_of_birth','height'] is_active 必须定义。 一个布尔属性，标识用户是否是 “active” 的。AbstractBaseUser默认为 Ture get_full_name()必须定义。 long格式的用户标识。 get_short_name()必须定义。 short格式的用户标识。 可用方法get_username()返回 USERNAME_FIELD 的值。 is_anonymous()一直返回 False。用来区分 AnonymousUser。 is_authenticated()一直返回 Ture。用来告诉用户已被认证。 set_password(raw_password)设置密码。按照给定的原始字符串设置用户的密码，taking care of the password hashing。 不保存 AbstractBaseUser 对象。如果没有给定密码，密码就会被设置成不使用，同用set_unusable_password()。 check_password(raw_password)检查密码是否正确。 给定的密码正确返回 True。 set_unusable_password()设置user无密码。 不同于密码为空，如果使用 check_password()，则不会返回True。不保存AbstractBaseUser 对象。 has_usable_password()如果设置了set_unusable_password()，返回False。 get_session_auth_hash()返回密码字段的HMAC。 Used for Session invalidation on password change. ⚠️注意1.在创建任何迁移或者第一次运行 manager.py migrate 前设置 AUTH_USER_MODEL。设置AUTH_USER_MODEL对你的数据库结构有很大的影响。它改变了一些会使用到的表格，并且会影响到一些外键和多对多关系的构造。在你有表格被创建后更改此设置是不被 makemigrations 支持的，并且会导致你需要手动修改数据库结构，从旧用户表中导出数据，可能重新应用一些迁移。2.由于Django的可交换模型的动态依赖特性的局限，你必须确保 AUTH_USER_MODEL 引用的模型在所属app中第一个迁移文件中被创建（通常命名为 0001_initial），否则你会碰到错误(The easiest way to construct a compliant custom User model is to inherit fromAbstractBaseUser. AbstractBaseUser provides the core implementation of a Usermodel, including hashed passwords and tokenized password resets. You must then provide some key implementation details:) 引用User如果你选择了自定义用户类型，那么当你在view.py中尝试使用外键引用他的时候，你会出现错误，你应该使用$\\color{red}{django.contrib.auth.get_user_model来引用模型} def get_user_model(): \"\"\" Return the User model that is active in this project. \"\"\" try: return django_apps.get_model(settings.AUTH_USER_MODEL, require_ready=False) except ValueError: raise ImproperlyConfigured(\"AUTH_USER_MODEL must be of the form 'app_label.model_name'\") except LookupError: raise ImproperlyConfigured( \"AUTH_USER_MODEL refers to model '%s' that has not been installed\" % settings.AUTH_USER_MODEL 同样的，他会根据setting中的AUTH_USER_MODEL来识别当前用户 from django.contrib.auth import get_user_modelUser = get_user_model 指定用户 # pro/app/models.pyclass UserProfile(models.Model): author = models.ForeignKey(setting.AUTH_USER_MODEL) https://www.cnblogs.com/huchong/p/9804635.html#_label0https://blog.csdn.net/qq_37049050/article/details/79211059","link":"/posts/f736b80/"},{"title":"docker基础-1","text":"use docker docker概念 镜像(Image)面向docker引擎的只读模版，包含了文件系统 容器(Container)沙箱，利用容器来运行和隔离应用，容器与容器之间是相互隔离、互不可见的镜像自身是只读的。容器从镜像启动的时候，Docker会在镜像的最上层创建一个可写层。镜像本身将保持不变。 仓库(Repository)存放镜像的地方，类似于代码仓库github gitee等等 安装# centos7安装yum install docker -y # 查看版本docker --versionDocker version 19.03.1, build 74b1e89 镜像指令获取镜像# 安装Ubuntu:latest镜像[root@CodeSheep ~]# docker pull ubuntuUsing default tag: latestlatest: Pulling from library/ubuntu5c939e3a4d10: Downloading 8.608MB/26.69MBc63719cdbe7a: Download complete19a861ea6baf: Download complete651c9d2d6c4f: Downloadan zhuang # 安装Ubuntu:14.04镜像docker pull ubuntu:14.04# 从社区安装ubuntu镜像docker pull dl.dockerpool.com:5000/ubuntu 运行镜像docker run -t -i ubuntu /bin/bash 查看镜像信息# 列出本地主机上所有镜像root:~# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/ubuntu latest ccc6e87d482b 6 days ago 64.2 MB# 添加新的镜像标签root:～# docker tag docker.io/ubuntu:latest docker-ubuntu-version:v2root:~# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker-ubuntu-version v2 ccc6e87d482b 6 days ago 64.2 MBdocker.io/ubuntu latest ccc6e87d482b 6 days ago 64.2 MBdocker.io/ubuntu 14.04 6e4f1fe62ff1 4 weeks ago 197 MB# 查看镜像相信信息docker inspect ccc6e87d482b docker imspect ccc REPOSITORY表示镜像来自于哪个仓库TAG 标签信息，版本信息IMAMGE ID 镜像的ID号码，唯一CREATED 创建时间SIZE 镜像大小 搜寻镜像docker search mysql# --automated=false 仅显示自动创建的镜像# --no-trunc=false 输出信息不截断显示# -s --starts=0 指定仅显示评价为指定星级以上的镜像 删除镜像docker rmi IMAGE[IMAGE...]# IMAGE...可以是标签或者ID# docker rmi -f IMAGE[IMAGE...] 强制删除 当前镜像有被使用于某一个容器的时候，使用docker rmi IMAGE 会出现报错的内容,可以进行强制的删除，但这样的做法并不建议，可以先删除依赖于该镜像的容器，然后再删除该镜像 创建镜像 基于已有镜像的容器创建docker commit [OPTIONS] CONTAINER [RSPOSITORY[:TAG]]# -a; --author=\"\" 作者信息# -m; --message=\"\" 提交信息# -p; --pause=true 提交时暂停容器运行 创建流程# pull 一个新的image docker pull ubuntu# 改变ubuntu 使其与原来image不同docker run -it ccc6e87d482b /bin/bashecho \"update file \" > testexit# 返回前记住当前容器的名字，一般都是主机名# 提交当前容器为新的镜像文件docker commit -m \"update - add a file in ubuntu \" -a \"hzj\" dc758c368fda test# 查看当前镜像列表root:~# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest latest 41f1d7eba8f3 10 seconds ago 64.2 MBdocker.io/ubuntu latest ccc6e87d482b 6 days ago 64.2 MB 基于本地模版导入# 下载模版压缩包wget xx# 根据压缩包导入成镜像cat ubuntu-14.04.tar.gz | docker import - ubuntu:14.04 # 保存镜像到本地文件docker save -o ubuntu_latest.tar ubuntu:latest# 载入镜像docker load --input ubuntu_latest.tardocker load < ubuntu_latest.tar 基于Dockerfile创建 容器创建容器与启动使用create创建容器后，容器是处于停止状态的，可以使用start开启 # 创建容器docker create -it ubuntu:test # 开启容器docker start ID# 重新开启容器docker restart ID 新建并启动容器docker run -i -t ubuntu:latest /bin/bash# -t 给docker分一个伪终端 # -i 提供交互模式 exit后容器处于终止状态 守护状态运行正常情况下，退出容器后，容器处于终止状态。使用-d可以在后台运行容器 docker run -d ubuntu:latest /bin/bash -c \"while true;do echo helloworld > xx.txt;sleep 1;done\" 终止容器使用stop终止容器的时候，会先发送一个SIGTERM信号，等待10s后发送SIGKILL信号终止容器kill 会直接发送SIGKILL终止容器 # 终止容器docker stop -t xxx IDdocker stop --time xxx IDdocker kill ID 进入容器 attach 命令attach可以进入-d开启的后台运行中的容器,但是多个窗口同时attach到同一个容器的时候，所有窗口会同步显示，当某个窗口命令阻塞的时候，其他窗口也无法执行操作了docker attach ID exec 命令通常使用这个docker exec -it ID /bin/bash 删除容器删除终止状态下的容器 docker rm [OPTIONS] CONTAINER [CONTAINER...]# -f --force=false 终止并删除一个正在运行的容器# -l --link=false 删除容器的连接，但保留容器# -v --volumes=false 删除容器挂载的数据卷 导入与导出容器# 导入docker export ID > xx.tar# 导出cat xx.tar | docker import - test/ubuntu:v1 查看容器# 查看所有容器root:~# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7945b6135dda ubuntu \"echo '“hello world'\" 5 seconds ago Exited (0) 4 seconds ago silly_kirch# 查看所有终止容器IDroot:~# docker ps -a -q225f9b6d5fc2674c77f3b1eadc758c368fda7945b6135dda2ebd811581a6 status 状态表示是否在后台运行，up表示在后台运行 Exited表示终止 数据管理数据卷是一个可提供使用的特殊目录，他绕过文件系统，可以提供很多有用的内容 数据卷可以在容器之间共享和重复使用 对数据卷的修改会立马生效 对数据卷的更新，不会影响镜像 卷会一直存在 知道没有容器使用 创建数据卷错误合集 错误1没有开启docker服务 Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running # 检测root:~# systemctl status docker* docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled) Active: inactive (dead) Docs: http://docs.docker.com# 开启服务systemctl start docker 错误2使用当前镜像的容器正在运行 root:~# docker rmi ccc6e87d482Error response from daemon: conflict: unable to delete ccc6e87d482b (must be forced) - image is referenced in multiple repositories# 强制删除docker rmi -f ccc6e87d482# 不建议强制删除，应当先删除所有依赖于该镜像的容器，再删除镜像","link":"/posts/3ee8c444/"},{"title":"数据库总结","text":"登陆数据库ssh 10.0.6.55mysql -uroot -p>123456 mysql 基本操作语句数据库语句操作 创建一个名为 tc 的数据库 create database tc;查看有哪些数据库 show databases; 查看数据库的创建细节 show create database tc; 创建一个使用gbk字符集的数据库 create database tc set gck;修改字符集 alter database tc character set utf8;删除创建的某个数据库 drop database tc; 表结构 use tc; # 切换数据库create table employee(_id int,name varchar(100),gender varchar(20),birthday date,entry_day date,salary flot(8,2),resume text); # 创建员工信息表show tables; # 查看当前数据库中的所有表show create table employee; # 查看表的创建心结alter table employee add image blob; # 在员工表上添加image列alter table employee modify job varchar(60); # 修改员工表中的job列，使其长度我饿60alter table employee drop image; 删除image列rename table employee to user; 表名字修改为useralter table user character set gbk; 修改表的字符集为utf-8 查看表 # 创建一个学生表create table student(id int primary key auto_increment,name varchar(20) unique not null ,chinese float,english float,math float);# 往学生表中添加一些信息insert into student(name,chinese,english,math) values ('wangba',93,22,77)insert into student (name,chinese,english,math) values('lisi',80,90,29);insert into student (name,chinese,english,math) values('wangwu',55,99,98);insert into student (name,chinese,english,math) values('zhaoliu',99,30,57);insert into student (name,chinese,english,math) values('zhouqi',78,22,77);#查询所有学生信息select * from user# 查询学生员工的姓名和对应的英语成绩select name,english from student# 过滤表中的重复数据select distinct english from student # 在所有学生分数上加10分的特长分 数据库可视化 navicatnavicat连接远程服务器的几种方式 直接连接数据库 Connection Name : hzj #随便写 主要记录的上这条连接的别名Host 10.0.6.55 # 远程服务器ipPort 3306 # 端口User Name root # 数据库账号Passwd #数据库密码 先登陆ssh 之后在连接本地的数据库 先连接ssh Host # 远程Port 22User Name # 连接数据库的用户名Authentication Method # 验证方法Private key # id_rsaPassphrase # 验证短密 选择密钥后自动生成 再连接数据库 Connection Name : hzj #随便写 主要记录的上这条连接的别名Host localhost # 远程服务器ipPort 3306 # 端口User Name root # 数据库账号Passwd #数据库密码 出现的错误 2013 - Lost connection to MySQL server at 'reading initial communication packet', system error: 0 \"Internal error/check (Not system error)\" 解决办法https://www.jb51.net/article/51480.htm","link":"/posts/3086330/"},{"title":"nginx基础","text":"learn nginx nginxnginx基本概念nginx是什么反向代理正向代理负载均衡动静分离 nginx安装 直接安装yum install nginx # 查看版本nginx -v 编译安装安装gcc、make、wget、g++这些软件 创建一个临时目录下载安装所需要的内容cd /tmpmkdir gen_nginx 下载安装openssl,主要用于ssl模块加密，支持htps wget https://www.openssl.org/source/openssl-1.0.2s.tar.gz 下载pcre来实现对地址重定向，地址重写功能和localtion指令以及正则表达式的支持wget https://ftp.pcre.org/pub/pcre/pcre-8.43.tar.gz 下载zlib gzip压缩模块wget https://zlib.net/zlib-1.2.11.tar.gz 下载nginxwget http://nginx.org/download/nginx-1.17.1.tar.gz 解压所有的文件ls *.tar.gz | xargs -n1 tar xzvf 使用configure编译安装具体的编译内容可以自己决定./configure \\ --with-openssl=../openssl-1.0.2s \\ --with-pcre=../pcre-8.43 \\ --with-zlib=../zlib-1.2.11 \\ --with-pcre-jit --user=admin \\ --prefix=/home/admin/nginx \\ --with-http_ssl_module \\ --with-http_v2_module 编译安装make && make install 分配权限sudo chown root nginx sudo chmod u+s nginx 正向代理局域网通过代理服务器访问Internet上的内容，这个过程叫做正向代理 反向代理客户端发送请求到反向代理服务器，由反向代理服务器选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP的地址 负载均衡通过反向代理服务器，将多个请求平均分配到目标服务器上 动静分离动态资源与动态资源分开放，由反向代理服务器来根据请求内容，将请求转发到指定目标服务器 nginx常用命令首先要进入到Nginx的目录下,如果是编译安装的话，nginx的目录应该在/usr/local/sbin/nginx中，如果是直接安装下载的话，nginx的目录应该在/usr/sbin/nginx cd /usr/sbin/nginx# 查看Nginx进程ps -ef | grep nginx# 查看nginx的版本号./nginx -v# 强制关闭Nginx./nginx -s stop# 退出nginx./nginx -s quit# 启动nginx./nginx# 重新加载nginx./nginx -s reload nginx配置文件如果是直接安装，则配置文件在/etc/nginx/nginx.conf，如果是编译安装，则配置文件在/usr/local/nginx中查找nginx配置文件 find / | grep nginx.conf \bnginx配置文件的组成主要分成3大块内容 第一部分: 全局模块 user nginx; # 用户 用户组 ; 一般只有类unix系统有,windows不需要worker_processes auto; # 工作进程，一般配置为cpu核心数的2倍，值越大，可以支持的并发处理量越多error_log /var/log/nginx/error.log; # 错误日志的配置路径pid /run/nginx.pid; # 进程ID存放路径include /usr/share/nginx/modules/*.conf; 第二部分: events模块主要影响nginx服务器与用户的网络连接 events { # 使用epoll的I/O 模型；epoll 使用于Linux内核2.6版本及以后的系统 use epoll; # 每一个工作进程的最大连接数量； 理论上而言每一台nginx服务器的最大连接数为： worker_processes*worker_connections worker_connections 1024; # 超时时间 keepalive_timeout 60 # 客户端请求头部的缓冲区大小，客户端请求一般会小于一页； 可以根据你的系统的分页大小来设定， 命令 getconf PAGESIZE 可以获得当前系统的分页大小（一般4K） client_header_buffer_size 4k; # 为打开的文件指定缓存，默认是不启用； max指定缓存数量，建议和打开文件数一致；inactive是指经过这个时间后还没有被请求过则清除该文件的缓存。 open_file_cache max=65535 inactive=60s; # 多久会检查一次缓存的有效信息 open_file_cache_valid 80s; # 如果在指定的参数open_file_cache的属性inactive设置的值之内，没有被访问这么多次（open_file_cache_min_uses），则清除缓存 # 则这里指的是 60s内都没有被访问过一次则清除 的意思 open_file_cache_min_uses 1;} 第三部分1: http模块http全局配置的指令包括文件引入、MIME-TYPE定义、日志自定义、连接超时时间、单链请求数上限等。 http { # 日志发送 # 日志格式 其中main是日志文件的名字 # -------------------------------------------------------------------------- # # 日志格式设置： # $remote_addr、$http_x_forwarded_for 可以获得客户端ip地址 # $remote_user 可以获得客户端用户名 # $time_local 记录访问的时区以及时间 # $request 请求的url与http协议 # $status 响应状态成功为200 # $body_bytes_sent 发送给客户端主体内容大小 # $http_referer 记录从哪个页面过来的请求 # $http_user_agent 客户端浏览器信息 # # 注意事项： # 通常web服务器(我们的tomcat)放在反向代理(nginx)的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。 # 反向代理服务器(nginx)在转发请求的http头信息中，可以增加$http_x_forwarded_for信息，记录原有客户端的IP地址和原来客户端的请求的服务器地址。 # -------------------------------------------------------------------------- # log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; # 指定日志文件存储地址 access_log /var/log/nginx/access.log main; # sendfile 指定 nginx 是否调用sendfile 函数（零拷贝 方式）来输出文件； # 对于一般常见应用，必须设为on。 # 如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # 负载均衡 START>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> # upstream 指令定义的节点可以被proxy_pass指令引用；二者结合用来反向代理+负载均衡配置 # 【内置策略】：轮询、加权轮询、ip_hash、最少连接 默认编译进了nginx # 【扩展策略】：fair、通用hash、一致性hash 默认没有编译进nginx #-----------------------------------------------------------------------------------------------# # 【1】默认是轮询；如果后端服务器down掉，能自动剔除。 # upstream bakend { # server 192.168.75.130:8080; # server 192.168.75.132:8080; # server 192.168.75.134:8080; # } # #【2】权重轮询(加权轮询)：这样配置后，如果总共请求了3次，则前面两次请求到130，后面一次请求到132 # upstream bakend { # server 192.168.75.130:8080 weight=2; # server 192.168.75.132:8080 weight=1; # } # #【3】ip_hash：这种配置会使得每个请求按访问者的ip的hash结果分配，这样每个访客固定访问一个后端服务器，这样也可以解决session的问题。 # upstream bakend { # ip_hash; # server 192.168.75.130:8080; # server 192.168.75.132:8080; # } # #【4】最少连接：将请求分配给连接数最少的服务器。Nginx会统计哪些服务器的连接数最少。 # upstream bakend { # least_conn; # server 192.168.75.130:8080; # server 192.168.75.132:8080; # } # # #【5】fair策略(需要安装nginx的第三方模块fair)：按后端服务器的响应时间来分配请求，响应时间短的优先分配。 # upstream bakend { # fair; # server 192.168.75.130:8080; # server 192.168.75.132:8080; # } # #【6】url_hash策略（也是第三方策略）：按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 # 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method指定hash算法 # upstream bakend { # server 192.168.75.130:8080; # server 192.168.75.132:8080; # hash $request_uri; # hash_method crc32; # } # #【7】其他设置，主要是设备的状态设置 # upstream bakend{ # ip_hash; # server 127.0.0.1:9090 down; # down 表示该机器处于下线状态不可用 # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # # # max_fails 默认为1； 最大请求失败的次数，结合fail_timeout使用； # # 以下配置表示 192.168.0.100:8080在处理请求失败3次后，将在15s内不会受到任何请求了 # # fail_timeout 默认为10秒。某台Server达到max_fails次失败请求后，在fail_timeout期间内，nginx会认为这台Server暂时不可用，不会将请求分配给它。 # server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15; # server 192.168.0.101:8080 weight=3; # server 192.168.0.102:8080 weight=1; # # 限制分配给某台Server处理的最大连接数量，超过这个数量，将不会分配新的连接给它。默认为0，表示不限制。注意：1.5.9之后的版本才有这个配置 # server 192.168.0.103:8080 max_conns=1000; # server 127.0.0.1:7070 backup; # 备份机；其他机器都不可用时，这台机器就上场了 # server example.com my_dns_resolve; # 指定域名解析器；my_dns_resolve需要在http节点配置resolver节点如：resolver 10.0.0.1; # } # # # #负载均衡 END","link":"/posts/21215442/"},{"title":"nginx配置实例","text":"learn nginx nginx配置实例nginx配置实例–反向代理配置内容1台客户机、1台Nginx代理服务器(10.0.5.233)、一个网页效果: 客户机在浏览器中输入www.123.com 由nginx代理进行转发到我们自己的网页上 # 首先 在客户机端做域名与ip的映射echo \"10.0.5.255 www.123.com\" >> /etc/hosts# 配置nginx文件server { listen 80; server_name 10.0.5.233; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { root html; proxy_pass http://127.0.0.1:8001; index index.html index.htm; } }","link":"/posts/12ec35da/"},{"title":"swagger-ui使用","text":"SwaggerUi使用django搭建swagger-uidjango2.0之前使用django-rest-swaggerdjango2.0之后使用drf-yasg这里主要记录一些使用drf-yasg安装的过程 Qucik-Start# 安装yum install drf-yasg# setting设置INSTALLED_APPS = [ ... ' drf_yasg '， ... ]# urls.py设置...from rest_framework import permissionsfrom drf_yasg.views import get_schema_viewfrom drf_yasg import openapi...schema_view = get_schema_view( openapi.Info( title=\"Snippets API\", default_version='v1', description=\"Test description\", terms_of_service=\"https://www.google.com/policies/terms/\", contact=openapi.Contact(email=\"contact@snippets.local\"), license=openapi.License(name=\"BSD License\"), ), public=True, permission_classes=(permissions.AllowAny,),)urlpatterns = [ url(r'^swagger(?P\\.json|\\.yaml)$', schema_view.without_ui(cache_timeout=0), name='schema-json'), url(r'^swagger/$', schema_view.with_ui('swagger', cache_timeout=0), name='schema-swagger-ui'), url(r'^redoc/$', schema_view.with_ui('redoc', cache_timeout=0), name='schema-redoc'), ...] 生成地址 A JSON view of your API specification at /swagger.json A YAML view of your API specification at /swagger.yaml A swagger-ui view of your API specification at /swagger/ A ReDoc view of your API specification at /redoc/ 网址官方网址https://swagger.io/tools/swagger-ui/drf-yasg gitbook文档https://drf-yasg.readthedocs.io/en/stable/drf-yasg gitbook地址https://github.com/axnsan12/drf-yasg","link":"/posts/a2d15b23/"},{"title":"git基础","text":"流程工作区(我们当前的文件夹)暂存区(add 提交之后文件所存在的位置)仓库(commit 之后将暂存区提交到的地方) 首先是init初始化我们的工作区，这时候当前存在.git文件的就是我们的工作区，当前路径为我们的根目录在工作区创建一个新的文件test.txt，git add 之后文件上传到暂存区，我们可以用git status 会记录当前暂存区的操作git diff可以比较工作区和暂存区的差异，当然这里是没有任何差异的，因为他们是同样的两份文件修改test.txt 之后再去git diff 你会发现他们之间存在着差异，因为这个时候他们已经不是同样两份文件了假如你再次 使用Git add . 再用git diff 时又没有差异了 安装# ubuntusudo apt-get install git# centos yum install git -y# mac brew install git 全局声明用户git config –global user.name “your name”git config –global user.email “xxx@xxx.com“ 声明仓库 必须mkdir testcd testgit init 会生成一个.git的仓库管理文件,如果你使用了zsh的主题，你会发现多了一个master 这是你当前的分支，也仅仅只有这个分支 git add . —> 将文件放到暂存区git commit —> 将文件提交到当前分支 master 声明仓库内容 不一定既然是作为开源共享的项目或者说是线上多平台交互的私库，那一定需要一个专门解释这个仓库是做什么的文件—> README.mdgit add README.md 提交并提供信息将文件提交到仓库 git commit -m \"your message\" 添加文件git add xxx.txtgit add . #添加当前文件夹所有文件 ``` ## 查看状态git status```bash# 添加文件后的状态 alpaca@hzj  ~/hzj/tu   master ●  git add README.md alpaca@hzj  ~/hzj/tu   master ✚  git statusOn branch masterChanges to be committed: (use \"git reset HEAD ...\" to unstage) modified: README.md# 提交 commit 后的状态 alpaca@hzj  ~/hzj/tu   master ✚  git commit -m \"update some file\"[master ff070f9] update some file 1 file changed, 2 insertions(+) alpaca@hzj  ~/hzj/tu   master # 状态 alpaca@hzj  ~/hzj/tu   master  git statusOn branch masternothing to commit, working tree clean 查看日志当你每一次使用commit 将文件提交到当前分支的时候，记录下每一个步骤查看使用 # 查看日志git logcommit bb3c0e3a1e850af0c70d3ce3a22995eaae177e82 (HEAD -> master)Author: alpaca Date: Thu Nov 21 11:46:24 2019 +0800 updatecommit ff070f92dee18935752e5a98b2310d275e1191b6Author: alpaca Date: Thu Nov 21 11:42:58 2019 +0800 update some filecommit 230660d585a95b90e3c6176ad21664c1b10f746aAuthor: alpaca Date: Thu Nov 21 10:37:04 2019 +0800 update some markdown file# 仅查看版本号git log --pretty=oneline# 指定版本号 如果你装了zsh 按tab就会出来commit_idgit log commit_id 由随机码(版本号) + 作者 + 日期 + commit_message 组成 回退操作版本回退，首先我们要知道一个事情 git log 只会记录下commit的过程，也就是上传到当前分支的过程，因此回退操作他并不会记录，但是他会重载之前的log状态，也就是当你一共提交了3次内容，你回退到了第三次提交前的版本。那么你的第三次提交log并不会被记录 # 回退add操作 checkout -- file 暂存区 --> 工作区git checkout -- file# 回退connit操作上 仓库 ---> 暂存区git reset --hard commit_id # 查看回退日志git reflog 提交远程仓库之前的操作都是本地的，包括最后一步git commit 也只是提交到了本地的仓库。为了更好的保存内容，我们已经引入云仓库或者说托管我们的项目 # 添加远程仓库地址git remote add origin https://gitee.com/Alpaca-H/how-to-learn-git.git # 提交当前分支到远程仓库git push origin master# 建议第一次使用push -u# Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来 在以后的推送或者拉取时就可以简化命令。 从远程仓库下载git clone https://gitee.com/Alpaca-H/how-to-learn-git.git 第一次提交的存在的问题 ! [rejected] master -> master (fetch first)error: failed to push some refs to 'https://gitee.com/Alpaca-H/how-to-learn-git.git'hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 如果你是在 码云上创建的项目，它本身就存在两个README文件，也就是说仓库中本身就存在文件了，这时候你删掉这两个也没用，(github上好像没这个问题)我们需要同步远程仓库，也就是拉取下来并用–allow-unrelated-histories 合并 git pull origin master --allow-unrelated-histories git commit -m \"xxx\" #重新提交git push origin master 从远程仓库下载 – 指定分支git clone -b hzj_branch https://gitee.com/Alpaca-H/how-to-learn-git.git 分支管理# 创建分支 git branch hzj# 切换分支git checkout hzj# 创建并切换分支git checkout -b hzj# 查看当前分支git branch 记住上面的只是分支管理，他只是在你的本地有了分支，在你没有push之前所有的一切都是本地操作 分支管理2# 切换到新的分支 git swicth -c dev# 切换到已有分支git swicth dev # 添加文件echo \"我是hzj分支\" > README2.mdgit add README2.mdgit commit -m \"update hzj\"git push -u origin hzj # 提交到hzj的分支 合并分支进入master git merge hzj # 合并在本地仓库的文件 删除分支git branch -d hzj 分支同步主干# 切换到master分支git checkout master # 下拉mastergit pull origin master# 切换分支git checkout hzj# 同步分支git merge master 主干同步分支(慎用)# 切换到主分支git checkout master# 同步分支git merge hzj# 提交git push origin master inventory操作 拉取项目git clone https://gitlab.s.upyun.com/infrastructure/inventory.gigit clone https://gitlab.s.upyun.com/infrastructure/inventory.git 查看当前分支git branch 切换分支git checkout hzj 修改内容… 上传git commit -am “update”git push到web端创建合并请求 更新首先切换到master，拉取最新git pull切换次分支 git checkout hzj合并更新分支到hzj分支 git merge origin hzj 发消息给有master权限的人，交由master来合并","link":"/posts/9891ebc8/"},{"title":"1-vue-cli目录结构详解","text":"vue-cli目录结构详解 vue-cli目录结构详解├─build // 保存一些webpack的初始化配置,项目构建│ ├─build.js // 生产环境构建│ ├─check-version.js // 检查npm、node版本│ ├─vue-loader.conf.js // webpack loader配置│ ├─webpack.base.conf.js// webpack基础配置│ ├─webpack.dev.conf.js // 开发环境配置，构建本地开发服务器│ ├─webpack.prod.conf.js// 生产环境的配置│├─config // config文件夹保存一些项目初始化的配置│ ├─dev.env.js // 开发环境的配置│ ├─index.js // 项目一些配置变量│ ├─prod.env.js // 生产环境的配置│├─dist // 打包后的项目├─node_modules // 依赖包│├─src // 源码目录│ ├─assets // 静态文件目录│ ├─components // 组件文件│ ├─router // 路由│ ├─App.vue // 是项目入口文件│ ├─main.js // 是项目的核心文件，入口├─static // 静态资源目录 ├─.babelrc // Babel的配置文件├─.editorconfig // 代码规范配置文件├─.gitignore // git忽略配置文件├─.postcssrc.js // postcss插件配置文件├─index.html // 页面入口文件├─package-lock.json // 项目包管控文件├─package.json // 项目配置└─README.md // 项目说明书","link":"/posts/3ffae61b/"},{"title":"element-ui使用指南","text":"element-ui使用指南 基本表单 export default { data() { return { ruleForm: { name: '', region: '', date1: '', date2: '', delivery: false, type: [], resource: '', desc: '' }, rules: { name: [ { required: true, message: '请输入活动名称', trigger: 'blur' }, { min: 3, max: 5, message: '长度在 3 到 5 个字符', trigger: 'blur' } ], region: [ { required: true, message: '请选择活动区域', trigger: 'change' } ], date1: [ { type: 'date', required: true, message: '请选择日期', trigger: 'change' } ], date2: [ { type: 'date', required: true, message: '请选择时间', trigger: 'change' } ], type: [ { type: 'array', required: true, message: '请至少选择一个活动性质', trigger: 'change' } ], resource: [ { required: true, message: '请选择活动资源', trigger: 'change' } ], desc: [ { required: true, message: '请填写活动形式', trigger: 'blur' } ] } }; }, methods: { submitForm(formName) { this.$refs[formName].validate((valid) => { if (valid) { alert('submit!'); } else { console.log('error submit!!'); return false; } }); }, resetForm(formName) { this.$refs[formName].resetFields(); } } }","link":"/posts/aefec9df/"},{"title":"vue-element-admin","text":"vue-element-admin框架学习目录结构 地址基本模版https://github.com/PanJiaChen/vue-admin-template基本模版-展示地址https://panjiachen.github.io/vue-admin-template/#/dashboard实例项目https://github.com/PanJiaChen/vue-element-admin/blob/master/README.zh-CN.md实例项目-展示地址https://panjiachen.github.io/vue-element-admin/#/dashboard","link":"/posts/a1c58685/"},{"title":"vuejs基础2","text":"vuejs基础2 https://cn.vuejs.org线上:https://jsfiddle.net/chrisvfritz/50wL7mdz/ 添加环境通过引入的方式引入vue id=\"app\" --- > //el:#appv-bind:title = \"message\" --- > //绑定标签属性(指令){{message}} ---- > data:{ message:\"hello vue!\"}var app2 = new Vue({}) ---> //申明vue的对象//v-if=true ----> //条件判断//v-if:\"seen\" new Vue({ el:'#app',data:{ seen:true} })//条件循环 {{ todo.text }} var app4 = new Vue({ el:\"#app-4\", data:{ todo:[ {text:'xxx'}, {text:'xxx'}, {text:'xxx'}, ] }})app4.todo.push({text:'yyy'}) //添加内容// v-on:click = \"funcname\" 自定义点击方法 {{message}} 反转消息var app5 = new Vue({ el:\"#app-5\", data:{ message: 'hello,vue.js!' } methods:{ reverseMessage:function () { this.message = this.message.split('').reveser().join('') } } }})// 表单双向绑定 {{message}} new app6 = new Vue({ el:\"#app6\", data:{ message: \"hello world\" }}) vue的生命周期每个 Vue 实例在被创建时都要经过一系列的初始化过程——例如，需要设置数据监听、编译模板、将实例挂载到 DOM 并在数据变化时更新 DOM等，但为了让开发者能更好的控制vue的整个流程，以及在特定时候添加特定功能，这时候我们必须要了解的是vue的生命周期 先了解一下dom的解析流程浏览器渲染引擎工作流程都差不多，大致分为5步，创建DOM树——创建StyleRules——创建Render树——布局Layout——绘制Painting1.用HTML分析器，分析分析HTML元素，构建一颗DOM树(标记化和树构建)2.用CSS分析器，分析CSS文件和元素上的inline样式，生成页面的样式表。3.将DOM树和样式表，关联起来，构建一颗Render树(这一过程又称为Attachment)。每个DOM节点都有attach方法，接受样式信息，返回一个render对象(又名renderer)。这些render对象最终会被构建成一颗Render树。4.有了Render树，浏览器开始布局，为每个Render树上的节点确定一个在显示屏上出现的精确坐标。5.Render树和节点显示坐标都有了，就调用每个节点paint方法，把它们绘制出来。 DOM树的构建是文档加载完成开始的？构建DOM数是一个渐进过程，为达到更好用户体验，渲染引擎会尽快将内容显示在屏幕上。它不必等到整个HTML文档解析完毕之后才开始构建render数和布局。 Render树是DOM树和CSSOM树构建完毕才开始构建的吗？这三个过程在实际进行的时候又不是完全独立，而是会有交叉。会造成一边加载，一遍解析，一遍渲染的工作现象。 JS操作真实DOM的代价！用我们传统的开发模式，原生JS或JQ操作DOM时，浏览器会从构建DOM树开始从头到尾执行一遍流程。在一次操作中，我需要更新10个DOM节点，浏览器收到第一个DOM请求后并不知道还有9次更新操作，因此会马上执行流程，最终执行10次。例如，第一次计算完，紧接着下一个DOM更新请求，这个节点的坐标值就变了，前一次计算为无用功。计算DOM节点坐标值等都是白白浪费的性能。即使计算机硬件一直在迭代更新，操作DOM的代价仍旧是昂贵的，频繁操作还是会出现页面卡顿，影响用户体验。为什么需要虚拟DOM，它有什么好处?Web界面由DOM树(树的意思是数据结构)来构建，当其中一部分发生变化时，其实就是对应某个DOM节点发生了变化，虚拟DOM就是为了解决浏览器性能问题而被设计出来的。如前，若一次操作中有10次更新DOM的动作，虚拟DOM不会立即操作DOM，而是将这10次更新的diff内容保存到本地一个JS对象中，最终将这个JS对象一次性attch到DOM树上，再进行后续操作，避免大量无谓的计算量。所以，用JS对象模拟DOM节点的好处是，页面的更新可以先全部反映在JS对象(虚拟DOM)上，操作内存中的JS对象的速度显然要更快，等更新完成后，再将最终的JS对象映射成真实的DOM，交由浏览器去绘制。 https://www.jianshu.com/p/af0b398602bc 首先我们先来了解一下生命周期的几个阶段1.beforeCreate2.created 3.beforeMount4.mount 5.beforeUpdate6.update 7.beforeDestroy8.destroyed 这个生命周期的过程分为三个阶段，初始化 运行中 销毁。 Document {{message}} //vuetest.jsnew Vue({ el:\"#app1\", data:{ message:\"helloworld\" }, beforeCreate() { console.log(\"----------------------------\") console.log(\"xxx我是beforeCreate\") console.log(this.message+\" ,beforeCreate阶段输出了这条信息\") console.log(\"结束了，我输出了message的信息吗\") }, created() { console.log(\"----------------------------\") console.log(\"我是create\") console.log(this.message+\" ,created阶段输出了这条信息\") console.log(\"结束了，我输出了message的信息吗\") }, //在created阶段已经能够拿到具体的数据，也可以更改数据，且不会触发update函数 //但是如果有两个created函数，则后一个重叠前一个 created(){ console.log(\"----------------------------\") console.log(\"我是created2代\") this.message = this.message + \"!!!!!!!\" console.log(this.message) console.log(\"over\") }, //虚拟dom创建完成,已经存在数据以及识别到了el(即虚拟dom) //可以修改数据，但是已经是最后一次机会了，且不会触发update函数 beforeMount() { console.log(\"----------------------------\") console.log(\"我是beforeMount\") this.message = this.message + \"~~~\" console.log(this.message) console.log(\"over\") }, // 这里再次修改数据的话，会触发update函数 mounted() { console.log(\"--------------------\") console.log(\"Mounted\") //console.log(this.message+\"我触发了update函数，所有渲染的内容也变了\")) console.log(\"over\") }, //循环阶段必须触发才能进入，触发条件如修改数据，但是在Created和beforeMount两个阶段 //是不会触发beforeupdate这个阶段的 //不可以更改数据，否则死循环 beforeUpdate() { console.log(\"--------------------\") console.log('beforeUpdate:重新渲染之前触发') console.log('然后vue的虚拟dom机制会重新构建虚拟dom与上一次的虚拟dom树利用diff算法进行对比之后重新渲染') }, //这里不能更改数据，否则会陷入死循环 updated() { console.log(\"--------------------\") console.log('updated:数据已经更改完成，dom也重新render完成') }, beforeDestroy() { console.log('beforeDestory:销毁前执行（$destroy方法被调用的时候就会执行）,一般在这里善后:清除计时器、清除非指令绑定的事件等等...') }, destroyed() { console.log('destroyed:组件的数据绑定、监听...都去掉了,只剩下dom空壳，这里也可以善后') },}) 输出内容 这个生命周期的如图1.首先创建一个vue实例 new Vue() ,这时候他只是一个空的壳子，无法访问到数据和真实的dom。—-> beforeCreate。 创建完实例之后就会执行 beforeCreate,在 beforeCreate中一般不执行任何的操作 2.之后执行 created函数，这个时候已经加载了数据，但是没有创建虚拟dom 3.之后执行 beforeMount函数，这个时候会创建一个虚拟的dom ，同时也加载了数据，你也可以选择修改数据，而且在此之前修改的数据都不会触发update 4.之后执行mounted函数，这个时候如果你修改了数据则会触发update函数 5.update函数需要被触发 6.destroyed 销毁","link":"/posts/6412f439/"},{"title":"vue组件基础","text":"vue组件基础 // 组件.jsvue.component(‘xxx’,{ data:function(){ return { count: 0, message: “xxx” } }, template: '{{message}}'}) // html调用组件 //js new Vue({el: ‘#app’}) 组件复用 vue.component(“标签名”,{ }) data必须是一个方法，返回参数这与之前不同之前new Vue({ data:{ },}) 传递数据Vue.component(‘blog-post’, { props: [‘title’], template: ‘vue组件基础‘}) 组件中的父子级 Document {{text}} //父级动态 new Vue({ el:\"#app5\", data:{ text:\"我是父级的\" } }) //子级模版动态跳动 Vue.component('child',{ props:[\"text\"], template:\"我是子级，这是我调用来的{{text}}\" }) Vue.component('my-c',{ props:[\"text\"], template:\"{{text}}\" }); new Vue({ el:\"#app4\" }); 在组件中返回数据可以使用data 以及 props ，但是这两者是有区别的，data只能返回当前组件的值,而props能够返回父组件的值，以上都是props调用父组件的例子，其中组件中的模版所创建出来的内容被称为子组件，分为动态和静态两种 Vue.component('blog-post', { props: ['title'], template: '{{ title }}'}) 如上也是一种静态调用的方法,blog-post为父组件 h3为子组件 new Vue({ el: '#blog-post-demo', data: { posts: [ { id: 1, title: 'My journey with Vue' }, { id: 2, title: 'Blogging with Vue' }, { id: 3, title: 'Why Vue is so fun' } ] }}) 如上是data调用当前组件的内容 监听子组件事件全局注册Vue.component('component-a', { /* ... */ })Vue.component('component-b', { /* ... */ })Vue.component('component-c', { /* ... */ })new Vue({ el: '#app' }) 局部注册var ComponentA = { /* ... */ }var ComponentB = { /* ... */ }var ComponentC = { /* ... */ } new Vue({ el: '#app', components: { 'component-a': ComponentA, 'component-b': ComponentB }}) 组件之间只能越一级访问，不能跨多级，比如你想要在 B这个子组件中访问A这个子组件，则需要 var ComponentA = { /* ... */ }var ComponentB = { components: { 'component-a': ComponentA }, // ...} 在模块系统中局部注册如果你还在阅读，说明你使用了诸如 Babel 和 webpack 的模块系统。在这些情况下，我们推荐创建一个 components 目录，并将每个组件放置在其各自的文件中。 然后你需要在局部注册之前导入每个你想使用的组件。例如，在一个假设的 ComponentB.js 或 ComponentB.vue 文件中： import ComponentA from ‘./ComponentA’import ComponentC from ‘./ComponentC’ export default { components: { ComponentA, ComponentC }, // …}现在 ComponentA 和 ComponentC 都可以在 ComponentB 的模板中使用了。","link":"/posts/1fd63f28/"},{"title":"vue中的各类插件以及使用方法","text":"vue中的各类插件以及使用方法 vue中的各类插件以及使用方法在vue的使用过程中遇到了很多插件，有些插件只是提供了一部分很小的功能，占据不了太大的篇幅，因此收集到这里记录一下 qs插件qs插件是一个地址解析工具,主要是对于一串url地址进行序列化 # 安装npm install qs 使用import qs from 'qs';# 定义全局别名Vue.prototype.$qs = qs# 使用this.$http.post('/bb', this.$qs.stringify({ aa:2, bb:3 }) ) .then(function (response) { console.log(response.data); }) .catch(function (error) { console.log(error); });# 则请求地址是这样的aa=2&&bb=3 vuex插件作为vue中的状态管理插件 npm install vuex --save 使用import Vue from 'vue'import Vuex from 'vuex'Vue.use(Vuex) vue-route插件作为vue中的路由插件 # 安装npm install vue-router 使用import Vue from 'vue'import VueRouter from 'vue-router'Vue.use(VueRouter) vue-axios插件使用 错误vue eslint 限制无法使用console.log调试 Failed to compile../src/components/leftroute.vueModule Error (from ./node_modules/eslint-loader/index.js):error: Unexpected console statement (no-console) at src/components/leftroute.vue:31:11: 29 | this.$axios.get('http://localhost:3000/people') 30 | .then(function(response){> 31 | console.log(response); | ^ 32 | }) 33 | .catch(function(error){ 34 | console.log(error);error: Unexpected console statement (no-console) at src/components/leftroute.vue:34:11: 32 | }) 33 | .catch(function(error){> 34 | console.log(error); | ^ 35 | }); 36 | } 37 | }2 errors found. 解决方法 加入 \"no-console\" : [\"false\"] 或者把 node_modules/lib/rules/no-console.js 中的true改成faslehttps://blog.csdn.net/weixin_42476786/article/details/85132793https://blog.csdn.net/qq_40637612/article/details/8760788 mock.js 数据模拟在开发过程中，有很多的ajax请求，前后端分离开发你肯定遇到这样的问题，后台给你的接口文档，你需要在本地模拟数据返回，可能你也用到过我之前用的蠢方法，就是新建一个test.json文件，放入接口文档中写的返回示例，这么做有个很大的问题是不够灵活，而且还需要切换url，现在学会使用mock.js拦截ajax请求，更加方便的构造你需要的假数据","link":"/posts/d0806758/"},{"title":"vim快捷键","text":"vim快捷键VIM 是 Linux 系统上一款文本编辑器，它是操作 Linux 的一款利器。当前有很多优秀的 IDE 都支持安装 VIM 插件，原因就是使用它便捷，高效，很爽！主要记录了 VIM 的一些常用使用技巧，方便随时查阅学习 。 快捷键# 跳转到行首 esc->0 -> shift+i # 跳转到行尾 esc->shift+a 编辑 清空当前行，并进入编辑模式 cc 清空当前单词，并进入编辑模式 cw","link":"/posts/e47927c/"},{"title":"linux就该这么学","text":"Linux就该这么学yum软件仓库 yum简化rpm管理软件难度，yum能够根据用于的要求分析出所需软件包及其相关依赖，自动从服务器上下载软件包并安装到系统 |-----> 客户机yum仓库 ---->| ----> 客户机 |-----> 客户机 yum仓库的配置文件都必须要以.repo结尾并放在/etc/yum.repos.d/目录中 [rhel-media]:yum 源的名称,可自定义baseurl=file://media/cdrom : 提供方式包括 FTP(ftp://..) 、HTTP(http://) 、本地(file://)enabled = 1 : 设置次元是否可用，1 为可用 0 为禁用gpgcheck = 1 : 设置此源是否校验文件，1为校验 0 为不校验gpgkey = file:///media/cdrom/RPM-GPG-KET-redhat-release 若为校验请指定公钥文件地址 YUM仓库中的RPM软件包可以由红帽官方发布，也可以是第三方组织发布 # 命令yum repolist all # 列出所有仓库yum list all # 列出仓库中所有软件包# 以上列出的是线上的还是本地的yum info 软件包名称 # 查看软件包信息yum install 软件包名称 # 安装软件包yum reinstall 软件包名称 # 重新安装yum remove 软件包名称 # 删除软件包yum update 软件包名称 # 升级yum clean alla # 清楚所有仓库缓存yum check-update # 检查可更新的软件包yum grouplist # 查看系统已经安装的软件包组yum groupinstall 软件包组 # 安装指定的软件包组yum groupremove 软件包组 # 移除指定的软件包组yum groupinfo 软件包组 # 查询指定的软件包信息 常用指令echo 用于在终端上显示字符或变量 , 格式为 echo [字符串|变量][root@localhost ~]# echo $SHELL/bin/bash[root@localhost ~]# echo namename[root@localhost ~]# echo $HOSTNAMElocalhost.localdomain data 命令用于显示/设置系统的时间或日期, 格式为: \"data[选项][+指定的格式]\"%t 制表符(表示一个TAB键)%H 小时(00-23)%I 小时(1-12)%M 分钟%S 秒%X 相当于%H:%M:%S%Z 显示时区%p 显示本地AM或PM%A 星期%a 星期[root@localhost ~]# date +%aWed[root@localhost ~]# date +%AWednesday reboot 命令用于重启系统(仅root用户可以使用)reboot wget 命令用于下载网络文件，格式为wegt[参数] 下载地址-b 后台下载模式-O 指定目录-t 最大尝试次数-c 断点续传 # 断点续传啥意思-p 下载页面内所有资源，包括图片,视频等-r 递归下载 elinks 在终端上访问网页yum install elinks -yelinks www.baidu.com ifconfig 用于获取网卡配置与网络状态等信息: 格式为 ifconfig [网络设备] [参数]# 在Centos7中，初始系统已经不在带有ifconfig命令,需要安装yum install net-tools -y [root@localhost ~]# ifconfig eth0: flags=4163 mtu 1500 inet 10.0.5.30 netmask 255.255.240.0 broadcast 10.0.15.255 inet6 fe80::546f:27ff:fe92:5 prefixlen 64 scopeid 0x20 ether 56:6f:27:92:00:05 txqueuelen 1000 (Ethernet) RX packets 2789743 bytes 2021122197 (1.8 GiB) RX errors 0 dropped 40085 overruns 0 frame 0 TX packets 255991 bytes 349383987 (333.1 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 uname 命令用于查看系统内核版本等信息，格式为\"uanme [-a]\"内核名称、内核发行版本、内核版本、节点名、硬件名称、硬件平台、处理器类型、操作系统等信息[root@localhost ~]# uname -aLinux localhost.localdomain 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux查看详细版本cat /etc/redhat-release uptime 查看系统的负载情况 系统当前时间、系统已运行时间、当前在线用户、平均负载均衡(1,5,15分钟)[root@localhost ~]# uptime 11:02:21 up 23:49, 2 users, load average: 0.00, 0.01, 0.05# 每秒刷新一次获得当前的系统负载均衡情况[root@localhost ~]# watch -n 1 uptime free 命令用于显示当前系统中内存的使用情况,格式为 free[-m/-g]以m或g显示当前系统中内存的使用情况[root@localhost ~]# free total used free shared buff/cache availableMem: 1995208 132640 813324 6520 1049244 1780360Swap: 2097148 0 2097148[root@localhost ~]# free -m total used free shared buff/cache availableMem: 1948 129 794 6 1024 1738Swap: 2047 0 2047[root@localhost ~]# free -g total used free shared buff/cache availableMem: 1 0 0 0 1 1Swap: 1 0 1 who 命令用于查看当前登录主机的用户情况,格式为: who[参数][root@localhost ~]# whoroot tty1 2019-08-14 11:25root pts/0 2019-08-15 10:38 (10.0.3.12) last命令用于查看所有系统的登入记录: 格式为 last[参数][root@localhost ~]# lastroot pts/1 10.0.3.12 Thu Aug 15 10:41 - 10:41 (00:00) root pts/0 10.0.3.12 Thu Aug 15 10:38 still logged in root pts/0 10.0.3.12 Thu Aug 15 10:33 - 10:37 (00:04) root pts/1 10.0.3.12 Wed Aug 14 14:40 - 21:38 (06:57) root pts/0 10.0.3.12 Wed Aug 14 14:11 - 21:38 (07:26) root pts/3 10.0.3.12 Wed Aug 14 11:30 - 21:37 (10:06) root pts/2 10.0.5.175 Wed Aug 14 11:26 - 11:33 (00:06) root tty1 Wed Aug 14 11:25 still logged in root pts/1 10.0.3.12 Wed Aug 14 11:19 - 11:32 (00:12) root pts/0 10.0.3.12 Wed Aug 14 11:15 - 11:32 (00:16) root tty1 Wed Aug 14 11:12 - 11:15 (00:02) reboot system boot 3.10.0-957.el7.x Wed Aug 14 11:12 - 11:12 (23:59) wtmp begins Wed Aug 14 11:12:34 2019 history命令用于显示历史执行过的命令,格式为： history [-c][root@localhost ~]# history # 清除历史记录[root@localhost ~]# history -c# 默认历史记录保存1000条，修改最大值vim /etc/profile HISTSIZE = xxx pwd用于查看当前的工作路径pwd cd用于切换工作路径,格式: cd[目录名称]cd - 切换到上一次目录cd ~ 切换到家目录cd ~username 切换到其他用户的家目录cd .. 切换到上级目录 cat 命令查看纯文本文件(较短的), 格式为:cat[选项][文件]-n 显示行号-b 显示行号(不包括空行)-A 显示出不可见的符号 more 命令用于查看纯文本文件(较长的),格式为 more[选项] 文件 -数字 预先显示的行数(要在文件前面输入)-d 显示提示语与报错信息[root@localhost ~]# more -5 test.txt head 命令用于查看纯文本文档的前N行，格式为 head[选项][文件]查看文本前10行head -n 10 文件名正常输出，不显示最后10行head -n -10 tail 命令用于查看纯文本文档的后N行,格式为 tail [选项][文件]查看文本文件后20行tail -n 20 文件名不断刷新文件最后一行tail -n 1 -f 文件名 od命令用于对查看特殊格式的文件,格式为 od[选项][文件]-t a 默认字符-t c ASCII字符-t o 八进制-t d 十进制-t x 十六进制-t f 浮点数 tr命令用于转换文本文件中的字符,格式为 tr[原始字符][目标字符]将小写字符改成大写cat test.txt | tr [a-z][A-Z] wc 命令用于统计指定文本的行数、字数、字节数, 格式为 wc[参数] 文本-l 只显示行数-w 只显示单词数-c 只显示字节数统计当前用户中的个数wc -l /etc/passwd cut 命令通过列来提取文本字符 cut[参数] 文本-d 分隔符 指定分隔符,默认为Tab-f 指定显示的列数-c 单位改为字符获取当前系统中所有用户的名称cut -d: -f1 /etc/passwd获取root用户的默认shell解释器grep ^root /etc/passwd | cut -d: -f 7 diff 命令用于比较多个文本文件的差异,格式为diff[参数] 文件-b 忽略空格引起的差异-B 忽略空行引起的差异--brief 或者 -q 仅返回是否存在差异 (没有差异，则无返回)-c 使用上下文输出格式 touch 创建空白文件和修改文件时间 ,格式为 touch[选项][文件]对于在linux中的文件有三种时间: 更改时间(mtime):内容修改时间(不包括权限) 更改权限(ctime):更改权限和属性的时间 读取时间(atime):读取文件内容的时间","link":"/posts/4d6061df/"},{"title":"额外知识","text":"额外知识盲打练习https://www.typingclub.com/sportal/program-3/116.playhttps://pqrs.org/osx/karabiner/https://vim-adventures.com/ 总线https://baike.baidu.com/item/%E6%80%BB%E7%BA%BF oss与cdn的区别xxx webapi框架哪个是最快的web框架https://github.com/the-benchmarker/web-frameworks python高性能web框架https://falconframework.org/","link":"/posts/4904e4f5/"},{"title":"图解算法","text":"这个博文可能跟图解算法的内容讲的不一样，一般都是看了书之后换一种自己认为更加形象的比喻去理解内容，如果想要看图解算法的可以去购买或者查找一些PDF的书籍，笔记对于算法和数据结构并不像语言那样，对于版本的更迭有一定程度的影响。另外，算法图解这本书中的实例都是依靠Python编写的。 二分查找其实二分法在我们生活中已经出现过了很多次，比如玩一个猜价格游戏，规定价格在500-1000之内，如果我们一个一个的去猜，则需要猜1000-500-2次，但是使用二分法猜测价格时，即每次对半猜测价格，那么每次都可以减去一半的错误价格，就像一张白纸对半折一样，最后的区域则会越来越小。而使用的次数则是log2n步。同样的例子也存在于字典中，查字典的手法同样也可以使用二分法。 概念:最多需要猜测的次数与列表长度相同，这被称为线性时间 例子1创建一个函数，接受一个有序数组和一个元素，如果指定的元素出现在数组中，则返回其位置 def filter_number(list,keywords): for i in range(len(list)): if list[i] == keywords: print(i)if __name__ == \"__main__\": list = [1,2,4,5,343,67,86,656] keywords = 343 filter_number(list,keywords) 如上所示是普通的遍历方法，遍历5次后得到343这个参数。但如果匹配的数字是656，则需要匹配7次，如果数组的长度是1000,匹配的结果是最后一个，则需要匹配1000次，这样就增加了负担 # 二分查找匹配def filter_number(list,keywords): first = 0 end = len(list) - 1 while first","link":"/posts/90ec9eea/"},{"title":"深拷贝与浅拷贝","text":"数据类型数据分为 基本数据类型(String, Number, Boolean, Null, Undefined，Symbol) 对象数据类型。 基本数据类型的特点: 直接存储在栈(stack)中的数据 引用数据类型的特点：存储的是该对象在栈中引用，真实的数据存放在堆内存里引用数据类型在栈中存储了指针，该指针指向堆中该实体的起始地址。当解释器寻找引用值时，会首先检索其在栈中的地址，取得地址后从堆中获得实体。 [图] 深拷贝和浅拷贝深拷贝和浅拷贝是只针对Object和Array这样的引用数据类型的。浅拷贝只复制指向某个对象的指针，而不复制对象本身，新旧对象还是共享同一块内存。但深拷贝会另外创造一个一模一样的对象，新对象跟原对象不共享内存，修改新对象不会改到原对象。是和Linux中的软硬链接有关系吗 赋值和浅拷贝的区别 当我们把一个对象赋值给一个新的变量时，赋的其实是该对象的在栈中的地址，而不是堆中的数据。也就是两个对象指向的是同一个存储空间，无论哪个对象发生改变，其实都是改变的存储空间的内容，因此，两个对象是联动的。 浅拷贝是按位拷贝对象，它会创建一个新对象，这个对象有着原始对象属性值的一份精确拷贝。如果属性是基本类型，拷贝的就是基本类型的值；如果属性是内存地址（引用类型），拷贝的就是内存地址 ，因此如果其中一个对象改变了这个地址，就会影响到另一个对象。即默认拷贝构造函数只是对对象进行浅拷贝复制(逐个成员依次拷贝)，即只复制对象空间而不复制资源。 浅拷贝与深拷贝 https://www.runoob.com/w3cnote/python-understanding-dict-copy-shallow-or-deep.htmlhttps://juejin.im/post/5b5dcf8351882519790c9a2e#heading-7","link":"/posts/23ccefd3/"},{"title":"extra-net","text":"Supplementary Info 额外知识私网地址有三个网段：10.x.x.x172.16.x.x至172.31.x.x192.168.x.x","link":"/posts/2a24e761/"},{"title":"20200128","text":"多云，没下雨，天气还好，风还是蛮冷的。 自己好像已经没有多少力气打字了。 外面正流传这新的冠性病毒，家家户户都待在家里不敢出去，好好人都聚集在武汉救助这次病源地，而我在杭州，村子里也没什么太大的动静，不带口罩的依旧不带，戴口罩的把自己裹得严严实实。 我也不知道自己有没有得这个病，总之是无力的 低烧的 偶尔咳嗽的，他们说这是正常现象，今天想明白去医院看一下，我走进了发热门诊，他们说他们只接受38度的，然后我跑去了普通门诊，一番颠簸之下算是挂上了号，紧接着又是要抽血 又是要做CT的，真的好无语；自己本来就没有怎么去过医院检查，今天做了上去，跟我说没有付钱别坐着。。 蛮累的，没有力气，的确是没有力气","link":"/posts/f2caabf2/"},{"title":"Python爬YouTube视频","text":"youtube视频爬虫缘由最近想学习nginx，无奈没有好的视频，网上的教程也是零零散散的，慕课网 51CTO 淘宝上又买不到太好的教程，主要还是贵，买来要是讲的烂还不能退QAQ 于是，在YouTobe上搜索了一下nginx的教程，我的天哪！油管简直就是一块宝地，好多付费的视频上面都能找到，长期混迹B站找视频的我，决定赶紧下下来，生怕待会就没了，那么问题来了，如何批量下载这些视频呢？ 当然拉，能不白嫖还不是不要白嫖，要是讲的好，赞助一下也很重要 使用you-getGithub地址: https://github.com/soimort/you-get不得不说，光看他的star，又是一块宝藏QAQ 编写脚本既然有了下载器，接下来就是使用脚本批量下载了。you-get是根据油管的视频网页地址去下载视频的，那么我们需要记录这一组视频列表中的url地址。https://www.youtube.com/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzDhttps://www.youtube.com/watch?v=wZAf-aE2KoI&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzDhttps://www.youtube.com/watch?v=ULcqKLwf6fE&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD如上是三个测试地址，很不幸的是他们之间存在规律，但唯一发生变化的v=uid 其中的id是一串随机字符，但当我们不断刷新当前页面时会发现，uid并没有改变，也就是说在他们的数据库中存在一个key-value的值，每一个视频对一个随机uid,并且当这相对的关系生成之后，随机uid不会再发生改变。 获取uid既然不会发生改变，那么我们就用爬虫来获取这些uid把注意 像这样的页面虽然在他的右侧出现了列表，但这样的情况在当我们使用爬虫+正则的时，会被下方的视频连接干扰，因此最好先进入播放列表后再爬取像当前页面这样，我们所获取出来的uid就相对于完整一些 整理循环下载OK,有了uid再加上之前我们发现的不变的元素，那么一条条完整的视频链接就有了 源码#!/usr/bin/python3from you_get import common as you_getimport sysimport osimport timeimport requestsimport restatic_url = \"https://www.youtube.com{0}list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD\"file_path = \"D:\\\\video\\youtobe_nginx_mooc\"# file_path = \"F:\\\\video\\youtobe_nginx_mooc\"resp = requests.get(\"https://www.youtube.com/playlist?list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD\")pattern = \"\\/watch\\?v=[0-9a-zA-Z_-]{11}&\"video_url_lists = re.findall(pattern,resp.text)# 去重video_url_lists = list(set(video_url_lists))print(len(video_url_lists))for list in video_url_lists: format_url = static_url.format(list) print(format_url) print(\"start get video from YouTobe\") sys.argv = ['you-get','-o',file_path,format_url] you_get.main() time.sleep(1)print(\"download finished\")# print(type(resp)) ## 由于这是返回的类型是 # 但是在正则表达式中，要求是为str类型，因此如果我们使用pattern = re.findall('index' resp)时候就会报错# 报错内容为TypeError: expected string or bytes-like object# 修改 pattern = re.findall('index=',str(resp))# 或者使用pattern = re.findall('index=',resp.text)\"\"\"\"https://www.bilibili.com/read/cv4360/https://www.jianshu.com/p/e323cf85bd3d\"\"\"\"\"\"https://www.youtube.com/watch?v=5i9Ce9vzGxE&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1https://www.youtube.com/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1https://www.youtube.com/watch?v=R4p7xxd3BTo&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=4https://www.youtube.com/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1https://www.youtube.com/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1https://www.youtube.com/watch?v=0JwSFgWUUQE&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzDhttps://www.youtube.com/watch?v=fvxAQsRy8Kk&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=8https://www.youtube.com/watch?v=R4p7xxd3BTo&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=4\"\"\"","link":"/posts/b3a48f7b/"},{"title":"Rust基础","text":"Installurl https://www.rust-lang.org/zh-CN/tools/install curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh while you input enter ，will install rust default 上面这条命令会安装一些内容，比如 cargo rustup如果你想要使用他们，需要将他们添加到环境变量中 # 方法1source $HOME/.cargo/env# 方法2export PATH=\"$HOME/.cargo/bin:$PATH\" # 其实env里面写的就是方法2# 查看是否安装完成rustc --versionrustc 1.39.0 (4560ea788 2019-11-04) update更新版本, rustup用来管理rust的版本,rust每6个礼拜会进行一次版本迭代，使用rustup update更新版本 rustup update cargo工具Cargo：Rust 的构建工具和包管理器 cargo build #构建项目cargo run # 构建并运行项目cargo test # 测试项目cargo doc # 为项目构建文档cargo publish # 将库发布到cartes.io cargo new xxproject # 创建xxproject项目# cargo 开发者社区 cargo 使用cargo new helloworld # 创建一个项目helloworld # 生成如下文件[root@dev rustttt]# tree ..└── helloworld ├── Cargo.toml └── src └── main.rs Cargo.toml中包含了编译你项目时所需要的内容清单 src/main.rs 中包含了主程序 使用cargo build 构建项目,编译完成之后，会在生成一个编译后的可执行文件，执行他们 [root@dev helloworld]# ./target/debug/helloworldHello, world! 使用cargo run 构建项目并运行。 [root@dev helloworld]# cargo run Compiling helloworld v0.1.0 (/root/rustttt/helloworld) Finished dev [unoptimized + debuginfo] target(s) in 0.51s Running `target/debug/helloworld`Hello, world! 具体是使用文档https://doc.rust-lang.org/cargo/guide/index.html 编译rust文件 rustc# 使用cargo build创建helloworld目录cargo build helloworldcd helloworld/src/# 编译文件rustc main.rs ./main# 输出内容hello wolrd other不下载环境，直接测试代码https://play.rust-lang.orgRust官方文档https://www.rust-lang.org/zh-CN/tools/install","link":"/posts/4fbe8671/"},{"title":"rust猜谜游戏","text":"rust猜谜游戏走完了hello world的流程之后，来做一个猜数字的游戏 rust项目结构生成一个基本项目 cargo new guessing_nametree . ➜ guessing_game git:(master) ✗ tree ..├── Cargo.toml└── src └── main.rs Cargo.toml文件➜ guessing_game git:(master) ✗ cat Cargo.toml[package]name = \"guessing_game\"version = \"0.1.0\"authors = [\"alpaca \"]edition = \"2018\"# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html 这个里面存储了该项目的信息, name表示项目名字 version 表示cargo 版本 authors 表示作者信息 edition 表示年份 main.rs文件这个文件就是你写的程序 运行该程序运行该程序有两种方法 一种是先编译后执行 rustc src/main.rs 另外一种是直接用cargo运行 cargo run ➜ guseeing_game git:(master) ✗ tree ..├── Cargo.lock├── Cargo.toml├── src│ └── main.rs└── target └── debug ├── build ├── deps │ ├── guseeing_game-0ed5a31a6f15733b │ ├── guseeing_game-0ed5a31a6f15733b.d │ └── guseeing_game-0ed5a31a6f15733b.dSYM │ └── Contents │ ├── Info.plist │ └── Resources │ └── DWARF │ └── guseeing_game-0ed5a31a6f15733b ├── examples ├── guseeing_game ├── guseeing_game.d ├── guseeing_game.dSYM -> deps/guseeing_game-0ed5a31a6f15733b.dSYM └── incremental └── guseeing_game-1u6x8rdyd2mj5 ├── s-fiv8l6i4ic-1486aks-139msrfhaunjd │ ├── 1651w9kfz3huxj9a.o │ ├── 24om6g1u5n10ayrw.o │ ├── 2hv2ystwqwaqr9uj.o │ ├── 3701sophdbnzpjeb.o │ ├── 407p5s5dk77zb92h.o │ ├── 4eavspy520jyuwpr.o │ ├── dep-graph.bin │ ├── query-cache.bin │ └── work-products.bin └── s-fiv8l6i4ic-1486aks.lock 你会发现这两种运行的结果所创建的文件结构是不同的 获取屏幕内容并输出use std::io;fn main() { println!(\"Guess the number!\"); println!(\"Please input your guess.\"); let mut guess = String::new(); io::stdin().read_line(&mut guess) .expect(\"Failed to read line\"); println!(\"You guessed: {}\", guess);} 包含语句和表达式的函数体 函数体有一系列的语句和一个可选的结尾的表达式构成 rust是基于表达式的语言 用分号区分语句和表达式 语句是执行一些操作但不返回值的指令 表达式计算并产生一个值返回 用let关键字创建变量并绑定一个值是一个语句 比如let y = 6; 于是当我们使用如下 fn main(){ let x = (let y =6);} let y = 6 是一个语句并不会返回一个值来使得x绑定，所以会报错 let y = 6; 是一个表达式 ，返回6 函数调用是一个表达式 {} 是一个表达式 具有返回值的函数 函数可以向调用它的代码返回值。我们并不对返回值命名，但要在箭头（->）后声明它的类型 函数的返回值等同于函数体最后一个表达式的值 使用 return 关键字和指定值，可从函数中提前返回；但大部分函数隐式的返回最后的表达式。这是一个有返回值的函数的例子： fn five() -> i32{ 5 } fn main(){ let x = five(); println!(\"the value of x is {} \",x )} 以上代码等同于， {}是表达式 返回5给five()函数， let x = five();是语句，不返回值，于是let x = 5; fn main(){ let x =5 ;} fn plus_one (x: i32) -> i32{ x + 1} fn main(){ let x = plus_one(5) println!(\"the value of x is :{}\",x);} 注释 rust中是用// 进行注释 控制 逻辑操作if语句 fn main() { let number = 3; if number < 5 { println!(\"condition was true\"); } else { println!(\"condition was false\"); } if number!=0{ println!(\"nuf mber was something other than zero\") } else if number != 2{ println!(\"the number was something other than two\") } else { println!(\"the number go\") }} 在let中使用iffn main(){ let } loop语句 fn main() { loop { println!(\"again!\"); }} fn main() { let mut counter = 0; let result = loop { counter += 1; if counter == 10 { break counter * 2; } }; println!(\"The result is {}\", result);} while条件循环 fn main() { let mut number = 3; while number != 0 { println!(\"{}!\", number); number = number - 1; } println!(\"LIFTOFF!!!\");} for 遍历循环 fn main() { let a = [10, 20, 30, 40, 50]; for element in a.iter() { println!(\"the value is: {}\", element); }} fn main() { // .rev()反转 1..4 4取不到 for number in (1..4).rev() { println!(\"{}!\", number); } println!(\"LIFTOFF!!!\");}","link":"/posts/93aa081f/"},{"title":"Rust概念-所有权","text":"Rust概念-所有权变量类型可以看一下这两篇文章https://learning-rust.github.io/docs/a6.variable_bindings,constants_and_statics.htmlhttp://wiki.jikexueyuan.com/project/rust/primitive-types.html 在rust中变量模式是不可变的，因此我们叫做变量绑定，为了使他们可变，使用mut关键字即可rust是一种静态类型的语言；它在编译时检查数据类型。并不需要在声明变量绑定时指定一个具体的数据类型。编译器会检查使用情况并为其设置更好的数据类型。但是对于 常量和静态变量，必须注释type。类型在冒号（:)之r 变量绑定// 变量绑定let a = true;let b: bool = true; // 以上可以声明具体的数据类型，也可以不指定let (x,y) = (1,2);let mut z = 5;z = 6;// 常数 必须指定const N: i32 = 5;// 静态变量static N: i32 = 6; 所有权在rust中，一共分为两种数据类型 基本数据类型： 如：bool（布尔），char（字符）,integer（整数）,floating（浮点）,arrays（数组），tuples(元组)，slice(切片),字符串（str），函数指针(functions) 非基本数据类型 也就是引用类型 在rust中，对于所有权一共有两种动作状态 移动和copy 复制当将a赋值给b的时候，首先rust会对原来a的元数据进行复制，并将复制的数据赋值给b，并把a的所有权状态 设置为“已复制（ copied ）”状态。 移动当将a赋值给b的时候，rust会把原来对a的原数据的所有权移动给b，并把a的所有权状态 设置为“已移动（ moved ）”状态。let x = 5;let y = x;// 基本数据类型 只发生了copiedlet x = String::from(\"hello world\");let y = x;// 引用数据类型，发生了moved 引用类型在存储到堆中时，会指定三个部分 分别时指针，长度和容量，并且指针指向堆上存放内存的内存地址长度表示 String 的内容当前使用了多少字节的内存。容量是 String 从操作系统总共获取了多少字节的内存。长度与容量的区别是很重要的， 复制行为复制行为中，拷贝了一整份内容，包括指针长度和容量，于是他们共用同一个内存，而不是分别指向相等的两个内存二次释放错误当变量离开作用域的使用,Rust自动调用drop函数并清理变量的堆内存，于是当出现复制行为的时候，他们执行的内存地址是相同的，当s1离开后，s2执行的内存地址无。当s1离开后，s2执行的内存地址无，这个叫做二次释放的错误，也是之前提到过的内存安全性 bug 之一。两次释放（相同）内存会导致内存污染，它可能会导致潜在的安全漏洞。但是我在代码中试了一下，没有报错。。。 fn main() { let x = 1; let y = x; println!(\"Hello, world!{}\",y); println!(\"{}\",x)} // inputHello, world!11 移动行为如果将原变量指针移向另外一个变量指针，原变量指针失效。当你再次调用s1变量时，由于指针的失去，没有指向存储数据的内存地址，报错无效引用 fn main() { let x = String::from(\"hello\"); // 这个是引用类型。数据在堆上面 let y = x; println!(\"Hello, world!{}\",y); println!(\"{}\",x)}// inputerror[E0382]: borrow of moved value: `x` --> src/main.rs:5:19 |2 | let x = String::from(\"hello\"); | - move occurs because `x` has type `std::string::String`, which does not implement the `Copy` trait3 | let y = x; | - value moved here4 | println!(\"Hello, world!{}\",y);5 | println!(\"{}\",x) | ^ value borrowed here after moveerror: aborting due to previous errorFor more information about this error, try `rustc --explain E0382`.error: could not compile `xx`.To learn more, run the command again with --verbose.// 指针报错指针已经被move 克隆行为对于基础类型来说，变量的数据交互形式是复制对于引用类型来说，变量的数据交互形式无法复制，只能移动。但是如果我们需要使用到复制堆上的数据，可以使用clone的通用函数 fn main() { let x = String::from(\"hello\"); // 这个是引用类型。数据在堆上面 let y = x.clone(); println!(\"Hello, world!{}\",y); println!(\"{}\",x)} 引用和借用不可变引用跳过所有权，引用对象数据，这里就要用到rust中的引用关键字&&关键字作用是创建了一条指向某一对象的引用，再由引用对象指向数据错在内存地址当引用本身&s1离开作用域后，调用drop函数，指向s1对象的指针被丢弃同时，rust的引用本身也是不可变的， fn main() { let s1 = String::from(\"hello\"); let len = calculate_length(&s1); println!(\"The length of '{}' is {}.\", s1, len);}//参数类型需要引用类型fn calculate_length(s: &String) -> usize { s.len()} 以上 &s1的过程称为引用，获取因果那个作为函数参数称为借用 可变引用可变引用同不可变类似，但要保证被引用类型为可变类型引用为可变函数参数为可变引用 fn main() { let mut s = String::from(\"hello\"); change(&mut s);}fn change(some_string: &mut String) { some_string.push_str(\", world\");}``` 在特定作用域中的特定数据有且只有一个可变引用。这些代码会失败;但可以有多个不可变引用,并且不可变引用和可变引用不能同时存在，可以在其中一个小时后再调用解决```rustlet mst s = String::from(\"hello\"){ let r1 = &mut s;} let r2 = &mut s; slice 切片let s = String::from(\"hello world\") let hello = &s[..5];// let hello = &s[0..5];let world = &s[6..11];// let world = &s[6..len];let helloworld = &s[..];let helloworld = &s[0..len];","link":"/posts/27cd4fcb/"},{"title":"rust基础2","text":"rust基础变量常量rust采用多种变量的定义形式，同时在定义的同时区分了变量与常量的区别 定义变量使用let xx=xx # 默认immutable定义可变变量 let mut xx=xx # mut 可变定义常量 const xx: u32 = 10000 # 常量定义 名为xx 类型为int32 值为10000 其中常量默认不变 fn main() { let x = 5; println!(\"The value of x is:{}\",x); let mut y = 6; println!(\"The mut value of y is:{}\",y); //修改不可变量x 报错 //x = 7 //println!(\"i upadte the x value 5 to {}\",x) y = 10; println!(\"i update the y value 6 to {}\",y); //定义常量,他的名字是MAX_POINTS const MAX_POINTS: u32 = 100_000; println!(\"is constants value MAX_POINTS: {}\",MAX_POINTS); //变量迭代 隐藏 //对变量的隐藏，也就是不断的对x进行隐藏 //虽然变量x是不可变的immutable 但是重复使用let可以多次进行隐藏，生成之后的仍就是immutable let q = 5; let q = q + 5; let q = q + 10; println!(\"q:{}\",q) // let spaces = \" \"; let spaces_line = spaces.len(); println!(\"spance_lines_number:{}\",spaces_line) // let mut numbers = \" \"; numbers = numbers.len(); println!(\"{}\",numbers)} 可变量mut 和隐藏shadowing有什么区别?mut 与隐藏的另一个区别是，当再次使用 let 时，实际上创建了一个新变量，我们可以改变值的类型，并且复用这个名字。例如，假设程序请求用户输入空格字符来说明希望在文本之间显示多少个空格，然而我们真正需要的是将输入存储成数字（多少个空格） datatype数据类型rust是静态类型语言(statically typed)也就是说在编译时就必须知道所有变量的类型。 整型 度 有符号 无符号8-bit i8 u816-bit i16 u1632-bit i32 u3264-bit i64 u64128-bit i128 u128arch isize usize 有符号和无符号代表数字能否为负值，有符号数以补码形式（two’s complement representation）[https://kaisery.github.io/trpl-zh-cn/ch03-02-data-types.html] 存储。 浮点型它们是带小数点的数字。Rust 的浮点数类型是 f32 和 f64，分别占 32 位和 64 位。默认类型是 f64，因为在现代 CPU 中，它与 f32 速度几乎一样，不过精度更高。 fn main(){ let x = 2.0; //f64 let y: f32 = 3.0; //f32} 数值运算fn main(){ let sum = 5 + 32; let difference = 95.5 - 4.3; let product = 4 * 30; let quotient = 56.7 / 32.2; let remainder = 43 % 5;} 布尔型fn main(){ let t = true ; let f: boole = false; // 显式指定类型注解} 字符型char使用单引号 string使用双引号 fn main() { let c = 'z'; let z = 'ℤ'; let heart_eyed_cat = '😻';} 元组类型元组是一个将多个其他类型的值组合进一个复合类型的主要方式。元组长度固定：一旦声明，其长度不会增大或缩小。 fn main() { let tup: (i32, f64, u8) = (500, 6.4, 1);} fn main() { let tup = (500, 6.4, 1); let (x, y, z) = tup; println!(\"The value of y is: {}\", y);} 使用解构拆分元祖tup 对应元祖值 fn main() { let x: (i32, f64, u8) = (500, 6.4, 1); let five_hundred = x.0; let six_point_four = x.1; let one = x.2;} 数组类型fn main() { # 定义方法1 let a = [1, 2, 3, 4, 5]; # 定义方法2 let a: [i32; 5] = [1, 2, 3, 4, 5]; # 定义方法3 let a = [3;5] # => [3,3,3,3,3]} fn main() { let a = [1, 2, 3, 4, 5]; let first = a[0]; let second = a[1];} 函数方法fn main() { println!(\"Hello, world!\"); another_function();}fn another_function() { println!(\"Another function.\");} # 加参数fn main() { another_function(5);}fn another_function(x: i32) { println!(\"The value of x is: {}\", x);}# 多参数fn main() { another_function(5, 6);}fn another_function(x: i32, y: i32) { println!(\"The value of x is: {}\", x); println!(\"The value of y is: {}\", y);}","link":"/posts/bb04cef6/"},{"title":"rust结构体","text":"定义实例化结构体定义结构体，需要使用 struct 关键字并为整个结构体提供一个名字。结构体的名字需要描述它所组合的数据的意义.在结构体中需要有相应的属性和属性对应的类型 fn main() {// 创建实例模版struct User { username: String, email: String, sign_in_count: u64, active: bool,}// 实例化不可变模型let user1 = User { email: String::from(\"someone@example.com\"), username: String::from(\"someusername123\"), active: true, sign_in_count: 1,};}// 实例化可变模型let mut user2 = User { email: String::from(\"someone@example.com\"), username: String::from(\"someusername123\"), active: true, sign_in_count: 1,};}// 调用与修改println!(\"{}\", user2.email)user2.email = String::from(\"other@example.com\") 使用函数来返回并创建实例化模型fn main() { let user = return_struct(String::from(\"xx\"),2); println!(\"{}\",user.name);}struct User { name: String, age: i32, active: bool, sigin_in_count: i32,}fn return_struct(name: String,age: i32 ) -> User { User { //同名字段 //1. name: name, //2. name, name, age, active: true, sigin_in_count: 1, }} 实例更新let user2 = User { email: String::from(\"another@example.com\"), username: String::from(\"anotherusername567\"), ..user1}; 元组结构体没有字段名 只有字段类型 fn main() {struct Color(i32, i32, i32);struct Point(i32, i32, i32);let black = Color(0, 0, 0);let origin = Point(0, 0, 0);} 方法语法方法语法同函数类似，但是方法实在结构体的上下文中被定义的，并且他们的第一个参数是self，它代表了调用该方法的结构体实例 我们将某个实例能做的所有事情一起放在impl(implementation)中 struct Rectangle{ width: u32, height: u32,}// 必须同名impl Rectangle{ fn area(&self) -> u32{ self.width * self.height }}fn main() { let rect1 = Rectangle{width: 30,height: 50}; println!( \"the area is {}\",rect1.area() );} 其中self表示调用该方法的结构体实例","link":"/posts/a02a083e/"},{"title":"drf-filter","text":"Introducing drf-filterhow to use it django-filterhttps://juejin.im/post/5d22e20f6fb9a07efb69a875","link":"/posts/933b28f1/"},{"title":"jwt","text":"Introducing drfhow to use it 使用drf-jwt# 安装jwtsource /bin/activepip install djangorestframework-jwt # 配置setting.pyREST_FRAMEWORK = { 'DEFAULT_PERMISSION_CLASSES': ( 'rest_framework.permissions.IsAuthenticated', ), 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework_jwt.authentication.JSONWebTokenAuthentication', 'rest_framework.authentication.SessionAuthentication', 'rest_framework.authentication.BasicAuthentication', ),}# 配置url.pyfrom rest_framework_jwt.views import obtain_jwt_tokenurlpatterns = [ '', # ... url(r'^api-token-auth/', obtain_jwt_token),]# 测试curl -X POST -d \"username=admin&password=password123\" http://localhost:8000/api-token-auth/# 返回jsoncurl -X POST -H \"Content-Type: application/json\" -d '{\"username\":\"admin\",\"password\":\"password123\"}' http://localhost:8000/api-token-auth/# 定义验证方式curl -H \"Authorization: JWT \" http://localhost:8000/protected-url/ //settings.py# jwt token 有效期import datetimeJWT_AUTH = { # jwt 验证码有效期 'JWT_EXPIRATION_DELTA': datetime.timedelta(days=365), # jwt 验证头部 'JWT_AUTH_HEADER_PREFIX': 'Bearer',} django-jwt 自定义用户认证//settings.pyAUTHENTICATION_BACKENDS = ( 'django.contrib.auth.backends.ModelBackend', 'guardian.backends.ObjectPermissionBackend', 'users.views.CustomBackend',)JWT_AUTH = { 'JWT_AUTH_HEADER_PREFIX': 'JWT', 'JWT_EXPIRATION_DELTA': datetime.timedelta(days=7)}//users views.pyfrom django.db.models import Qfrom django.contrib.auth.backends import ModelBackendfrom django.contrib.auth import get_user_modelUser = get_user_model()# Create your views here.class CustomBackend(ModelBackend): \"\"\" 自定义用户验证 \"\"\" def authenticate(self, request, username=None, password=None, **kwargs): try: user = User.objects.get(Q(username=username) | Q(mobile=username)) if user.check_password(password): return user except Exception as e: return None https://zhuanlan.zhihu.com/p/30524397https://jpadilla.github.io/django-rest-framework-jwt/#security vue中使用token验证https://blog.csdn.net/baiqiangdoudou/article/details/100174505 curl -H \"Authorization: JWT eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoxLCJ1c2VybmFtZSI6ImFkbWluIiwiZXhwIjoxNTc0OTMwMjYyLCJlbWFpbCI6IjEwOTc2OTAyNjhAcXEuY29tIn0.cxzZhCOStN_w9OpVcq7rO-bcA_vWA172DtQaNdeGF3A\" http://localhost:8000/switch/ 为什么要用token 与其他的差别","link":"/posts/8d17cdf0/"},{"title":"drf-model","text":"drf-model drf-modelclass TestViewSet(viewsets.ModelViewSet): serializer_class = TestSerializer queryset = test_Model.objects.all() # create @action(methods=['post'],detail=False) def create_field(self, request, *args, **kwargs): request.data['name'] = \"hzj默认\" serializer = self.get_serializer(data=request.data) serializer.is_valid(raise_exception=True) self.perform_create(serializer) headers = self.get_success_headers(serializer.data) return Response(serializer.data, status=status.HTTP_201_CREATED, headers=headers) # update @action(methods=['patch'], detail=False) def update_field(self, request, *args, **kwargs): request.data[\"text\"] = \"更新dsdsd\" instance = test_Model.objects.get(id=request.data['id']) # instance = self.get_object() 会报错 # https://docs.djangoproject.com/en/2.2/ref/class-based-views/mixins-single-object/#django.views.generic.detail.SingleObjectMixin.get_object # 默认使用id查找 serializer = self.get_serializer(instance,data=request.data,partial=True) serializer.is_valid() serializer.save() return Response(serializer.data,status=status.HTTP_200_OK) # delete @action(methods=['delete'],detail=False) def delete_field(self,request,*args,**kwargs): instance = test_Model.objects.get(id=request.data['id']) if instance: self.perform_destroy(instance) return Response({\"flag\":\"删除成功\"},status=status.HTTP_200_OK) else: return Response(status=status.HTTP_400_BAD_REQUEST)","link":"/posts/4b10b818/"},{"title":"drf-note","text":"drf如何使用django-rest-framework 1.首先下载 pip3 install django-rest-framework 2.应用在setting中添加 INSTALLED_APPS = ( ... 'rest_framework',) 3.在drf中使用登陆登出的功能 urlpatterns = [ ... url(r'^api-auth/', include('rest_framework.urls'))] 序列化创建model 与 django类似创建serializer 序列化model数据，以json的形式展示 （serializer modelserialzier）创建view 与django类似 使用httpie查看 pip install httpiehttp http://localhost:8000/snippets/","link":"/posts/437192d0/"},{"title":"drf-pagination","text":"Introducing drf-paginationhow to use it django-rest-framework 分页drf一共有三种分页的方式 PageNumberPagination此分页样式在请求查询参数中接受单个数字页码，事先规定好每一页的数量,url中定义分页的标识 ,每一页最大数量等等形式 https://api.example.org/accounts/?page=3 全局设置 REST_FRAMEWORK = { 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.LimitOffsetPagination'} LimitOffsetPagination这种分页样式反映了查找多个数据库记录时使用的语法。客户端同时包括“限制”和“偏移”查询参数。该限制指示要返回的最大项目数，并且与page_size其他样式相同。偏移量表示查询相对于未分页项的完整集合的开始位置。形式 https://api.example.org/accounts/?limit=100&offset=300 全局设置 REST_FRAMEWORK = { 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination', 'PAGE_SIZE': 100} 自定义设置page_size 指示页面大小的数值。如果设置，则此PAGE_SIZE设置将覆盖设置。默认值为与PAGE_SIZE设置键相同的值。page_query_param -一个字符串值，指示用于分页控件的查询参数的名称。page_size_query_param-如果设置，则这是一个字符串值，指示查询参数的名称，该参数允许客户端根据每个请求设置页面大小。默认为None，表示客户端可能无法控制请求的页面大小。max_page_size-如果设置，这是一个数字值，表示请求的最大允许页面大小。只有page_size_query_param同时设置了此属性，该属性才有效。last_page_strings-字符串值的列表或元组，指示可与一起使用page_query_param以请求集合中的最后一页的值。默认为(‘last’,) ## setting.pyREST_FRAMEWORK = { 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',}# 设置分页样式class LargeResultsSetPagination(PageNumberPagination): page_size = 1000 page_size_query_param = 'page_size' max_page_size = 10000# 使用样式---> 局部样式class BillingRecordsView(generics.ListAPIView): queryset = Billing.objects.all() serializer_class = BillingRecordsSerializer pagination_class = LargeResultsSetPagination# 请求格式curl http://localhost:8000/switch/?page=1 CursorPagination光标分页","link":"/posts/10ccc76d/"},{"title":"DRF框架","text":"rust风格Representational State Transfer 表现层状态转化（ 资源定位及资源操作）表象层面说就是通过get,post,put,delete方式来实现前后台通信的一种轻量级,跨平台,跨语言架构设计风格的web服务 http不仅仅是传输协议，更是一种应用协议。REST，即Representational State Transfer的缩写。意为是”表现层状态转化”。RESTful表示一种风格，理解REST前需要理解资源，何谓资源，广义的资源是指可以操作的所有对象。可能是一个系统资源，如txt、jgp、xml …，亦可以是诸如自己定义的虚拟集合的抽象，如books、usrs、times。RESTfutl代表一种简洁、方便、快捷、高效、透明的架构，这取决于你怎样组合。具有如下特点： 1、规范化接口访问方式。这些http操作方法包括GET/POST/PUT/DELETE/OPTIONS等，每个操作方法都代表一个相同意义的操作，它向所有人透明地表明操作方式。比如GET只能读取/拉数据，当然你也可以是添加数据，但建议不要这么做，不然这样就失去了REST的意义。GET 读取POST 添加PUT 修改DELETE 删除2、资源标识唯一。通过URI表示一个资源名称，形式/resource/patch。如/users，表示用户的组合，或用户群。当然还可以继续标识某个具体的一个用户，/users/11，表示id为11的用户。当然，你也可以又用一组/usrgroup/11的URI代表操作用户组，不过不建议这么做，因为这样从字面上重复了/users/11资源表示的内容。一个资源URI总是包含第一条实现的方法：GET /users/11POST /users/11PUT /users/11DELETE /users/11当然，仅有这些还不足以包括资源操作的所有需求，所以还可以包含请求参数，如GET /users?type=list&page=1。3、状态的转化。这就是REST的真实含义，指它允许资源URI具有不同的表现形式。同一个URI，根据不同请求方式，执行的动作不同；还可以根据请求的Header Accept的不同返回不同的结果，如text/html、text/css、text/xml等等。也可以理解为body不同。如查询快递一般，可以上次查询，物品还在仓库，而过一段时间已经在路上了。它表示的是一个互动过程。4、所有信息都包含在当前请求中。请求的方式包含在 Request Header的Method中，还可以包含Accept、Accept-Encoding、Accept-Language，使用Authentication、Cookie等信息表明身份。同样，服务端通过发送Content-Length、Content-Type响应执行情况。最重要的是，需要返回Status Code通知执行状态，如200 201 400 404 500等http code。REST认为，所有信息都能通过请求一次性发送，而不必再采用方式保存状态，请求的信息本身已经说明了请求的意义。5、无状态性。这是REST最重要的特性之一，这个状态指的是客户端与服务端无需为每次保存请求状态，客户端请求不必考虑当前状态，不必考虑上下文。具体上说，就是不必使用session等工具跟踪、保存请求的特殊性。比如，无论是谁，从哪里发送，几时发送，对同一个URI资源发送请求的结果都是一样的。据传，这样的设计是为当一台服务器宕机时，另一台服务器可以无差别地响应对方的请求。客户端请求只认URI，而不需理后台的设计。实际上，在如今执行的RESTful设计当中，完全能执行这个要求的很少，最彻底的云服务，大部份为RESTful-like的风格。6、可实现请求缓存。通过缓存减少请求次数，在HTTP响应里利用Cache-Control、Expires、Last-Modified三个头字段，可以让浏览器缓存资源一段时间。 drf的视图集ViewSet类只是一种类型的基于类的视图，即不提供任何方法的处理程序，例如.get()或.post()，而是提供操作，如.list()和.create()。http://www.sinodocs.cn/api-guide/viewsets.html drf字段更新默认只有list和create 对应的方法就是get 和postpartial = True 局部更新 class TestViewSet(viewsets.ModelViewSet): serializer_class = TestSerializer queryset = test_Model.objects.all() @action(methods=['patch'], detail=False) def update_field(self, request, *args, **kwargs): request.data[\"text\"] = \"更新dsdsd\" instance = test_Model.objects.get(id=request.data['id']) # instance = self.get_object() 会报错 # https://docs.djangoproject.com/en/2.2/ref/class-based-views/mixins-single-object/#django.views.generic.detail.SingleObjectMixin.get_object # 默认使用id查找 serializer = self.get_serializer(instance,data=request.data,partial=True) serializer.is_valid() serializer.save() return Response(serializer.data,status=status.HTTP_200_OK) @action(methods=['delete'],detail=False) def delete_field(self,request,*args,**kwargs): instance = test_Model.objects.get(id=request.data['id']) if instance: self.perform_destroy(instance) return Response({\"flag\":\"删除成功\"},status=status.HTTP_200_OK) else: return Response(status=status.HTTP_400_BAD_REQUEST) 基本的视图集使用viewsets.ModelViewSet + DefaultRouter其中base-name表示基础url lookup表示查询参数(只根据主键查找)获取局部地址 http://localhost:8080/{base-name}/{lookup} drf路由集为了更加便捷的开发项目,drf设计了路由集的内容，免去了路由配置中的麻烦，当然他也同时兼容django的路由设计https://www.django-rest-framework.org/api-guide/routers/ 使用from rest_framework import routersrouter = DefaultRouter(trailing_slash=False) # 是否以斜杠/结尾# 声明注册路由# 同path('switch/',views.per_switch.as_view()),router.register(prefix='users', viewset=UserViewSet,basename=\"another_name\")router.register('accounts', AccountViewSet)# 添加规则，django主动扫描urlpatterns变量获取路由urlpatterns = router.urls 以上 prefix定义前缀 viewset定义视图 basename定义前缀别名 形成url格式(本地) —>http://localhost:8080/user/http://localhost:8000/accounts/ 兼容使用framework rest_framework.routers import DefaultRouterrouter = DefaultRouter()router.register('test',viewset=TestViewSet,base_name=\"test\")urlpatterns = [ path('switch/',views.switch_list.as_view()),]# 变量累加urlpatterns += router.urls 路由集urldjango的路由集是真滴变态，当你使用带值参数去查找列表中的特定内容时候，他所表现的url是^users/{pk}/set_password/$注意 pk在中间 set_password是你方法的名字如果你需要修改这些内容，可以在@action中指定url_path = set_passwordurl_name = change_password class SwitchViewSet(viewsets.GenericViewSet, mixins.ListModelMixin): serializer_class = SwitchSerializer queryset = SwitchModel.objects.all() # get @action(detail=True,url_path=\"xx\") def list_peer(self, request, pk): queryset = SwitchModel.objects.get(name=pk) print(queryset) # page = self.paginate_queryset(queryset) # if page is not None: # serializer = self.get_serializer(page, many=True) # return self.get_paginated_response(serializer.data) serializer = self.get_serializer(queryset) return Response(serializer.data) 如上一个列表查询的地址是 http://localhost:8080/{pk}/xx drf过滤drf通用过滤# setting.py# 全局设置过滤器REST_FRAMEWORK = { 'DEFAULT_FILTER_BACKENDS': ['django_filters.rest_framework.DjangoFilterBackend']}# views.py# 单视图设置过滤器 filter_backends = [django_filters.rest_framework.DjangoFilterBackend] https://www.django-rest-framework.org/api-guide/filtering/ drf分页https://www.django-rest-framework.org/api-guide/pagination/ drf过滤器https://www.django-rest-framework.org/api-guide/serializers/ drf解析器与渲染器视图的有效解析器集始终定义为类列表。当 request.data被访问时，REST框架将检查Content-Type传入请求上的标头，并确定使用哪个解析器来解析请求内容。如果您未设置内容类型，则大多数客户端将默认使用’application/x-www-form-urlencoded’例如，如果要json使用jQuery和.ajax（）方法发送编码数据，则应确保包括该contentType: ‘application/json’设置。 设置解析器仅允许json的内容 # setting.py# 全局设置解析REST_FRAMEWORK = { 'DEFAULT_PARSER_CLASSES': [ 'rest_framework.parsers.JSONParser', ]} # 单视图设置解析class modelview(): parser_classes = [JSONParser] 其他各类解析https://www.django-rest-framework.org/api-guide/parsers/ 渲染器既然有收的解析器，那也有发出数据的渲染器，REST框架包括许多内置的Renderer类，使您可以返回各种媒体类型的响应。还支持定义自己的自定义渲染器，这使您可以灵活地设计自己的媒体类型。 设置渲染器# setting.py# 全局设置解析REST_FRAMEWORK = { 'DEFAULT_RENDERER_CLASSES': [ 'rest_framework.renderers.JSONRenderer', 'rest_framework.renderers.BrowsableAPIRenderer', ]} # 单视图设置解析class modelview() renderer_classes = [JSONRenderer] 其他渲染器https://www.django-rest-framework.org/api-guide/renderers/","link":"/posts/7068483c/"},{"title":"drf框架解析","text":"drf框架解析1在drf的view视图中，我们经常会用到viewset视图集的内容。引用的方法有很多种 直接引用 我们可以使用ModelViewSet 根据不同的需求添加不同的mixins # 列出列表class SwitchViewSet(viewsets.GenericViewSet, mixins.ListModelMixin): serializer_class = SwitchSerializer queryset = SwitchModel.objects.all() 其中mixins有很多种 ListModelMixin UpdateModelMixin CreateModelMixin RetrieveModelMixin DestroyModelMixin这些mixins本身就已经提供了最基础的功能，如果我们需要添加附加的需求，可以重写这些方法mixins中的内容 class SwitchViewSet(viewsets.GenericViewSet, mixins.ListModelMixin): # 获取序列化工具 serializer_class = SwitchSerializer # 获取集合 queryset = SwitchModel.objects.all() ListModelMixinclass ListModelMixin: \"\"\" List a queryset. \"\"\" def list(self, request, *args, **kwargs): queryset = self.filter_queryset(self.get_queryset()) page = self.paginate_queryset(queryset) if page is not None: serializer = self.get_serializer(page, many=True) return self.get_paginated_response(serializer.data) serializer = self.get_serializer(queryset, many=True) return Response(serializer.data) ListModelMixin 也就是get请求返回当前模型所有列表,filter_queryset达成过滤 get_queryset获取集合第二段判断是否有做分类功能第三段返回serializer def filter_queryset(self, queryset): \"\"\" Given a queryset, filter it with whichever filter backend is in use. You are unlikely to want to override this method, although you may need to call it either from a list view, or from a custom `get_object` method if you want to apply the configured filtering backend to the default queryset. \"\"\" for backend in list(self.filter_backends): queryset = backend().filter_queryset(self.request, queryset, self) return queryset","link":"/posts/23293bb2/"},{"title":"linux初始化","text":"初始化脚本#!/bin/sh# ---> 脚本初始化export LC_ALL=en_US.utf8 # 全局设置为en_US.utf8,为了防止出现乱码echo -e 'nameserver 192.168.147.20\\nnameserver 192.168.21.20\\nnameserver 114.114.114.114' > /etc/resolv.conf# 写入DNS到/etc/resolv.conf 保证能ping通外网# ---> 设置变量KERNEL=\"kernel-ml\"# 设置KERNEL变量，一开始为无 ，reload后为无HOST=\"DCK-ZJ-SAD-xxx\"# 设置HOST变量ZONE=\"Asia/Shanghai\"# 设置时区变量# ---> 直接设置hostnamectl --static set-hostname $HOST# 修改主机名 也可以直接修改# echo \"DCK-ZJ-SAD-xxx\" > /etc/hostnametimedatectl set-timezone $ZONE# 设置本地时间timedatectl set-ntp 0# 关闭ntp同步timedatectl set-local-rtc 0# 设置硬件时钟为UTC setenforce 0 # 暂时取消selinux 高安全模式sed -r -i '/^SELINUX=/s^=.*^=disabled^g' /etc/selinux/config# 永久取消selinuxsed -r -i '/^[^root]/s:/bin/bash:/sbin/nologin:g' /etc/passwd# -r 支持正则# -i 直接修改文件# 匹配所有不是root开头的行 将后面的/bin/bash 修改成/sbin/nologin 收回所有除root用户以外的管理者登陆权限# /^[^root]/ 取反，不是root的行sed -r -i '/#Port 22/s^.*^Port 65422^g;/^PasswordAuthentication/s^yes^no^g' /etc/ssh/sshd_config#[root@localhost ~]# sed -r -n '/#Port 22/s^.*^Port 65422^p;/^PasswordAuthentication/s^yes^no^p' /etc/ssh/sshd_config#Port 65422#PasswordAuthentication no# 将登陆端口22 改成65422# 将密码验证从yes改成no# --------> ??????????????sed -r -i -e '/DefaultLimitCORE/s^.*^DefaultLimitCORE=infinity^g' -e '/DefaultLimitNOFILE/s^.*^DefaultLimitNOFILE=100000^g' -e '/DefaultLimitNPROC/s^.*^DefaultLimitNPROC=100000^g' /etc/systemd/system.conf #[root@localhost ~]# sed -r -n -e '/DefaultLimitCORE/s^.*^DefaultLimitCORE=infinity^p' -e '/DefaultLimitNOFILE/s^.*^DefaultLimitNOFILE=100000^p' -e '/DefaultLimitNPROC/s^.*^DefaultLimitNPROC=100000^p' /etc/systemd/system.conf#DefaultLimitCORE=infinity#DefaultLimitNOFILE=100000#DefaultLimitNPROC=100000# -e 多点编辑# 好像也可以写成 # sed -r -i 'xxxx:g;xxx:g;xx:g‘# /etc/systemd/system.conf 有啥用# 为什么要这样设置# 适当放大系统里的资源限制配额# 还是不懂？sed -r -i 's@weekly@daily@g;s@^rotate.*@rotate 7@g;s@^#compress.*@compress@g' /etc/logrotate.conf#root@localhost ~]# sed -r -n 's@weekly@daily@p;s@^rotate.*@rotate 7@p;s@^#compress.*@compress@p ' /etc/logrotate.conf# rotate log files daily#daily#rotate 7#compress#将logrotate日志系统设置为 每天执行 保留7天日志 日志进行压缩 等功能开启# ----------------> ??????????????????sed -r -i -e '/Compress=/s@.*@Compress=yes@g; /SystemMaxUse=/s@.*@SystemMaxUse=4G@g; ' -e '/SystemMaxFileSize=/s@.*@SystemMaxFileSize=256M@g; /MaxRetentionSec=/s@.*@MaxRetentionSec=2week@g' /etc/systemd/journald.conf#[root@localhost ~]# sed -r -n -e '/Compress=/s@.*@Compress=yes@p; /SystemMaxUse=/s@.*@SystemMaxUse=4G@p; ' -e '/SystemMaxFileSize=/s@.*@SystemMaxFileSize=256M@p; /MaxRetentionSec=/s@.*@MaxRetentionSec=2week@p' /etc/systemd/journald.conf#Compress=yes#SystemMaxUse=4G#SystemMaxFileSize=256M#MaxRetentionSec=2week# /etc/systemd/journald.conf 有啥用localectl set-locale LANG=en_US.utf8# 声明语言环境，zh_CN.utf8 中文请款下可能会出现各种乱码cat > /etc/locale.conf LANGexport LC_ALL=zh_CN.utf8 # 重置export LC_ALL=C linux时钟设置 timedatectltimedatectl命令可以查询和更改系统时钟和设置，你可以使用此命令来设置或更改当前的日期，时间和时区，或实现与远程NTP服务器的自动系统时钟同步。 # 查看系统当前时间和日期root:~# timedatectl status Local time: Wed 2020-01-15 19:42:13 CST Universal time: Wed 2020-01-15 11:42:13 UTC RTC time: Wed 2020-01-15 11:41:51 Time zone: Asia/Shanghai (CST, +0800) NTP enabled: n/aNTP synchronized: no RTC in local TZ: no DST active: n/a# 查看Timeroot:~# timedatectl | grep Time --color Time zone: Asia/Shanghai (CST, +0800)# 查看所有可用时区timedatectl list-timezones# 设置时区timedatectl set-timezone \"Asia/Shanghai\"# 协调世界时timedatectl set-timezone UTC# 设置时间timedatectl set-time 15:38:30# 设置硬件时钟为本地时间timedatectl set-local-rtc 1# 设置硬件时钟为世界时(UTC)timedatectl set-local-rtc 0# 查看硬件时钟timedatectl | grep local --color 将Linux时钟同步到远程NTP服务器NTP即Network Time Protocol（网络时间协议) # 自己当NTP服务器timedatectl set-ntp true# 禁用timedatectl set-ntp false linux 网络时间协议(Network Time Protocol) NTPNTP服务器用来同步时间 ，搭建一台本地的NTP服务器 # 安装yum install -y ntp# 启动ntp服务systemctl start ntpd# 设置开机启动systemctl enable ntpd# 查看同步情况/usr/sbin/ntpq -p ntp配置# 查看安装ntp工具会产生哪些文件 root:~# rpm -ql ntp/etc/dhcp/dhclient.d /etc/dhcp/dhclient.d/ntp.sh/etc/ntp.conf # ntp配置文件/etc/ntp/crypto...# 配置文件内容driftfile /var/lib/ntp/drift #系统时间与BIOS时间的偏差记录restrict default nomodify notrap nopeer noquery # 控制相关权限# default 指带所有ip# ignore ：关闭所有的 NTP 联机服务# nomodify：客户端不能更改服务端的时间参数，但是客户端可以通过服务端进行网络校时。# notrust ：客户端除非通过认证，否则该客户端来源将被视为不信任子网# noquery ：不提供客户端的时间查询：用户端不能使用ntpq，ntpc等命令来查询ntp服务器# notrap ：不提供trap远端登陆：拒绝为匹配的主机提供模式 6 控制消息陷阱服务。陷阱服务是 ntpdq 控制消息协议的子系统，用于远程事件日志记录程序。# nopeer ：用于阻止主机尝试与服务器对等，并允许欺诈性服务器控制时钟# kod ： 访问违规时发送 KoD 包。# restrict -6 表示IPV6地址的权限设置restrict 127.0.0.1restrict ::1 # 确保localhost（这个常用的IP地址用来指Linux服务器本身）有足够权限server 192.168.20.1 perfer # 设定主机来源，perfer定义最优先restrict 192.168.20.1 nomodify notrap noquery # 允许上有 时间服务器主动修改本机#server 0.centos.pool.ntp.org iburst #erver 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburstincludefile /etc/ntp/crypto/pwkeys /etc/ntp/keysdisable monitor# NTP服务需要使用到UDP端口号123# 初次同步ntpdate -u 192.168.20.1 linux科学计算器 bc科学计算器 # 安装yum install bc -y# \b运行计算机bc -q # 借助管道echo \"1+2\" | bcret=$(echo \"4+9\" | bc) && echo $ret linux网络工具 NetCat# 安装yum install nc -y# 使用-l Port # 使用监听端口，等待端口活动-o # 指定文件名称，把往来传输的数据以16进制字码倾倒成该文件保存-p # 设置本地主机使用的通信端口。-r # 指定本地与远端主机的通信端口。-s #设置本地主机送出数据包的IP地址-u #使用UDP传输协议-v #显示指令执行过程-w # 设置等待连线的时间-z # 使用0输入/输出模式，只在扫描通信端口时使用 使用传文件,注意关闭防火墙或者关闭端口 # 发送端 10.0.5.197nc 10.0.5.233 8888 < xx.py# 接收端 10.0.5.233nc -l 8888 > yy.py 端口扫描 nc -v -w 1 10.0.5.233 -z 20-30 聊天 # 主机端nc 10.0.5.233 8888# 接收端nc -l 8888 /etc/logrotate 滚动日志Linux系统默认安装logrotate工具，它默认的配置文件在：/etc/logrotate.conf/etc/logrotate.d/logrotate.conf 是主要的配置文件，logrotate.d 是一个目录，该目录里的所有文件都会被主动的读入/etc/logrotate.conf中执行。 查看安装会产生哪些文件[root@DCK-ZJ-SAD-035 logrotate.d]# rpm -ql logrotate/etc/cron.daily/logrotate/etc/logrotate.conf # main/etc/logrotate.d # main/etc/rwtab.d/logrotate/usr/sbin/logrotate/usr/share/doc/logrotate-3.8.6/usr/share/doc/logrotate-3.8.6/CHANGES/usr/share/doc/logrotate-3.8.6/COPYING/usr/share/man/man5/logrotate.conf.5.gz/usr/share/man/man8/logrotate.8.gz/var/lib/logrotate/var/lib/logrotate/logrotate.status 定时轮循机制Logrotate是基于CRON来运行的，其脚本是/etc/cron.daily/logrotate，日志轮转是系统自动完成的。 logrotate这个任务默认放在cron的每日定时任务cron.daily下面 /etc/cron.daily/logrotate/etc/目录下面还有cron.weekly/, cron.hourly/, cron.monthly/ 的目录都是可以放定时任务的 日志轮询周期根据时间分配有4种daily、weekly 、monthly、yearly默认daily cat /etc/cron.daily/logrotate #!/bin/sh/usr/sbin/logrotate -s /var/lib/logrotate/logrotate.status /etc/logrotate.confEXITVALUE=$?if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"fiexit 0 logrotate配置全局配置 /etc/logrotate.conf对应不同程序的配置 /etc/logrotate.d/ 全局配置 # 轮询时间,可以是weekly,monthly,yearlydaily# 日志备份保存时间 7天,超过则删除rotate 7create # 创建文件dateext # 日志文件切割后添加日期后缀compress # 切割后压缩include /etc/logrotate.d # 指向文件夹/var/log/wtmp { monthly create 0664 root utmp minsize 1M rotate 1}/var/log/btmp { missingok monthly create 0600 root utmp rotate 1} 部分应用程序配置，以nginx为例子 # 首先需要指定存放nginx日志文件的地址/usr/local/nginx/logs/access.log {dailyrotate 7missingok # 在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错dateextcompress# npcompress # 如果你不希望对日志文件进行压缩，设置这个参数即可delaycompress # 总是与compress选项一起用，delaycompress选项指示logrotate不要将最近的归档压缩，压缩将在下一次轮循周期进行notifempty # 如果日志为空，轮询不进行sharedscripts #表示postrotate脚本在压缩了日志之后只执行一次postrotate [ -e /usr/local/nginx/logs/nginx.pid ] && kill -USR1 `cat /usr/local/nginx/logs/nginx.pid`endscript}# create 644 www root # 以指定的权限创建全新的日志文件，同时logrotate也会重命名原始日志文件。# 执行程序logrotate /etc/logrotate.d/nginx 手动使用# 如果等不及cron自动执行日志轮转，想手动强制切割日志，需要加-f参数/usr/sbin/logrotate -f /etc/logrotate.d/nginx# 正式执行前最好通过Debug选项来验证一下（-d参数）/usr/sbin/logrotate -d -f /etc/logrotate.d/nginx logrotate命令格式logrotate [OPTION...] -d, --debug ：debug模式，测试配置文件是否有错误，不真实执行。-f, --force ：强制转储文件。-m, --mail=command ：压缩日志后，发送日志到指定邮箱。-s, --state=statefile ：使用指定的状态文件。-v, --verbose ：显示转储过程。 默认将日志保存在/var/lib/logrotate.status文件中 logrotate原理 create copytruncate 地址logrotate具体https://wsgzao.github.io/post/logrotate/locale具体https://www.cnblogs.com/wn1m/p/10837609.html","link":"/posts/1d7a61af/"},{"title":"linux脚本","text":"建议在sed前使用sed -n ‘///p’ 查看结果 linux脚本记录 删除文档中的所有带#的行sed -i -r '/^#.*/s:::g' /etc/ntp.conf","link":"/posts/705ac99d/"},{"title":"linux文本编辑三剑客","text":"linux文本编辑三剑客，awk、grep、sed是linux操作文本的三大利器，合称文本三剑客，也是必须掌握的linux命令之一。三者的功能都是处理文本，但侧重点各不相同，其中属awk功能最强大，但也最复杂。grep更适合单纯的查找或匹配文本，sed更适合编辑匹配到的文本，awk更适合格式化文本，对文本进行较复杂格式处理 关于”三剑客”的特长什么是三剑客的特长= grep 更适合单纯的查找和匹配文本 sed 更适合编辑匹配的文本 awk 更适合格式化文本,对文本进行较复杂格式处理 linux文本编辑三剑客grep基础grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来 grep (选项) pattern flie-A 除了显示符合匹配行，也显示匹配行后的n行-B 除了显示符合匹配行，也显示匹配行前的n行-C 除了显示符合匹配行，也显示匹配行前后的n行 但不显示每一行的行数-c 仅显示统计匹配行数的总数-e 实现多个选项件的逻辑关系 or-E 扩展的正则表达式-f FILE：从FILE获取匹配参数格式-i --ignore-case 忽略字符大小写的差别-n 显示匹配的行号-o 仅显示匹配到的字符串-v 反向匹配，显示不被匹配的内容-w 只显示全字符合的列 需要注意的地方 egrep = grep -E 除了 < \\> \\b 以外其他正则都可以去掉\\ 如果有要匹配的内容中,有( ; )这种的话最好加”” 比如 grep “;” test.txt 正则表达式匹配内容.匹配全部字符，不匹配空行[]匹配指定范围内的任意单个字符[^] 取反[:alnum:] [0-9a-zA-Z][:alpha:] [a-zA-Z][:upper:] 或 [A-Z][:lower:] 或 [a-z][:blank:] 匹配空白字符[:punct:] 标点符号匹配次数 *匹配任意次 0-n次 ,贪婪模式(尽可能多匹配).*匹配任意次 1-n次 \\?匹配 0-1次\\+至少匹配1次 位置确定^ 行首$ 行尾^$ 空白行 划组匹配在正则表达示中使用之前匹配到的内容，即划组匹配 # 分组形式 \\(\\)# 读取方式 \\1 \\2 \\3 实例 多文件查找grep \"match_pattern\" file1 file2 file3 反项查找grep -v \"macth_pattern\" file1 file2 file3 匹配项标记颜色grep \"macth_pattern\" file1 --color=auto 正则匹配grep -E \"[1-9]+\"或egrep \"[1-9]+\" 只显示匹配到的字符串echo this is a test line. | grep -o -E \"[a-z]+\\.\" 统计匹配到的内容数量grep -c \"text\" file1 显示匹配到的行号grep -n \"text\" file1 多级目录中递归搜索grep \"text\" . -r -n 忽略大小写echo \"hello world\" | grep -i \"HELLO\" awk基础awk是由Alfred Aho 、Peter Weinberger 和 Brian Kernighan这三个人创造的，awk由这个三个人的姓氏的首个字母组成。awk其实可以看成是一门独立的编程语言，他支持条件判断、数组、循环等功能。awk共有两个版本(gawk与nawk版本),在linux中我们最常使用的是gawk,同时awk、grep、sed被称为Linux中的三剑客 [root@CodeSheep ~]# ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Feb 15 2019 /usr/bin/awk -> gawk 语法awk [options] ‘{pattern + action}’ {filenames}其中的action 我们最常用的就是print以及prinf,对于action来说，每次经过一行，都会当前行执行一边action比如 awk '{print \"1\",NR}' /etc/passwd 你会发现有多少行，他就输出了多少个1 每行一个 awk的工作流程首先awk并不是列操作，而是行操作，同样的他也是一行一行的处理的，其中$0表示当前行，比如在正常情况下我们输出全文是用cat来查看的，那么用awk的操作是这样的,另外awk的接受标准输入和文件 cat /etc/passwdawk '{print $0}' /etc/passwd# 如上的内容是一样的 awk中的分隔符为了处理好每一行中的每一个字段，awk引入了分隔符的概念，分隔符有三种表现的形式，一种是不输入任何不指定任何，则默认为空格一种是自定义的分隔符 使用 -F 指定 比如 -F:另外一种是使用 内置变量指定 -v FS=’#’ 自定义分隔符既然默认的分隔符是空格,那么当然还有自定义的分隔符咯。我们使用-F选项来指定我们的分隔符 # 使用#分隔符[root@CodeSheep ~]# cat demo3.text 123#123#dsdshj#dlsj#[root@CodeSheep ~]# awk -F# '{print $1}' demo3.text 123[root@CodeSheep ~]# cat demo3.text 123#123#dsdshj#dlsj#[root@CodeSheep ~]# awk -v FS='#' '{print $1}' demo3.text 123 其实在awk中不仅仅有输入的分割符,还有输出的分隔符，默认也为空格 [root@CodeSheep ~]# awk -F# '{print $1,$2}' demo3.text 123 123 OFS(output field separator)可以指定输出的分隔符,用法与FS相同 [root@CodeSheep ~]# awk -v FS='#' -v OFS='++++' '{print $1,$2}' demo3.text 123++++123 awk重定向awk 'BEGIN { print \"Hello, World !!!\" > \"/tmp/message.txt\" }' awk的内建变量awk支持内建变量和自定义变量 内建变量 $0 当前行 $1~$n 第n个字段 $NF 最后一个字段 NF 当前行被分割字段总数 NR 当前行行号 FNR 各文件分别计数的行号 FS 输入分隔符 OFS 输出分隔符 RS 输入换行符 ORS 输出换行符 FILENAME 当前文件名 ARGC 命令行参数的个数 ARGV 数组,保存的命令行所给定的各参数 # 给每一行添加行号,输出当前行号，以及当前行的内容[root@CodeSheep ~]# df | awk '{print NR,$0}'1 Filesystem 1K-blocks Used Available Use% Mounted on2 /dev/vda1 41147472 6848400 32395580 18% /3 devtmpfs 930656 0 930656 0% /dev4 tmpfs 941116 0 941116 0% /dev/shm5 tmpfs 941116 452 940664 1% /run6 tmpfs 941116 0 941116 0% /sys/fs/cgroup7 tmpfs 188224 0 188224 0% /run/user/0# 多个文件使用NR时,会根据的文件顺序累加序号# FNR则会分开标序# ARGV,ARGC[root@CodeSheep ~]# awk 'BEGIN{print ARGV[0],ARGV[1],ARGV[2],ARGC}' demo1.txt demo2.text awk demo1.txt demo2.text 3# 其中ARGV作为数组,第一个参数是awk 自定义变量名自定义变量的两种形式,一种是在action外面 使用选项指定变量，比如 -v name=”hzj”另外一种则是在action前的pattern中定义，比如 {name=”hzj”; action->print name} [root@CodeSheep ~]# awk -v name=\"hzj\" 'BEGIN{print name}'hzj[root@CodeSheep ~]# awk 'BEGIN{name=\"hzj\";print name}'hzj[root@CodeSheep ~]# name=hzj[root@CodeSheep ~]# awk -v name=$name 'BEGIN{print name}'hzj awk 参数options-v name=”xx” -v外部定义变量###s## pattern+action抛开Pattern 我们先来使用{action} # 输出文本内容[root@CodeSheep ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/vda1 41147472 6848500 32395480 18% /devtmpfs 930656 0 930656 0% /devtmpfs 941116 0 941116 0% /dev/shmtmpfs 941116 452 940664 1% /runtmpfs 941116 0 941116 0% /sys/fs/cgrouptmpfs 188224 0 188224 0% /run/user/0[root@CodeSheep ~]# df | awk '{print $1}'Filesystem/dev/vda1devtmpfstmpfstmpfstmpfstmpfs awk是逐行处理的,也就是说当awk处理一个文本的时候，他会一行一行的处理内容。其中awk默认以 换行符 为标记识别每一行。另外对于每一行的处理中 awk会按照用户指定的 分隔符 去分隔当前行，如果没有指定，则默认使用空格作为分隔符，当出现多个空格的时候,awk会自动将连续的空格理解成为一个分隔符。其中 我们将被awk处理后的每一行都使用了特定的变量标记$0表示当前处理的整行$1表示第一个字段$2表示第二个字段$NF表示最后一个字段NF表示当前行被分割后字段总数因此 假设一行文本被空格分为8段，则$NF表示$8 NF=8 则$7=$(NF-1) # 输出多行[root@CodeSheep ~]# df | awk '{print $1 $2 $3}'Filesystem1K-blocksUsed/dev/vda1411474726848536devtmpfs9306560tmpfs9411160tmpfs941116452tmpfs9411160tmpfs1882240[root@CodeSheep ~]# df | awk '{print $1, $2 ,$3}'Filesystem 1K-blocks Used/dev/vda1 41147472 6848536devtmpfs 930656 0tmpfs 941116 0tmpfs 941116 452tmpfs 941116 0tmpfs 188224 0# 自己添加字段[root@CodeSheep ~]# df | awk '{print $1 ,\"this print test\"}'Filesystem this print test/dev/vda1 this print testdevtmpfs this print testtmpfs this print testtmpfs this print testtmpfs this print testtmpfs this print test[root@CodeSheep ~]# df | awk '{print \"$1=\"$1 , \"testfield:\"\"this print test\"}'$1=Filesystem testfield:this print test$1=/dev/vda1 testfield:this print test$1=devtmpfs testfield:this print test$1=tmpfs testfield:this print test$1=tmpfs testfield:this print test$1=tmpfs testfield:this print test$1=tmpfs testfield:this print test#看上面的案例我们可以发现,当$1被双引号包裹的时候，他就是一个字符串,不再是变量 awk中的Pattern其实action的主要操作就是print输出,简单来用就是输出内容，更复杂的就是对输出的内容进行格式化的操作。而Pattern所存在的两种模式,愈加加强了awk的能力。 awk中的逻辑为了更好的格式化,awk中也带有逻辑参数，其中包括开始BEGIN和结尾END,他们之间用{}分隔,比如 awk -v test=\"test\" 'BEGIN{print \"1\",NR}{print test}END{print \"input end\" }' /etc/passwd 你会发现他输出了很多个test，首先begin进入，然后输出1和行号0 紧接着不断的进入行输出test 在最后一行输入时 执行input end 特殊模式下的BEGIN与END BEGIN 模式指定了处理文本之前需要执行的操作 END 模式指定了处理完所有行之后所需要执行的操作 [root@CodeSheep ~]# df | awk 'BEGIN{print \"$1\",\"$2\"}'$1 $2[root@CodeSheep ~]# df | awk 'BEGIN{print \"$1\",\"$2\"} {print $1,$2}'$1 $2Filesystem 1K-blocks/dev/vda1 41147472devtmpfs 930656tmpfs 941116tmpfs 941116tmpfs 941116tmpfs 188224[root@CodeSheep ~]# df | awk 'BEGIN{print \"$1\",\"$2\"} {print $1,$2} END{print \"end for file\"}'$1 $2Filesystem 1K-blocks/dev/vda1 41147472devtmpfs 930656tmpfs 941116tmpfs 941116tmpfs 941116tmpfs 188224end for file 在BEGIN的模式下，首先awk会执行BEGIN中的action 之后才做去执行其他的action,同理,在执行完所有的action之后,awk回去执行END模式下面的action。需要注意的是两个特殊的模式BEGIN以及END都需要大写 于是 awk的格式化能力表露无疑了,提取字段再加上BEGIN与END的两种特殊模式，一张完整的表不就出来了嘛 关系运算符 < 小于 x < y=y> 大于 x>y~ 正则匹配 x ~ /正则/!~ 正则不匹配 x !~ /正则/ awk中的正则模式既然上面的关系运算符中出现了正则，那我们就来讲一讲正则模式需要注意的是 当使用{x,y}这种次数匹配的正则表达式时，需要配合–posix选项或者–re-interval选项 # 匹配/etc/passwd 中以 tss开头的行[root@CodeSheep ~]# cat /etc/passwd | awk '/tss/{print $0}'tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin# 匹配/etc/passwd 中以 /bin/bash结尾的行[root@CodeSheep ~]# cat /etc/passwd | awk '/\\/bin\\/bash$/{print $0}'root:x:0:0:root:/root:/bin/bash# 匹配/etc/passwd 中以/bin/bash结尾的行 到以 tss开头的行[root@CodeSheep ~]# cat /etc/passwd | awk '/\\/bin\\/bash$/,/^tss/{print $0}'root:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpolkitd:x:999:998:User for polkitd:/:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinchrony:x:998:996::/var/lib/chrony:/sbin/nologinntp:x:38:38::/etc/ntp:/sbin/nologintcpdump:x:72:72::/:/sbin/nologinnscd:x:28:28:NSCD Daemon:/:/sbin/nologinmysql:x:27:27:MySQL Server:/var/lib/mysql:/bin/falsedockerroot:x:997:994:Docker User:/var/lib/docker:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin# 匹配行号大于2 且小于6的行[root@CodeSheep ~]# cat /etc/passwd | awk 'NR>2 && NR>> test by geminis' /etc/passwdsed -r '/^root/c\\>>>> test by geminis' /etc/passwd# 删除空格sed s/[[:space:]]//g file# 删除空格 sed /^$/d file 地址https://www.cnblogs.com/along21/p/10366886.html#auto_id_15","link":"/posts/ec496181/"},{"title":"shell脚本","text":"shell脚本简单的介绍shell脚本的使用 规范shell脚本对空格有一定的规定 空格的使用 赋值语句中等号=两边不能有空格，而字符串比较中等号= == 两边必须有空格 中括号[] [[]] 前后一定要加空格 i=1if [ $a == $b ] ;then 括号的使用常见的三种括号 (()) [] [[]] () 只能进行整数比较，不能用于字符串比较，括号中变量可以省略前缀 [] [[]] [] 与test等价都是命令，而[[]]是关键字, && || < > 不能存在于[] 中，只能粗在于[[]]中 [[[] 支持算术扩展 [] 不支持 [[]] 支持字符串匹配，[] 不支持if [[ $a != 1 && $a != 2 ]], 对if [ $a != 1 ] && [ $a != 2] 对if [[ 1+2 -eq 3 ]] 对 字符串对比对比字符串只能使用=、==、、!=、-z、-n。其中，-n 表示字符串不为空，即长度大于0，-z 表示字符串为空，即长度为0 对比数字，只能使用==、=、!=，或者 -eq、-ne、-gt、-ge、-lt、-le。其中-eq的意思是 equal，-ne是 unequal，-gt是 greater than，-ge是 greater than or equal to，-lt是 less than，-le是 less than or equal to。 https://blog.csdn.net/HappyRocking/article/details/90476264 语法判断 ifif 条件; then command1else command2fi 举例 if [[ $a == $b ]]; then echo \"equal\"fi","link":"/posts/d0a69eae/"},{"title":"httpd服务","text":"apache http serverApache HTTP Server（简称Apache）是Apache软件基金会的一个开放源码的网页服务器，可以在大多数计算机操作系统中运行，由于其多平台和安全性被广泛使用，是最流行的Web服务器端软件之一。它快速、可靠并且可通过简单的API扩展，将Perl/Python等解释器编译到服务器中。 在Apache中，其配置文件目录为“/etc/httpd/conf/httpd.conf”，这里面包括设置网站资源的存放目录及一些相关的配置。 # 安装httpyum install httpd # 开启服务systemctl start httpd# 检查httpd服务状态systemctl status httpd# 查看端口状态 netstat -anutp | grep 80 目录介绍配置文件目录为“/etc/httpd/conf/httpd.conf” [root@localhost httpd]# ls -1conf # 存放服务的主配置文件conf.d # 存放apache的主页信息conf.modules.dlogsmodulesrun 配置信息配置文件目录为“/etc/httpd/conf/httpd.conf” [root@localhost httpd]# vi /etc/httpd/conf/httpd.confServerRoot \"/etc/httpd\" #apache配置文件的根目录Timeout 60 #超时时间，即连接服务端在60秒内没有任何操作，即自动断开Listen 80 #监听的端口ServerAdmin root@localhost #设置管理员，e-mail 地址ServerName www.example.com:80 #服务器主机名.DocumentRoot \"/var/www/html\" #网站页面根目录,存放文档的地方 Options Indexes FollowSymLinks #O目录浏览 #Followsymlinks:可以用连接，要是想要禁止显示文件目录，可以直接在‘indexes’前加‘-’。 AllowOverride None Order allow,deny #目录与访问的控制 Allow from all # 别名Alias /icons/ \"/var/www/icons/\" #别名和别名目录 Options Indexes MultiViews FollowSymLinks AllowOverride None Order allow,deny Allow from all# 默认页面 Options Indexes #当一个目录没有默认首页时，允许显示此目录列表 Options FollowSymLinks AllowOverride None--DirectoryIndex index.html index.html.var #指定默认首页AddDefaultCharset UTF-8 #设置服务器的默认编码为： UTF-8 python3构建http服务python3 -m http.server 维护&错误http服务已开启，但是无法访问网站 在本地查看httpd服务curl http://localhost:80 看端口，如果是在公司内部，查看是否有部分ip端口被封 比如80 8080 88 等等如果是以上情况，修改httpd 配置文件中的监听端口，重启http服务即可 永久关闭selinux ,需要重启vi /etc/selinux/configSELINUX=disabled 临时关闭setenforce 0 可能会出现的报错信息(13)Permission denied: make_sock: could not bind to address [::]:88—-> 关闭selinux即可 检测端口是否被开启使用telnet登陆的方式测试服务器端口是否开放 # 未开放状态下的返回情况➜ ~ telnet 10.0.5.92 8888Trying 10.0.5.92...telnet: Unable to connect to remote host: Connection refused# 开放状态下的返回情况➜ ~ telnet 10.0.5.91 8888Trying 10.0.5.91...Connected to 10.0.5.91.Escape character is '^]'. 开放端口端口未被开放———> iptables -I INPUT -p tcp –dport 8888 -j ACCEPT 地址https://www.linuxidc.com/Linux/2017-05/143468.htm","link":"/posts/4982550/"},{"title":"iptables、firewall 防火墙","text":"iptables、firewall防火墙Linux中有两种防火墙软件，ConterOS7.0以上使用的是firewall，ConterOS7.0以下使用的是iptables firewall# 开启防火墙systemctl start firewalld# 关闭防火墙systemctl stop firewalld# 查看状态systemctl status firewalldfirewall-cmd --state# 设置开机启动systemctl enable firewalld# 禁用开机启动systemctl disabled firewalld# 重启防火墙firewall-cmd --reload# 开放端口firewall-cmd --zone=public --add-port=8080/tcp --permanet# 查看已经开放的端口firewall-cmd --list-ports firewall-cmd --list-all# 关闭端口firewall-cmd --zone=public --remove-port=8080/tcp --permanet\\ https://juejin.im/post/5d538326f265da03ce39cf38 iptables# 安装iptables yum install iptables# 安装iptables-servicesyum install iptables-services# 开启防火墙systemctl start iptables# 关闭防火墙systemctl stop iptables.services# 防火墙状态 、开机启动 、 禁用开机启动、status 、 enable 、disable# 查看filter表的几条链规则(INPUT链可以看出开放了哪些端口)：iptables -L -n# 查看连标规则iptables -t nat -L -n # 清除防火墙所有规则iptables -F# 给INPUT链添加规则（开放8080端口）iptables -I INPUT -p tcp --dport 8080 -j ACCEPT# 查找规则所在行iptables -L INPUT --line-numbers -n# 根据行号删除过滤规则(关闭8080)iptables -D INPUT 1 防火墙错误导致的原因 开通httpd后，当前机器下使用curl可访问，但外部机器访问ip+端口则无法访问[root@localhost ~]# curl http://10.0.5.92:8888curl: (7) Failed connect to 10.0.5.92:8888; No route to host curl报如下错误：curl: (7) Failed connect to 172.16.225.43:7001; No route to host 解决办法—-> 在被访问机器下开放8888端口—-> iptables -l INPUT -p tcp –dport 8888 -j ACCEPTt 8888 -j ACCEPT","link":"/posts/60486/"},{"title":"netstat","text":"netstat工具netstat是在内核中访问网络相关信息的程序。 提供TCP连接、TCP和UDP监听、进程内存管理的状态。 监控TCP/IP网络的非常有用的工具，显示路由表、实际网络连接以及每一个网络接口设备的状态信息。 使用netstat可以让用户知道有哪些网络连接正在运作，使用时如果不带参数，netstat显示活动的TCP连接 # 安装yum install net-tools# 使用netstat 选项：常用参数：-a:显示所有的socket，包括监听的以及未监听的。-n:不使用域名和服务名，而使用IP和端口号。-l:仅列出在listen状态的网络服务。-p:显示建立连接的程序名和PID。-e:显示以太网统计。-s:显示每个协议的统计。-t：显示TCP协议连接情况。-u:显示UDP协议连接情况。-c:每隔一个固定时间，执行netstat命令。-r：显示核心路由表。-i:显示所有的网络接口信息 常用指令# 显示建立连接的程序名 PID IP 端口以及监听状态[root@localhost ~]# netstat -pan | grep 8888tcp6 0 0 :::8888 :::* LISTEN 16711/httpd","link":"/posts/4421/"},{"title":"blog_back_new/linux/net/记录","text":"hook 钩子 用户空间 与 内核空间 内核空间释放hook给用于空间调用调用过程使用command line执行 hook与库有差别 filter 正常防止nat 转发mangle 打标记 qos限速等等 网桥","link":"/posts/67b35a0f/"},{"title":"linux常用命令整理","text":"learn linux linux常用命令整理查看linux版本信息1.使用lsb_release 查看 lsb_release -a# 出现错误 bash: lsb_release: command not found...# 安装lsb_releaseyum install -y readhat-lsblsb_release -a 2.uname 适合所有的linux发行版本 [root@CodeSheep ~]# unameLinux[root@CodeSheep ~]# uname -r3.10.0-957.5.1.el7.x86_64[root@CodeSheep ~]# uname -aLinux CodeSheep 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux[root@CodeSheep ~]# 3.使用redhat-release [root@CodeSheep ~]# cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) 4.查看Cetnos版本于redhat对应版本的命令 [root@CodeSheep ~]# cat /proc/version Linux version 3.10.0-957.5.1.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) ) #1 SMP Fri Feb 1 14:54:57 UTC 2019 netstat命令可以帮助查找本机的网络状态netstat -pt #可以输出PID以及程序名 输出结果 Active Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 localhostname:16061 192.168.1.1:50060 ESTABLISHED 22000/java 是本机的16061端口在调192.168.1.1:50060上的服务，且本机16061端口上跑的是一个java程序，进程ID是22000 netstat -ant netstat -input lsof可以查看系统打开的文件，这里的“文件”包括/proc文件、磁盘文件、网络IO等lsof /etc/passwd # 查看哪个进程在占用/etc/passwdlsof -c mysql # 列出某个程序打开的文件信息lsof -u username # 列出某个用户打开的文件lsof -u ^root # 排除某个用户外的被打开的文件信息lsof -p 1 # 列出某个进程号打开的文件lsof -i # 列出所有的网络连接lsof -i :22 # 列出谁在使用22端口lsof | grep usbserial #查看usb端口使用情况 ps命令查找与进程相关的PID号ps a # 显示所有进程以及相关的pidps -A # 现实所有进程信息ps -u root #显示root进程用户信息ps -ef # 显示所有命令，连带命令行ps -aux # 显示所有包含其他使用者的行程ps c # 列出程序显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示ps -e # 显示每一个程序的环境变量ps -ef | grep java | grep -v grep # 显示所有a进程,去掉当前的grep进程kill -9 pid # 杀死进程 查看linux版本信息1.使用lsb_release 查看 lsb_release -a# 出现错误 bash: lsb_release: command not found...# 安装lsb_releaseyum install -y readhat-lsblsb_release -a 2.uname 适合所有的linux发行版本 [root@CodeSheep ~]# unameLinux[root@CodeSheep ~]# uname -r3.10.0-957.5.1.el7.x86_64[root@CodeSheep ~]# uname -aLinux CodeSheep 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux[root@CodeSheep ~]# 3.使用redhat-release [root@CodeSheep ~]# cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) 4.查看Cetnos版本于redhat对应版本的命令 [root@CodeSheep ~]# cat /proc/version Linux version 3.10.0-957.5.1.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) ) #1 SMP Fri Feb 1 14:54:57 UTC 2019 netstat命令可以帮助查找本机的网络状态netstat -pt #可以输出PID以及程序名 输出结果 Active Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 localhostname:16061 192.168.1.1:50060 ESTABLISHED 22000/java 是本机的16061端口在调192.168.1.1:50060上的服务，且本机16061端口上跑的是一个java程序，进程ID是22000 netstat -ant netstat -input lsof可以查看系统打开的文件，这里的“文件”包括/proc文件、磁盘文件、网络IO等lsof /etc/passwd # 查看哪个进程在占用/etc/passwdlsof -c mysql # 列出某个程序打开的文件信息lsof -u username # 列出某个用户打开的文件lsof -u ^root # 排除某个用户外的被打开的文件信息lsof -p 1 # 列出某个进程号打开的文件lsof -i # 列出所有的网络连接lsof -i :22 # 列出谁在使用22端口lsof | grep usbserial #查看usb端口使用情况 ps命令查找与进程相关的PID号ps a # 显示所有进程以及相关的pidps -A # 现实所有进程信息ps -u root #显示root进程用户信息ps -ef # 显示所有命令，连带命令行ps -aux # 显示所有包含其他使用者的行程ps c # 列出程序显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示ps -e # 显示每一个程序的环境变量ps -ef | grep java | grep -v grep # 显示所有a进程,去掉当前的grep进程kill -9 pid # 杀死进程 创建目录mkdirmkdir (选项) (参数)-m 建立目标的同时设置属性-p 多层级建立-v 显示建立信息 使用 [root@test-ceph ~]# mkdir -m 777 -pv kk/kk/kkkmkdir: 已创建目录 \"kk\"mkdir: 已创建目录 \"kk/kk\"mkdir: 已创建目录 \"kk/kk/kkk\" [root@test-ceph alpaca]# mkdir -pv ~/alpaca/tt/{,name/}{n,a,m,e}mkdir: 已创建目录 \"/root/alpaca/tt\"mkdir: 已创建目录 \"/root/alpaca/tt/n\"mkdir: 已创建目录 \"/root/alpaca/tt/a\"mkdir: 已创建目录 \"/root/alpaca/tt/m\"mkdir: 已创建目录 \"/root/alpaca/tt/e\"mkdir: 已创建目录 \"/root/alpaca/tt/name\"mkdir: 已创建目录 \"/root/alpaca/tt/name/n\"mkdir: 已创建目录 \"/root/alpaca/tt/name/a\"mkdir: 已创建目录 \"/root/alpaca/tt/name/m\"mkdir: 已创建目录 \"/root/alpaca/tt/name/e\" 下载文件工具wgetLinux系统中的wget是一个下载文件的工具，它用在命令行下。对于Linux用户是必不可少的工具，我们经常要下载一些软件或从远程服务器恢复备份到本地服务器。wget支持HTTP，HTTPS和FTP协议，可以使用HTTP代理。所谓的自动下载是指，wget可以在用户退出系统的之后在后台执行。这意味这你可以登录系统，启动一个wget下载任务，然后退出系统，wget将在后台执行直到任务完成，相对于其它大部分浏览器在下载大量数据时需要用户一直的参与，这省去了极大的麻烦。wget 可以跟踪HTML页面上的链接依次下载来创建远程服务器的本地版本，完全重建原始站点的目录结构。这又常被称作”递归下载”。在递归下载的时候，wget 遵循Robot Exclusion标准(/robots.txt). wget可以在下载的同时，将链接转换成指向本地文件，以方便离线浏览。wget 非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性.如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用 wget (参数) (地址)-V 显示版本-h 语法帮助-b 启动后转入后台执行-o --output-file=file 把下载记录写到文件中-a 追加写到文件中-q 静默输出-i --input-file=file 下载在file文件中出现过的urls-F 把输入文件当作html格式来对待-O 下载并以不同的文件名保存 使用 # 下载一个包wegt http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 下载一个文件并重命名，默认以最后一个/后面的内容为文件名wegt -O test.tar.gz http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz # 限速下载wget --limit-rate=300k http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 断点续传wget -c http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 后台运行 , 并使用tail观察进度wget -b http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gztail -f wget-log# 指定下载文件存放地址wget --directory-prefix/sources http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 伪装代理名称wget --user-agent=\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16\" http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 测试下载wget --spider http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 增加重试下载次数wget --tries=40 http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 多链接下载wget -i urllist.txt# 过滤格式下载wget --reject=gif http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 把下载信息存入日志文件wget -o downloads.log http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 限制下载文件大小,超过5m就退出，对单个下载无用，需要递归下载wget -Q5m -i urllist.txt# 下载指定格式文件wget -r -A .pdf http://downloads.sourceforge.net/project/tcl/Tcl/8.6.3/tcl8.6.3-src.tar.gz# 下载ftp上的内容wget ftp-urlwget --ftp-user=username --ftp-passwd=passwd xxx.ftp 查找文件find用来在指定目录下查找文件。任何位于参数之前的字符串都将被视为欲查找的目录名。如果使用该命令时，不设置任何参数，则find命令将在当前目录下查找子目录与文件。并且将查找到的子目录和文件全部进行显示 find . # 列出当前目录以及子目录下所有文件和文件夹find /home -name \"*.txt\" #列出/home目录下所有.txt结尾的文件名find /home -iname \"*.txt\" #同上，忽略大小写find /home \\(-name \"*.txt\" -o -name \"*.pdf\"\\) # 满足逻辑关系 andfind /home -name \"*.txt\" -o -name \"*.pdf\" # 同上find /usr/ -path \"*local\" # 查找文件或路径find . -regex \".*\\(\\.txt\\|\\.pdf\\)$\" # 正则匹配find /home ! -name \"*.txt\" # ! 否定find . -type 参数类型 f 普通文件 l 软链接 d 目录 c 字符设备 b 快设备 s 套接字find . -maxdepth 3 -type f # 定义目录最大深度 3find . -mindepth 2 -type f # 定义目录最小深度 2find . -type f -atine -7 # 最近7天内find . -type f -atime 7 # 7天前当天被访问过的文件find . -type f -atime +7 # 7天前被访问过的文件find /var/log -size +1G # 查找大于1G的文件find /data -owner user # 找到user用户的文件find ./ -iname '_macosx' -depth -exec rm -rf {} \\; # 删除自动生成的文件 https://wangchujiang.com/linux-command/c/find.html 复制文件 cpcp (选项) (参数) -r 可以复制目录-i 覆盖文件之前询问-f 强行复制文件或目录,无论是否存在-u 使用这项参数后只会在源文件的更改时间较目标文件更新时或是名称相互对应的目标文件并不存在时，才复制文件；-v 看详细信息 查看动态库依赖关系 ldd首先ldd并不是一个二进制的可执行程序，他是依附在Linux中的一个shell脚本用于打印程序或者库文件所依赖的共享库列表比如https://www.cnblogs.com/zhangjxblog/p/7776556.htmlhttps://blog.csdn.net/qq_26819733/article/details/50610129 [root@gogogo ~]# ldd /bin/ls linux-vdso.so.1 => (0x00007ffe7cbcc000) libselinux.so.1 => /lib64/libselinux.so.1 (0x00007fedc8e77000) libcap.so.2 => /lib64/libcap.so.2 (0x00007fedc8c72000) libacl.so.1 => /lib64/libacl.so.1 (0x00007fedc8a69000) libc.so.6 => /lib64/libc.so.6 (0x00007fedc869b000) libpcre.so.1 => /lib64/libpcre.so.1 (0x00007fedc8439000) libdl.so.2 => /lib64/libdl.so.2 (0x00007fedc8235000) /lib64/ld-linux-x86-64.so.2 (0x00007fedc909e000) libattr.so.1 => /lib64/libattr.so.1 (0x00007fedc8030000) libpthread.so.0 => /lib64/libpthread.so.0 (0x00007fedc7e14000) 查看快捷输入 aliasalias 或者 ~/.bash_profile 查看当前目录文件 ls# 语法ls [option] [name] -a 显示所有文件或目录-l 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出-r 倒叙显示-t 时间顺序排列-R 递归显示-h 以可读大小显示-i 额外显示inode信息 # 常用ls -alls -altr #倒叙时间ls -lh # 列出详细信息并以可读大小显示文件大小 查看目录或文件所占用磁盘大小 du -sh# 语法du [option] [name] -h 以人类可读的方式显示-a：显示目录占用的磁盘空间大小，还要显示其下目录和文件占用磁盘空间的大小-s：显示目录占用的磁盘空间大小，不要显示其下子目录和文件占用的磁盘空间大小-c：显示几个目录或文件占用的磁盘空间大小，还要统计它们的总和–apparent-size：显示目录或文件自身的大小-l ：统计硬链接占用磁盘空间的大小-L：统计符号链接所指向的文件占用的磁盘空间大小 # 常用du -sh 查看当前目录总共占的容量。而不单独列出各子项占用的容量 du -lh --max-depth=1 : 查看当前目录下一级子文件和子目录占用的磁盘容量。du -sh * | sort -n 统计当前文件夹(目录)大小，并按文件大小排序du -sk filename 查看指定文件大小 文件传输 scp命令scp -h # 查看帮助scp -v # 显示进度scp -P # 选择端口scp -r # 传输目录 从本地将文件传输到服务器scp【本地文件的路径】【服务器用户名】@【服务器地址】：【服务器上存放文件的路径】scp /Users/mac_pc/Desktop/test.png root@192.168.1.1:/root 从本地将文件夹传输到服务器scp -r【本地文件的路径】【服务器用户名】@【服务器地址】：【服务器上存放文件的路径】sup -r /Users/mac_pc/Desktop/test root@192.168.1.1:/root 将服务器上的文件传输到本地scp 【服务器用户名】@【服务器地址】：【服务器上存放文件的路径】【本地文件的路径】scp root@192.168.1.1:/data/wwwroot/default/111.png /Users/mac_pc/Desktop 将服务器上的文件夹传输到本地scp -r 【服务器用户名】@【服务器地址】：【服务器上存放文件的路径】【本地文件的路径】sup -r root@192.168.1.1:/data/wwwroot/default/test /Users/mac_pc/Desktop grep使用# -w精确匹配grep -w '192.168.20.1' test.txt# 或者grep '\\' test.txt grep -C1 只输出匹配以及其上下各一行 echo的使用# 输出内容echo \"test\"# 输出空行echo echo -e '\\n\\n'# 输出，但不换行echo -n \"test\" traceroute 路由追踪\btraceroute可以追踪网络数据包，并展现路由途径 通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址 https://tools.ipip.net/traceroute.php 使用首先你要下载tracerouteyum install traceroute -y traceroute [参数] 主机 实战[root@gogogo ~]# traceroute www.baidu.comtraceroute to www.baidu.com (180.101.49.11), 30 hops max, 60 byte packets 1 10.0.0.130 (10.0.0.130) 1.151 ms 1.582 ms 2.369 ms 2 10.255.106.1 (10.255.106.1) 1.056 ms 1.647 ms 2.266 ms 3 10.128.0.1 (10.128.0.1) 0.441 ms 0.421 ms 0.389 ms 4 115.231.100.65 (115.231.100.65) 2.023 ms 2.055 ms 2.201 ms 5 10.100.128.21 (10.100.128.21) 1.844 ms 1.977 ms 2.696 ms 6 172.31.110.249 (172.31.110.249) 0.632 ms 0.645 ms 0.630 ms 7 172.31.123.53 (172.31.123.53) 0.536 ms 0.685 ms 0.623 ms 8 * * * 9 61.164.31.120 (61.164.31.120) 2.390 ms 220.191.194.116 (220.191.194.116) 3.258 ms 61.164.31.122 (61.164.31.122) 2.264 ms10 220.191.200.201 (220.191.200.201) 6.861 ms 220.191.200.217 (220.191.200.217) 6.413 ms 220.191.200.201 (220.191.200.201) 5.955 ms11 202.97.76.10 (202.97.76.10) 13.005 ms 202.97.75.174 (202.97.75.174) 14.885 ms 202.97.22.6 (202.97.22.6) 19.543 ms12 58.213.95.118 (58.213.95.118) 19.171 ms 58.213.95.2 (58.213.95.2) 14.327 ms 58.213.94.118 (58.213.94.118) 15.157 ms13 * 58.213.95.126 (58.213.95.126) 20.922 ms 58.213.95.134 (58.213.95.134) 16.233 ms14 58.213.96.102 (58.213.96.102) 14.907 ms 58.213.96.94 (58.213.96.94) 15.467 ms 58.213.96.90 (58.213.96.90) 15.166 ms15 * * *16 * * *17 * * *18 * * *19 * * *20 * * *21 * * *22 * * *23 * * *24 * * *25 * * *26 * * *27 * * *28 * * *29 * * *30 * * * 最左边的是表示每一条的序号,从1开始，每一个序号表示一跳，每一跳表示一个网关第二个字段表示主机名和对应ip后面三个表示发送的三个包所返回的时间一行*号 有可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。 # 添加每次发送的数据包个数 traceroute -q 4 www.baidu.com# 不查主机名，仅显示ip地址traceroute -n www.baidu.com# 设置跳数数量traceroute -m 10 www.baidu.com# 发送到直连主机traceroute -r www.baidu.com 工作原理Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？ Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。 Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。 每次写到TTL值访问路由，每到达一个路由，TTL值减少1 到0返回， 重新装载比上次+1的TTL值访问路由，如此循环 记住他只记录路由, 如果是二层之间的机器访问是不是只有一条？ mtr 路由追踪MTR是Linux平台上一款非常好用的网络诊断工具，集成了traceroute、ping、nslookup的功能，用于诊断网络状态非常有用。下面请看简单介绍。 安装 yum install mtr -y 使用方法mtr ip或域名 My traceroute [v0.85]PG-VPN (0.0.0.0) Wed Oct 9 18:22:54 2019Resolver: Received error response 2. (server failure)er of fields quit Packets Pings Host Loss% Snt Last Avg Best Wrst StDev 1. 115.231.97.1 0.0% 20 0.8 1.0 0.8 1.3 0.0 2. 10.100.129.24 0.0% 20 0.9 0.9 0.9 1.0 0.0 3. 10.100.128.65 0.0% 20 0.9 1.0 0.9 1.1 0.0 4. 10.100.129.27 0.0% 20 1.3 1.1 1.0 1.3 0.0 5. 124.14.9.238 0.0% 20 4.0 4.1 3.8 4.3 0.0 第一列(Host) : IP地址和域名 按n键可以切换IP和域名第二列(Loss%): 丢包率第三列(Snt): 设置每秒发送数据包的数量，默认是10 可以通过参数-c来指定第四列(Last)： 最近一次的Ping值第五六七列(AVG BEST WRST) : 分别是Ping的平均 最好 最差值第八列(StDev): 标准偏差 其他用法$ mtr -h #提供帮助命令$ mtr -v #显示mtr的版本信息$ mtr -r #已报告模式显示$ mtr -s #用来指定ping数据包的大小$ mtr --no-dns #不对IP地址做域名解析$ mtr -a #来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的$ mtr -i #使用这个参数来设置ICMP返回之间的要求默认是1秒$ mtr -4 #IPv4$ mtr -6 #IPv6 域名查询工具 dig常用的域名查询工具，可以用来测试域名系统工作是否正常 dig (选项)(参数)alpaca@hzj  ~  dig www.baidu.com; DiG 9.10.6 www.baidu.com;; global options: +cmd;; Got answer:;; ->>HEADER","link":"/posts/f6c82bc1/"},{"title":"linux 常用命令2","text":"learn linux dmesgdmesg 命令可以列出系统启动时硬件检测和驱动加载的情况，以及后续由内核生成的其他信息。 [root@gogogo ~]# dmesg[ 0.000000] Linux version 5.3.0-1.el7.elrepo.x86_64 (mockbuild@Build64R7) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC)) #1 SMP Mon Sep 16 08:44:46 EDT 2019[ 0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-5.3.0-1.el7.elrepo.x86_64 root=UUID=f13d84b4-c756-4d89-9d5e-6b534397aa14 ro console=tty0 crashkernel=auto console=ttyS0,115200[ 0.000000] Disabled fast string operations[ 0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'[ 0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'[ 0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'[ 0.000000] x86/fpu: xstate_offset[2]: 576, xstate_sizes[2]: 256[ 0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'standard' format.[ 0.000000] BIOS-provided physical RAM map:[ 0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009bbff] usable[ 0.000000] BIOS-e820: [mem 0x000000000009bc00-0x000000000009ffff] reserved[ 0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved[ 0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000007fffcfff] usable[ 0.000000] BIOS-e820: [mem 0x000000007fffd000-0x000000007fffffff] reserved[ 0.000000] BIOS-e820: [mem 0x00000000fffbc000-0x00000000ffffffff] reserved[ 0.000000] NX (Execute Disable) protection: active[ 0.000000] SMBIOS 2.4 present.[ 0.000000] DMI: RDO Project OpenStack Nova, BIOS 0.5.1 01/01/2007[ 0.000000] Hypervisor detected: KVM[ 0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 内核加载开始记录，记录时打印出来我们可以使用他来看是否有识别到一些外部加入的设备，比如识别USB 鼠标 串口等等[1206367.860755] usb 2-1.6: FTDI USB Serial Device converter now attached to ttyUSB0 比如这一条就是识别到了一个USB设备,检测设备是否可用,echo “test” >> /dev/ttyUSB0 常用命令因为dmesg是从内核加载开始后记录的，记录的内容太长，如果我们要过滤 ，还要加入管道和grep来筛选 dmesg | head -20 # 只输出前20行日志dmesg | tail -20 # 只输出后20行日志dmesg | grep -i usb # 只筛选出有usb日志行的 -i 忽略大小写dmesg | grep -E -i \"eth|sda\" # 只筛选包含字符串“eth”或“sda”的日志行 lspcilspci 命令可以列出系统中的 PCI 总线及其连接的设备。该命令的输出如下：什么是PCIhttps://zh.wikipedia.org/wiki/%E5%A4%96%E8%AE%BE%E7%BB%84%E4%BB%B6%E4%BA%92%E8%BF%9E%E6%A0%87%E5%87%86 [root@gogogo ~]# lspci00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma] (rev 02)00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]00:01.1 IDE interface: Intel Corporation 82371SB PIIX3 IDE [Natoma/Triton II]00:01.2 USB controller: Intel Corporation 82371SB PIIX3 USB [Natoma/Triton II] (rev 01)00:01.3 Bridge: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 03)00:02.0 VGA compatible controller: Cirrus Logic GD 544600:03.0 Ethernet controller: Red Hat, Inc. Virtio network device00:04.0 SCSI storage controller: Red Hat, Inc. Virtio block device00:05.0 SCSI storage controller: Red Hat, Inc. Virtio block device00:06.0 RAM memory: Red Hat, Inc. Virtio memory balloon 输出信息中包括声音（Multimedia audio controller），USB设备（USB controller），视频输出（VGA compatible controller），有线网卡（Ethernet controller）和磁盘（SATA controller）等。如需获取更详尽的信息，还可以在该命令后增加一至多个 -v 选项（如 -vvv）。 lsusb查看usb设备的情况 找出连接了多少usb设备 find /dev/bus 列出某台USB设备的详细信息 lsusb -D /dev/bus/usb/001/002 以树层结构列出 USB 设备 lsusb -t 如需获取更详尽的信息，还可以在该命令后增加一至多个 -v 选项（如 -vvv） lsblklsblk 命令用于列出所有可用块设备的信息，还能显示他们之间的依赖关系。块设备有硬盘，闪存盘，cd-ROM等等。 [root@test-ceph ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 447.1G 0 disk├─sda1 8:1 0 200M 0 part /boot/efi├─sda2 8:2 0 1G 0 part /boot└─sda3 8:3 0 446G 0 part ├─centos-root 253:0 0 50G 0 lvm / ├─centos-swap 253:1 0 7.8G 0 lvm [SWAP] └─centos-home 253:2 0 388.1G 0 lvm /homesdb 8:16 0 1.8T 0 disk├─sdb1 8:17 0 8G 0 part├─sdb2 8:18 0 4G 0 part├─sdb3 8:19 0 40G 0 part└─sdb4 8:20 0 1.8T 0 partsdc 8:32 0 1.8T 0 disksdd 8:48 0 1.8T 0 disksde 8:64 0 1.8T 0 disksdf 8:80 1 7.5G 0 disk├─sdf1 8:81 1 918M 0 part└─sdf2 8:82 1 8.5M 0 part NAME: 块设备名MAJ:MIN: 主要和次要设备号RM: 设备是否属于可移动设备，如sdb的RM值为1 ，是可移动设备SIZE: 设备的容量大小信息RO: 设备是否为只读TYPE: 设备是磁盘还是磁盘上的一个分区MOUNTPOINT: 设备的挂载点 sda 是盘 sda1是区 lsblk -m # 显示设备所有者相关的信息，包括文件的所属用户、所属组以及文件系统挂载的模式[root@gogogo ~]# lsblk -mNAME SIZE OWNER GROUP MODEvdb 40G root disk brw-rw----vda 20G root disk brw-rw----└─vda1 20G root disk brw-rw---- blkid显示关于块的信息 blkid # 显示所有可用信息 和唯一识别idblkid /dev/sad1 # 特指blkid -U # 设备blkid -g # 清除缓存 lscpulscpu 命令可以获得 CPU 的详细信息，如CPU架构（如 i686 或 x86_64）、运算模式（32bit 或 64bit）、核心数、每颗核心的线程数、型号、主频等。 lsmod如果你新增加了硬件，却不能被系统自动识别。可能你需要手动地加载对应的内核模块。内核模块安装在 /lib/modules/ 的子目录下，该子目录的名字对应内核的版本。即 /lib/modules/4.10.0-19-generic 目录下包含了 4.10.0-19-generic 内核的驱动程序 [root@gogogo ~]# lsmodModule Size Used bycrct10dif_pclmul 16384 1crc32_pclmul 16384 0ghash_clmulni_intel 16384 0aesni_intel 372736 0cirrus 16384 0crypto_simd 16384 1 aesni_intelcryptd 24576 2 crypto_simd,ghash_clmulni_intelglue_helper 16384 1 aesni_inteldrm_kms_helper 176128 3 cirrusjoydev 24576 0input_leds 16384 0drm 487424 3 drm_kms_helper,cirrusinput_leds 16384 0drm 487424 3 drm_kms_helper,cirrusvirtio_balloon 24576 0 获取已加载模块的信息，可以使用modinfo命令 modinfo drm[root@gogogo ~]# modinfo drmfilename: /lib/modules/5.3.0-1.el7.elrepo.x86_64/kernel/drivers/gpu/drm/drm.kolicense: GPL and additional rightsdescription: DRM shared core routinesauthor: Gareth Hughes, Leif Delgass, José Fonseca, Jon Smirllicense: GPL and additional rightsdescription: DRM bridge infrastructureauthor: Ajay Kumar license: GPL and additional rights 另外，还可以使用 modprobe 命令加载模块，rmmod 命令移除模块。","link":"/posts/3f665668/"},{"title":"linux-mtr命令","text":"MTR是Linux平台上一款非常好用的网络诊断工具，集成了traceroute、ping、nslookup的功能，用于诊断网络状态非常有用。下面请看简单介绍。一旦你运行mtr ，它将探测本地系统和你指定的远程主机之间的网络连接。 它首先建立主机之间的每个网络跳跃点（网桥，路由器和网关等）的地址，然后ping每个跳跃点（发送一个序列ICMP ECHO请求）以确定到每台机器的链路的质量。 安装yum install mtr -y 使用方法mtr ip或域名 My traceroute [v0.85]PG-VPN (0.0.0.0) Wed Oct 9 18:22:54 2019Resolver: Received error response 2. (server failure)er of fields quit Packets Pings Host Loss% Snt Last Avg Best Wrst StDev 1. 115.231.97.1 0.0% 20 0.8 1.0 0.8 1.3 0.0 2. 10.100.129.24 0.0% 20 0.9 0.9 0.9 1.0 0.0 3. 10.100.128.65 0.0% 20 0.9 1.0 0.9 1.1 0.0 4. 10.100.129.27 0.0% 20 1.3 1.1 1.0 1.3 0.0 5. 124.14.9.238 0.0% 20 4.0 4.1 3.8 4.3 0.0 第一列(Host) : IP地址和域名 按n键可以切换IP和域名第二列(Loss%): 丢包率第三列(Snt): 设置每秒发送数据包的数量，默认是10 可以通过参数-c来指定第四列(Last)： 最近一次的Ping值第五六七列(AVG BEST WRST) : 分别，是Ping的平均 最好 最差值第八列(StDev): 标准偏差，越大说明相应节点越不稳定。 判别 判断各区域是否存在异常，并根据各区域的情况分别处理。 区域 A：客户端本地网络，即本地局域网和本地网络提供商网络。针对该区域异常，客户端本地网络相关节点问题，请对本地网络进行排查分析；本地网络提供商网络相关节点问题，请向当地运营商反馈。 区域 B：运营商骨干网络。针对该区域异常，可根据异常节点 IP 查询归属运营商，然后直接或通过阿里云售后技术支持，向相应运营商反馈问题。 区域 C：目标服务器本地网络，即目标主机归属网络提供商网络。针对该区域异常，需要向目标主机归属网络提供商反馈问题。 查看节点丢包率，若 Loss% 不为零，则说明这一跳网络可能存在问题。 导致节点丢包的原因通常有两种： 人为限制了节点的 ICMP 发送速率，导致丢包。 节点确实存在异常，导致丢包 命令-h #提供帮助命令-v #显示mtr的版本信息-r #已报告模式显示-s #用来指定ping数据包的大小-i #使用这个参数来设置ICMP返回之间的要求默认是1秒-4 #默认IPv4-6 # 指定IPv6-c --report-cycles COUNT # 指定发送多少个数据包-r --report # 结果显示，并不动态显示-n --no-dns #不对IP地址做域名解析-p --split # 将每次追踪的结果分别列出来，而非如 --report 统计整个结果-a #来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的 使用mtr -r -c5 google.com > xx.log","link":"/posts/877ac6e6/"},{"title":"linux故障问题及解决方案","text":"linux故障问题及解决方案linux系统使用过程中 会遇到很多的故障和报错，与之对应的是一些快速的解决方案这里记录一下 忘记root密码，无法登陆服务器 centos7 解决方案 重启服务器 进入启动界面后选择e进入编辑引导 修改内容,在尾部添加rd.breaklinux16 /vmlinuz-3.10.0-123.el7.x86_64 root=UUID=449d53d1-84c2-40c0-b05e-d1900591d71b ro rd.lvm.lv=vg_kvm7usb/swap crashkernel=auto vconsole.keymap=us crashkernel=auto vconsole.font=latarcyrheb-sun16 rd.lvm.lv=vg_kvm7usb/root rhgb quiet LANG=en_US.UTF-8 rd.break ctrl+x 以当前设定开机开机后的互动式命令环境，並不是正常开机的系統，正常开机系統挂载在 /sysboo 且挂载成只读，必須重新挂载成可写入，才能修改密碼 重新挂在 /sysroot 并改成可读可写mount –o remount,rw /sysroot chroot 工作目录到/sysrootchroot /sysroot 设定新的root 密码passwd rootupyun1upyun1 在此情況下，SELinux 並沒有启动，对所有文件的更改，可能会造成文档的context 不正确，为确保开机时重新设定SELinux context，必須在根目录下添加隐藏文件.autorelabel。 避开selinuxtouch /.autorelabel 重启reboot centos7 解决方案二 重启服务器 按e编辑引导 修改re 为 rw 添加 init=/bin/bash linux16 /vmlinuz-3.10.0-123.el7.x86_64 root=UUID=449d53d1-84c2-40c0-b05e-d1900591d71b rw rd.lvm.lv=vg_kvm7usb/swap crashkernel=auto vconsole.keymap=us crashkernel=auto vconsole.font=latarcyrheb-sun16 rd.lvm.lv=vg_kvm7usb/root rhgb quiet LANG=en_US.UTF-8 init=/bin/bash ctrl+x 以当前设定开机 重置密码passwd rootupyun1upyun1 避开selinuxtouch /.autorelabel 重启exec /sbin/init","link":"/posts/bc3af3e9/"},{"title":"linux常用命令","text":"linux常用命令记录一些经常使用的命令和命令组合 find (常用)find命令用来在指定目录下查找文件 find . # 列出当前目录及子目录下所有文件和文件夹find /home -name \"*.txt\" # 在/home目录下查找以.txt结尾的文件名find /home -iname \"*.txt\"# 在/home目录下查找以.txt结尾的文件名 ,忽略大小find . \\( -name \"*.txt\" -o -name \"*.pdf\" \\) # 当前目录及子目录下查找所有以.txt和.pdf结尾的文件find /home ! -name \"*.txt\" # 不是.txt结尾的文件find . -type # 类型参数 【f-普通文件，l-符号连接 ， d-目录 s-套接字 】find . -maxdepth 3 -type f # -maxdepth 指定深度find . -type f -size -10K # 搜索小于10K的文件 +10K 大于 find /usr/ -path \"*local\" # 匹配文件路径或者文件[root@lvs-web1 ~]# find /usr/ -path \"*local\"/usr/share/doc/postfix-2.10.1/examples/qmail-local/usr/share/aclocal/usr/libexec/postfix/local/usr/local 更加具体的https://man.linuxde.net/find chrootchroot主要用于修改系统的根分区，linux系统中常常是以/为根目录的 功能: 在忘记root密码的时候，进入单用户修改密码 隔离环境在经过 chroot 之后，在新根下将访问不到旧系统的根目录结构和文件，这样就增强了系统的安全性。这个一般是在登录 (login) 前使用 chroot，以此达到用户不能访问一些特定的文件系统读取的是新根下的目录和文件，这是一个与原系统根下文件不相关的目录结构。在这个新的环境中，可以用来测试软件的静态编译以及一些与系统不相关的独立开发。 构建临时系统lfs系统构建中，为了隔离原系统的目录，会用到chroot 用chroot构建linux临时环境 # 复制依赖库cd /root/xxmkdir /root/xx/bincp -av /bin/bash /root/xx/bin/bashmkdir /root/xx/lib64/# 复制依赖库文件cp -av /lib64/ld-linux-x86-64.so.2 /lib64/ld-2.12.so \\> /lib64/libc.so.6 /lib64/libc-2.12.so /lib64/libdl.so.2 \\> /lib64/libdl-2.12.so /lib64/libtinfo.so.5 \\> /lib64/libtinfo.so.5.7 /mnt/123/lib64 \\> /mnt/123/lib64……chroot /root/xx https://www.ibm.com/developerworks/cn/linux/l-cn-chroot/index.htmlhttps://www.cnblogs.com/sparkdev/p/8556075.html","link":"/posts/fe4ef317/"},{"title":"linux文件系统2","text":"linux文件系统2linux中有许多常用的文件，各自有各自主要的作用 ，怕忘记，这里做些笔记 /etc/hosts文件hosts —— the static table lookup for host name（主机名查询静态表）。hosts文件是Linux系统上一个负责ip地址与域名快速解析的文件，以ascii格式保存在/etc/目录下。hosts文件包含了ip地址与主机名之间的映射，还包括主机的别名。在没有域名解析服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的ip地址，否则就需要使用dns服务程序来解决。通过可以将常用的域名和ip地址映射加入到hosts文件中，实现快速方便的访问。优先级 ： dns缓存 > hosts > dns服务 —> 配置 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.0.5.91 lvs-master10.0.5.93 lvs-slave10.0.5.92 lvs-web1#10.0.5.90 lvs-web210.0.5.90 www.baidu.com# ip地址 主机名/域名 主机别名 相当于本地的域名解析，当你ping www.baidu.com的时候，会默认去ping 10.0.5.90","link":"/posts/cd527bc1/"},{"title":"keepalive+haproxy负载均衡","text":"haproxy负载均衡 # yum安装yum install haproxy -y # centos7默认版本是1.5# 查看包信息rpm -qi haproxy# 查看包所创建的目录rpm -ql haproxy —->主要目录主程序：/usr/sbin/haproxy配置文件：/etc/haproxy/haproxy.cfg启动服务：systemctl start haproxy停止服务：systemctl stop haproxy开机启动：systemctl enable haproxy —->配置文件结构 haproxy配置文件可分为全局配置（globalsettings）和 代理配置（proxies），而代理段配置包含defaults、frontend、backend、listen。 global settings：#全局参数配置，主要用于定义haproxy进程管理安全及性能相关的参数defaults < name >：#默认配置参数，下面的段继承该配置，名称是可选的,这配置默认配置参数可由下一个”defaults”所重新设定frontend < name >：#前端配置，定义一系列监听的套接字，这些套接字可接受客户端请求并与之建立连接，可以监听多个端口。backend < name >：#后端配置，定义后台服务器，前端代理服务器将会把客户端的请求调度至这些服务器，类似nginx中的upstreamlisten < name >：#定义一组前端和后端的完整代理，可理解为frontend+backend，通常用于tcp流量代理 —->配置参数可支持的时间单位 us : 微秒. 1 microsecond = 1/1000000 s ms : 毫秒. 1 millisecond = 1/1000 s s : 秒 1s = 1000ms m : 分 1m = 60s = 60000ms h : 小时 1h = 60m = 3600s = 3600000ms d : 天 1d = 24h = 1440m = 86400s = 86400000ms haproxy配置文件 全局配置参数(global) chroot: #修改haproxy的工作目录至指定的目录，并在放弃权限之前执行chroot（）操作，可以提升haproxy的安全级别，不过需要注意的是确保指定的目录为空目录且任何用户均不能有写权限;daemon: #让haproxy以守护进程的方式工作于后台，其等同于\"-D\"选项的功能，当然，也可以在命令行中以\"-db\"选项将其禁用;gid: #以指定的GID运行haproxy，建议使用专用于运行haproxy的GID，以避免因权限带来的风险;group: #同gid，不过这里为指定的组名;uid: #已指定的UID身份运行haproxy进程;user: #同uid，但这里使用的为用户名;log: #定义全局的syslog服务器，最多可以定义两个;nbproc: #指定启动的haproxy进程个数，只能用于守护进程模式的haproxy；默认为止启动一个进程，鉴于调试困难等多方面的原因，一般只在但进程仅能打开少数文件描述符的场中才使用多进程模式;pidfile: #pid文件的存放位置;ulimit-n: #设定每个进程所能够打开的最大文件描述符，默认情况下其会自动进行计算，因此不建议修改此选项;node: #定义当前节点的名称，用于HA场景中多haproxy进程共享同一个IP地址时;description: #当前实例的描述信息;maxconn: #设定每个haproxy进程所接受的最大并发连接数，其等同于命令行选项\"-n\"，\"ulimit-n\"自动计算的结果正式参照从参数设定的;maxpipes: #haproxy使用pipe完成基于内核的tcp报文重组，此选项用于设定每进程所允许使用的最大pipe个数，每个pipe会打开两个文件描述符，因此，\"ulimit -n\"自动计算的结果会根据需要调大此值，默认为maxcoon/4;noepoll: #在linux系统上禁用epoll机制;nokqueue: #在BSE系统上禁用kqueue机制;nopoll: #禁用poll机制;nosepoll: #在linux系统上禁用启发式epoll机制;nosplice: #禁止在linux套接字上使用tcp重组，这会导致更多的recv/send调用，不过，在linux2.6.25-28系列的内核上，tcp重组功能有bug存在;spread-checks: #在haprorxy后端有着众多服务器的场景中，在紧缺是时间间隔后统一对中服务器进行健康状况检查可能会带来意外问题，此选项用于将检查的时间间隔长度上增加或减少一定的随机时长，为当前检查检测时间的%;maxconnrate：#设置每个进程每秒种所能建立的最大连接数量，速率，一个连接里可以有多个会话，也可以没有会话maxsessrate：#设置每个进程每秒种所能建立的最大会话数量maxsslconn：#每进程支持SSL 的最大连接数量tune.bufsize: #设定buffer的大小，同样的内存条件下，较小的值可以让haproxy有能力接受更多的并发连接，较大的值了可以让某些应用程序使用较大的cookie信息，强烈建议使用默认值;tune.chksize: #设定检查缓冲区的大小，单位为字节，更大的值有助于在较大的页面中完成基于字符串或模式的文本查找，但也会占用更多的系统资源，不建议修改;tune.maxaccept: #设定haproxy进程内核调度运行时一次性可以接受的连接的个数，较大的值可以带来较大的吞吐量。tune.maxpollevents: #设定一次系统调用可以处理的事件最大数，默认值取决于OS,其至小于200时可介于带宽，但会略微增大网络延迟，但大于200时会降低延迟，但会稍稍增加网络带宽的占用;tune.maxrewrite: #设定在首部重写或追加而预留的缓存空间，建议使用1024左右的大小，在需要更大的空间时，haproxy会自动增加其值;tune.rcvbuf.client: #设定内核套接字中客户端接收缓存区的大小，单位为字节，强烈推荐使用默认值;tune.rcvbuf.server: #设定内核套接字中服务器接收缓存区的大小，单位为字节，强烈推荐使用默认值;tune.sndbuf.client: #设定内核套接字中客户端发送缓存区的大小，单位为字节，强烈推荐使用默认值;tune.sndbuf.server: #设定内核套接字中服务器端发送缓存区的大小，单位为字节，强烈推荐使用默认值;debug: #调试模式，输出启动信息到标准输出;quiet: #安装模式，启动时无输出; global默认配置 # 全局配置global log 127.0.0.1 local0 # 设置日志 log 127.0.0.1 local1 notice maxconn 4000 # 最大连接数 chroot /usr/local/haproxy # 安装目录 user haproxy group haproxy daemon # 守护进程运行 #nbproc 1 # 进程数量，只能用于守护进程模式的haproxy；默认启动一个进程，一般只在单进程仅能打开少数文件描述符的场景中才使用多进程模式； pidfile /var/run/haproxy.pid # pid文件的存放位置 defaults默认配置 defaults mode http #默认负载均衡模式为http log global #日志定义 option httplog #启用日志记录HTTP请求，默认不记录http log option dontlognull #不记录空日志 option httpclose # 每次请求完毕后主动关闭http通道 option forwardfor except 127.0.0.0/8 #插入x-forward标记，反向代理时候可以通过该字段获取客户端真实IP balance roundrobin # 负载均衡算法,轮询 retries 3 # 定义连接后端服务器的失败重连次数 timeout http-request 10s：#在客户端建立连接但不请求数据时，关闭客户端连接 timeout queue 1m : #服务器的maxconn时，连接在队列中保持挂起状态而设置的超时时间，想客户端返回503错误 timeout connect 10s： #定义haproxy将客户端请求转发至后端服务器所等待的超时时长 timeout client 1m：#客户端非活动状态的超时时长 timeout server 1m：#客户端与服务器端建立连接后，等待服务器端的超时时长 timeout http-keep-alive 10s: #定义保持连接的超时时长 timeout check 10s: #健康状态监测时的超时时间，过短会误判，过长资源消耗 maxconn 3000: #每个server最大的连接数 # 超时参数 timeout http request ：#在客户端建立连接但不请求数据时，关闭客户端连接 timeout queue ：#等待最大时长 timeout connect： #定义haproxy将客户端请求转发至后端服务器所等待的超时时长 timeout client：#客户端非活动状态的超时时长 timeout server：#客户端与服务器端建立连接后，等待服务器端的超时时长， timeout http-keep-alive ：#定义保持连接的超时时长 timeout check：#健康状态监测时的超时时间，过短会误判，过长资源消耗 listen默认配置 # 监听页面配置listen admin_stats bind 0.0.0.0:50000 # 监听IP和端口，为了安全可以设置本机的局域网IP及端口； mode http option httplog # 采用http日志格式 stats refresh 30s # 统计页面自动刷新时间 stats enable # 启用状态统计报告 stats uri /stats # 状态管理页面，通过 ip+port/stats来访问 如10.0.5.92:9999/stats stats realm \"LOGIN\" # 密码框上显示的文本 stats auth admin:psadmin # 统计页面用户名和密码设置 stats hide-version # 隐藏统计页面上HAProxy的版本信息 #errorfile 403 /usr/local/haproxy/examples/errorfiles/ #设置haproxy 错误页面 stats admin_stats if TRUE #如果认证通过就做管理功能，可以管理后端的服务器 前端配置 frontend http_main bind 0.0.0.0:80 # http请求的端口，会被转发到设置的ip及端口 # bind :80 # 监听本机所有ip80端口 # bind *:80 # bind 192.168.12.1:8080,10.1.0.12:8090 # 转发规则 #acl url_yuming path_beg www.yuming.com #use_backend server_yuming if url_yuming # 默认跳转项，当上面都没有匹配上，就转到backend的http_default上； default_backend http_default # 提升失败的时候的用户体验 #errorfile 502 /usr/local/haproxy/examples/errorfiles/502.http #errorfile 503 /usr/local/haproxy/examples/errorfiles/503.http #errorfile 504 /usr/local/haproxy/examples/errorfiles/504.http 后端配置 backend http_default # 额外的一些设置，按需使用 option forwardfor option forwardfor header Client-IP option http-server-close option httpclose # 负载均衡方式 #source 根据请求源IP #static-rr 根据权重 #leastconn 最少连接先处理;在有着较长时间会话的场景中推荐使用此算法，如LDAP、SQL等，其并不太适用于较短会话的应用层协议，如HTTP；此算法是动态的， #uri 根据请求的uri #url_param 根据请求的url参数 #rdp-cookie 据据cookie(name)来锁定并哈希每一次请求 #hdr(name) 根据HTTP请求头来锁定每一次HTTP请求 #roundrobin 轮询方式 balance roundrobin # 负载均衡的方式,轮询方式 # 设置健康检查页面 #option httpchk GET /index.html #传递客户端真实IP option forwardfor header X-Forwarded-For # 需要转发的ip及端口 # inter 2000 健康检查时间间隔2秒 # rise 3 检测多少次才认为是正常的 # fall 3 失败多少次才认为是不可用的 # weight 30 权重 server node1 192.168.1.101:8080 check inter 2000 rise 3 fall 3 weight 30 server node2 192.168.1.101:8081 check inter 2000 rise 3 fall 3 weight 30 常用参数bind 用于监听 bind []: [,...] [param*] # 仅在frontend和listen区域使用bind 0.0.0.0:80 # http请求的端口，会被转发到设置的ip及端口 # bind :80 # 监听本机所有ip80端口 # bind *:80 # bind 192.168.12.1:8080,10.1.0.12:8090 单台haproxy+两台RS服务器配置haproxy 服务器 10.0.5.93RS 服务器1 10.0.5.90RS 服务器2 10.0.5.91 初始化准备如果对防火墙没有太大的要求，可以直接关闭防护墙 所有机器都关闭 # 关闭防火墙systemctl stop firewalldsystemctl status firewalld# 安装haproxyyum install haproxy -y# 配置vi /etc/haproxy/haproxy.cfg haproxy服务器 DS # 基础配置global log 127.0.0.1 local0 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/statsdefaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 balance roundrobin timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 # 开启监听端口listen Status # 名字随便用 bind 10.0.5.93:9999 # 绑定监听端口 mode http stats enable stats uri /stats stats realm \"LOGIN\" stats refresh 6s stats auth upyun:upyun123# 端口转发listen web_server # 名字随便用 mode tcp #采用7层模式 bind *:7777 # 转发端口 请求7777 -> RS:8888 上面 因此这里的*:7777 可做vip -> keepalive balance roundrobin #负载均衡算法，这里是轮换 # 轮询算法 #option httpchk GET /test.test #健康检测 # 健康检测 server web1 10.0.5.91:8888 weight 3 check inter 500 fall 3 server web2 10.0.5.90:8888 weight 2 check inter 500 fall 3 查看haproxy 监听端状态不断请求10.0.5.93:7777 会发现ip会在90 与91 之间不断改变，因为我们采用了轮询的机制，相应的图中web total也会不断增加 while 1; do curl http://10.0.5.93:7777/|grep \"< h2 >.*< /h2 >\" ;sleep 1; done over keepalive+haproxy就是在上面的单台haproxy机器上 添加一台haproxy机器，同时利用keepalived的特性，使用vip在两台haproxy机器上漂移，无论vip漂移到哪个地方，都有对应的haproxy机器去对下面的两台RS机器进行负载均衡 keepalive 提高 haproxy的稳定性haproxy 提高 RS的稳定性 配置DS1 keepalive + haproxy 10.0.5.93DS2 keepalive + haproxy 10.0.5.92 RS1 10.0.5.91RS2 10.0.5.90 VIP 10.0.5.96监控端口 10.0.5.96:9999/statsVIP端口 10.0.5.96:8888 —- > 10.0.5.91:8888 DS1 keepalive配置 # 声明一下身份和vip就醒了! Configuration File for keepalivedglobal_defs { router_id LVS_DEVEL}vrrp_instance VI_1 { state MASTER interface eno1 virtual_router_id 51 priority 1000 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }} DS2 keepalived配置 ! Configuration File for keepalivedglobal_defs { router_id LVS_DEVEL}vrrp_instance VI_1 { state BACKUP interface eno1 virtual_router_id 51 priority 10 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }} 这时候你可以先测试一下keepalived是否成功，两边开起来，然后关掉DS-master机器，如果VIP漂移到DS-BACKUP上面则表示成功 DS1 haproxy配置 与 DS2 haproxy相同 global log 127.0.0.1 local0 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/statsdefaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 balance roundrobin timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000# 监听端口listen Status bind 10.0.5.96:9999 mode http stats enable stats uri /stats stats realm \"LOGIN\" stats refresh 6s stats auth upyun:upyun123# 这个80端口有什么用listen web_server mode tcp #采用7层模式 bind *:7777 balance roundrobin #负载均衡算法，这里是轮换 #option httpchk GET /test.test #健康检测 server web1 10.0.5.91:8888 weight 3 check inter 500 fall 3 server web2 10.0.5.90:8888 weight 2 check inter 500 fall 3 RS机器将VIP写入回源地址 ifconfig enp4s0:0 10.0.5.96 broadcast 10.0.5.96 netmask 255.255.240.0 up 另外，当我切断master-keepalived的是否，会有一定时间的延迟","link":"/posts/14c89e63/"},{"title":"keepalive+lvs 四层负载均衡","text":"关键词LB (Load Balancer 负载均衡)HA (High Available 高可用)Failover (失败切换)Cluster (集群)LVS (Linux Virtual Server Linux 虚拟服务器)DS (Director Server)，指的是前端负载均衡器节点RS (Real Server)，后端真实的工作服务器VIP (Virtual IP)，虚拟的 IP 地址，向外部直接面向用户请求，作为用户请求的目标的 IP 地址DIP (Director IP)，主要用于和内部主机通讯的 IP 地址RIP (Real Server IP)，后端服务器的 IP 地址CIP (Client IP)，访问客户端的 IP 地址 仅使用lvs单节点lvs 、 vip 两台RS服务器 vip: 10.0.5.97/20lvs-director: 10.0.5.92RS1: 10.0.5.90RS2: 10.0.5.91 在lvs上进行操作 # 安装lvsyum install ipvsadm -y # 安装net-toolsyum install net-tools# 在网卡上绑定vipifconfig eno1:0 10.0.5.97 broadcast 10.0.5.97 netmask 255.255.240.0 up# 添加路由route add -host 10.0.5.97 dev eno1# 启用系统的包转发功能echo \"1\" > /proc/sys/net/ipv4/ip_forward# 清空系统之前所有的ipvsadm规则ipvsadm --clearipvsadm -C# 增加虚拟ip (-s rr 表述轮询)ipvsadm -A -t 10.0.5.97:8888 -s rr# ipvsadm -D -t 10.0.5.97:8888 # 删除规则# 添加服务对象 -g表示工作模式为直接路由 端口必须一致ipvsadm -a -t 10.0.5.97:8888 -r 10.0.5.91:8888 -gipvsadm -a -t 10.0.5.97:8888 -r 10.0.5.92:8888 -g 在RS机上进行操作 # //RS1# 绑定VIP ifconfig eno1:0 10.0.5.91 broadcast 10.0.5.91 netmask 255.255.240.0 up# 添加路由route add -host 10.0.5.91 dev eno1:0#//RS2 同 lvs搭建成功后查看搭建状态 [root@lvs-web1 ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -> RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 10.0.5.97:8888 rr -> 10.0.5.90:8888 Route 1 0 0 -> 10.0.5.91:8888 Route 1 0 0 当你访问VIP地址的时候，VIP会指向其所服务的两个真实IP地址 在轮询模式下，一定时间后指向另一个ip 单节点lvs可能会出现错误，需要使用Keepalive+lvs 仅使用keepalive不使用RS服务器，仅使用两台DS服务器测试vip在两台DS之间保持活性的过程目的—-> 保证vip的活性 vip 10.0.5.96DS1: 10.0.5.93DS2: 10.0.5.90 在DS-Master机器上操作 # 安装keepalivedyum install keepalived# 修改配置文件! Configuration File for keepalivedglobal_defs { //全局配置 notification_email { //通知邮件， 当keepalived中master和backup身份改变的是否会发送邮件 acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL_master // 集群名字 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_instance VI_1 { //vrrp实例 + 名字(同集群名字需要相同) state MASTER // 当前机器身份 只能有一个master interface enp10s0 //当前网络接口 virtual_router_id 51 // 虚拟路由序号 主从需要相同 priority 100 // 优先级别 主> 从 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { //虚拟ip 10.0.5.96/20 }} 在DS-Backup机器上的操作 # 安装keepalivedyum install keepalived# 修改配置文件! Configuration File for keepalivedglobal_defs { notification_email { acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_instance VI_1 { state BACKUP // DS-backup机器 interface eno1 virtual_router_id 51 priority 10 //优先级别 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }} 主从机器启动keepalived后 可以发现现在的vip是在DS-master上的，为了验证master主机出现错误的时候，vip会漂移到DS-backup的现象，我们可以在master关闭keepalived以上，当master出现错误的时候，backup机器上出现vip，从而保证vip的活性，以此来保证lvs的稳定性 另外，当master机器再次重启的时候，vip又会飘回到master身上 keepalive+lvs 主从方式高可用主从模式需要准备四台服务器，均开启httpd服务 配置 vip 10.0.5.96DS1: 10.0.5.90 lvs-masterDS2: 10.0.5.93 lvs-slaveRS1: 10.0.5.91 lvs-web1RS2: 10.0.5.92 lvs-web2 # 测试ping lvs-master 首先保证 90 93两台机器的keepalive搭建成功，配置参考上面的keepalived Keepalived主备配置文件区别： 01. router_id 信息不一致 02. state 状态描述信息不一致 03. priority 主备竞选优先级数值不一致 master机器上配置lvs vi /etc/keepalived/keepalived.confvirtual_server 10.0.5.96 8888 { //vip delay_loop 3 lb_algo rr // 负载均衡模式 rr--轮询 lb_kind DR // 负载均衡连接形式 直连路由 !persistence_timeout 50 protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 //连接端口 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }} backup机器上配置lvs vi /etc/keepalived/keepalived.confvirtual_server 10.0.5.96 8888 { delay_loop 3 lb_algo rr lb_kind DR !persistence_timeout 50 protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }} RS机器上配置只要是作为lvs服务的对象，这些步骤都要做，包括后面如果我们把ds-master机器在作为keepalived调度机的同时，也提供web服务的时候，就需要做这些步骤 # 绑定VIPifconfig lo:0 10.0.5.96 netmask 255.255.240.0 broadcast 10.0.5.96 up # 添加路由route add -host 10.0.5.96 dev lo:0# 抑制arpecho 2 > /proc/sys/net/ipv4/conf/all/arp_announce echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announceecho 1 > /proc/sys/net/ipv4/conf/all/arp_ignoreecho 1 >/proc/sys/net/ipv4/conf/lo/arp_ignore ## 永久抑制arpvi /etc/sysctl.confnet.ipv4.conf.lo.arp_ignore = 1net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_ignore = 1net.ipv4.conf.all.arp_announce = 2 同时启动keepalived，查看lvs连接状态 systemctl start keepalivedipvsadm -ln[root@localhost ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -> RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 10.0.5.96:8888 rr -> 10.0.5.91:8888 Route 1 0 0 -> 10.0.5.92:8888 Route 1 0 0 while 1; do curl http://10.0.5.96:8888/| grep '< h2 >.* ' ;sleep 1; done 可以看到 双主方式互为主从：主从都在工作；其中一个宕机了，VIP漂移到另一个上，提供服务 配置 vip1: 10.0.5.96vip2: 10.0.5.97RS1: 10.0.5.91RS2: 10.0.5.92DS1: 10.0.5.90DS2: 10.0.5.93 DS1 配置: ! Configuration File for keepalivedglobal_defs { router_id LVS_DEVEL_master}vrrp_instance VI_1 { state MASTER interface enp10s0 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }}virtual_server 10.0.5.96 8888 { delay_loop 3 lb_algo rr lb_kind DR protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }}vrrp_instance VI_2 { state BACKUP interface enp10s0 virtual_router_id 52 priority 11 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.97/20 }}virtual_server 10.0.5.97 8888 { delay_loop 3 lb_algo rr lb_kind DR protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }} DS2配置 ! Configuration File for keepalivedglobal_defs { router_id LVS_DEVEL}vrrp_instance VI_1 { state BACKUP interface eno1 virtual_router_id 51 priority 10 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }}virtual_server 10.0.5.96 8888 { delay_loop 3 lb_algo rr lb_kind DR protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }}vrrp_instance VI_2 { state MASTER interface eno1 virtual_router_id 52 priority 101 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.97/20 }}virtual_server 10.0.5.97 8888 { delay_loop 3 lb_algo rr lb_kind DR protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }}``` 两个配置都差不多，无非就是两台机器都作为对方机器的Master和Backup机器，同时拥有两个vip，注意权重的大小RS上的配置```bash#配置VIP到本地回环网卡lo上，并只广播自己ifconfig lo:0 172.17.100.100 broadcast 172.17.100.100 netmask 255.255.255.255 upifconfig lo:1 172.17.100.101 broadcast 172.17.100.101 netmask 255.255.255.255 up #配置本地回环网卡路由route add -host 172.17.100.100 lo:0route add -host 172.17.100.101 lo:1# 关闭arpvim /etc/sysctl.confnet.ipv4.conf.lo.arp_ignore = 1net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_ignore = 1net.ipv4.conf.all.arp_announce = 2 查看结果 关闭其中一个DS机器时，另外一台DS机器上出现三个IP ，自身IP+2个VIP https://www.cnblogs.com/f-ck-need-u/p/8492298.html#2-keepalived-lvs- sorry_server 和local RS如果RS都在同一刻down掉了的话，外界就无法访问网站了。因为vip已经没有了RS的去处，这里提供了两种解决方法 使用keepalived来配置一个服务页面。例如告诉外界客户端网站正在维护状态.使用sorry_server 来指向 某一个ip+端口, 因为是在所有RS都宕机的情况下sorry server提供的临时服务才生效，因此通常将sorry server配置在virtual_server中而非real_server中。 需要在master和backup节点上都配置sorry_server virtual_server 192.168.100.10 8888 { delay_loop 6 lb_algo wrr lb_kind DR protocol TCP sorry_server 127.0.0.1 8888# 也可以指向本地，需要开启httpd服务 开启keepalived 然后将两台RS的机器上的httpd服务全部停掉，会发现vip会漂移到两台DS中的其中一台上 使用local RS对于集群系统不大的情况下，DS 一般会比较空闲，这样就比较浪费资源。这时通常会将LVS Director自身也作为一个RS，一边提供web服务，一边提供调度功能，不过应该将它的调度权重设置低一点，以免影响负载均衡的性能。这称为local RS，local RS的RIP可以写Director上的任意地址(127.0.0.1都可以)。例如：virtual_server 192.168.100.10 8888 { .... real_server 127.0.0.1 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 1 nb_get_retry 2 delay_before_retry 1 }}} 两个不应该同时配置，因为如果local RS 坏了，sorry server肯定无法调度 脑裂解决方法在高可用（HA）系统中，当联系2个节点的“心跳线”断开时，本来为一整体、动作协调的HA系统，就分裂成为2个独立的个体。由于相互失去了联系，都以为是对方出了故障。两个节点上的HA软件像“裂脑人”一样，争抢“共享资源”、争起“应用服务”，就会发生严重后果——或者共享资源被瓜分、2边“服务”都起不来了；或者2边“服务”都起来了，但同时读写“共享存储”，导致数据损坏（常见如数据库轮询着的联机日志出错）。 添加冗余的心跳线，例如：双线条线（心跳线也HA），尽量减少“裂脑”发生几率； 设置仲裁机制。例如设置参考IP（如网关IP），当心跳线完全断开时，2个节点都各自ping一下参考IP，不通则表明断点就出在本端。不仅“心跳”、还兼对外“服务”的本端网络链路断了，即使启动（或继续）应用服务也没有用了，那就主动放弃竞争，让能够ping通参考IP的一端去起服务。更保险一些，ping不通参考IP的一方干脆就自我重启，以彻底释放有可能还占用着的那些共享资源。 脑裂原因： Keepalived配置里同一 VRRP实例如果 virtual_router_id两端参数配置不一致也会导致裂脑问题发生。 RS上开启了 iptables防火墙阻挡了心跳消息传输。 高可用服务器上心跳网卡地址等信息配置不正确，导致发送心跳失败。 其他服务配置不当等原因，如心跳方式不同，心跳广插冲突、软件Bug等 解决: 做好对裂脑的监控报警（如邮件及手机短信等或值班）.在问题发生时人为第一时间介入仲裁，降低损失。例如，百度的监控报警短倍就有上行和下行的区别。报警消息发送到管理员手机上，管理员可以通过手机回复对应数字或简单的字符串操作返回给服务器.让服务器根据指令自动处理相应故障，这样解决故障的时间更短. 强行关闭一个节点保证，避免争夺 检测当前服务器上是否存在vip 要赋予执行权限 while truedoif [ `ip a show eth0 |grep 10.0.0.3|wc -l` -ne 0 ]then echo \"keepalived is error!\"else echo \"keepalived is OK !\"fidone 自定义健康状态检测keepalived可以通过设置vrrp_script自定义 # 自定义VRRP实例健康检查脚本 keepalived只能做到对自身问题和网络故障的监控，Script可以增加其他的监控来判定是否需要切换主备vrrp_script chk_sshd { script \"killall -0 sshd\" # 示例为检查sshd服务是否运行中 interval 2 # 检查间隔时间 weight -4 # 检查失败降低的权重} keepalived自动配置# /keepalived.conf! Configuration File for keepalivedglobal_defs {router_id SLB-SAD}vrrp_script chk_upyun { ¦ ¦ ¦ script \"/etc/keepalived/bin/check_vip.sh\" ¦ ¦ ¦ interval 3}vrrp_instance upyun_lb { ¦ state MASTER ¦ interface eth3 ¦ virtual_router_id 20 ¦ priority 100 ¦ advert_int 1 ¦ notify_master /etc/keepalived/bin/change_master.sh ¦ notify_backup /etc/keepalived/bin/change_backup.sh ¦ authentication { ¦ ¦ ¦ auth_type PASS ¦ ¦ ¦ auth_pass upyun.com ¦ } ¦ track_script { ¦ ¦ ¦ chk_upyun ¦ } ¦ virtual_ipaddress { ¦ ¦ ¦ 192.168.147.20 label eth3:9 ¦ }} include /etc/keepalived/virserver.conf# virserver.confvirtual_server 192.168.147.20 8600 { ¦ delay_loop 2 ¦ lb_algo wrr ¦ lb_kind DR ¦ protocol UDP ¦ #persistence_timeout 5 ¦ real_server 192.168.13.250 8600 { ¦ ¦ ¦ weight 1 ¦ ¦ ¦ connect_port 8600 ¦ ¦ ¦ connect_timeout 5 ¦ ¦ ¦ nb_get_retry 1 ¦ ¦ ¦ delay_before_retry 1 ¦ }} 状态检测脚本 # check_backup # 修改状态从master-> backup 权重 100 -> 80 注销 notify_backup 注销include echo \"--- I am BACKUP #`date`\" >> /tmp/keepalived.logsed -r -i '/state/s^MASTER^BACKUP^g;/priority/s^100^80^g;/notify_backup/s@^@#@g;/include/s@^@#@g;' /etc/keepalived/keepalived.confsystemctl restart keepalived# check_masterecho \"+++ I am MASTER #`date`\" >> /tmp/keepalived.logsed -r -i '/state/s^BACKUP^MASTER^g;/priority/s^80^100^g;/notify_backup/s@#@@g;' /etc/keepalived/keepalived.confipvsadm --set 100 15 15systemctl restart keepalived 报错解决方案keepalived报错信息在/usr/log/messages下面 主服务器停止后，备用服务没有启用监控主服务器上的日志Jun 28 09:18:32 rust Keepalived_vrrp: receive an invalid ip number countassociated with VRID!Jun 28 09:18:32 rust Keepalived_vrrp: bogus VRRP packet received on eth0 !!!Jun 28 09:18:32 rust Keepalived_vrrp: VRRP_Instance(VI_1) Dropping receivedVRRP packet.HA 解决方案：改变配置文件/etc/keepalived/keepalived.conf 中virtual_route_id的值virtual_router_id 60 主从方都要改，默认为51 lvs默认超时时间过程，导致框架已经搭建成功，但是效果看不出来900 120 300这三个数值分别是TCP TCPFINUDP的时间.也就是说一条tcp的连接经过lvs后,lvs会把这台记录保存15分钟，就是因为这个时间过长，所以大部分人都会发现做好LVS DR之后轮询现象并没有发生，而且我也看到大部分的教程是没有说明这一点的，巨坑！！！！！！因为是实验性质，所以将此数值调整为非常小，使用以下命令调整在两台DS服务器上修改[root@DR1 keepalived]# ipvsadm -L --timeoutTimeout (tcp tcpfin udp): 900 120 300 [root@DR1 ~]# ipvsadm --set 1 2 1 概念篇Keepalived软件起初是专为LVS负载均衡软件设计的，用来管理并监控LVS集群系统中各个服务节点的状态，后来又加入了可以实现高可用（HA）的VRRP功能。于是keepalived除了能够管理LVS软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL等）的高可用解决方案软件 Keepalived软件主要是通过VRRP协议实现高可用功能的。 官网https://www.keepalived.org/ 主要功能–> 管理LVS负载均衡–> 实现LVS集群节点的健康检查–> 作为系统网络服务的高可用性（failover） 运行流程在 Keepalived服务正常工作时，主 Master节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备Backup节点自己还活看，当主 Master节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master节点的心跳了，于是调用自身的接管程序，接管主Master节点的 IP资源及服务。而当主 Master节点恢复时，备Backup节点又会释放主节点故障时自身接管的IP资源及服务，恢复到原来的备用角色。 配置文件说明全局配置，一般保留路由标识信息就可以了 global_defs { #全局配置 notification_email { #定义报警邮件地址 acassen@firewall.loc failover@firewall.loc # 收件人 sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc #定义发送邮件的地址 smtp_server 192.168.200.1 #邮箱服务器 smtp_connect_timeout 30 #定义超时时间 router_id LVS_DEVEL #定义路由标识信息，相同局域网唯一 } 虚拟ip配置 brrp vrrp_instance VI_1 { #定义实例 state MASTER #状态参数 master/backup 只是说明 interface eth0 #虚IP地址放置的网卡位置 virtual_router_id 51 #vrrp_instance的唯一标识 priority 100 # keepalived权重,数值越大权重越大,MASTER应大于BACKUP advert_int 1 #发送心跳间隔,如果backup1秒收不到心跳就接管,单位是秒 authentication { # ↓ auth_type PASS #↓ auth_pass 1111 #认证 } #↑ virtual_ipaddress { #↓ 192.168.200.16 #vip 192.168.200.17 192.168.200.18 } nopreempt # 设置不抢占功能 #nopreempt 表示主节点故障恢复后不再切回到主节点，让服务一直在备用节点下工作，直到备用节点出现故障才会进行切换。 preemtp_delay 300 # 设置抢占延时时间，单位是秒。} lvs配置 #相当于 ipvsadm -A -t 192.168.0.89:80 -s wrr virtual_server 192.168.0.89 80 { delay_loop 6 #服务健康检查周期,单位是秒 lb_algo wrr #调度算法 lb_kind DR #模式 nat_mask 255.255.255.0 persistence_timeout 50 #回话保持时间,单位是秒 protocol TCP #TCP协议转发 sorry_server # 当所有 real server 失效后，指定的 Web 服务器的虚拟主机地址。#添加后端realserver#相当于 ipvsadm -a -t 192.168.0.89:80 -r 192.168.0.93:80 -w 1 real_server 192.168.0.93 80 { #realserver的真实IP weight 1 #权重 #健康检查 TCP_CHECK { connect_timeout 8 #超时时间 nb_get_retry 3 #重试次数 delay_before_retry 3 #重试间隔 connect_port 80 #检查realserver的80端口,如果80端口没监听,就会从集群中剔除 } } real_server 192.168.0.94 80 { weight 1 TCP_CHECK { connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 80 } }} ipvsadm 概念篇添加虚拟服务器 语法:ipvsadm -A [-t|u|f] [vip_addr:port] [-s:指定算法] -A:添加 -t:TCP协议 -u:UDP协议 -f:防火墙标记 -D:删除虚拟服务器记录 -E:修改虚拟服务器记录 -C:清空所有记录 -L:查看添加后端RealServer 语法:ipvsadm -a [-t|u|f] [vip_addr:port] [-r ip_addr] [-g|i|m] [-w 指定权重] -a:添加 -t:TCP协议 -u:UDP协议 -f:防火墙标记 -r:指定后端realserver的IP -g:DR模式 -i:TUN模式 -m:NAT模式 -w:指定权重 -d:删除realserver记录 -e:修改realserver记录 -l:查看通用: ipvsadm -ln:查看规则 service ipvsadm save:保存规则 lvs的几种调度算法 RR：roundrobin轮询,后端RS均摊所有的请求 WRR weighted RR加权轮询，根据权值来分配请求的数量 SH：Source Hashin[root@lvs-web1 ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags-> RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 10.0.5.97:8888 rr-> 10.0.5.90:8888 Route 1 0 0-> 10.0.5.91:8888 Route 1 0 0g DH：Destination Hashing LC：least connections WLC：Weighted LC 具体的调度算法 其他概念什么是VRRPVRRP是Virtual Router RedundancyProtocol(虚拟路由器冗余协议）的缩写，VRRP出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行。VRRP通过一种竞选机制来将路由的任务交给某台VRRP路由器的。https://www.cnblogs.com/f-ck-need-u/p/8483807.html keepalived官网http://www.keepalived.org keepalived高可用架构图 网址高并发场景 LVS 安装及高可用实现https://www.cnblogs.com/clsn/p/7920637.html#auto_id_30VRRP原理和分析https://www.jianshu.com/p/4b46586e79aaHaproxy+Keepalived高可用环境部署梳理（主主和主从模式）https://blog.51cto.com/dengaosky/2129856 https://www.cnblogs.com/f-ck-need-u/p/8492298.html#3-keepalived-lvs-Keepalived+LVS的高可用集群网站架构https://www.cnblogs.com/along21/p/7841132.html#auto_id_6","link":"/posts/a33a1a7d/"},{"title":"电商后台管理系统(vue)-搭建基本环境","text":"elementUI电商项目1 创建基本环境# 安装各种内容yum install nodejs,vue,vue-cli 使用vue构建项目# 创建项目的过程其实有很多种，一般建议用ui可视化创建和命令行创建，这里用可视化创建来举例子vue ui 这里会给我们创建一个项目管理器，在里面我们可以创建项目和导入项目点击创建项目,输入完信息以后，选择模版，点击完成。 项目运行的几种方式npm run # 会出现运行项目的几种方式，基础的配置中会出现下面三个 serve vue-cli-service serve build vue-cli-service build lint vue-cli-service lint serve是热更新本地运行build是打包项目lint是编码规范检查 项目部署 github-page部署因为我已经部署了博客，所以这里就先不用这种部署方式了url:https://cli.vuejs.org/guide/deployment.html#github-pages有用到的地方可以看一下 docker-nginx部署这个之后马上就要用到了，docker+nginx的使用。","link":"/posts/f538ba9d/"},{"title":"电商后台管理系统(vue)-login模块","text":"login模块 login模块登陆验证功能element-ui为我们提供了良好的验证功能模块 在el-form中绑定rules 编写规则 对应输入框指定prop传出信息 登陆 重置 export default { data() { return { form: { username: \"admin\", password: \"admin\" }, // 定义规则 rules: { username: [ // 空验证和格式验证 { required: true, message: '错误', trigger: 'blur' }, { min: 3, max: 5, message: '长度在 3 到 5 个字符', trigger: 'blur' } ], password: [ { required: true, message: '错误', trigger: 'blur' }, { min: 3, max: 5, message: '长度在3到5个字符',trigger: 'blur'} ], } }; }};#app { background-color: #2b4b6b; height: 100%;}.login_box { width: 450px; height: 300px; background-color: #fff; border-radius: 3px; position: absolute; left: 50%; right: 50%; top: 50%; transform: translate(-50%, -50%);}.login_form{ position: absolute; bottom: 0; width: 100%; padding: 0 20px; box-sizing: border-box;}.btns { display: flex; justify-content: flex-end;} 重置表单 resetFields使用ref声明对象名称给标签添加ref 写成方法，传递refname到script中 重置 重置表单 methods: { //重置form表格 resetForms(loginform) { this.$refs[loginform].resetFields(); } 表单预验证 vaildate给标签添加ref 写成方法，传递refname到script中 登陆 登陆表单 methods: { //登陆form表格 login(editForm){ this.$refs[editForm].validate(vaild => { console.log(vaild) }); } 消息提示message局部引用message组件 import { Message } from 'element-ui'Vue.prototype.$message = Message 标签绑定属性 登陆 重置 script中编写逻辑 this.$message.success(\"登陆成功\"); 前端获取token存放 methods: { //重置form表格 resetForms(editForm) { //根据refs获取实例对象，得到对象以后调用element-ui方法重置字段 this.$refs[editForm].resetFields(); this.$message.success(\"重置成功\"); }, login(editForm) { // 获取对象内容，根据状态码验证是否登陆成功，并返回消息弹窗 this.$refs[editForm].validate(async vaild => { if (!vaild) return; const { data: data, status: status } = await this.$http.post( \"login/\", this.form ); //这里有个bug 不应该是直接拿的status状态码来看，而是应该应该拿到result返回数据中的status来看，由于前面接口没有写好，所以这里只能根据浏览器返回的status来看 if (status != 200) return this.$message.error(\"登陆失败\"); this.$message.success(\"登陆成功\"); window.sessionStorage.setItem(\"token\", data.token); //存放token this.$router.push(\"/home\"); }); } }}; 路由导航权限路由导航守卫控制访问权限如果用户没有登陆，但是直接通过URL访问特定页面，需要重新导航到登陆页面 原来的路由导航 const routes = [ { path: '/' , redirect: '/login'}, { path: '/login' ,component: Login }, { path: '/home',component: Home}] 修改成路由导航守卫后 //router.jsconst routes = [ { path: '/' , redirect: '/login'}, { path: '/login' ,component: Login }, { path: '/home',component: Home}]const router = new VueRouter({ mode: 'history', // base: process.env.BASE_URL, routes})// 挂载路由导航守卫router.beforeEach((to,form,next) => { // to 将要访问的路径 // from 代表从那个路径跳转过来 // next 是一个函数,表示放行 // next() 放行 next('/login') 强制跳转 if (to.path === '/login') return next() //获取token const tokenStr = window.sessionStorage.getItem('token') if(!tokenStr) return next('/login') next()})export default router 登陆与注销基于token的方式实现退出比较简单，只需要本地的token即可，这样，后续的请求就不会携带token，必须重新生成一个新的token之后才可以访问页面 /home 退出 export default { methods:{ Userexit(){ window.sessionStorage.clear(); this.$router.push('/login'); this.$message.success(\"退出成功\"); } }};","link":"/posts/4dba38f8/"},{"title":"电商后台管理系统(vue)-home模块","text":"home模块 home模块 通过接口获获取菜单数据通过axios请求拦截器添加token，保证拥有获取数据的权限","link":"/posts/403006fc/"},{"title":"项目注意点","text":"vue项目注意点 项目注意点export default {} scoped 关键字用在样式标签中，主要是表示该样式是只使用于当前的vue组件","link":"/posts/6cd97811/"},{"title":"二层交换机","text":"二层交换机知识 图片笔记 somethings二层交换机，只能在相同vlan间通信，因此在业务上配置二层交换机的同时，需要知道对端交换机的vlan是如何划分的对于多vlan之间的交互，需要在端口上设置trunk的模式，另外服务器在端口上只允许access的模式，也就是说switch — 上联switch(trunk)switch — 下联server(access) 如果交换机对端设置了dynamic,则本端也需要设置dynamic模式 dynamic与static两种聚合模式的区别 首先需要明确链路聚合的概念：链路聚合是将两个或更多数据信道结合成一个单个的信道，该信道以一个单个的更高带宽的逻辑链路出现。链路聚合一般用来连接一个或多个带宽需求大的设备，例如连接骨干网络的服务器或服务器群。 区别如下： 静态聚合模式：配置聚合的端口数量是固定的，聚合后的带宽也是固定的； 动态聚合模式：实际聚合的端口数量是根据流量策略动态调整的，聚合带宽也会随之变化。例如在低负载时有2个端口参与聚合，高负载时会有4个端口参与聚合，从而更好的满足应用的要求。 静态聚合，就是人工设定把多条信道分开或者合并动态聚合就是系统自动分配信道 h3c文档 look..look 直接透传和间接透传 直接透传就是某个数据包在两个直连链路的两个端口间传输，数据包的VLAN标记没有发生任何变化。如两个直连的Trunk口，两个端口的PVID 都是vlan 1，VLAN 2的数据包从Trunk口A发送出来，被另一端的Trunk口B接收，收发之间，VLAN 2的数据包无任何改变。 间接透传就是数据包在两个直连端口链路间传输时，在两个端口收发时，数据包的VLAN标签会发生改变，但是最终数据包的VLAN还是没变。如两个直连的Trunk口，两个端口的PVID 都是vlan 1，VLAN 1的数据包从Trunk口A发送出来，此时被剥除VLAN 1的信息，被另一端的Trunk口B接收，此时又被添加VLAN 1的信息。收发之间，VLAN 2的数据包先是被剥离VLAN信息，然后在接收端又被打上原先的VLAN1信息。不管是哪种方式透传，透传的结果都是数据包的最终VLAN信息在经历端口收发后，都不改变。 vlan与交换机端口模式Access，Hybrid，TrunkVLAN（Virtual Local Area Network）的中文名为”虚拟局域网”。VLAN是一种将局域网设备从逻辑上划分成一个个网段，从而实现虚拟工作组的新兴数据交换技术。这一新兴技术主要应用于交换机和路由器中，但主流应用还是在交换机之中。但又不是所有交换机都具有此功能，只有VLAN协议的第二层以上交换机才具有此功能。802.1Q的标准的出现打破了虚拟网依赖于单一厂商的僵局，从一个侧面推动了VLAN的迅速发展。交换机端口有三种工作模式，分别是Access，Hybrid，Trunk。 Access类型的端口只能属于1个VLAN，一般用于连接计算机的端口； Trunk类型的端口可以允许多个VLAN通过，可以接收和发送多个VLAN的报文，一般用于交换机之间连接的端口； Hybrid类型的端口可以允许多个VLAN通过，可以接收和发送多个VLAN的报文，可以用于交换机之间连接，也可以用于连接用户的计算机。Hybrid端口和Trunk端口在接收数据时，处理方法是一样的，唯一不同之处在于发送数据时：Hybrid端口可以允许多个VLAN的报文发送时不打标签，而Trunk端口只允许缺省VLAN的报文发送时不打标签。 untag就是普通的ethernet报文，普通PC机的网卡是可以识别这样的报文进行通讯；tag报文结构的变化是在源mac地址和目的mac地址之后，加上了4bytes的vlan信息，也就是vlan tag头；一般来说这样的报文普通PC机的网卡是不能识别的因此对于Pc机来说，只允许使用在传输数据时，不带标签的模式access Access、Trunk、Hybrid三种端口模式接收发数据状态在网络的分层结构和宽带的合理分配方面，TRUNK被解释为“端口汇聚”，是带宽扩展和链路备份的一个重要途径。TRUNK把多个物理端口捆绑在一起当作一个逻辑端口使用，可以把多组端口的宽带叠加起来使用。TRUNK技术可以实现TRUNK内部多条链路互为备份的功能，即当一条链路出现故障时，不影响其他链路的工作，同时多链路之间还能实现流量均衡，就像我们熟悉的打印机池和MODEM池一样。 Acess端口收报文: 收到一个报文,判断是否有VLAN信息：如果没有则打上端口的PVID，并进行交换转发,如果有则直接丢弃（缺省） trunk端口收报文： 收到一个报文，判断是否有VLAN信息：如果没有则打上端口的PVID，并进行交换转发，如果有判断该trunk端口是否允许该 VLAN的数据进入：如果允许则报文携带原有VLAN标记进行转发，否则丢弃该报文。 hybrid端口收报文： 收到一个报文,判断是否有VLAN信息：如果没有则打上端口的PVID，并进行交换转发，如果有则判断该hybrid端口是否允许该VLAN的数据进入：如果可以则转发，否则丢弃 Acess端口发报文：将报文的VLAN信息剥离，直接发送出去 trunk端口发报文：比较端口的PVID和将要发送报文的VLAN信息，如果两者相等则剥离VLAN信息，再发送，否则报文将携带原有的VLAN标记进行转发。 hybrid端口发报文：1、判断该VLAN在本端口的属性 2、如果是untag则剥离VLAN信息，再发送，如果是tag则比较端口的PVID和将要发送报文的VLAN信息，如果两者相等则剥离VLAN信息，再发送，否则报文将携带原有的VLAN标记进行转发 实践经过实验，我们可以知道一些配置在某些情况下是相同的比如上联的信息是这样的 interface Ten-GigabitEthernet1/0/9 port link-mode bridge description CCM@UPYUN-KC-ALS-06 port link-type trunk undo port trunk permit vlan 1 port trunk permit vlan 1000 port trunk pvid vlan 1000 从上面的内容可以知道，只允许标签为1000的数据进入 可以这样配置 vlan 1000ip address 10.0.5.124 20ip router-static 0.0.0.0 0 10.0.0.130 也可以这样配置 int bridge 1000int g1/0/5port link-aggretion group 1000int g 1/0/6port link-aggretion group 1000int bridge 1000[10.0.5.125-Bridge-Aggregation1000]dis this#interface Bridge-Aggregation1000 port link-type trunk undo port trunk permit vlan 1 port trunk permit vlan 1000 port trunk pvid vlan 1000#return trunk在对端相同vlan-id的时候同样会剥离vlan的id信息 级连、堆叠、集群级连https://baike.baidu.com/item/%E7%BA%A7%E8%BF%9E 什么是pvidPVID英文为Port-base VLAN ID，是表示网络通信中基于端口的VLAN ID，一个端口可以属于多个VLAN，但是只能有一个PVID，收到一个不带tag头的数据包时，会打上PVID所表示的VLAN号，视同该VLAN的数据包处理一个物理端口只能拥有一个PVID，当一个物理端口拥有了一个PVID的时候，必定会拥有和PVID相等的VID，而且在这个VID上，这个物理端口必定是Untagged Port。PVID的作用只是在交换机从外部接受到可以接受Untagged 数据帧的时候给数据帧添加TAG标记用的，在交换机内部转发数据的时候PVID不起任何作用https://baike.baidu.com/item/PVID 网址交换机三种端口模式Access、Hybrid和Trunk的理解http://www.word666.com/zhishi/62797.html","link":"/posts/9bb9b12b/"},{"title":"交换机状态检测","text":"交换机状态检测记录交换机上的一些状态检测指令，以及流程 查看端口上的流量dis int Bri 100dis int T 1/0/1display interface XGigabitEthernet 2/0/0 XGigabitEthernet2/0/0 current state : UPLine protocol current state : UPDescription:connet to f5-2Switch Port, PVID : 1, TPID : 8100(Hex), The Maximum Frame Length is 9216IP Sending Frames' Format is PKTFMT_ETHNT_2, Hardware address is f84a-bf70-3d00Last physical up time : 2014-03-09 18:12Last physical down time : 2014-03-09 18:12Current system time: 2014-03-09 18:12Port Mode: COMMON FIBERSpeed : 10000, Loopback: NONEDuplex: FULL, Negotiation: DISABLEMdi : NORMALLast 300 seconds input rate 1602936 bits/sec, 1784 packets/secLast 300 seconds output rate 1393224 bits/sec, 1732 packets/secInput peak rate 142352400 bits/sec, Record time: 2014-03-09 18:12Output peak rate 136841800 bits/sec, Record time: 2014-03-09 18:12Input: 26101952708 packets, 3055712267640 bytes 其中INPUT和OUTPUT部分就是交换机的进出口流量 查看交换机上下联状态dis link s","link":"/posts/845aaf29/"},{"title":"ipv6部署","text":"ipv6部署部署案例由于ipv4快要用完了，很多交换机需要更换ipv6的地址，这里做一些配置的过程 西安光通高防 ipv6配置 要求西安光通高防业务ipv6 240e:bf:b800:1900::/64互联 对端:240e:bf:b800:19ff::100/127 公司:240e:bf:b800:19ff::101/127 # 先配置互联地址，看和机房是否互通，默认vlan1为业务vlan ,其他vlan为互联vlan[CTN-SN-XIY-S01]dis int briefBrief information on interfaces in route mode:Link: ADM - administratively down; Stby - standbyProtocol: (s) - spoofingInterface Link Protocol Primary IP DescriptionInLoop0 UP UP(s) --NULL0 UP UP(s) --Vlan1 UP UP 1.81.5.161Vlan10 DOWN DOWN --Vlan101 UP UP 192.168.100.2# 配置互联地址Interface vlan-interface 101ipv6 address 240e:bf:b800:19ff::101/127 # 测试互联是否互通ping ipv6 240e:bf:b800:19ff::100# 配置业务地址和静态路由interface vlan-interface 1ipv6 address 240e:bf:b800:1900::1/64undo ipv6 nd ra halt# 配置静态路由ipv6 route-static :: 0 240e:bf:b800:19ff::100 四川成华移动机房 要求四川成华移动机房（自有节点）IPV6资源：2409:8C62:410:6::/64，互联： 对端2409:8062:3000:0201:: C/127 公司2409:8062:3000:0201:: D/127 对端2409:8062:3000:0202:: 6/127 公司2409:8062:3000:0202:: 7/127 dis int briefBrief information on interfaces in route mode:Link: ADM - administratively down; Stby - standbyProtocol: (s) - spoofingInterface Link Protocol Primary IP DescriptionVlan1 UP UP 117.172.22.129Vlan200 UP UP 117.172.4.50Vlan201 UP UP 117.172.4.54# 配置互联地址interface Vlan-interface200 ip address 117.172.4.50 255.255.255.252 ipv6 address 2409:8062:3000:201::D/127interface Vlan-interface201 ip address 117.172.4.54 255.255.255.252 ipv6 address 2409:8062:3000:202::7/127# 测试互联ping ipv6 2409:8062:3000:201::Cping ipv6 2409:8062:3000:202::6# 配置业务vlaninterface Vlan-interface1 ip address 117.172.22.129 255.255.255.224 ipv6 address 2409:8C62:410:6::1/64 undo ipv6 nd ra halt# 配置静态[CMN-SC-CTU4-S01]dis current-configuration | include ipv6.ro ipv6 route-static :: 0 2409:8062:3000:201::C ipv6 route-static :: 0 2409:8062:3000:202::6# 测试路由tracert ipv6 2409:8062:3000:201::Ctraceroute to 2409:8062:3000:201::C (2409:8062:3000:201::C), 30 hops at most, 60 byte packets, press CTRL_C to break 1 2409:8062:3000:201::C 2.934 ms 2.345 ms 2.336 mstracert ipv6 2409:8062:3000:202::6traceroute to 2409:8062:3000:202::6 (2409:8062:3000:202::6), 30 hops at most, 60 byte packets, press CTRL_C to break 1 2409:8062:3000::202 3.957 ms 3.125 ms 3.879 ms# 测试外网能否访问 check-listipv6配置完成以后需要确认内容 测试互联是否正确，ping ipv6 对端互联ip 业务地址是否配了 undo ipv6 nd ra halt 静态路由配置以后是否正确，本地是否通，外网是否通这里以西安高防为例子，如果是内网机器，比如互联ip是fe这种，那就是内网机器，找cdn那边要机器测mtr ipv6 240e:bf:b800:1900::1如果是外网机器，找其他的交换机测tracert ipv6 240e:bf:b800:1900::1 另外还要注意的是如果掩码是/72的只能自己分配ip不能dhcp","link":"/posts/82cf9f4/"},{"title":"网络部署需求分析","text":"网络部署需求分析后面需要根据tower给出的内容对网络环境，机器上架规划内容由于tower中给出的大部分都是纸上信息，这里做几个例子进行一下总结 凡是没有提到2层或者3层需求的，都按照3层需求来处理 *****基础配置基础配置 二三层通用 # 用户配置local-user admin class manage service-type ssh authorization-attribute user-role level-3 authorization-attribute user-role network-admin authorization-attribute user-role network-operator#local-user root class manage service-type ssh authorization-attribute user-role level-3 authorization-attribute user-role network-admin authorization-attribute user-role network-operatoruser-interface vty 0 4authentication-mode scheme user-role network-adminprotocol inbound allquit# 不显示版本信息undo copyright-info enable# 公钥导入public-key peer pub public-key-code begin 30820122300D06092A864886F70D01010105000382010F003082010A0282010100D37D67EC 5A9466CD38895097E74386EBBEFA9EC59236DF5E96D7514B2903C21F09C6D47D74792B5E3D C1F99DB4D43614AE3AD61DEFFAF35CED9B94DBD85DE174598C491FA043F8C700DA686BFFCA 227E4E7417A251CD7590673B4C1A227962F65CBA6017329479484EF8FE48A8E2FED636C846 5765801A0D62C821906FF8E7188DA69D716FD392E8C0D4D0618E9020670FFA24CF083E2EF7 690EABCA43AA4341D798A72B6FFB5A0A1BEF0F4B14B6B66E5F7126582BD11A11F4220EA3FF C1A5DF36E86E76A8EF6A97949158F094CBAD09725069A090CBA36D95CB6A9531A5AB8B3ED5 8D6C63C8138320F0F1ECD7B25203A1B79FC82635B0F53475BC428B3B741F0203010001 public-key-code end peer-public-key endpublic-key peer upyun public-key-code begin 30820122300D06092A864886F70D01010105000382010F003082010A0282010100BEF4DB4E 5224F5FFE95AF67CC1753592979F6C1379E0A1FB8519C0E6E626B50F221957806B64384173 F2B370254381D583D3EC70D4211CC599CF6C1615754E985895D1E78E1E62788A9BC2E4D2EB 55A18FD20D2B692813114C650FE4FC883DB5467039264C2478332C2C967F3DAE83AFBDFAB3 D794F38DCB2E112184127A151741947DFBB00E8E66B9037131C54A27DE703B2E80A3D8D3C6 79CFC9E851D9C76610228790D7E2253D7E7735481D2EA61AA71D6DFD2EAC037203CE08943E 43DF88AC1ECCB77433358B5ABDF080616D6B6C40AEBEEEDD64D8B8718F091CAA0EA8D5A6A0 2B6106D931E45717C94DBC0F3FF6608CB609C4DA4860C8C48EE67CB304470203010001 public-key-code end peer-public-key end# 用户公钥认证ssh user admin service-type stelnet authentication-type publickey assign publickey pubssh user root service-type stelnet authentication-type publickey assign publickey upyun# acl过滤acl number 2000description Login IP Controlrule 1 permit source 192.168.0.0 0.0.255.255rule 5 permit source 115.238.93.82 0rule 10 permit source 115.231.100.64 0.0.0.63rule 15 permit source 121.52.226.192 0.0.0.63rule 20 permit source 115.238.54.160 0.0.0.15rule 25 permit source 124.160.114.192 0.0.0.15rule 30 permit source 106.186.117.158 0.0.0.255rule 35 permit source 157.119.232.0 0.0.0.31rule 40 permit source 218.205.64.19 0.0.0.31rule 45 permit source 112.17.251.0 0.0.0.31rule 50 permit source 121.52.250.193 0.0.0.31rule 55 permit source 183.131.0.65 0.0.0.31rule 60 permit source 43.230.89.160 0.0.0.31rule 65 permit source 111.1.32.0 0.0.0.127rule 70 permit source 115.231.97.0 0.0.0.31rule 1000 deny source anyquitundo ip http enable# ssh过滤ssh server enablessh server acl 2000# 接口过滤user-interface vty 0 4acl 2000 inbound# snmp监控snmp-agentsnmp-agent local-engineid 800063A203snmp-agent community read hgE6ofdZ3bsnmp-agent sys-info version v2c v3 # 机器时间同步ntp-service unicast-server 218.189.210.4 source Vlan-interface 1ntp-service unicast-server 137.189.4.10 source Vlan-interface 1clock timezone beijing add 8# 路由追踪ip ttl-expires enableip unreachables enableipv6 unreachables enable ***二层环路检测配置h3c 5130配置 loopback-detection global enable vlan all# 端口定时器shutdown-interval 120 # 环路检测报文发送周期loopback-detection interval-time 5# 接口内部配置# 环路检测接口配置loopback-detection action shutdownloopback-detection enable vlan all h3c 5120配置 loopback-detection multi-port-mode enableloopback-detection enable# 端口定时器shutdown-interval 120 # 环路检测报文发送周期loopback-description interval-time 5# 接口内配置# 环路检测接口配置loopback-detection action shutdownloopback-detection enable vlan all 走二层与走三层的关系交换机的二三层决定取决于OSI模型 ，二层走数据链路层 三层在二层基础上添加网络层另外交换机是否走三层，应该取决于网络的规划 首先是二层交换机走二层，路由在核心交换机上，不转发多网段的数据(Vlan)数据走数据链路层以上说明二层交换机不能跨网段传输信息，在划分vlan的情况下，只能走同vlan下的数据 需要测试 # 在同vlan下，不通网段ip需要默认路由？# 在同vlan下，同网段ip不需要默认路由？ # 静态路由的功能除了 规定流量转发还有什么？ 静态路由指向核心交换机上的网关 其次是三层交换机三层交换机就是在二层交换机的基础上加了路由功能，交换机走三层，路由在当前三层交换机上三层交换机能转发多网段的数据,路由器转发数据是基于IP地址进行转发的！！而二层交换机是基于MAC地址转发的！！让基于MAC地址转发的交换机实现基于IP地址转发 ===> 三层交换机 三层交换机可以转发多网段的数据，不局限于同vlan下的数据转发， 静态路由指向网关 虽然三层交换机有路由功能，但不能完全取代路由器，基础原理不同 二层架构于三层架构的区别https://blog.51cto.com/fenggao/1582958https://www.cnblogs.com/sunada2005/articles/2666902.html 举例比如你现在有两台交换机 A BA 作为核心交换机B 作为核心机下面的机器 要走二层的话，则同vlan走个静态就ok了 要走三层的话，也就是说B下面有多个网段的机器 两台机器的vlan是不需要相同的，三层交换机会动态配置 福建厦门联通CUN-FJ-XMN-S01如图以上信息 ip信息 36.248.208.224/27机器信息 15台1U服务器 1台5130交换机(52口) 2个万兆多模 30根网线 16根电源线-->-->-->也就是说 15台服务器每台2根网线 5130交换机前面30个电口做汇聚interface bridge-aggregation 1interface GigabitEthernet1/0/1port link-aggregation group 1interface GigabitEthernet1/0/2port link-aggregation group 1# 可以用脚本生成两个万兆多模，交换机上联接入一个，上联一个 ****走二层不走vlan1 指定vlan 2250# 配置vlan2250vlan 2250int vlan-interface 2250ip address 36.248.208.226 255.255.255.224# 端口汇聚interface bridge-aggregation 1interface GigabitEthernet2/0/1port link-aggregation group 1interface GigabitEthernet2/0/2port link-aggregation group 1...int range Bridge-Aggregation 1 to Bridge-Aggregation 15port access vlan 2250# 配置上联口interface ten1/0/49port link-type trunk # 接入trunk模式，对应trunk模式undo port trunk permit vlan 1port trunk permit vlan 2250# 关闭端口stp生成树功能int range g1/0/1 to g1/0/30 undo stp enable# 二层环路检测配置 四川成都联通CMN-SC-CTU4-S01ZA-16030782 1 2 口ZA-16030781 3 4 口ZA-16031259 5 6 口ZA-16031257 7 8 口ZA-16030285 9 10 口ZA-15041213 11 12 口ZA-15041819 13 14 口ZA-15041852 15 16 口ZA-15070367 17 18 口ZA-19010018 19 20 口 6300 47 48上联口 # 走三层10 台交换机 汇聚 走1-20口 走47 48口 # 这个需要问，图里没给 *****走三层# 基础配置 复制粘贴# 配置vlan 200 201vlan 200int vlan-interface 200ip address 117.172.4.50 255.255.255.252vlan 201 int vlan-interface 201ip address 117.172.4.54 255.255.255.252vlan 1int vlan-interface 1ip address 117.172.22.129 255.255.255.224# 配置静态路由ip route-static 0.0.0.0 0 117.172.4.49ip route-static 0.0.0.0 0 117.172.4.53# 配置上联int ten 1/0/47port access vlan 200int ten 1/0/49port access vlan 201# 二层环路检测配置 自动生成汇聚端口配置脚本import osimport json# 指定端口类型 有些做过堆叠的交换机 MemberID是不同的port_type = \"1\"for i in range(1,16): print(\"interface bridge-aggregation %s\"%i) print(\"interface GigabitEthernet%s/0/%s\"%(port_type,int(i*2-1))) print(\"port link-aggregation group %s\"%i) print(\"interface GigabitEthernet%s/0/%s\"%(port_type,int(i*2))) print(\"port link-aggregation group %s\"%i)## REANME.md##交换机的配置需要批量配置管理端口##用这个脚本生成就ok了 check-list 基础配置是否完成基础配置主要是上面打*的部分，一般情况下复制粘贴就可以了 互联是否已通ping 下自己，ping 下对端 如果机房临时有事，导致交换机时间内无法连上网络，可以先试着ping一下loopback 接口3.","link":"/posts/291d4679/"},{"title":"jwt原理与实战应用","text":"jwt原理与实战应用 基于传统的token认证用户登陆，服务端给返回token,并将token保存在服务端，以后用户访问时，需要携带token，服务端获取token后，再去数据库中获取token认证校验 jwt形式的token认证用户登录，服务端给用户返回一个token(服务端不保存)，以后用户再来访问，需要携带token，服务端获取token后，再做token认证 不用在服务端保存token jwt实现过程 用户提交用户名和密码给服务器，如果登录成功，使用jwt创建一个token，并给用户返回。 jwt-token组成由三段字符串组成，并且用.连接 加密过程 第一段字符串 header 内部包含算法/token类型.json 转换成字符串，然后做base64url加密(base64加密) { \"alg\": \"HS256\", # 算法 \"typ\": \"JWT\", # 类型} 第二段字符串payload 自定义值json转换成字符串，然后做base64url加密(base64加密) { \"id\": \"12343242\", \"name\": \"hzj\", \"exp\": 323212423 # 超时时间} 第三段字符串:拼接1,2部分内容，并对其进行HS256加密 + 加盐(加随机字符串)对HS256加密后的密文再做base64url加密 返回给用户，用户下次访问带着jwt-token来访问 解密过程用户第二次访问，带着jjwt-token来访问，后端需要对token进行验证 获取token，根据.对token进行切割 对第二段进行base64url解密，并获取payload信息{ \"id\": \"1234343\", \"name\": \"hzj\", \"exp\": 432423 # 超时时间} 第三步: 把第一二段拼接，再次HS256加密后对base64url解密后的内容进行比较(认证通过)在 jwt实现原理 底层使用pyjwt drf封装库使用的是django-estframework-jwt pyjwt使用# 安装pip install pyjwt 生成token # 配置import jwtimport datetimefrom django.conf import settings# 生成tokendef create_token(payload,timeout=1): # 随机符号，这里写了该项目的secret_key salt = settings.SECRET_KEY # 构造header headers = { 'typ': 'jwt', 'alg': 'HS256', } # 构造payload payload = { 'user_id': \"ud\", 'username': \"username\", 'exp': datetime.datetime.utcnow() + datetime.timedelta(minutes=timeout) } token = jwt.encode(payload=payload, key=salt, algorithm=\"HS256\", headers=headers).decode('utf-8') return token 验证token from rest_framework.authentication import BaseAuthenticationimport thisimport jwtimport datetimefrom rest_framework.response import Responsefrom django.conf import settingsfrom rest_framework import exceptionssalt = settings.SECRET_KEYclass JwtQueryParamsAuthentication(BaseAuthentication): def authenticate(self, request): # 获取token 并判断token的合法性 token = request.query_params.get(\"token\") # 1。切割 # 2. 解密第二段/判断过期 # 3. 验证第三段合法性 playload = None msg = None try: payload = jwt.decode(token,salt,True) except exceptions: msg = 'token已经失效' except jwt.DecodeError: msg = \"token认证失败\" except jwt.InvalidTokenError: msg = \"非法的token\" if not playload: pass else: return (playload,msg) views编写 # views编写 from api.extensions.auth import JwtQueryParamsAuthenticationclass ProOrderView(ApiView): authentication_classes = [JwtQueryParamsAuthentication,] djangorestframework-jwt使用djangorestframework-jwt本质是调用pyjwt实现的 # 安装pip install djangorestframework-jwt 地址jwt认证http://yangjianhua.me/2020/01/django-drf-8/ https://shuke163.github.io/2019/02/24/Django-REST-framework-API%E8%AE%A4%E8%AF%81-%E5%8C%85%E5%90%ABJWT%E8%AE%A4%E8%AF%81/https://www.cnblogs.com/ruhai/p/11311852.htmlhttps://www.cnblogs.com/chichung/p/9967325.html","link":"/posts/e8b3a2c2/"},{"title":"mac配置","text":"mac配置Mac OS 中如何优雅的创建定时任务mac 可以像linux一样使用crontab来使用定时任务.另外还有一个launchctl的工具 配置文件 xxx.plist Label cn.rayjun..plist ProgramArguments /path/to/programer StartCalendarInterval Minute 00 Hour 22 StandardOutPath /path/to/log/x.log StandardErrorPath /path/to/err/x.err 在 Plist 中，支持两种定时任务的设置： StartInterval：定义任务多长时间（单位，秒）执行一次 StartCalendarInterval：这个配置类似在 crontab 中的配置，指定具体的执行日期、星期、每月、每日的各个时间点，具体参照上面的配置文件。月份和天数的配置类似。 存放点在 Mac 系统中，可以将需要处理的事情都写在 plist 文件中，plist 是一个 xml 格式的文件。plist 文件根据不同的需要可以放在不同的目录底下。Mac OS X 中支持放 plist 的目录如下： /Library/LaunchDaemons: 系统启动后就会执行 /Library/LaunchAgents: 当用户登录系统后才会执行 ~/Library/LaunchAgents: 用户自定义的 plist /System/Library/LaunchAgents: 由 Mac OS X 为用户定义的任务 /System/Library/LaunchDaemons: 由 Mac OS X 定义的守护进程任务 命令行 launchctl load xx.plist # 启动程序launchctl unload xx.plist # 停止程序 解决讨厌的.DS_Store.DS_Store (Desktop Services Store) 是一种由苹果公司的 Mac OS X 操作系统所创造的隐藏文件，目的在于存贮目录的自定义属性，例如文件们的图标位置或者是背景色的选择。相当于 Windows 下的 desktop.ini 为什么要解决？如果不处理，每次拷贝给你同事的文件里都会包含有这个文件，或者上传网页的时候，应该把这个文件删除比较妥当，因为里面包含了一些你不一定希望别人看见的信息。（尤其是网站，通过 .DS_Store 可以知道这个目录里面所有文件的清单，很多时候这是一个不希望出现的问题。） 解决 删除当前目录的.DS_Storefind . -name '*.DS_Store' -type f -delete 删除所有目录的.DS_Storesudo find / -name \".DS_Store\" -depth -exec rm {} \\; 禁止.DS_Store生成defaults write com.apple.desktopservices DSDontWriteNetworkStores -bool TRUE 恢复.DS_Store生成defaults delete com.apple.desktopservices DSDontWriteNetworkStores git上传忽略全局文件，并且在gitconfig中引入touch ~/.gitigonre_global# .gitignore_global############################################ OS generated files ############################################.DS_Store.DS_Store?*.swp._*.Spotlight-V100.TrashesIcon?ehthumbs.dbThumbs.db################################################# packages #################################################*.7z*.dmg*.gz*.iso*.jar*.rar*.tar*.zip #.gitconfig[filter \"lfs\"] required = true clean = git-lfs clean %f smudge = git-lfs smudge %f[user] name = bingozb email = 454113692@qq.com[core] excludesfile = /Users/bingo/.gitignore_global","link":"/posts/76ec0771/"},{"title":"软件配置","text":"设备本文主要记录一些设备上的变动，包括快捷键的设置等等 vscodevscode设置代码块1.由于markdown不是什么编程语法，vscode不支持自动提示和补全,所以我们要现在用户设置中打开markdown的自动补全ctrl+shift+p打开设置—> setting —-> 在其中添加 \"[markdown]\": { \"editor.wordWrap\": \"on\", \"editor.quickSuggestions\": true,}, 2.添加补全代码块ctrl+shift+p —> 输入markdown –> 打开markdown.json —> 添加内容 \"Print to console\": { \"prefix\": \"fcr\", \"body\": [ \"$1\" ], \"description\": \"change font-color to red sign import \" } 其中prefix 是指你代码块的简洁写法,在你输入的时候会出现代码块的提示body是主体内容,也就是我们添加的代码块description 是注释，你可以标注一下这代码块是用来干嘛的 vscode 绑定vim自定义快捷键在vscode中自定义vim快捷键“vim.insertModeKeyBindings”: [ { “before”: [“j”, “j”], “after”: [““] }]https://github.com/VSCodeVim/Vim/#key-remapping chrome清除特定网址的缓存打开开发者工具（F12），选择 Network——Disable cache 即可。需要清除某网站缓存时 F12 打开开发者工具就会自动清除这个网站的缓存，而不必清除所有网站的缓存了 ssss加强模式 Mac电脑使用shadowsocks无法连接公司内网问题最近换了mac但是发现无法连接mac电脑，主要原因是在mac电脑中ss无法对所有软件都支持端口转发,这时候需要用到一个软件 proxifier,在这个上面做全局的端口转发即可 看到socks5的监听端口为 1086 添加代理 添加规则 macmac连接交换机由于在mac中没有像windows中xshell这样简单方便的串口连接工具，因此我们只能使用screen来连接交换机 首先用串口线连接交换机，然后查看接入的串口设备，他们放在/dev下面 由于不同的串口线命名不同，但是他们应该都会带有usb字样 ls /dev | grep -i tty.*usbscreen /dev/tty.usbxxxxx 9600 这里9600为交换机的默认波特率，但你也可以在交换机更换波特率的内容 mac下使用ftp由于新的Mac系统去调了自带的telnet命令和ftp命令，所以第一步我们要安装ftp命令。我的系统是10.13.6 ftp的安装需要很多的软件依赖 brew install telnetbrew install inetutilsbrew link --overwrite inetutils 登陆- # 方式一ftp ip# 方式二ftp open ip https://www.jianshu.com/p/10c4e46c77f1ftp使用方法https://blog.csdn.net/tianlesoftware/article/details/5818990 mac下改键记录使用karabiner-element修改mac按键修改内容为:切换输入法 由之前的caps lock改成 shift之前的caps 改成了 control 下载karabiner-element 在simple modifitions 中修改映射from key caps_lockto_key left_control 修改shift和caps由于karabiner-element不支持在窗口中修改，但可以指定json形式的配置文件vi /Users/alpaca/.config/karabiner/karabiner.json \"rules\": [ { \"manipulators\": [ { \"description\": \"Change left_shift to control+space when used alone\", \"from\": { \"key_code\": \"left_shift\", \"modifiers\": { \"optional\": [ \"any\" ] } }, \"to\": [ { \"key_code\": \"left_shift\" } ], \"to_if_alone\": [ { \"key_code\": \"spacebar\", \"modifiers\": [ \"left_control\" ] } ], \"type\": \"basic\" } ] } ] mac /usr/bin/python 权限问题operation not permitted一般情况下我们在使用mac系统过程中下载一些文件、新建一些项目之后，这些文件都会默认是只读状态，这时我们只需要简单的一句权限设置命令就可以解决 sudo chmod -R 777 filename /usr/bin下面的文件在mac中会出现一下的错误 operation not permitted 这是因为mac启用了SIP（System Integrity Protection），增加了rootless机制，导致即使在root权限下依然无法修改文件，在必要时候为了能够修改下面的文件，我们只能关闭该保护机制 1) 重启 开机过程中按住command+R 进入保护模式2) 打开终端 csrutil disable 3) 再次重启，就可以修改/usr/bin下的目录文件 4)恢复保护机制 csrutil enable","link":"/posts/cd35325c/"},{"title":"hexo博客优化","text":"handsome博客优化修改右侧栏sidebar.php 此处直接去除了 热门文字 、 最新评论 、 随机文字 这三个模块（他们在一个 Tab 里） 这里是我的个人小站：猫之三千岁，用以记录生活中的点点滴滴，我一直认为有一个安静的、温馨的小窝是一件很快乐的事情。最后欢迎您不经意间的光临~ 🐾 部分修改网站https://szyink.com/archives/229/ 如何获取自己的备案号https://icp.chinaz.com/noback.top 改成CDN的内容public static function whenSwitchHeaderImgSrc($index = 0, $howToThumb, $attach, $content, $thumbField) { $options = mget(); //$randomNum = unserialize(INDEX_IMAGE_ARRAY); // 随机缩略图路径 // $random = \"http://image.noback.top/\" . @$randomNum[$index] . '.jpg';//如果有文章置顶，这里可能会导致index not undefined $random = 'http://image.noback.top/'.rand(1, 69).'.jpg'; $pattern = '/\\]*>/i'; 突然又想了一个骚操作 只要把bing 4k壁纸上的https://bing.lylares.com/detail/cnjX2Vj0.html 后缀拿到 弄一个列表 随机一下 这样CDN流量钱都省了～ 网站测速https://developers.google.com/speed/pagespeed/insights/?hl=zh-cn&url=http%3A%2F%2Fnoback.top%2F hexo博客优化end of the stream or a document separator is expected at line 8, column 1:报错内容 没有添加---title:tags:---等头部内容","link":"/posts/83186147/"},{"title":"Vimrc配置","text":"配置NERDtree配置\" ---------------------文件树\" \\\"表示注视\" 关闭NERDTree快捷键map t :NERDTreeToggle\" 当NERDTree为剩下的唯一窗口时自动关闭autocmd bufenter * if (winnr(\"$\") == 1 && exists(\"b:NERDTree\") && b:NERDTree.isTabTree()) | q | endif\" 修改树的显示图标let g:NERDTreeDirArrowExpandable = '►'let g:NERDTreeDirArrowCollapsible = '▼'let NERDTreeAutoCenter=1\" 显示行号let NERDTreeShowLineNumbers=1\" 是否显示隐藏文件let NERDTreeShowHidden=1\" 设置宽度let NERDTreeWinSize=25\" 在终端启动vim时，共享NERDTreelet g:nerdtree_tabs_open_on_console_startup=1\" 忽略一下文件的显示let NERDTreeIgnore=['\\.pyc','\\~$','\\.swp']let g:NERDTreeIndicatorMapCustom = { \\ \"Modified\" : \"✹\", \\ \"Staged\" : \"✚\", \\ \"Untracked\" : \"✭\", \\ \"Renamed\" : \"➜\", \\ \"Unmerged\" : \"═\", \\ \"Deleted\" : \"✖\", \\ \"Dirty\" : \"✗\", \\ \"Clean\" : \"✔︎\", \\ 'Ignored' : '☒', \\ \"Unknown\" : \"?\" \\ }\" 打开NERDTree的快捷键设置为F6map :NERDTreeToggle tmux配置安装Tumx# 先安装Homebrew，有则跳过ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"# 安装tmuxbrew install tmux tmux的配置文件在～/.tmux.conf退出tmux后生成配置 source .tmux.conf tmux简介对于tmux来说,最好能了解一些概念,在tmux中,一共分为 窗口（windows)，会话(session) 以及 面板(pane)三块内容, tumx 使用指南（会话篇）tumx # 新建一个无名称的会话tmux new -s demo # (-s -session) 新建一个名称为demo的会话tmux detach # 断开当前会话，会话在后台运行tmux ls # 查看当前会话列表tmux a # 默认进入第一个会话tmux a -t demo # 进入到名称为demo的会话 (-t -tmux)tmux kill-session -t demo #关闭demo会话tmux kill-server # 关闭服务器，即所有的会话都将关闭tmux ls # 查看所有会话 tmux使用指南（窗口篇）c-b d # 断开当前窗口，后台运行c-b s # 在当前窗口打来其他正在运行的tmuxc-b ? # 显示快捷键帮助文档c-b d # 断开当前会话c-b c+z # 挂起当前会话c-b r # 强制重载当前会话c-b s # 显示会话列表用于选择并切换c-b [ # 进入复制模式 按q退出c-b ] # 粘贴复制模式中的文本c-b c # 新建窗口c-b & # 关闭当前窗口 需要输入y n 确认c-b 0~9 # 切换到指定窗口c-b p # 切换到指定窗口c-b n # 切换到下一个窗口c-b w # 打开窗口列表，用于切换窗口c-b , # 重命名当前窗口c-b . # 修改当前窗口编号c-b f # 快速定位到窗口 Tmux使用手册地址：http://louiszhai.github.io/2017/09/30/tmux/ 还需要在记录一下 tmux美化篇tumx配置篇首先tmux默认将作为启动功能的前缀按键，当然我们可以自定义修改这个前缀按键，具体配置可以参照下面的配置文件 常用按键在具体配置之前我们先来了解一下tmux常用按键,这里我已经把前缀按键替换成了c-z # 常用按键c-z ？显示快捷键帮助c-z c-o 调换窗口位置c-z space 采用上下布局或左右布局c-z u 纵向分割窗口c-z v 横向分割窗口c-z q 显示分割窗口的编号c-z hjkl 上下左右选择窗口c-z c 创建新窗口c-z 0-9 选择几号窗口c-z n 切换下一个窗口c-z p 选择前一个窗口c-z w 以菜单方式显示及选择窗口c-z t 显示时钟c-z x 关闭面板c-z d 退出当前窗口，丢到缓存 , tmux a 进入指定会话c-z s 以菜单形式显示和选择会话c-z $ 修改当前会话名字tmux new -s xxx 创建并指定session名字tmux ls 列出sessiontmux a -t xxx进入已经在的sessiontmux kill-session -t session_name 删除指定session 具体配置# Tumx配置文件# from hzj# remap prefix from 'C-b' to 'C-a'# 修改前缀权限unbind C-b # 取消Ctrl-Bset -g prefix C-z # 添加Ctrl-zbind-key C-z send-prefix 绑定ctrl+z为新的前缀 # split panes using | and -# 使用c-u c-v分割面板bind u split-window -hbind v split-window -vunbind '\"'unbind %# 使用c-(hijk)选择面板bind h select-pane -Lbind l select-pane -Rbind j select-pane -Dbind k select-pane -U bind-key e setw synchronize-panes # Set the default terminal mode to 256color modeset -g default-terminal \"screen-256color\" # Set scrollback buffer to 10000set -g history-limit 10000# resize panebind -r ^k resizep -U 10 # upward (prefix Ctrl+k)bind -r ^j resizep -D 10 # downward (prefix Ctrl+j)bind -r ^h resizep -L 10 # to the left (prefix Ctrl+h)bind -r ^l resizep -R 10 # to the right (prefix Ctrl+l) # app# htop (prefix !)bind ! splitw htop # python bind / command-prompt \"splitw 'exec python3 %%'\" # reload config (prefix r)bind r source ~/.tmux.conf \\; display \"Configuration reloaded!\" #-- statusbar --#set -g status-interval 1set -g status-keys vi setw -g mode-keys visetw -g automatic-rename off #-- colorscheme --##https://github.com/daethorian/conf-tmux/blob/master/colors/zenburn.conf# mouse# 支持鼠标set-option -g mouse on # 支持复制粘贴连续到剪切板bind C-c run \"tmux save-buffer - | reattach-to-user-namespace pbcopy\"bind C-v run \"reattach-to-user-namespace pbpaste | tmux load-buffer - \\; paste-buffer\"bind-key -T copy-mode-vi 'y' send-keys -X copy-pipe-and-cancel 'reattach-to-user-namespace pbcopy'bind-key -T copy-mode-vi MouseDragEnd1Pane send -X copy-pipe-and-cancel \"pbcopy\"set -g status-utf8 on # 状态栏支持utf8set -g status-interval 1 # 状态栏刷新时间set -g status-justify left # 状态栏列表左对齐setw -g monitor-activity on # 非当前窗口有内容更新时在状态栏通知set -g status-bg black # 设置状态栏背景黑色set -g status-fg yellow # 设置状态栏前景黄色set -g status-style \"bg=black, fg=yellow\" # 状态栏前景背景色set -g status-left \"#[bg=#FF661D] ❐ #S \" # 状态栏左侧内容set -g status-right 'Continuum status: #{continuum_status}' # 状态栏右侧内容set -g status-left-length 300 # 状态栏左边长度300set -g status-right-length 500 # 状态栏左边长度500set -wg window-status-format \" #I #W \" # 状态栏窗口名称格式set -wg window-status-current-format \" #I:#W#F \" # 状态栏当前窗口名称格式(#I：序号，#w：窗口名称，#F：间隔符)set -wg window-status-separator \"\" # 状态栏窗口名称之间的间隔set -wg window-status-current-style \"bg=red\" # 状态栏当前窗口名称的样式set -wg window-status-last-style \"fg=red\" # 状态栏最后一个窗口名称的样式set -g message-style \"bg=#202529, fg=#91A8BA\" # 指定消息通知的前景、后景色set -g default-terminal \"screen-256color\"","link":"/posts/b4afac26/"},{"title":"又拍云","text":"又拍云工作记录交换机命名格式三大运营商缩写 + 附近机场代码 + S01等 移动 CMN电信 CTN联通 CUN 交换机ipv6检测内容原因 内网机器比如全是移动的，交换机配的移动的ip，下面配的也是移动的ip这样ping的通，但是联通的服务器ip ping不同。也就是说是内网通，外网不同。内网ping 网关肯定通 检测：用移动的交换机下面的服务器（出问题的交换机） 去mtr外网的ip，去看是哪里断掉的而不是用外网的机器来mtr内网的ip，这样截止的地方会看不出来，因为不是内网的机器 ipv6配置#业务vlaninterface Vlan-interface1ipv6 address +业务vlan ipundo ipv6 nd ra halt#互联vlaninterface Vlan-interface200ipv6 address +互联本地ip#默认路由ipv6 route-static :: 0 + 互联对端ip 配置案例广东广州移动机房（自有机房NM）：2409:8C54:B000:0704::/64 互联地址 机房：FEC0::C/127， 我司 FEC0::D/127vlan 1 ip address 2409:8C54:B000:0704::/64 undo ipv6 nd ra haltvlan 20ipv6 address FEC0::D/127router-staticipv6 route-static :: 0 FEC0::C山东济南移动机房（自有节点NM）：2409:8C3C:0004:000C::/64，互联地址为：2409:8C3C:00FF:0004::000E/127、 我司 2409:8C3C:00FF:0004::0010/127vlan 1ip address 2409:8C3C:0004:000C::/64undo ipv6 nd ra haltvlan 20ipv6 address 2409:8C3C:00FF:0004::0010/127route-staticipv6 route-static :: 0 2409:8C3C:00FF:0004::000Evlan 1ipv6 address 240E:E9:B804:3:400::1/72undo ipv6 nd ra haltvlan 30 ipv6 address 240E:E9:B804:3:200::A3/127ipv6 address 240E:E9:B804:3:200::B3/127router-staticipv6 route-static :: 0 240E:E9:B804:3:200::A3 无法联网 首先ping交换机ip 看是否通 串口线连接交换机 ping网关是否通不通 10.0.0.130 查看端口状态dis int brief聚合口是否起来 端口是否起来 pvid是否对应1000(统一是1000 除个别外可以在上联交换机上看10.0.0.130) 硬件问题看模块是否发光 看跳线是否发光 整理香港ntt点ip对应关系 登陆netop服务器 登陆香港ntt交换机 查看vlan1 对应ip 其中157.xxx/27 [NTT-CN-HKG-S01-Vlan-interface1]display this#interface Vlan-interface1 ip address 157.119.232.1 255.255.255.224 ip address 10.81.0.254 255.255.255.0 sub ip address 103.211.192.221 255.255.255.252 sub ip address 103.251.128.1 255.255.255.224 sub ip address 157.119.232.65 255.255.255.224 sub ip address 192.168.1.1 255.255.255.0 sub ip address 192.168.128.1 255.255.255.0 sub ip address 192.168.232.1 255.255.255.224 sub ipv6 address 2405:FD80:110::1/52#return 在netop服务器上用fping -g 157.119.231.1/27 来查看对应ip的状态 [root@NETOPS machines]# fping -g 157.119.232.65/27157.119.232.65 is alive157.119.232.66 is alive157.119.232.67 is alive157.119.232.68 is alive157.119.232.69 is alive157.119.232.70 is alive157.119.232.71 is alive157.119.232.72 is alive157.119.232.73 is alive157.119.232.74 is alive157.119.232.75 is alive157.119.232.85 is alive157.119.232.87 is alive157.119.232.86 is alive157.119.232.88 is alive157.119.232.89 is alive157.119.232.90 is alive157.119.232.91 is alive157.119.232.76 is unreachable157.119.232.77 is unreachable157.119.232.78 is unreachable157.119.232.79 is unreachable157.119.232.80 is unreachable157.119.232.81 is unreachable157.119.232.82 is unreachable157.119.232.83 is unreachable157.119.232.84 is unreachable157.119.232.92 is unreachable157.119.232.93 is unreachable157.119.232.94 is unreachable[root@NETOPS machines]# fping -g 157.119.232.1/27157.119.232.1 is alive157.119.232.2 is alive157.119.232.3 is alive157.119.232.4 is alive157.119.232.5 is alive157.119.232.6 is alive157.119.232.7 is alive157.119.232.8 is alive157.119.232.9 is alive157.119.232.10 is alive157.119.232.11 is alive157.119.232.12 is alive157.119.232.13 is alive157.119.232.14 is alive157.119.232.15 is alive157.119.232.16 is alive157.119.232.17 is alive157.119.232.19 is alive157.119.232.18 is alive157.119.232.20 is alive157.119.232.21 is alive157.119.232.22 is alive157.119.232.23 is alive157.119.232.24 is alive157.119.232.25 is alive157.119.232.26 is alive157.119.232.27 is alive157.119.232.28 is alive157.119.232.29 is alive157.119.232.30 is alive 查看inventory中对应关系 [root@NETOPS machines]# grep 157.119.232.73 /root/mingtao/inventory/machines/*/root/mingtao/inventory/machines/lists-upapp-01:157.119.232.73[root@NETOPS machines]# grep 157.119.232.30 /root/mingtao/inventory/machines/*/root/mingtao/inventory/machines/lists-cdn-v406:# NTT-CN-HKG-030 ansible_ssh_host=157.119.232.30/root/mingtao/inventory/machines/lists-openstack:# NTT-CN-HKG-030 ansible_ssh_host=157.119.232.30/root/mingtao/inventory/machines/lists-openstack:OPK-HKG-M30 ansible_ssh_host=157.119.232.30/root/mingtao/inventory/machines/lists-upops:NTT-CN-HKG-030 ansible_ssh_host=157.119.232.30[root@NETOPS machines]# grep 157.119.232.29 /root/mingtao/inventory/machines/*/root/mingtao/inventory/machines/lists-cdn-v406:# NTT-CN-HKG-029 ansible_ssh_host=157.119.232.29/root/mingtao/inventory/machines/lists-openstack:# NTT-CN-HKG-029 ansible_ssh_host=157.119.232.29/root/mingtao/inventory/machines/lists-upapp-01:157.119.232.29[root@NETOPS machines]# grep 157.119.232.20 /root/mingtao/inventory/machines/*[root@NETOPS machines]# grep 157.119.232.24 /root/mingtao/inventory/machines/*[root@NETOPS machines]# grep 157.119.232.21 /root/mingtao/inventory/machines/* 记录机器的对应名字 ntt机器对应脚本#!/usr/bin/bash# add ip (active and unknown)fping -g 157.119.232.65/27 > ntt_machinefping -g 157.119.231.1/27 >> ntt_machine# filter active to tmp.txtawk '{if($3==\"alive\"){print $1}}' > tmp.txt ntt_machine# Calculate the totalnums=`cat tmp.txt | wc -l`# reset result.txt to blankecho \"result:\" > result.txt# filter ipfor i in `seq 1 $nums`do ip=`awk \"NR==$i\" tmp.txt` link=`grep -w $ip mingtao/inventory/machines/machines/*` link=`echo $link | awk -F\":\" '{print $2}' ` link=`echo $link | awk '{if($1==\"#\"){print $2}else{print $1}}'` echo $ip ,\"active\" , $link >> result.txtdone# add unknown to tmp.txtawk '{if($3!=\"alive\"){print $1,$3}}' >> result.txt ntt_machine~ 底层设备到网络配置通过该tower截图来获取网络配置需求15台1U服务器1台5130交换机2个万兆多模模块30根网线16根电源线 1个万兆口 1-30口汇聚49口接上联 走trunk","link":"/posts/899b698f/"},{"title":"常见错误","text":"linux错误yum不支持python3[root@gogogo alpaca]# yum File \"/bin/yum\", line 30 except KeyboardInterrupt, e: ^SyntaxError: invalid syntax File \"/usr/libexec/urlgrabber-ext-down\", line 28 except OSError, e: 解决办法 sed -i 's:bin/python:bin/python2.7:' /usr/bin/yumsed -i 's:bin/python:bin/python2.7:' /usr/libexec/urlgrabber-ext-down 可以通外网，但是无法ping百度包括无法使用yum wget 等下载工具或者报错 cannot find a valid baseurl for repo:base/7/x86_64 的解决方法 解决办法原因 - > DNS的问题 echo nameserver 114.114.114.114 > /etc/reslov.conf linux中如何恢复到后台进程linux 下我们如果想一个任务或者程序进行调度bg 将一个后台暂停的命令，变成继续执行fg 将后台的命令调至前台继续运行jobs 查看当前在后台运行的命令c-z 将前台命令放到后台运行 并且暂停nohup command & 在后台不断运行command命令 ssh配置的问题这个问题主要是存在于交换机ssh登陆交换机的过程ssh配置过程中，配置了密码登陆，但是出现下面的错误 ssh 10.0.0.166The server's host key does not match the local cached key. Either the server administrator has changed the host key, or you connected to another server pretending to be this server. Please remove the local cached key, before logging in! 主要问题是一开始用ssh登陆交换机的时候，选择了保存key ssh 10.0.0.166Username: ttPress CTRL+C to abort.Connecting to 10.0.0.166 port 22.The server is not authenticated. Continue? [Y/N]:yDo you want to save the server public key? [Y/N]:y 这样导致的问题就是在当前交换机上会保存一个登陆另一个交换机的key #public-key peer 10.0.0.166 public-key-code begin 30819F300D06092A864886F70D010101050003818D0030818902818100DF3E1240D158E197 CE0712173C8591883F88CC925B1C0CFC63C779E9F531C3B7E409BBB2CCED954C09A339BE78 46B1497E4771EDD7E88D2E380C50F37A6EC9254E6B27EC7AFFE6DCDFC1EA230D16C4DC9BB8 B831A2F0CB578B736566052E830A582836AA9BFFE0821CE7CB43F74077D38B20437479F260 A5D0550CA7D3D0747F0203010001 public-key-code end peer-public-key end# 于是当你下次选择使用ssh+密码登陆交换机的时候就会发现错误 解决删除当前交换机的key 并在下次登陆的时候选择 ssh 10.0.0.166Username: ttPress CTRL+C to abort.Connecting to 10.0.0.166 port 22.The server is not authenticated. Continue? [Y/N]:yDo you want to save the server public key? [Y/N]:n","link":"/posts/c10f304f/"}],"tags":[],"categories":[{"name":"编程","slug":"编程","link":"/categories/%E7%BC%96%E7%A8%8B/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"C语言","slug":"编程/C语言","link":"/categories/%E7%BC%96%E7%A8%8B/C%E8%AF%AD%E8%A8%80/"},{"name":"Python","slug":"编程/Python","link":"/categories/%E7%BC%96%E7%A8%8B/Python/"},{"name":"checklist","slug":"checklist","link":"/categories/checklist/"},{"name":"django","slug":"编程/django","link":"/categories/%E7%BC%96%E7%A8%8B/django/"},{"name":"ansible","slug":"linux/ansible","link":"/categories/linux/ansible/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"mysql","slug":"编程/mysql","link":"/categories/%E7%BC%96%E7%A8%8B/mysql/"},{"name":"nginx","slug":"nginx","link":"/categories/nginx/"},{"name":"SwaggerUi","slug":"编程/SwaggerUi","link":"/categories/%E7%BC%96%E7%A8%8B/SwaggerUi/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"vue","slug":"编程/vue","link":"/categories/%E7%BC%96%E7%A8%8B/vue/"},{"name":"vim","slug":"编程/vim","link":"/categories/%E7%BC%96%E7%A8%8B/vim/"},{"name":"扩展","slug":"扩展","link":"/categories/%E6%89%A9%E5%B1%95/"},{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"},{"name":"记事本","slug":"记事本","link":"/categories/%E8%AE%B0%E4%BA%8B%E6%9C%AC/"},{"name":"extra","slug":"网络/extra","link":"/categories/%E7%BD%91%E7%BB%9C/extra/"},{"name":"Rust","slug":"编程/Rust","link":"/categories/%E7%BC%96%E7%A8%8B/Rust/"},{"name":"脚本","slug":"linux/脚本","link":"/categories/linux/%E8%84%9A%E6%9C%AC/"},{"name":"linux网络管理","slug":"linux/linux网络管理","link":"/categories/linux/linux%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86/"},{"name":"常用命令","slug":"linux/常用命令","link":"/categories/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"},{"name":"故障问题","slug":"linux/故障问题","link":"/categories/linux/%E6%95%85%E9%9A%9C%E9%97%AE%E9%A2%98/"},{"name":"文件系统","slug":"linux/文件系统","link":"/categories/linux/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"负载均衡","slug":"linux/负载均衡","link":"/categories/linux/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"code/more","slug":"code-more","link":"/categories/code-more/"},{"name":"二层交换机","slug":"网络/二层交换机","link":"/categories/%E7%BD%91%E7%BB%9C/%E4%BA%8C%E5%B1%82%E4%BA%A4%E6%8D%A2%E6%9C%BA/"},{"name":"交换机","slug":"网络/交换机","link":"/categories/%E7%BD%91%E7%BB%9C/%E4%BA%A4%E6%8D%A2%E6%9C%BA/"},{"name":"交换机部署","slug":"网络/交换机部署","link":"/categories/%E7%BD%91%E7%BB%9C/%E4%BA%A4%E6%8D%A2%E6%9C%BA%E9%83%A8%E7%BD%B2/"},{"name":"vue","slug":"code-more/vue","link":"/categories/code-more/vue/"},{"name":"jwt","slug":"编程/jwt","link":"/categories/%E7%BC%96%E7%A8%8B/jwt/"},{"name":"设备","slug":"设备","link":"/categories/%E8%AE%BE%E5%A4%87/"}]}