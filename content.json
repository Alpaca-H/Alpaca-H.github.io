{"pages":[{"title":"","text":"rust-language 备忘录https://cheats.rs/#data-structures","link":"/about-me/index.html"},{"title":"","text":"rust-language 备忘录https://cheats.rs/#data-structures rust bloghttps://www.snoyman.com/blog/2018/10/introducing-rust-crash-coursehttp://llever.com/gentle-intro/2-structs-enums-lifetimes.zh.html#%E6%B3%9B%E5%9E%8B%E5%87%BD%E6%95%B0 清华镜像源地址https://mirrors.tuna.tsinghua.edu.cn/","link":"/rust/index.html"},{"title":"study listing","text":"iptables and firewalld 端口转发等.","link":"/listing/index.html"}],"posts":[{"title":"hello,new-world","text":"hello,new-world 👨 hello,new-worldcmd.fm命令行的fm电台https://cmd.to/fm","link":"/posts/1f4442b1/"},{"title":"Python报错总结","text":"learn python 🐍 Python报错总结Non-ASCIIpython出现SyntaxError: Non-ASCII character ‘\\xe6’ in file 打印日期.py on line 1, but no encoding declared; 解决方法在文件头部添加如下两行注释码： #!/usr/bin/python# -*- coding: -*- 例如，可添加# -*- coding: utf-8 -*-","link":"/posts/1d0174bc/"},{"title":"ansible基础","text":"主机清单 inventoryansible中添加主机清单的几种形式 直接在命令行中指定ip,-k登陆时指定密码 ansible 192.168.20.1 -m ping -kansible 192.168.20.1,192.168.20.2 -m ping -k 在配置文件中指定 默认文件夹/etc/ansible/hosts [name1]192.168.20.1[name2]192.168.20.2ansible name1 -m ping -k # 指定分组ansible all -m ping -k # 指定所有 由于ansible是通过ssh访问被执行端主机的，因此没有ssh的权限是无法完成任务的，即使这里的命令是ping，但依旧要走ssh的流程这里的ping并不是linux下的ping ,而是ansible工具下面的ping模块 不使用默认文件下，自定义文件夹 echo \"192.168.20.1\" >> xxansible -i xx all -m ping -k 在配置组里面中直接确认登陆用户 echo \"192.168.20.1 ansible_ssh_user=root ansible_ssh_pass=upyun123\"ansible -i xx all -m ping 配置文件 local_tmp是本地的执行指令 remote_tmp是远程的执行指令当用户使用ansible控制被控端执行指令的时候，他会先将内容放在local_tmp文件中，然后上传到被控端并生成remote_tmp上执行。执行完成之后会删除这两个tmp文件 library = /usr/share/my_modules/ 库存放地址 forks = 5 默认并发数 sudo_user = root 默认sudo 用户 ask_sudo_pass = True 每次执行ansible是否询问ssh密码 ask_pass = True remote_port = 22 host_key_checking = False 检查对应服务器的host_key —–>建议取消注释 log_path=/var/log/ansible.log 日志文件 命令ansible-doc 说明文档ansible-doc [options] [module..]-a 显示所有模块的文档 参数尽量放在单引号里面-l –list 列出可用模块-s –snippet xxx 显示xxx模块的playbook片段 role扩展模块ansible-galaxy专门有一个网站提供不同用户上传的”角色”地址:https://galaxy.ansible.com/ # 列出所有已安装的galaxyansible-galaxy list# 安装galaxyansible-galaxy install xxx# 删除galaxyansible-galaxy remove xxx role默认安装路径为/etc/ansible/roles/下 ansible列出指定组别的host列表ansible appsevr –list-hosts列出所有列表的hostansible all –list-hostsansible all –list支持通配符匹配hostansible *serv –list多IP批量执行ansible 192.168.0.1,192.168.0.2 -m ping多组别批量执行(逻辑或关系,合并，A和B所有)ansible websevr:appsevr -m ping(逻辑与关系,区分,在A中,也在B中)ansible “websevr:&appsevr” -m ping(逻辑非,在A中不在B中,此处必须要用单引号)ansible ‘websevr:!appsevr’ -m ping ansible [-m module_name] [-a args]–version 显示版本-m module 指定模板,默认为command-v 详细过程 -vv -vvv更详细–list –list-hosts 显示主机列表，-k –ask-pass 提示输入ssh连接密码，默认为key验证-K –ask-become-pass 提示输入sudo时的口令-C –check 检查，并不执行-T –timeout=TIMEOUT 执行命令的超时时间,默认为10s-u –user=REMOTE_USER 执行远程执行的用户-b –become 代替旧版的sudo切换 (默认为ansible.cfg里面设置的用户,一般为root)-a 指定参数 ansible -m命令模块command在command中,我们可以创建文件，但是对于文件的操作,有一个专门的file模块 # 创建一个文件ansible -m command -a 'mkdir \\data'# 查看文件是否创建成功ansible -m command -a 'ls -al \\data'# 查看command帮助ansible-doc command shell如果-a 后带的参数中出现 $ < > | ; & 等字符，command是不支持的，需要用到shell 模块 # 输出主机名字ansible 192.168.1.3 -m shell -a 'echo $HOSTNAME' ansible命令执行流程1.加载自己的配置文件 默认为/etc/ansible/ansible.cfg2.加载自己对应的模块文件,如command3.通过ansible将模块或命令生成对应的临时py文件,并将文件传输至远程服务器的对应执行用户$HOME/.ansible/tmp/ansible-tmp-数字/xxx.py文件4.增加文件的执行权限5.执行并返回结果6.删除临时py文件,sleep 0退出执行状态:绿色 执行成功并且不需要做改变的操作黄色 执行成功但是对目标主机做了修改红色 执行失败(颜色内容在/etc/ansible.cfg里面修改) 生成sshssh-keygen复制ssh密钥到其他主机ssh-copy-id 主机ip 模块由于Ansible的模块过多，将近有1378个模块数量,但是每个模块的介绍以及使用方法都存放在/usr/bin/ansible-doc当中 # 查看当前ansible模块数量ansible-doc -l | wc -l# ansible-doc的使用方法ansible-doc [options] [module..]-a 显示所有模块的文档 参数尽量放在单引号里面-l --list 列出可用模块-s --snippet xxx 显示xxx模块的playbook片段# 使用-m指定模块，默认为commandansible -m command command在command中,我们可以创建文件，但是对于文件的操作,有一个专门的file模块 # 创建一个文件ansible -m command -a 'mkdir \\data'# 查看文件是否创建成功ansible -m command -a 'ls -al \\data'# 查看command帮助ansible-doc command shell如果-a 后带的参数中出现 $ < > | ; & 等字符，command是不支持的，需要用到shell 模块 # 输出主机名字ansible 192.168.1.3 -m shell -a 'echo $HOSTNAME' script既然ansible可以对多台主机进行批量的操作，那往往我们会遇到一个场景，即需要我们在多台主机上执行一个脚本，这个场景下我们有两个方法:1.将脚本文件复制到多台主机上后,调用ansible使用2.使用script模块，仅在控制端存在脚本文件即可 # 方法一,先将文件发到对应控制端主机ansible 192.168.1.3 -m command -a '/root/ansible_test.sh'# 方法二root@DESKTOP-GT1K5L0:~# ansible 192.168.1.3 -m script -a '/root/ansible_test.sh'192.168.1.3 | SUCCESS => { \"changed\": true, \"rc\": 0, \"stderr\": \"Shared connection to 192.168.1.3 closed\", \"stdout\": \"to do it,ansible\", \"stdout_lines\": [ \"to do it,ansible\" ]} Copy在上面我们提到了从控制端传输文件到被控端,既然是批量的操作,那么在ansible中同样存在一个copy的模块,可以用来传输文件场景: 关闭多台主机的selinux流程: 复制控制端selinux的配置文件，修改后发送到被控制端 注意:这里的ho表示的是一个主机群 在/etc/ansible/hosts中已经添加了 # 查看控制端selinux状态getenforce# 查看被控端selinux状态[root@localhost ~]# ansible ho -m command -a 'getenforce'192.168.1.6 | SUCCESS | rc=0 >>Enforcing192.168.1.7 | SUCCESS | rc=0 >>Enforcing192.168.1.5 | SUCCESS | rc=0 >>Enforcing192.168.1.4 | SUCCESS | rc=0 >>Enforcing# 复制selinux配置文件，并修改配置cp /etc/selinux/config .SELINUX=disabled# 复制配置文件到被控端指定路径,并做好备份ansible ho -m copy -a'src=/root/hzj/config dest=/etc/selinux/config backup=yes'# 查看被控端是否生成备份文件ansible ho -m command -a 'ls /etc/selinux/'# 重启ansible ho -m command -a 'reboot'# 查看被控端selinux是否修改完成ansible ho -m command -a 'getenforce'[root@localhost hzj]# ansible ho -m command -a 'getenforce'192.168.1.7 | SUCCESS | rc=0 >>Disabled192.168.1.4 | SUCCESS | rc=0 >>Disabled192.168.1.5 | SUCCESS | rc=0 >>Disabled192.168.1.6 | SUCCESS | rc=0 >>Disabled fetchansible支持从被控端抓取文件到控制端,抓取后的格式为\\example.com\\destsrc表示抓取路径dest表示存放路径 # 复制所有主机的日志到控制端ansible ho -m fetch -a 'src=/var/log/messages dest=/root/data' 但是fetch仅支持单个文件的抓取，当我们想要抓取多个日志文件时，可以先进行打包 file设置文件的属性 # 创建文件ansible ho -m file -a 'name=/data/f3 state=touch'# 删除文件ansible ho -m file -a 'name=/data/f3 state=absent'# 创建文件夹ansible ho -m file -a 'name=/data/f3 state=directory'# 删除文件夹ansible ho -m file -a 'name=/data/f3 state=absent'# 创建软连接ansible ho -m file -a 'src=/root/test name=/data/fq state=link'# 但是需要注意的是如果你创建了文件f3 当你创建文件夹f3的时候会出现错误 hostname修改主机名 ansible ho -m hostname -a 'name=node'# 重启后生效 cron# 给每台主机添加任务,name为注释ansible ho -m cron -a 'minute=* weekday=1,3,5,7 job=\"usr/bin/wall message\" name=test'# 取消任务ansible ho -m cron -a 'disabled=true job=\"usr/bin/wall message\" name=test'# 重新启用ansible ho -m cron -a 'disabled=no job=\"usr/bin/wall message\" name=test'# 删除某条任务ansible ho -m corn -a 'jon=\"usr/bin/wall message\" state=absent' yum# name指定包 state指定状态ansible ho -m yum -a 'name=httpd state=latest' 安装ansible ho -m yum -a 'name=httpd state=absent' 删除 Service# 关闭服务 name指定服务名称 state指定状态ansible ho -m service -a 'name=httpd state=stopped'ansible ho -m service -a 'name=httpd state=started'ansible ho -m service -a'name=httpd state=reloaded'ansible ho -m service -a'name=httpd state=restarted' Useransible ho -m user -a 'name=user comment=\"test user\" uid=2048 home=/app/user group=root'ansible ho -m user -a 'name=sysuser system=yes home=/app/syseser1'ansible ho -m user -a 'name=user state=absent remove=yes' 删除用户以及家目录等数据 playbook的编写随着工作的增加,单条ansible命令(adhoc)已经不能满足我们的需求.于是我们可以把多条ansible命令写入playbook中,让系统根据playbook中的顺序依次执行ansible。我们把它叫做剧本 Playbook的编写方式Playbook的编写格式采用的是yaml语言url: http://www.ruanyifeng.com/blog/2016/07/yaml.htmlurl2: https://www.jianshu.com/p/97222440cd08urs3: https://yaml.org/ 多种语言实现yaml 简单的介绍一下yaml语言的使用 1. 在单一档案中,可以用连续的连字符(---)区分多个档案。另外，还有选择性的连续三个点号(...)用来表示档案结尾2. 次行开始正常写Playbook的内容，一般建议写明该playbook的功能3. 使用#号注释代码4. 缩进统一用tab5. 一个完整的代码块功能最少的元素需要包括name:task6. 一个name只能包括一个task7. yaml文件扩展名通常为yml或者yaml playbook例子 ---- hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted playbook核心元素 Hosts 执行的远程主机列表 Tasks 任务集 Varniables 内置变量或自定义变量在playbook中调用 Templates 模板,可替换模板文件中的变量并实现一些简单逻辑的文件 Handlers 和 notity 结合使用,由特定条件触发的操作，满足条件方才执行,否则不执行 tags 标签 指定某条任务执行,用于选择运行playbook中的部分代码。ansible具有幂等性,因此会自动跳过没有变化的部分，即便如此，有些代码为测试其确实没有发生变化的时间依然会很长。因此可以使用tags跳过一些代码片段。ansible-playbook -t tagsname useradd.yml adhoc 和 playbook 对比 # adhoc 改变主机名字ansible ho -m hostname -a 'name=xxx'# playboot 修改主机名字---- host: ho remote_user: root tasks: - name: hello hostname: name=node 多条adhoc 和playbook对比 # adhoc ansible ho -m file -a 'name=/data/newfile state=touch' # 创建文件ansible ho -m user -a 'name=test2 system=yes shell=/sbin/nologin' # 创建用户ansible ho -m yum -a 'name=httpd' # 安装httpdansible ho -m copy -a 'src=/var/www/html/index.html dest=/var/www/html' # 复制文件ansible ho -m service -a 'name=httpd state=started enabled=yes' # 启动服务# playbook- hosts: ho remote_user: root tasks: - name: create file file: name=/data/newfile state=touch - name: create user file: name=test2 system=yes shell=/sbin/nologin - name: install httpd yum: name=httpd - name: copy file copy: src=/var/www/html/index.html dest=/var/www/html - name: start service service: name=httpd state=started enabled=yes shell脚本与playbook对比 # shell脚本#!/bin/bash# 安装Apacheyum install --quiet -y httpd# 复制配置文件cp /tmp/httpd.conf /etc/httpd/conf/httpd.confcp /tmp/vhosts.conf /etc/httpd/conf.d/# 启动Apache 并设置开机启动systemctl start httpd.servicechkconfig httpd on# playbook---- host: all tasks: - name: \"安装Apache\" yum: name=httpd - name: \"复制配置文件\" copy: src=/tmp/httpd.conf dest=/etc/httpd/conf/ - name: \"复制文件\" copy: src=/tmp/vhosts.conf dest=/etc/httpd/conf.d/ - name: \"启动Apache,并设置开机启动\" service: name=httpd state=started enabled=yes 执行流程play的主体部分是task list 。 task list 中的各任务按次序逐个在hosts中指定的所有主机上执行，即在所有主机上完成第一个任务后在开始第二个，在运行自上而下某一个playbook时，如果中途发生错误，所有已执行任务都将回滚，因此，在更正playbook后重新执行一次即可 忽略错误信息 task:- name: copy file copy: src=/root/file dest=/root/ || /bin/true# 或者task:- name: copy file copy: src=/root/file dest=/root/ ignore_erros: True playbook运行方式ansible-playbook [options]--check 只检测可能会发生的改变，但不真正执行操作--list-hosts 列出运行任务的主机--limit 主机列表 只针对主机列表中的主机执行-v 显示过程 -vv -vvv显示更详细 Playbook剧本ansible-playbook是ansible中的一个工具,存放在/usr/bin/ansible-playbook 其他 模块https://www.cnblogs.com/f-ck-need-u/p/7550603.htmlhttps://docs.ansible.com/ansible/2.6/modules/list_of_all_modules.html ansible模块开发https://www.jianshu.com/p/f72b79b0d3f9","link":"/posts/ea06c230/"},{"title":"ansible总结","text":"登陆h3c交换机h3c交换机的模块支持度极低，网上大多都是思科交换机的模块，很多要用到H3c的都是自己写的，感觉很坑 问题:现在又一个问题就是命令行使用raw模块可以登陆交换机，并且输出执指令 返回结果，但是在ansible-playbook中不行 echo \"10.0.5.124\" >> ./xxansible -i xx all -m raw -a 'system-view ;dis arp ;' 如上是可以的，但是如下的playbook则不行 echo first.yml < EOF","link":"/posts/20d6cad/"},{"title":"任务流程-checklist","text":"任务流程-checklist 交换机下架流程 首先知道哪些机器要下架,知道以后登陆上去看一下交换机上下是不是有机器还连在上面，可以让机房帮忙看一下 查看接口的流量dis int bri xxx像这种没多少流量的基本上就是没有机器了 找到机柜 交换机型号 发给商务， 商务发工单给机房下架 完事 inventory上架流程拉取项目git clone https://gitlab.s.upyun.com/infrastructure/inventory.gigit clone https://gitlab.s.upyun.com/infrastructure/inventory.git 查看当前分支git branch 切换分支git checkout hzj 修改内容… 上传git commit -am “update”git push 到web端创建合并请求 更新首先切换到master，拉取最新git pull切换次分支 git checkout hzj合并更新分支到hzj分支 git merge origin hzj 发消息给有master权限的人，交由master来合并","link":"/posts/b3883d25/"},{"title":"Python常用方法1","text":"learn python 🐍 python 常用方法保留小数使用字符串格式化 a = 11.234print(\"%.2f\"%a) 使用round内置函数 a = 11.234a = round(a,2)print(a) 使用decimal模块 from decimal import Decimala = 12.345Decimal(a).quantize(Decimal(\"0.00\")) 列表列表合并# 使用+号操作list1 = [1,2,3,4,5]list2 = [\"z\",\"xx\",] list3 = list1+list2# 使用extendlist4.extend(list1)# 使用切片list4[len(11):len(11)] = list5 os模块Python获取指定文件夹下的文件名模块os.walk可以遍历文件夹下的所有文件 os.walk(top, topdown=Ture, οnerrοr=None, followlinks=False)# return (dirpath dirnames filenames) dirpath: string 代表目录的路径 dirnames list 包含了当前dirpath路径下所有的子目录名字（不包含目录路径） filenames：list，包含了当前dirpath路径下所有的非目录子文件的名字（不包含目录路径）。import os def file_name(file_dir): for root, dirs, files in os.walk(file_dir): print(root) #当前目录路径 print(dirs) #当前路径下所有子目录 print(files) #当前路径下所有非目录子文件 for file in files: # os.path.splitext # 对文件名进行切割成数组 if os.path.splitext(file)[1] == \".jpeg\": print(file) else: pass 模块os.listdir()可以得到当前路径下的文件名，不包括子目录中的文件 import os# 遍历获取所有文件def listdir(path, list_name): for file in os.listdir(path): file_path = os.path.join(path, file) # os.path.isdir(file) #判断文件是否为文件夹 if os.path.isdir(file_path): listdir(file_path, list_name) elif os.path.splitext(file_path)[1]=='.jpeg': list_name.append(file_path) 判断文件类型os.path.isdir(path) # 是否为文件夹os.path.isfile(path) # 是否为文件 文件操作mode选项r 读模式，只能读 文件不存在报错，w 写模式，只能写 文件不存在则创建，以上存在存在则清空在打开 rb 二进制读模式 只能读 文件不存在报错wb 二进制写模式 只能写 文件不存在则创建，以上存在则清空再打开有二进制内容 写入则需要encode(“utf-8”) rb+ 二进制读模式 可读可写 文件不存在报错wb+ 二进制写模式 可读可写 文件不存在则创建，以上存在则清空再打开 a 追加写模式，文件存在则追加写入a+ 追加读写方式以上存在则追加写入 默认进入为文件末尾f.seek(0) 设置读写位置为开头f.truncate(0) 将文章字节阶段为0 文件头部写如文件with open(path, \"r+\") as f: old = f.read() f.seek(0) f.write(data) f.write(old) 或者 with open(path,\"a\") as f: f.seek(0) old = f.read() # 全部删除 f.truncate(0) f.write(\"---\") f.write(\"tags: xxx\") f.write(\"---\") f.close() Python-math库向上取整 math.ceil向下取整 math.floor四舍五入 round import math#向上取整print \"math.ceil---\"print \"math.ceil(2.3) => \", math.ceil(2.3)print \"math.ceil(2.6) => \", math.ceil(2.6) #向下取整print \"\\nmath.floor---\"print \"math.floor(2.3) => \", math.floor(2.3)print \"math.floor(2.6) => \", math.floor(2.6) #四舍五入print \"\\nround---\"print \"round(2.3) => \", round(2.3)print \"round(2.6) => \", round(2.6) #这三个的返回结果都是浮点型print \"\\n\\nNOTE:every result is type of float\"print \"math.ceil(2) => \", math.ceil(2)print \"math.floor(2) => \", math.floor(2)print \"round(2) => \", round(2)","link":"/posts/79b81c10/"},{"title":"django字段总结","text":"django字段的设计https://docs.djangoproject.com/zh-hans/2.2/ref/models/fields/#module-django.db.models.fieldsorm的设计模式在django的应用过程中，往往要设计model的设计，在model设计过程中要使用各种各样的关键词，这些关键词 关联到了数据库中每条记录的配置 # 引用from django.db import models 通用字段null字段如果设置为 True， 当该字段为空时，Django 会将数据库中该字段设置为NULL，默认为 False。即数据库置空 如果null=true blank=true 则数据库内容为空白字符串 blankField.blank默认blank = False ,如果设置为True，则允许该字段为空。与null不同的是,null存粹与数据库有相关，而blank与验证相关。如果blank=true,则表单验证将允许输入空值,如果blank=False 则不允许输入空值 choicesclass TaskSwitchModel(models.Model): ActionType = models.CharField(choices=[ ('snmp','_(snmp)'), (\"vlan\",\"_vlan\"), (\"sysname\",\"_sysname\"), (\"copyright-info\",\"_copyright-info\"), (\"int-vlan\",\"_int-vlan\"), (\"int\",\"_int\")],max_length=100,default=\"\") test = models.CharField(max_length=1, choices=[('A', ('Author')), ('E', ('Editor'))]), class TaskSwitchModel(model.ModelForm): choices=( ('snmp','_(snmp)'), (\"vlan\",\"_vlan\"), (\"sysname\",\"_sysname\"), (\"copyright-info\",\"_copyright-info\"), (\"int-vlan\",\"_int-vlan\"), (\"int\",\"_int\") ) ActionType = model.CharField(choices=choices,max_length=100,default=\"\") Field.choices每个元组中的第一个元素是要在模型上设置的实际值，第二个元素是人类可读的名称. select_choices =[ ('A','A_'), ('B','B_'), ('C','C_'), ('D','D_'),]choices字段迭代每个元组的第一个元素是要应用于组的名称。第二个元素是一个可迭代的2代元组select2_select1_choices=[ ('A',( ('A_/','A_movie'), ('A_+','A_video'), ('A_-','A_City'), ) ), ('Video', ( ('vhs', 'VHS Tape'), ('dvd', 'DVD'), ) ), ('unknown', 'Unknown'),] db_column设置数据库列的名称 age = models.CharFiled(db_column=”年龄”) db_indexage = models.CharFiled(db_index=true)如果设置为True，则创建数据库索引 default可以是值也可以是可调用的对象，每次实例化模型的时候 会调用这个对象或值 # 1def contact_defult(): return {\"email\":\"1097690268@qq.com\"}contact_info = JSONField(\"ContactInfo\", default=contact_default)# 2member_name = CharFiled(default=\"小明\") editable可编辑字段如果为False，则该字段将不会显示在管理员或其他任何人中 ModelForm。在模型验证期间也将跳过它们。默认值为True。 uniquename = CharFiled(unique=true)如上则会保证该字段的值为表中唯一，也就是不会出现同名的人如果存在了unique 则不再需要db_index 因为unique默认存在索引 primary_key如果设置为True，则初始设置为该模型的主键。如果您未primary_key=True在模型中指定任何字段，则Django会自动添加一个AutoField来保留主键，因此primary_key=True暗示null=False和 unique=True。一个对象只允许使用一个主键。主键字段是只读的。如果更改现有对象上的主键的值然后保存，则将在旧对象的旁边创建一个新对象。 自定义的字段https://docs.djangoproject.com/zh-hans/2.2/howto/custom-model-fields/","link":"/posts/65abc8f/"},{"title":"django内容总结","text":"django内容总结在后台对某些固定字段设置颜色# models.pyfrom django.urls.html import format_htmlclass Person(models.Model): first_name = models.CharField(max_length=50) last_name = models.CharField(max_length=50) color_code = models.CharField(max_length=6) def colored_name(self): return format_html( '{} {}', self.color_code, self.first_name, self.last_name, ) admin.pyclass PersonAdmin(admin.ModelAdmin): list_display = (‘first_name’, ‘last_name’, ‘colored_name’) DjangoAdmin Django自带后台管理模板是其一大特色，但作为后台管理很多地方需要我们去改进，当然也可以使用一些其他的后台模板 推荐模板1: xadmin xadmin在几年前是为django定制的后台管理模板，但是作者已经停止维护，但是在其分支中依旧有部分人在维护。 具体使用跳转到我的掘金https://juejin.im/post/5afd267d51882542714ff756 推荐模板2： django simple-ui 在github上的星数并不高，但是是基于饿了么element-ui所写的django后台模板，我还未使用 使用本身自带的admin模板 使用其他兼容多语言的后台模板 url :https://my.oschina.net/zhiyonghe/blog/1532030 自带的Admin模板 这里介绍一下自带的admin模板。 admin界面汉化在setting.py文件中设置语言 # setting.pyLANGUAGE_CODE = 'zh-hans'IME_ZONE = 'Asia/Shanghai' Model注册在Model.py中创建完类后，需要在admin.py中完成注册，才能在后台模板中显示，方法有二 # admin.py# 方法一from django.contrib import admin from blog.models import Blogclass BlogAdmin(admin.ModelAdmin): list_display=('xx','xx','xx') # 要显示的字段 list_per_page = 50 # 每页最多显示50条 ordering = (\"-xxx\") # 设置排序，-表示降序排序 list_editable = ['','',''] # 设置可编辑字段 list_display_links = ('','',) # 默认情况下只能点击第一个字段进入编辑，设置多个字段可点击进入编辑 list_filter = ('','','') # 筛选器 search_fields = ('','','',) # 搜索字段 date_hierarchy = 'go_time' # 详细时间筛选admin.site.register(Blog,BlogAdmin)# 方法二from djang.contrib import adminfrom blog.models import Blog@admin.register(Blog)class BlogAdmin(admin.ModelAdmin): list_display=('','','') Django for ajaxdjango 前后台传递消息内容的方法有很多种,这里我们来讲一下ajax for django # 路由地址# 项目路径下path('',include('GraphPro.urls'))# 应用路径下path('echartsdemo/',demoView.as_view(),name=\"demo\"),# 视图层class demoView(View): def get(self,request): if request.GET.get('name') == 'hzj': return HttpResponse(\"ssdsdsd\") else: print(2) return render(request,'demo.html') def post(self,request): pass# 模板层 点击 {{ data }} $(document).ready(function () { var name = $('#name').val(); var data = {\"name\":name}; $(\"#click_func\").click(function () { $.get( //请求的url '{% url 'demoecharts' %}', data, function (ret) { console.log(ret) } ) }) }) 进入页面直接请求后台数据 $(document).ready(function () { var data = {\"name\":\"hzj\"}; $.get( //请求的url '{% url 'demo' %}', data, function (ret) { console.log(ret) } ) }) 异步加载数据 $(document).ready(function () { var data = {\"name\":\"hzj\"}; $.get( //请求的url '{% url 'demo' %}', data, ).done(function(ret){ console.log(ret) }) }) 介绍Mysql在Django中的引用由于Django在初始化项目后，所使用的数据库是sqlite3,但为了扩展，我们这里计划使用Mysql,配置步骤如下 配置1.在服务器上安装Mysql数据库(Centos版)2.在django的setting.py中引用 错误类型总结由于mysql与django在配置过程中会存在很多的错误，这里总结一下 Mysql在Centos中权限不足的错误ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 原因是/var/lib/mysql的访问权限不足 1.改变权限 chown -R mysql:mysql /var/lib/mysql 2. 启动服务器 /etc/init.d/mysql start (会自动生成mysql.sock文件) 3.重新启动mysql服务 /etc/init.d/mysql start 密码类型错误1045, \"Access denied for user 'root'@'122.224.83.xxx 原因 密码错误，注意密码不能是字符串 GRANT ALL PRIVILEGES ON *.* TO root@'%' IDENTIFIED BY '123456' WITH GRANT OPTION; django setting 中的配置DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'itemids', # 数据库名字 'USER': 'root', # 数据库登录名 'PASSWORD': '12345x', # 数据库密码 'HOST': '106.14.195.xxx', 数据库IP 'POST': 3306, # 端口 }} 引用pymysql由于MySQLdb只能使用在Python2中，在python3中已经停止了维护，所以这里我们引用pymyql的库 pipenv install pymysql# 在与setting.py同级别的__init__.py中使用import pymysqlpymysql.install_as_MySQLdb() pymysql版本不符合报错内容:django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.3 or newer is required; you have 0.7.11修改Pipenv\\Lib\\site-packages\\django\\db\\backends\\mysql\\base.py注释下面内容if version < (1, 3, 3): raise ImproperlyConfigured(“mysqlclient 1.3.3 or newer is required; you have %s” % Database.version) (在Centos中，pipenv install 所生成的包 会在pipenv shell 激活环境的时候出现) 由于上面注释，还会出现的报错内容为File “C:\\Users\\Administrator\\PycharmProjects\\untitled1\\venv\\lib\\site-packages\\django\\db\\backends\\mysql\\operations.py”, line 146, in last_executed_query将operations.py中的decode改成encode mysql不能插入中文报错内容： django.db.utils.InternalError: (1366, “Incorrect string value: ‘\\xE5\\xAE\\x9A\\xE6\\x97\\xB6…’ for column ‘name’ at row 1”)解决方法: https://blog.csdn.net/tzh476/article/details/52644271删除之前的库，创建一个新的数据库，使用utf8mb64 之前默认创建的都是latin1 mysql 长度的问题django.db.utils.InternalError: (1071, ‘Specified key was too long; max key length is 767 bytes’)https://blog.csdn.net/ljfphp/article/details/80406907https://www.orcode.com/question/407126_k280b8.html 解决方法1: 升级Mysql5.6–>>Mysql5.7centos7 下 对mysql的操作 https://blog.csdn.net/xufengzhu/article/details/81110982https://blog.51cto.com/lisea/1941616 解决方法2 : 先使用utf8格式 —-> 介绍Mysql在Django中的引用由于Django在初始化项目后，所使用的数据库是sqlite3,但为了扩展，我们这里计划使用Mysql,配置步骤如下 配置1.在服务器上安装Mysql数据库(Centos版)2.在django的setting.py中引用 错误类型总结由于mysql与django在配置过程中会存在很多的错误，这里总结一下 Mysql在Centos中权限不足的错误ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 原因是/var/lib/mysql的访问权限不足 1.改变权限 chown -R mysql:mysql /var/lib/mysql 2. 启动服务器 /etc/init.d/mysql start (会自动生成mysql.sock文件) 3.重新启动mysql服务 /etc/init.d/mysql start 密码类型错误1045, \"Access denied for user 'root'@'122.224.83.xxx 原因 密码错误，注意密码不能是字符串 GRANT ALL PRIVILEGES ON *.* TO root@'%' IDENTIFIED BY '123456' WITH GRANT OPTION; django setting 中的配置DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'itemids', # 数据库名字 'USER': 'root', # 数据库登录名 'PASSWORD': '12345x', # 数据库密码 'HOST': '106.14.195.xxx', 数据库IP 'POST': 3306, # 端口 }} 引用pymysql由于MySQLdb只能使用在Python2中，在python3中已经停止了维护，所以这里我们引用pymyql的库 pipenv install pymysql# 在与setting.py同级别的__init__.py中使用import pymysqlpymysql.install_as_MySQLdb() pymysql版本不符合报错内容:django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.3 or newer is required; you have 0.7.11修改Pipenv\\Lib\\site-packages\\django\\db\\backends\\mysql\\base.py注释下面内容if version < (1, 3, 3): raise ImproperlyConfigured(“mysqlclient 1.3.3 or newer is required; you have %s” % Database.version) (在Centos中，pipenv install 所生成的包 会在pipenv shell 激活环境的时候出现) 由于上面注释，还会出现的报错内容为File “C:\\Users\\Administrator\\PycharmProjects\\untitled1\\venv\\lib\\site-packages\\django\\db\\backends\\mysql\\operations.py”, line 146, in last_executed_query将operations.py中的decode改成encode mysql不能插入中文报错内容： django.db.utils.InternalError: (1366, “Incorrect string value: ‘\\xE5\\xAE\\x9A\\xE6\\x97\\xB6…’ for column ‘name’ at row 1”)解决方法: https://blog.csdn.net/tzh476/article/details/52644271删除之前的库，创建一个新的数据库，使用utf8mb64 之前默认创建的都是latin1 mysql 长度的问题django.db.utils.InternalError: (1071, ‘Specified key was too long; max key length is 767 bytes’)https://blog.csdn.net/ljfphp/article/details/80406907https://www.orcode.com/question/407126_k280b8.html 解决方法1: 升级Mysql5.6–>>Mysql5.7centos7 下 对mysql的操作 https://blog.csdn.net/xufengzhu/article/details/81110982https://blog.51cto.com/lisea/1941616 解决方法2 : 先使用utf8格式","link":"/posts/7e91b378/"},{"title":"django 用户","text":"django用户django为开发者提供了三种不同的用户形式，一种是自带的用户模型(User),另外两种是可以自定义的用户模型，分别是(AbstractUser)(AbstractBaseUser),他们的继承关系分别是 User 继承子AbstractUser 继承自AbstractBaseUser django自带的用户模型使用django自带的用户模型(快速实现)，该模型提供了一些开发过程中会经常使用到的参数，比如用户级别，名字，邮箱，密码等等。我们可以在$\\color{red}{from django.contrib.auth.models import User}$中查看User的使用 class User(AbstractUser): \"\"\" Users within the Django authentication system are represented by this model. Username and password are required. Other fields are optional. \"\"\" class Meta(AbstractUser.Meta): swappable = 'AUTH_USER_MODEL' 自定义User Model自定义Usermodel需要注意的是，$\\color{red}{需要在setting.py中添加AUTH_USER_MODEL}$ ，由于django寻找用户的方式是在setting.py中寻找这个标示，所以在我们自定义的时候需要添加这个内容 # pro/setting.pyfrom app.model import .AUTH_USER_MODEL=\"app.modelname\" 其他需要注意的地方，请看文章底部注意栏 方法一：扩展AbstractUser如果你觉得django自带的用户不能满足你所需要的字段，需要额外添加字段的话，你可以使用AbstractUser # pro/app/models.pyfrom django.contrib.auth.models import AbstractUserfrom django.db import modelsclass NewUser(AbstractUser): new_field = models.CharField(max_length=100)# pro/setting.pyAUTH_USER_MODEL=\"app.modelname\" 方法二：扩展AbstractBaseUserAbstractBaseUser中只含有3个field: password, last_login和is_active. 如果你对django user model默认的first_name, last_name不满意, 或者只想保留默认的密码储存方式, 则可以选择这一方式 自定义形式如AbstarctUser一样 使用AbstractBaseUser时，虽然他提供了User最核心的实现，比如password，但是我们依旧需要添加一些必须定义的关键字段和方法 USERNAME_FIELD，用户名称字段，必须设置，且 uniqe=True class UserProfile(AbstractBaseUser): author = models.CharField(max_length=40,unique=True) USERNAME_FIELD = 'author' REQUIRED_FIELDS，当通过createsuperuser管理命令创建一个用户时，用于提示一个字段名称列表,不能包含USERNAME_FIELD以及password字段 # pro/models.pyclass UserProfile(AbstractBaseUser) date_of_birth = models.DateField() height = models.FloatField() REQUIRED_FIELDS=['date_of_birth','height'] is_active 必须定义。 一个布尔属性，标识用户是否是 “active” 的。AbstractBaseUser默认为 Ture get_full_name()必须定义。 long格式的用户标识。 get_short_name()必须定义。 short格式的用户标识。 可用方法get_username()返回 USERNAME_FIELD 的值。 is_anonymous()一直返回 False。用来区分 AnonymousUser。 is_authenticated()一直返回 Ture。用来告诉用户已被认证。 set_password(raw_password)设置密码。按照给定的原始字符串设置用户的密码，taking care of the password hashing。 不保存 AbstractBaseUser 对象。如果没有给定密码，密码就会被设置成不使用，同用set_unusable_password()。 check_password(raw_password)检查密码是否正确。 给定的密码正确返回 True。 set_unusable_password()设置user无密码。 不同于密码为空，如果使用 check_password()，则不会返回True。不保存AbstractBaseUser 对象。 has_usable_password()如果设置了set_unusable_password()，返回False。 get_session_auth_hash()返回密码字段的HMAC。 Used for Session invalidation on password change. ⚠️注意1.在创建任何迁移或者第一次运行 manager.py migrate 前设置 AUTH_USER_MODEL。设置AUTH_USER_MODEL对你的数据库结构有很大的影响。它改变了一些会使用到的表格，并且会影响到一些外键和多对多关系的构造。在你有表格被创建后更改此设置是不被 makemigrations 支持的，并且会导致你需要手动修改数据库结构，从旧用户表中导出数据，可能重新应用一些迁移。2.由于Django的可交换模型的动态依赖特性的局限，你必须确保 AUTH_USER_MODEL 引用的模型在所属app中第一个迁移文件中被创建（通常命名为 0001_initial），否则你会碰到错误(The easiest way to construct a compliant custom User model is to inherit fromAbstractBaseUser. AbstractBaseUser provides the core implementation of a Usermodel, including hashed passwords and tokenized password resets. You must then provide some key implementation details:) 引用User如果你选择了自定义用户类型，那么当你在view.py中尝试使用外键引用他的时候，你会出现错误，你应该使用$\\color{red}{django.contrib.auth.get_user_model来引用模型} def get_user_model(): \"\"\" Return the User model that is active in this project. \"\"\" try: return django_apps.get_model(settings.AUTH_USER_MODEL, require_ready=False) except ValueError: raise ImproperlyConfigured(\"AUTH_USER_MODEL must be of the form 'app_label.model_name'\") except LookupError: raise ImproperlyConfigured( \"AUTH_USER_MODEL refers to model '%s' that has not been installed\" % settings.AUTH_USER_MODEL 同样的，他会根据setting中的AUTH_USER_MODEL来识别当前用户 from django.contrib.auth import get_user_modelUser = get_user_model 指定用户 # pro/app/models.pyclass UserProfile(models.Model): author = models.ForeignKey(setting.AUTH_USER_MODEL) https://www.cnblogs.com/huchong/p/9804635.html#_label0https://blog.csdn.net/qq_37049050/article/details/79211059","link":"/posts/f736b80/"},{"title":"django错误合集","text":"错误类型总结由于mysql与django在配置过程中会存在很多的错误，这里总结一下 Mysql在Centos中权限不足的错误ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 原因是/var/lib/mysql的访问权限不足 1.改变权限 chown -R mysql:mysql /var/lib/mysql 2. 启动服务器 /etc/init.d/mysql start (会自动生成mysql.sock文件) 3.重新启动mysql服务 /etc/init.d/mysql start 密码类型错误1045, \"Access denied for user 'root'@'122.224.83.xxx 原因 密码错误，注意密码不能是字符串 GRANT ALL PRIVILEGES ON *.* TO root@'%' IDENTIFIED BY '123456' WITH GRANT OPTION; django setting 中的配置DATABASES = { 'default': { 'ENGINE': 'django.db.backends.mysql', 'NAME': 'itemids', # 数据库名字 'USER': 'root', # 数据库登录名 'PASSWORD': '12345x', # 数据库密码 'HOST': '106.14.195.xxx', 数据库IP 'POST': 3306, # 端口 }} 引用pymysql由于MySQLdb只能使用在Python2中，在python3中已经停止了维护，所以这里我们引用pymyql的库 pipenv install pymysql# 在与setting.py同级别的__init__.py中使用import pymysqlpymysql.install_as_MySQLdb() pymysql版本不符合报错内容:django.core.exceptions.ImproperlyConfigured: mysqlclient 1.3.3 or newer is required; you have 0.7.11修改Pipenv\\Lib\\site-packages\\django\\db\\backends\\mysql\\base.py注释下面内容if version < (1, 3, 3): raise ImproperlyConfigured(“mysqlclient 1.3.3 or newer is required; you have %s” % Database.version) (在Centos中，pipenv install 所生成的包 会在pipenv shell 激活环境的时候出现) 由于上面注释，还会出现的报错内容为File “C:\\Users\\Administrator\\PycharmProjects\\untitled1\\venv\\lib\\site-packages\\django\\db\\backends\\mysql\\operations.py”, line 146, in last_executed_query将operations.py中的decode改成encode mysql不能插入中文报错内容： django.db.utils.InternalError: (1366, “Incorrect string value: ‘\\xE5\\xAE\\x9A\\xE6\\x97\\xB6…’ for column ‘name’ at row 1”)解决方法: https://blog.csdn.net/tzh476/article/details/52644271删除之前的库，创建一个新的数据库，使用utf8mb64 之前默认创建的都是latin1不一样要删除之前的库，修改数据库的属性即可 mysql 长度的问题django.db.utils.InternalError: (1071, ‘Specified key was too long; max key length is 767 bytes’)https://blog.csdn.net/ljfphp/article/details/80406907https://www.orcode.com/question/407126_k280b8.html 解决方法1: 升级Mysql5.6–>>Mysql5.7centos7 下 对mysql的操作 https://blog.csdn.net/xufengzhu/article/details/81110982https://blog.51cto.com/lisea/1941616 解决方法2 : 先使用utf8格式 django migrate的问题出现下面这个问题，基本上就是你的model设置错误了。有些字段类型需要固定的属性如integerField字段需要default这个选项，添加完之后就Ok了 Please select a fix: 1) Provide a one-off default now (will be set on all existing rows with a null value for this column) 2) Quit, and let me add a default in models.p","link":"/posts/7f55f388/"},{"title":"docker基础","text":"use docker dockerdocker与虚拟机的区别虚拟机虚拟机运行多个隔离应用时 从下到上来看: 基础设施(Infrastructure)。它可以是你的个人电脑，数据中心的服务器，或者是云主机。 主操作系统(Host Operating System)。你的个人电脑之上，运行的可能是MacOS，Windows或者某个Linux发行版。 虚拟机管理系统(Hypervisor)。利用Hypervisor，可以在主操作系统之上运行多个不同的从操作系统。类型1的Hypervisor有支持MacOS的HyperKit，支持Windows的Hyper-V以及支持Linux的KVM。类型2的Hypervisor有VirtualBox和VMWare。 从操作系统(Guest Operating System)。假设你需要运行3个相互隔离的应用，则需要使用Hypervisor启动3个从操作系统，也就是3个虚拟机。这些虚拟机都非常大，也许有700MB，这就意味着它们将占用2.1GB的磁盘空间。它们还会消耗很多CPU和内存。 各种依赖。每一个从操作系统都需要安装许多依赖。如果你的的应用需要连接PostgreSQL的话，则需要安装libpq-dev；如果你使用Ruby的话，应该需要安装gems；如果使用其他编程语言，比如Python或者Node.js，都会需要安装对应的依赖库。 应用。安装依赖之后，就可以在各个从操作系统分别运行应用了，这样各个应用就是相互隔离的。 dokcer容器相比于虚拟机来说 docker更加的简洁 从下到上 基础设施(Infrastructure)。 主操作系统(Host Operating System)。所有主流的Linux发行版都可以运行Docker。对于MacOS和Windows，也有一些办法”运行”Docker。 Docker守护进程(Docker Daemon)。Docker守护进程取代了Hypervisor，它是运行在操作系统之上的后台进程，负责管理Docker容器。 各种依赖。对于Docker，应用的所有依赖都打包在Docker镜像中，Docker容器是基于Docker镜像创建的。 应用。应用的源代码与它的依赖都打包在Docker镜像中，不同的应用需要不同的Docker镜像。不同的应用运行在不同的Docker容器中，它们是相互隔离的 区别Docker守护进程可以直接与主操作系统进行通信，为各个Docker容器分配资源；它还可以将容器与主操作系统隔离，并将各个容器互相隔离。虚拟机启动需要数分钟，而Docker容器可以在数毫秒内启动。由于没有臃肿的从操作系统，Docker可以节省大量的磁盘空间以及其他系统资源。 说了这么多Docker的优势，大家也没有必要完全否定虚拟机技术，因为两者有不同的使用场景。虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而Docker通常用于隔离不同的应用，例如前端，后端以及数据库。 概念 镜像(Image)面向docker引擎的只读模版，包含了文件系统 容器(Container)沙箱，利用容器来运行和隔离应用，容器与容器之间是相互隔离、互不可见的镜像自身是只读的。容器从镜像启动的时候，Docker会在镜像的最上层创建一个可写层。镜像本身将保持不变。 仓库(Repository)存放镜像的地方，类似于代码仓库github gitee等等 安装这个方法已经不实用了 # centos7老版本安装yum install docker -y # 查看版本docker --versionDocker version 19.03.1, build 74b1e89 安装docker-ce 社区版本docker 具有社区版和企业版，在企业版中会提供一起额外的收费服务https://docs.docker.com/install/linux/docker-ce/centos/ # centos7安装docker-ce# 卸载旧版本dockersudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine# 设置存储库sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2# 添加下载源# 国外源sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo# 阿里源sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 安装docker社区版本sudo yum install docker-ce docker-ce-cli containerd.io# 启动dockersudo systemctl start docker# 测试docker run hello-world# 查看版本docker version 镜像获取镜像# 安装Ubuntu:latest镜像[root@CodeSheep ~]# docker pull ubuntuUsing default tag: latestlatest: Pulling from library/ubuntu5c939e3a4d10: Downloading 8.608MB/26.69MBc63719cdbe7a: Download complete19a861ea6baf: Download complete651c9d2d6c4f: Downloadan zhuang # 安装Ubuntu:14.04镜像docker pull ubuntu:14.04# 从社区安装ubuntu镜像docker pull dl.dockerpool.com:5000/ubuntu 提交一个容器为新的镜像(不提倡)建议使用dockerfile创建新的镜像 docker commit CONTAINER REPOSITORY:tagroot:~# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES612090a371f6 centos \"/bin/bash\" 5 seconds ago Up 5 seconds frosty_tereshkovaroot:~# docker commit frosty_tereshkova new/centos:v4sha256:2b405e30c679a448d9b913c19c48a4c435447655001abad264fcc3e7b2264312 运行镜像docker run -t -i ubuntu /bin/bash 查看镜像信息# 列出本地主机上所有镜像# --------------------------root:~# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/ubuntu latest ccc6e87d482b 6 days ago 64.2 MB# REPOSITORY 表示镜像的仓库源# TAG 表示镜像的标签# IMAGE ID 表示镜像的ID# CREATED 镜像的创建时间# SIZE 镜像大小# --------------------------# 显示所有镜像的ID -a 显示所有镜像 -q显示IDroot:~# docker images -qa41f1d7eba8f3470671670cacccc6e87d482bfce289e99eb9# 显示镜像的摘要信息root:~# docker images --digests# 显示镜像详细信息root:~# docker images --no-trunc# 添加新的镜像标签root:～# docker tag docker.io/ubuntu:latest docker-ubuntu-version:v2root:~# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker-ubuntu-version v2 ccc6e87d482b 6 days ago 64.2 MBdocker.io/ubuntu latest ccc6e87d482b 6 days ago 64.2 MBdocker.io/ubuntu 14.04 6e4f1fe62ff1 4 weeks ago 197 MB# 查看镜像相信信息docker inspect ccc6e87d482b docker imspect ccc REPOSITORY表示镜像来自于哪个仓库TAG 标签信息，版本信息IMAMGE ID 镜像的ID号码，唯一CREATED 创建时间SIZE 镜像大小 搜寻镜像docker search mysql# --automated=false 仅显示自动创建的镜像# --no-trunc=false 输出信息不截断显示# -s --starts=0 指定仅显示评价为指定星级以上的镜像 删除镜像docker rmi IMAGE[IMAGE...]# IMAGE...可以是标签或者ID# docker rmi -f IMAGE[IMAGE...] 强制删除# 删除全部docker rmi -f $(docker images -qa) 当前镜像有被使用于某一个容器的时候，使用docker rmi IMAGE 会出现报错的内容,可以进行强制的删除，但这样的做法并不建议，可以先删除依赖于该镜像的容器，然后再删除该镜像 容器创建容器与启动使用create创建容器后，容器是处于停止状态的，可以使用start开启 # 创建容器docker create -it ubuntu:test # 开启容器docker start ID# 重新开启容器docker restart ID 新建并启动容器# docker run [OPTIONS] IMAGE [COMMAND][ARG...]# --name 指定容器名字，未指定则随机生成# -t 给docker分一个伪终端 # -i 提供交互模式 # -d 后台运行容器，并返回容器ID# -P 随机端口映射# -p 指定端口映射 主机端口:容器端口# -e 指定环境变量docker run -i -t ubuntu:latest /bin/bash# 区分-p 与 -P的区别docker pull comcat docker run -it -d -p 8080:8080 tomcatdocker run -it -d -P tomcatroot:~# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd5987c3d0257 tomcat \"catalina.sh run\" 3 seconds ago Up 2 seconds 0.0.0.0:32768->8080/tcp xenodochial_hugleae1370718b31 tomcat \"catalina.sh run\" 36 seconds ago Up 35 seconds 0.0.0.0:8080->8080/tcp upbeat_beaver exit后容器处于终止状态 守护状态运行正常情况下，退出容器后，容器处于终止状态。使用-d可以在后台运行容器 docker run -d ubuntu:latest /bin/bash -c \"while true;do echo helloworld > xx.txt;sleep 1;done\" 终止容器使用stop终止容器的时候，会先发送一个SIGTERM信号，等待10s后发送SIGKILL信号终止容器kill 会直接发送SIGKILL终止容器 # 终止容器docker stop -t xxx IDdocker stop --time xxx IDdocker kill ID 进入容器 attach 命令attach可以进入-d开启的后台运行中的容器,但是多个窗口同时attach到同一个容器的时候，所有窗口会同步显示，当某个窗口命令阻塞的时候，其他窗口也无法执行操作了docker attach ID exec 命令通常使用这个docker exec -it ID /bin/bash 删除容器删除终止状态下的容器 docker rm [OPTIONS] CONTAINER [CONTAINER...]# -f --force=false 终止并删除一个正在运行的容器# -l --link=false 删除容器的连接，但保留容器# -v --volumes=false 删除容器挂载的数据卷# 停止所有容器docker stop $(dokcer ps -q)# 删除所有容器docker rm $(docker ps -aq) #需要先暂停docker rm -f $(docker ps -aq) # 不需要暂停 导入与导出容器# 导入docker export ID > xx.tar# 导出cat xx.tar | docker import - test/ubuntu:v1 查看容器# 查看活跃的容器root:~# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4171c783b51f 470671670cac \"/bin/bash\" 12 days ago Up 2 seconds devtest# 查看所有容器root:~# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7945b6135dda ubuntu \"echo '“hello world'\" 5 seconds ago Exited (0) 4 seconds ago silly_kirch# -l 显示最近创建的容器# -n 显示最近n个创建的容器# 查看容器日志docker logs -f -t --tail IMAGE# 查看容器内运行进程docker top IMAGE# status 状态表示是否在后台运行，up表示在后台运行 Exited表示终止 复制容器内文件docker cp IMAGE:file_path now_path 帮助命令# 查看版本docker version# 显示docker信息，包括容器数量，镜像数量等等[root@CodeSheep ~]# docker infoClient: Debug Mode: falseServer: Containers: 3 Running: 0 Paused: 0 Stopped: 3 Images: 1 Server Version: 19.03.1 Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs# 查看日志docker logs CONTAINER 错误合集 错误0docker下载源出错 base | 3.6 kB 00:00:00 http://download.docker.com/linux/centos/docker-ce.rep/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not FoundTrying other mirror.To address this issue please refer to the below wiki article 这是因为添加源是国外源，有时候网络不对的情况下无法安装，建议添加阿里源 # 删除仓库内的国外源cd /etc/yum.repos.d/rm -rf docker-ce.repo download.docker.com_linux_centos_docker-ce.rep.repo # 添加阿里源sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 错误1没有开启docker服务 Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running # 检测root:~# systemctl status docker* docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; disabled; vendor preset: disabled) Active: inactive (dead) Docs: http://docs.docker.com# 开启服务systemctl start docker 错误2使用当前镜像的容器正在运行 root:~# docker rmi ccc6e87d482Error response from daemon: conflict: unable to delete ccc6e87d482b (must be forced) - image is referenced in multiple repositories# 强制删除docker rmi -f ccc6e87d482# 不建议强制删除，应当先删除所有依赖于该镜像的容器，再删除镜像","link":"/posts/3ee8c444/"},{"title":"docker-k8s","text":"learn docker 🐳🕸️ docker-k8s安装k8s及其管理工具一些需要准备的环境 关闭防火墙systemctl stop firewalldsystemctl disable firewalld 禁用selinuxsetenforce 0sed -i 's/SELINUX=permissive/SELINUX=disabled/' /etc/sysconfig/selinux 关闭swapswapoff -aecho \"vm.swappiness = 0\">> /etc/sysctl.conf 安装k8s # 国外镜像# 这里的eof会被屏蔽掉所以我在这里加了注释。让他能够完整的显示# cat < EOF > /etc/yum.repos.d/kubernetes.repo vmx /proc/sys/net/bridge/bridge-nf-call-iptables minikube搭建的单节点的过程中会需要一些时间，可能就卡着不动了 安装完成 [root@ops ~]# minikube start --vm-driver=none😄 minikube v1.7.3 on Centos 7.2.1511✨ Using the none driver based on user configuration⌛ Reconfiguring existing host ...🏃 Using the running none \"minikube\" VM ...ℹ️ OS release is CentOS Linux 7 (Core)🐳 Preparing Kubernetes v1.17.3 on Docker 19.03.6 ...🚀 Launching Kubernetes ...🌟 Enabling addons: default-storageclass, storage-provisioner🤹 Configuring local host environment ...⚠️ The 'none' driver provides limited isolation and may reduce system security and reliability.⚠️ For more information, see:👉 https://minikube.sigs.k8s.io/docs/reference/drivers/none/⚠️ kubectl and minikube configuration will be stored in /root⚠️ To use kubectl or minikube commands as your own user, you may need to relocate them. For example, to overwrite your own settings, run: ▪ sudo mv /root/.kube /root/.minikube $HOME ▪ sudo chown -R $USER $HOME/.kube $HOME/.minikube💡 This can also be done automatically by setting the env var CHANGE_MINIKUBE_NONE_USER=true🏄 Done! kubectl is now configured to use \"minikube\" 使用minikub ssh 进入容器，如果你是在Linux机器上的还，是无法使用minikub ssh 登陆的，因为你已经在minikue节点上了 使用k8s搭建多节点集群机器分配10.0.6.55 master10.0.5.233 node110.0.5.196 node2 kubeadm init on master node sudo kubeadm init --pod-network-cidr 172.100.0.0/16 --apiserver-advertise-address 192.168.205.120 # 192.168.205.120 is master node ip# result[addons] Applied essential addon: CoreDNS[addons] Applied essential addon: kube-proxyYour Kubernetes control-plane has initialized successfully!To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/Then you can join any number of worker nodes by running the following on each as root:kubeadm join 10.0.6.55:6443 --token dbw4qc.ey3dpkozmv8yb15t \\ --discovery-token-ca-cert-hash sha256:b1c47bc371709d90c6c381e6f3c7c9c034a7dcbfc585b18260016d480aab24a8 继续运行 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 检查pod [root@manager55 ~]# kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-6955765f44-2d7b4 0/1 Pending 0 7m34s # 这两个是网络插件后面安装kube-system coredns-6955765f44-hmg9g 0/1 Pending 0 7m34skube-system etcd-manager55 1/1 Running 0 7m49skube-system kube-apiserver-manager55 1/1 Running 0 7m49skube-system kube-controller-manager-manager55 1/1 Running 0 7m49skube-system kube-proxy-v8dxm 1/1 Running 0 7m34skube-system kube-scheduler-manager55 1/1 Running 0 7m49s 安装网络插件 kubectl apply -f \"https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\\n')\" 检查网络插件 [root@manager55 ~]# kubectl get pod --all-namespacesNAMESPACE NAME READY STATUS RESTARTS AGEkube-system coredns-6955765f44-2d7b4 1/1 Running 0 9m1skube-system coredns-6955765f44-hmg9g 1/1 Running 0 9m1skube-system etcd-manager55 1/1 Running 0 9m16skube-system kube-apiserver-manager55 1/1 Running 0 9m16skube-system kube-controller-manager-manager55 1/1 Running 0 9m16skube-system kube-proxy-v8dxm 1/1 Running 0 9m1skube-system kube-scheduler-manager55 1/1 Running 0 9m16skube-system weave-net-bf5jp 2/2 Running 0 42s 将其他node机器加入到master主机群下面 kubeadm join 10.0.6.55:6443 --token dbw4qc.ey3dpkozmv8yb15t \\ --discovery-token-ca-cert-hash sha256:b1c47bc371709d90c6c381e6f3c7c9c034a7dcbfc585b18260016d480aab24a8 在master主机上查看node节点加入情况 # 加入node 前[root@manager55 ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONmanager55 Ready master 11m v1.17.2 # 加入之后[root@manager55 ~]# kubectl get nodesNAME STATUS ROLES AGE VERSIONmanager55 Ready master 60m v1.17.2work196 Ready 34m v1.17.2work233 Ready 15m v1.17.2 构建docker+k8s系统环境脚本centos7版本 #/bin/sh# install some toolssudo yum install -y vim telnet bind-utils wget# install dockercurl -fsSL get.docker.com -o get-docker.shsh get-docker.shif [ ! $(getent group docker) ];then· sudo groupadd docker;else echo \"docker user group already exists\"fisudo gpasswd -a $USER dockersudo systemctl restart dockerrm -rf get-docker.sh# open password auth for backup if ssh key doesn't work, bydefault, username=vagrant password=vagrantsudo sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/g' /etc/ssh/sshd_configsudo systemctl restart sshdsudo bash -c 'cat","link":"/posts/7cebdf57/"},{"title":"docker-swarm-wordpress","text":"learn docker 🐳🐳 docker-swarm-wordpress通过docker + swarm + wordpress 建立集群 实战在不指定同网络组的情况下，docker默认将所有的ip都归类到名字叫做docker0的bridge组里面，但是这样在跨机器的容器中，构建会十分麻烦，无法通过容器名来进行ip通信因此，在创建的过程中需要指定网络组 创建一个overlay的网络docker network create -d overlay demo# 查看是否创建成功 [root@manager55 ~]# docker network lsNETWORK ID NAME DRIVER SCOPEee5b54750620 bridge bridge localmxmjjml84ldx demo overlay swarm6ad358de8e6b docker_gwbridge bridge localf127d4764edd host host localihvz4z5lfwis ingress overlay swarm 8000/tcp[root@manager55 ~]# docker service ps clientID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSt7xe5omklz28 client.1 busybox:latest work196 Running Running 15 minutes ago 可以发现busybox的容器是运行在work196上面的，这个时候我们去busybox ping whoami这个容器名， [root@work196 ~]# docker exec bd2b98fdc7f9 ping whoamiPING whoami (10.0.2.2): 56 data bytes64 bytes from 10.0.2.2: seq=0 ttl=64 time=0.077 ms64 bytes from 10.0.2.2: seq=1 ttl=64 time=0.194 ms64 bytes from 10.0.2.2: seq=2 ttl=64 time=0.193 ms # 查看whoami容器的ip[root@manager55 ~]# docker ecec dfcd2f4c0396 ip adocker: 'ecec' is not a docker command.See 'docker --help'[root@manager55 ~]# docker exec dfcd2f4c0396 ip a1: lo: mtu 65536 qdisc noqueue state UNKNOWN qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever31: eth1@if32: mtu 1450 qdisc noqueue state UP link/ether 02:42:0a:00:00:08 brd ff:ff:ff:ff:ff:ff inet 10.0.0.8/24 brd 10.0.0.255 scope global eth1 valid_lft forever preferred_lft forever33: eth2@if34: mtu 1500 qdisc noqueue state UP link/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff inet 172.18.0.3/16 brd 172.18.255.255 scope global eth2 valid_lft forever preferred_lft forever35: eth0@if36: mtu 1450 qdisc noqueue state UP link/ether 02:42:0a:00:02:03 brd ff:ff:ff:ff:ff:ff inet 10.0.2.3/24 brd 10.0.2.255 scope global eth0 valid_lft forever preferred_lft forever 在ping whoami容器时候，并没有其ping他的任何一个ip说明在这之上又做了一层vip，用来统一管理所有容器名为whoami的机器 扩展whoamin容器 docker service scale whami=4 再次使用ping的时候会发现，同样ping的是这个vip 查看虚拟ip下面的ip [root@work196 ~]# docker exec bd2b98fdc7f9 nslookup tasks.whoamiServer: 127.0.0.11Address: 127.0.0.11:53Non-authoritative answer:Name: tasks.whoamiAddress: 10.0.2.10Name: tasks.whoamiAddress: 10.0.2.3Name: tasks.whoamiAddress: 10.0.2.9Name: tasks.whoamiAddress: 10.0.2.8*** Can't find tasks.whoami: No answer 其实这些内容就是vip下面的真正的IP因此service 与service之间是通过vip进行通信的","link":"/posts/1976fb59/"},{"title":"docker镜像分层原理","text":"learn docker 😊 docker镜像分成原理base镜像base 镜像有两层含义： 不依赖其他镜像，从 scratch 构建。 其他镜像可以之为基础进行扩展。如centos镜像 原理解析了解几个概念 联合文件系统(Union File System):是一种把其它文件系统联合到一个联合挂载点的文件系统服务，它使用 branch 把不同文件系统的文件和目录”透明地”覆盖，形成一个单一一致的文件系统。这些 branch 或者是 read-only 的，或者是 read-write 的，所以当对这个虚拟后的联合文件系统进行写操作的时候，系统是真正写到了一个新的文件中。看起来这个虚拟后的联合文件系统是可以对任何文件进行操作的，但是其实它并没有改变原来的文件。这是因为 Union File System 用到了一个重要的资源管理技术：写时复制。 写时复制(copy-on-write，常被简写为 CoW)，也叫隐式共享，是一种提高资源使用效率的资源管理技术。它的思想是：如果一个资源是重复的，在没有对资源做出修改前，并不需要立即复制出一个新的资源实例，这个资源被不同的所有者共享使用。当任何一个所有者要对该资源做出修改时，复制出一个新的资源实例给该所有者进行修改，修改后的资源成为其所有者的私有资源。通过这种资源共享的方式，可以显著地减少复制相同资源带来的消耗，但是这样做也会在进行资源的修改时增加一部分开销。 AUFS文件系统实例https://www.cnblogs.com/sparkdev/p/11237347.html docker镜像组成在docker的image中,他其实是由一层一层的基础文件系统所叠加起来的，联合文件系统(UnionFS)他可以将几层目录挂载到一起，形成一个虚拟文件系统,docker 通过这些文件再加上宿主机的内核提供了一个 linux 的虚拟环境。每一层文件系统我们叫做一层 layer，联合文件系统可以对每一层文件系统设置三种权限，只读（readonly）、读写（readwrite）和写出（whiteout-able） 但是在docker的镜像中的每一层的基础文件系统都是只读的，我们可以把他们叫做base 最基础的。构建镜像的时候，从一个最基本的操作系统开始，每个构建的操作都相当于做一层的修改，增加了一层文件系统。一层层往上叠加，上层的修改会覆盖底层该位置的可见性，这也很容易理解，就像上层把底层遮住了一样。当你使用的时候，你只会看到一个完全的整体，你不知道里面有几层，也不清楚每一层所做的修改是什么。结构类似这样： 当我们在从官方拉去镜像的时候，他的操作也会实现这一步叠加的过程，记住 像我们平时使用的ubuntu centos nginx这样的docker镜像都不是最原始的镜像，他们也都是一层一层的文件系统base叠加起来的,比如拉去ubuntu镜像他一共会拉去四层文件系统来完成整个ubuntu镜像的搭建，最后生成一个ubuntu的镜像，因此在外部看来他是单独的镜像文件，但其实他是由多个基础的文件系统通过联合文件系统叠加产生的。 docker镜像加载 bootfs 在linux的开机过程中会用到bootfs,主要包含bootloader 和 kernel，bootloader 主要用于引导加载 kernel，当 kernel 被加载到内存中后kernel后，bootfs就会被umount掉。 rootfs rootfs (root file system) 包含的就是典型 Linux 系统中的/dev，/proc，/bin，/etc 等标准目录和文件,不同的linux发行版本，rootfs文件系统可能不通 控制读写权限,传统的 Linux 加载 bootfs 时会先将 rootfs 设为 read-only，然后在系统自检之后将 rootfs 从 read-only 改为 read-write，然后我们就可以在 rootfs 上进行读写操作了。但 Docker 在 bootfs 自检完毕之后并不会把 rootfs 的 read-only 改为 read-write，而是利用 union mount（UnionFS 的一种挂载机制）将 image 中的其他的 layer 加载到之前的 read-only 的 rootfs层之上，每一层 layer 都是 rootfs 的结构，并且是read-only 的。所以，我们是无法修改一个已有镜像里面的 layer 的！只有当我们创建一个容器，也就是将 Docker 镜像进行实例化，系统会分配一层空的 read-write 的 rootfs ，用于保存我们做的修改。 镜像大小的问题为什么tomcat镜像大小大于centos镜像大小?可以通过上面docker镜像的组成、加载两方面来解释同样以kernel作为最底层文件系统，在centos镜像中，上层只放了一个centos的rootfs，而tomcat需要写入多层base文件系统，比如jdk8 tomcat 等等，因此tomcat的镜像大小大于centos的镜像大小 镜像分层的好处共享资源有多个镜像都从相同的base镜像构建而来，那么宿主机只需在磁盘上保存一份base镜像，同时内存中也只需加载一份base镜像，就可以为所有容器服务了，饿而且镜像的每一层都可以被共享 创建镜像 基于已有镜像的容器创建# 提交一个容器成为一个新的镜像docker commit [OPTIONS] CONTAINER [RSPOSITORY[:TAG]]# -a; --author=\"\" 作者信息# -m; --message=\"\" 提交信息# -p; --pause=true 提交时暂停容器运行 创建流程# pull 一个新的image docker pull ubuntu# 改变ubuntu 使其与原来image不同docker run -it ccc6e87d482b /bin/bashecho \"update file \" > testexit# 返回前记住当前容器的名字，一般都是主机名# 提交当前容器为新的镜像文件docker commit -m \"update - add a file in ubuntu \" -a \"hzj\" dc758c368fda test# 查看当前镜像列表root:~# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest latest 41f1d7eba8f3 10 seconds ago 64.2 MBdocker.io/ubuntu latest ccc6e87d482b 6 days ago 64.2 MB 基于本地模版导入# 下载模版压缩包wget xx# 根据压缩包导入成镜像cat ubuntu-14.04.tar.gz | docker import - ubuntu:14.04 # 保存镜像到本地文件docker save -o ubuntu_latest.tar ubuntu:latest# 载入镜像docker load --input ubuntu_latest.tardocker load < ubuntu_latest.tar 基于Dockerfile创建 如何创建一个hello-world的docker镜像 创建一个输出hello world的c文件#includeint main(){ printf(\"hello world\\n\");} 编译c文件gcc -static hello.c -o hello 编写dockerfileFROM scratchADD hello /CMD ['/hello'] 新建helloworld镜像docker -f /tmp/dockerfile -t helloworld .","link":"/posts/685470da/"},{"title":"docker容器数据卷","text":"learn docker 数据管理数据卷是一个可提供使用的特殊目录，他绕过文件系统，可以提供很多有用的内容 数据卷可以在容器之间共享和重复使用 对数据卷的修改会立马生效 对数据卷的更新，不会影响镜像 卷会一直存在 直到没有容器使用 创建数据卷# 查看数据卷root:~# docker volume lsDRIVER VOLUME NAMElocal 1c4c829dcedf5c071d6a14dea5cf9a40e5459a6d81d2a009ecef6c392156121clocal 2a8601766a8ec82c39132bc64c2c99546053cb4104bd94507f215b888e60464dlocal 3fad677be0bbe16df041895a36b7ce088a57f6c75fcab163664522ddc405100dlocal 3ff453f8da89ad256ee7971df11bc3297443b894584cec147c8637ce838a274b# 查看volumes详细信息docker volume inspect 1c4c829dcedf5c071d6a14dea5cf9a40e5459a6d81d2a009ecef6c392156121c# 创建数据卷连接docker run -it -v /宿主机绝对目录:/容器内目录 镜像名# 运行时，挂载卷# 无论哪一方修改文件，数据卷都会同步到另一端# --privileged 关闭selinuxdocker run -it -d -v /tmp/data/:/tmp/ --name test1 --privileged=true centos# 定义权限doker run -it -v /宿主机绝对目录:/容器内目录:权限 镜像名# 只读 ro - read-onlydocker run -it -d -v /tmp/data/:/tmp/:ro --name test1 --privileged=true centos 查看是否挂载成功docker inspect test1 inspect会按照json的形式输出配置，其中mount表明了数据卷的挂载情况RW:true表示可读写 容器间数据共享传递从上面我们可以直到容器与本机之间的传递我们是有的是-v 或者dockerfile中的VOLUME进行挂载在容器与容器之间，使用的是–volumes-from来进行文件之间的挂载,并且只要容器存在，容器数量上的减少和增加都不会使得挂载文件的消失 docker -it --name doc2 --volumes-from doc1 hzj/centos2 报错 问题1ls: cannot open directory ‘tmp/‘: Permission denied无法访问目录，权限拒绝。该问题通常在centos7下出现。或者一个容器启动成功后，里面的服务无法成功访问，这是因为centos7中的安全模块selinux把权限禁掉了，一般的解决方案有以下两种： 临时关闭selinux直接在centos服务器上执行以下命令即可。执行完成以后建议重新docker run。setenforce 0 给容器加权限在docker run时给该容器加权限，加上以下参数即可# --privileged=truedocker run -it -d -v /tmp/data/:/tmp/ --name test1 --privileged=true centos 问题2为啥没有这个命令root@8d3aece482eb tmp]# getenforcebash: getenforce: command not found[root@8d3aece482eb tmp]#[root@8d3aece482eb tmp]#[root@8d3aece482eb tmp]# setenforcebash: setenforce: command not found[root@8d3aece482eb tmp]# 因为这是最精简的centos,删除了所有跟内核无关的东西","link":"/posts/5f4d14d2/"},{"title":"CI-CD实践","text":"learn CI/CD CI/CD 自动化部署流程gitlabgitlab-ci 另外的参数https://docs.gitlab.com/ce/ci/yaml/README.html 项目一 使用gitlab作为代码托管-实践shellgitlab-help文档http://10.0.5.233:8888/help 搭建gitlab-server安装git-lab 清华镜像源地址https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/ # cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) # git --versiongit version 1.8.3.1# wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7/gitlab-ce-12.5.9-ce.0.el7.x86_64.rpm # lsgitlab-ce-12.0.2-ce.0.el7.x86_64.rpm 安装依赖 sudo yum install -y git vim gcc glibc-static telnetsudo yum install -y curl policycoreutils-python openssh-serversudo systemctl enable sshdsudo systemctl start sshdsudo yum install postfixsudo systemctl enable postfixsudo systemctl start postfix 安装gitlab rpm -i gitlab-ce-12.0.2-ce.0.el7.x86_64.rpm 上传项目到gitlab地址➜ untitled git:(doc5) git push -u origin masterUsername for 'http://gitlab.example.com:8888': rootPassword for 'http://root@gitlab.example.com:8888':Enumerating objects: 8414, done.Counting objects: 100% (8414/8414), done.Delta compression using up to 8 threadsCompressing objects: 100% (5158/5158), done.Writing objects: 100% (8414/8414), 11.67 MiB | 732.00 KiB/s, done.Total 8414 (delta 2103), reused 8401 (delta 2099)remote: Resolving deltas: 100% (2103/2103), done.To http://gitlab.example.com:8888/root/tc.git * [new branch] master -> masterBranch 'master' set up to track remote branch 'master' from 'origin'. gitlab-ci搭建安装docker curl -sSL https://get.docker.com/ | sh 安装gitlab-ci-runner curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-ci-multi-runner/script.rpm.sh | sudo bashsudo yum install gitlab-ci-multi-runner -y 查看运行状态 [root@manager55 ~]# sudo gitlab-ci-multi-runner statusgitlab-runner: Service is running! 为了能让gitlab-runner能正确的执行docker命令，需要把gitlab-runner用户添加到docker group里, 然后重启docker和gitlab ci runner [root@manager55 ~]# sudo usermod -aG docker gitlab-runner[root@manager55 ~]# sudo systemctl restart docker[root@manager55 ~]# sudo gitlab-ci-multi-runner restart 注册CI-CD [root@manager55 ~]# sudo gitlab-ci-multi-runner registerRunning in system-mode.Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):http://gitlab.example.com:8888Please enter the gitlab-ci token for this runner:ppq_iFivNbgFgnusLE26Please enter the gitlab-ci description for this runner:[manager55]:Please enter the gitlab-ci tags for this runner (comma separated):tcWhether to run untagged builds [true/false]:[false]:Whether to lock Runner to current project [true/false]:[false]:Registering runner... succeeded runner=ppq_iFivPlease enter the executor: shell, ssh, virtualbox, docker-ssh+machine, docker-ssh, parallels, kubernetes, docker, docker+machine:shellRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! 如何获取token 编写gitlab.yml 任务流程 # 定义 stagesstages: - build - test# 定义 jobjob1: stage: test tags: - tc script: - echo \"I am jb1\" - echo \"I am in test stage\"# 定义 jobjob2: stage: build tags: - tc script: - echo \"I am jb2\" - echo \"I am in build stage\" 提交gitlab.yml之后再去卡看CI/CD里面的pipeline，会发想任务正在进行通过所有的jobs,包括检验等等，并在CI服务器上执行script gitlab操作修改端口,gitlab默认端口为8080端口，可以将它修改成其他的端口 sed -r '/^external_url/s/com/com:8888/g' /etc/gitlab/gitlab.rb 修改完配置文件之后要重启配置 sudo gitlab-ctl reconfigure 查看一下启用状态 root:~# gitlab-ctl statusrun: alertmanager: (pid 32102) 297s; run: log: (pid 30552) 532srun: gitaly: (pid 32128) 296s; run: log: (pid 29584) 630srun: gitlab-exporter: (pid 32151) 296s; run: log: (pid 30382) 550srun: gitlab-workhorse: (pid 32166) 296s; run: log: (pid 30066) 574srun: grafana: (pid 854) 240s; run: log: (pid 30748) 505srun: logrotate: (pid 32218) 295s; run: log: (pid 30285) 562srun: nginx: (pid 839) 241s; run: log: (pid 30184) 568srun: node-exporter: (pid 32300) 294s; run: log: (pid 30327) 556srun: postgres-exporter: (pid 32306) 294s; run: log: (pid 30633) 526srun: postgresql: (pid 32316) 293s; run: log: (pid 29748) 624srun: prometheus: (pid 32327) 293s; run: log: (pid 30489) 538srun: redis: (pid 32347) 292s; run: log: (pid 29494) 636srun: redis-exporter: (pid 32450) 292s; run: log: (pid 30432) 544srun: sidekiq: (pid 743) 251s; run: log: (pid 30005) 580srun: unicorn: (pid 1106) 214s; run: log: (pid 29965) 586s 项目二 使用gitlab作为代码托管-实践dockerPassword 项目三 gitlab-ci + drf项目 搭建CI流程线 在搭建好的gitlab上，上传项目 注册gitlab-ci-runningroot:~/tc# gitlab-ci-multi-runner registerRunning in system-mode.Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/):http://gitlab.example.com:8888Please enter the gitlab-ci token for this runner:ppq_iFivNbgFgnusLE26Please enter the gitlab-ci description for this runner:[work233]:Please enter the gitlab-ci tags for this runner (comma separated):tccWhether to run untagged builds [true/false]:[false]:Whether to lock Runner to current project [true/false]:[false]:Registering runner... succeeded runner=ppq_iFivPlease enter the executor: virtualbox, kubernetes, docker, docker-ssh, parallels, shell, ssh, docker+machine, docker-ssh+machine:sshPlease enter the SSH server address (e.g. my.server.com):10.0.5.233Please enter the SSH server port (e.g. 22):22Please enter the SSH user (e.g. root):rootPlease enter the SSH password (e.g. docker.io):upyun123Please enter path to SSH identity file (e.g. /home/user/.ssh/id_rsa):Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! 编写gitlab-ci.yml# 定义 stagesstages: - reployjob1: stage: reploy tags: - tcc script: - echo \"start reploy project about drf\" # - sudo rm -rf /root/tc/ # - git clone http://gitlab.example.com:8888/root/tc.git - cd /root/tc - cd /root/tc - sudo git fetch --all - sudo git reset --hard origin/master - sudo git pull - sudo sed -i -r '/^ALLOWED/s#\\[\\]#\\[\"\\*\"\\]#' /root/tc/untitled/settings.py - source /root/tc/venv/bin/activate - echo \"successed\" # - cd /root/tc/ - python3 manage.py runserver 0.0.0.0:8887 错误 错误1，在创建CI的时候，没有在hosts中指定ip与域名的对应关系 ERROR: Registering runner... failed runner=ppq_iFiv status=couldn't execute POST against https://gitlab.com:8888/api/v4/runners: Post https://gitlab.com:8888/api/v4/runners: dial tcp 35.231.145.151:8888: i/o timeoutPANIC: Failed to register this runner. Perhaps you are having network problems 解决: echo 10.0.5.233 gitlab.example.com >> /etc/hosts 权限的问题 gitlab-runner当你创建完成gitlab-runner之后，系统会创建多个用户来提供服务 ...git:x:995:991::/var/opt/gitlab:/bin/shgitlab-redis:x:993:990::/var/opt/gitlab/redis:/bin/falsegitlab-psql:x:992:989::/var/opt/gitlab/postgresql:/bin/shgitlab-prometheus:x:991:988::/var/opt/gitlab/prometheus:/bin/shgitlab-runner:x:990:987:GitLab Runner:/home/gitlab-runner:/bin/bash 运行gitlab-ci 时候，使用的是gitlab-runner用户的权限，有时候一些文件只有root才有权限执行，这里如果不切用户的话，可以给gitlab-runner用户附加root的权限 vi /etc/sudoers ## Allow root to run any commands anywhereroot ALL=(ALL) ALLgitlab-runner ALL=(ALL) ALL 或者可以不使用shell的模式，在创建gitlab-running的时候使用ssh的模式 git服务器上传内容之后，Gitlab的Pipelines一直在pending?可能存在的几个问题，一个是网络的问题，项目包被pull到gitlab-runner上的时间过程如果存在struct标签的话，应该是gitlab-runner被暂停了解决办法:重启gitlab-runner就可以了","link":"/posts/4115d0cd/"},{"title":"docker-DokcerFile","text":"learn docker 🐳 DokcerFiledockerfile构建三步骤dockerfile,docker build ,docker run dockerfiley有很多具体的实例可以在docker hub上看到 ，比如 centoshttps://hub.docker.com/_/centosFROM scratchADD centos-7-x86_64-docker.tar.xz /LABEL org.label-schema.schema-version=\"1.0\" \\ org.label-schema.name=\"CentOS Base Image\" \\ org.label-schema.vendor=\"CentOS\" \\ org.label-schema.license=\"GPLv2\" \\ org.label-schema.build-date=\"20191001\"CMD [\"/bin/bash\"] # 在进入容器后第一步执行的命令 tomcat镜像https://github.com/docker-library/tomcat/blob/807a2b4f219d70f5ba6f4773d4ee4ee155850b0d/8.5/jdk11/openjdk/Dockerfile dockerfile编写规则 每条保留字指令都必须为大写字母且后面要跟至少一个参数 指令按照顺序从上倒下，依次执行 #表示注释 每条指令都会创建一个新的镜像层，并对镜像进行提交 dockerfile执行顺序 docker从基础镜像运行一个容器 执行一条指令并对容器作出修改 执行类似docker commit的操作提交一个新的镜像层 docker再基于刚提交的镜像运行一个新容器 执行dockerfile中的下一跳指令直到所有指令都执行完成 docker编写关键字 FROM声明基础镜像，如centos中声明的scratch MAINTAINER镜像维护者的姓名和邮箱地址 LABEL镜像版本信息 RUN容器构建时需要运行的命令，可以用 \\ 分行 EXPOSE暴露端口，比如tomcat镜像中的dockerfile 他expose了一个8080端口，当我们在用-P随机指定端口的时候，他会默认映射我们所暴露的端口，如8080 WORKDIR登陆之后的工作目录 ENV用来构建镜像过程中设置环境变量 ADD拷贝并解压到镜像中 COPY拷贝文件到镜像中，写法:COPY src destCOPY [\"src\",\"dest\"] VOLUME容器数据卷,用于数据保存和持久化工作,写法:VOLUME [\"/data/\",\"/data1/\",] CMDdockerfile中可以有多个CMD命令,但只有最后一个生效，且CMD会被docker run之后的CMD替换掉，比如我们在启动一个镜像的时候会执行docker run -it centos /bin/bash指定一个容器要运行时，启动的命令,写法:# shell 格式CMD # exec 格式CMD [\"可执行文件\",\"参数1\",\"参数2\"]# 参数列表格式CMN ['参数1','参数2'] ENTRYPOINT指定一个容器启动时候要运行的命令，不会被替换 ONBUILD当构建一个被继承的Dockerfile时运行命令,父镜像在被子继承后，父镜像的onbuild被触发 ADD和COPY 以及远程文件的添加ADD不但可以复制还可以解压 ADD xx.tar.gz /COPY xx /tmp/data1/ 添加远程文件/目录 使用RUN curl | RUN wget WORKDIRWORKDIR表示工作目录 WORKDIR /test 如果没有test工作目录，则会自动创建 WORKDIR /testWORKDIR demo1 以上会生成的工作目录是/test/demo1 尽量使用绝对目录 CMD与ENTRYPOINT在tomcat的官方镜像包中，dockerfile里面的最后有这么一句CMD CMD [\"catalina.sh\",\"run\"] 意思就是说在dokcer run没有加CMD的情况下启动时，会去运行CMD [“catalina.sh”,”run”] 这一串内容。 06-Feb-2020 05:29:22.623 INFO [main] org.apache.catalina.startup.Catalina.load Initialization processed in 389 ms06-Feb-2020 05:29:22.639 INFO [main] org.apache.catalina.core.StandardService.startInternal Starting service [Catalina]06-Feb-2020 05:29:22.639 INFO [main] org.apache.catalina.core.StandardEngine.startInternal Starting Servlet Engine: Apache Tomcat/8.5.5006-Feb-2020 05:29:22.647 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [\"http-nio-8080\"]06-Feb-2020 05:29:22.653 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [\"ajp-nio-8009\"]06-Feb-2020 05:29:22.655 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 32 ms 但如果我们在后面加了如 /bin/bash root:/tmp# docker run -it -P tomcat /bin/bashroot@2ee3ee482178:/usr/local/tomcat# 他就不回去运行这个catalina.sh这个程序 ENTRYPOINT可以将参数累加 FROM centosRUN yum install curl -yENTRYPOINT [\"curl\",\"-s\",\"https://ip.cn/\"]docker run -it centos -> [\"curl\",\"-s\",\"https://ip.cn/\"] docker run -it centos -i -> [\"curl\",\"-s\",\"-i\",\"https://ip.cn/\"] 两种风格的编写格式 ONBUILD使用ONBUILD就是在继承父容器之后，如果子容器运行了，就会在父容器中运行ONBUILD后面的命令 FROM centosRUN yum install -y curlENTRYPOINT [\"curl\",\"-s\",\"https://ip.cn/\"] ONBUILD RUN echo \"son is run \" 父容器为m1 子容器为m2,这里的继承就是说以父容器镜像为基本模版创建的子镜像后生成的子容器 编写实例一个挂载文件的dockerfileFROM centosVOLUME [\"data1/\",\"data2/\"] # 这种定义方式无法像命令一样指定本地的文件CMD echo \"VOLUME TEST!\"CMD /bin/bash 根据编写的dockerfile构建自定义镜像 docker build -f /tmp/dockerfile -t hzj/centos . 使用Inspect查看挂载的文件路径 docker inspect hzj/centos 出现挂载的路径 \"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"2a8601766a8ec82c39132bc64c2c99546053cb4104bd94507f215b888e60464d\", \"Source\": \"/var/lib/docker/volumes/2a8601766a8ec82c39132bc64c2c99546053cb4104bd94507f215b888e60464d/_data\", \"Destination\": \"/data2\", \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" }, 用dockerfile创建一个centos镜像初始centos镜像只有最基本的kernel内容，并没有其他的软件，比如vim，比如ifconfig等。使用dockerfile创建一个centos系统 FROM centos # 基于centos，网上写东西 再生成镜像 镜像的分层原理MAINTAINER hzj # 作者信息ENV workdir /usr/local # 申明环境变量WORKDIR $workdir # 设置登陆后的工作环境RUN yum -y install vimRUN yum -y install net-toolsEXPOSE 80 # 暴露端口CMD echo $workdirCMD echo \"success\"CMD /bin/bash docker build -f dockerfile -t hzj/centos:v3 . docker开启mysql镜像docker pull mysqldocker run -p 12345:3306 --name mysql \\-v /conf/mysql/conf:/etc/mysql/conf.d \\-v /conf/mysql/logs:/logs \\ -v /conf/mysql/data:/var/lib/mysql \\-e MYSQL_ROOT_PASSWD=123456 \\ #初始化密码-d mysql:5.6 docker开启redis镜像docker pull redisdocker run -p 6379:6379 \\-v /hzj/myredis/data:/data \\-v /hzj/myredis/conf/redis.conf:/usr/local/etc/redis/redis.conf \\ -d redis:3.2 redis-server /usr/local/etc/redis/redis.conf \\--appendonly yes docker安装stress压力测试软件FROM ubuntuRUN apt-get update && apt-get install stress -yENTRYPOINT [\"/usr/bin/stress\"]# ENTRYPOINT [\"/bin/bash\",\"-c\",\"stress\"]CMD [] 生成镜像 dokcer build -f dockerfile -t new/ubuntu-stress . 利用镜像运行容器 # 不加参数 /usr/bin/stressroot:~# docker run -it new/ubuntu-stress'stress' imposes certain types of compute stress on your systemUsage: stress [OPTION [ARG]] ... -?, --help show this help statement --version show version statement -v, --verbose be verbose -q, --quiet be quiet -n, --dry-run show what would have been done -t, --timeout N timeout after N seconds --backoff N wait factor of N microseconds before work starts -c, --cpu N spawn N workers spinning on sqrt() -i, --io N spawn N workers spinning on sync() -m, --vm N spawn N workers spinning on malloc()/free() --vm-bytes B malloc B bytes per vm worker (default is 256MB) --vm-stride B touch a byte every B bytes (default is 4096) --vm-hang N sleep N secs before free (default none, 0 is inf) --vm-keep redirty memory instead of freeing and reallocating -d, --hdd N spawn N workers spinning on write()/unlink() --hdd-bytes B write B bytes per hdd worker (default is 1GB)Example: stress --cpu 8 --io 4 --vm 2 --vm-bytes 128M --timeout 10s# 加参数 /usr/bin/stress -m 1root:~# docker run -it new/ubuntu-stress -m 1stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd^Cstress: FAIL: [1] (415)","link":"/posts/8d3c2c27/"},{"title":"docker搭建wordpress","text":"learn docker 🐳 docker搭建wordpress 安装mysql、wordpress镜像docker pull mysqldocker pyll wordpress 创建mysql需要做一些初始化的配置，建议在dockerhub上查看https://hub.docker.com/_/mysqldocker run -it -d --name mysql \\-v db_data:/var/lib/mysql \\-e MYSQL_ROOT_PASSWORD=root \\-e MYSQL_DATABASE=wordpress \\mysql:8.0 创建wordpress需要连接数据库与暴露端口转换docker run -d -e WORDPRESS_DB_HOST=mysql:3306 \\--name wordpress \\--link mysql \\-e WORDPRESS_DB_USER=root \\-e WORDPRESS_DB_PASSWD=root \\-p 8888:80 \\wordpress 未成功，一直提醒数据库错误，不知道为什么? 是因为mysql没有加–default-auth=mysql_native_password这个嘛 使用docker-compose搭建wordpressversion: \"3\"services: db: image: mysql:8.0 command: - --default_authentication_plugin=mysql_native_password - --character-set-server=utf8mb4 - --collation-server=utf8mb4_unicode_ci volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest ports: - \"8000:80\" restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpressvolumes: db_data:","link":"/posts/a8b92e4/"},{"title":"docker网络","text":"learn docker 🐳 docker网络docker网络的几种模式 网路地址转换NAT内网转外网 linux的网络命名空间namesapceroot:~# sudo ip a | tail -68: docker0: mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:4f:aa:73:10 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 scope global docker0","link":"/posts/20783356/"},{"title":"swarm与k8s的区别","text":"learn docker 🐳🐳 🐳🕸️ swarm与k8s的区别url:https://cloud.tencent.com/developer/article/1361203","link":"/posts/59fd12f/"},{"title":"docker-compose","text":"learn docker 🐳 docker-compose docker-compose是一个工具 通过yml文件定义多容器的docker应用 通过一条命令就可以根据yml文件的定义去创建或者管理多个容器 三大概念 services一个service代表了一个container 这个container可以从dockerhub的image创建，或者从本地的dockerfile build出来的image创建# compose部分services: db: images: mysql:8.0 volumes: - \"db-data:/var/lib/mysql\" networks: - back-tier# 类似于COMMAND命令docker run -d --network back-tier -v db-data:/var/lib/mysql mysql:8.0# compose部分services: worker: build: ./worker links: - db - redis network: - back-tier networks volumes docker-compose安装https://docs.docker.com/compose/install/ sudo curl -L \"https://github.com/docker/compose/releases/download/1.25.3/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-composesudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose# 查看版本docker-compose --version 使用docker-compose搭建wordpressversion: \"3\"services: db: image: mysql:8.0 command: - --default_authentication_plugin=mysql_native_password - --character-set-server=utf8mb4 - --collation-server=utf8mb4_unicode_ci volumes: - db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest ports: - \"8000:80\" restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpressvolumes: db_data: docker-compose命令# 根据docker-compose.yml文件运行docker-compose -f docker-compose.yml up# 后台运行docker-compose up -d# 查看root:~# docker-compose ps Name Command State Ports------------------------------------------------------------------root_db_1 docker-entrypoint.sh --def ... Exit 0root_wordpress_1 docker-entrypoint.sh apach ... Exit 0# 停止docker-compose stop# 开启docker-compose start# 停止并删除docker-compose down# 查看compose的容器docker-compose images# 进入compose的容器docekr-compose exec IMAGE COMMAND","link":"/posts/f9b84192/"},{"title":"docker-swarm","text":"learn docker 🐳🐳 docker-swarm 准备机器 三台centos7 IP分别为10.0.5.233 10.0.5.196 10.0.6.55其中一台作为manager管理机，其他作为work随从机 # 声明管理机[root@dev ~]# docker swarm init --advertise-addr=10.0.6.55Swarm initialized: current node (yi6s9lbwc402zvv8384wiras7) is now a manager.To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-4tnasb86t2w9bppugns4v8f9vjuf635kkhfkt341lnd18sqf4c-9m7jfe2u493h3wpr24z7audiy 10.0.6.55:2377To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions. 会给出一段信息，其中node节点的token值，以及声明node节点的方法 # 声明node机[root@196 hzj]# docker swarm join --token SWMTKN-1-4tnasb86t2w9bppugns4v8f9vjuf635kkhfkt341lnd18sqf4c-9m7jfe2u493h3wpr24z7audiy 10.0.6.55:2377This node joined a swarm as a worker.[root:~]# docker swarm join --token SWMTKN-1-4tnasb86t2w9bppugns4v8f9vjuf635kkhfkt341lnd18sqf4c-9m7jfe2u493h3wpr24z7audiy 10.0.6.55:2377This node joined a swarm as a worker. 可以在manager上查看node节点 [root@manager55 ~]# docker node lsID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSIONyi6s9lbwc402zvv8384wiras7 * manager55 Ready Active Leader 19.03.5wxq2hk8ozhv1x6fdm7wplra8t work196 Ready Active 19.03.5zq7zgn8o9ozyqipw5rofub6m5 work233 Ready Active 19.03.5 docker-swarm使用可以把docker-swarm开成一个集群的搭建，首先是建立一个service的集群，在service创建多个work进行工作 # 创建服务 managerdocker service create --name demo busybox sh -c \"while true;do sleep 3600;done\"# 服务查看[root@manager55 ~]# docker service lsID NAME MODE REPLICAS IMAGE PORTSob8p30vdkhnn demo replicated 1/1 busybox:latest# container查看[root@manager55 ~]# docker service ps demoID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSrbl6tfetw25m demo.1 busybox:latest manager55 Running Running 3 hours ago 水平扩展docker-swarm可以水平扩展容器 #水平扩展5个 [root@manager55 ~]# docker service scale demo=5demo scaled to 5overall progress: 5 out of 5 tasks1/5: running [==================================================>]2/5: running [==================================================>]3/5: running [==================================================>]4/5: running [==================================================>]5/5: running [==================================================>]verify: Waiting 4 seconds to verify that tasks are stable... 将5个service同配置部署到其他机器上面，分配的方式为平均分配 [root@manager55 ~]# docker service ps demoID NAME IMAGE NODE DESIRED STATE CURRENT STATE ERROR PORTSrbl6tfetw25m demo.1 busybox:latest manager55 Running Running 3 hours agouc3tn3coc8q3 demo.2 busybox:latest work233 Running Running about a minute agody1tza747g3w demo.3 busybox:latest work233 Running Running 56 seconds agomqbt0myozide \\_ demo.3 busybox:latest work196 Shutdown Rejected about a minute ago \"No such image: busybox:latest…\"mtb3x9mabokn \\_ demo.3 busybox:latest work196 Shutdown Rejected about a minute ago \"No such image: busybox:latest…\"yyq86fjpf0i4 demo.4 busybox:latest manager55 Running Running 50 seconds agomo12k2g7gx1s \\_ demo.4 busybox:latest work196 Shutdown Rejected about a minute ago \"No such image: busybox:latest…\"cqpsqtvfeo9y \\_ demo.4 busybox:latest work196 Shutdown Rejected about a minute ago \"No such image: busybox:latest…\"t8z0vqc0kow7 \\_ demo.4 busybox:latest work196 Shutdown Rejected about a minute ago \"No such image: busybox:latest…\"fojfst6j5pa2 demo.5 busybox:latest manager55 Running Running about a minute ago 这里在部署的过程中发生了一个错误，work196的机器因为没有配置好DNS，导致无法从网上拉去busybox的镜像文件，于是发生了这样的情况首先work196收到请求去拉去busybox创建容器，但是没有DNS拉去不了，报错。根据自动分配的设置，将任务追加分配给其他work或者manage机器部署 部署之后，我们可以在work233的机器上查看起来的容器 [root@work233]:~# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES837720ea43f8 busybox:latest \"sh -c 'while true;d…\" 17 minutes ago Up 17 minutes demo.3.dy1tza747g3whbv2zuasgc6s569d08591e255 busybox:latest \"sh -c 'while true;d…\" 17 minutes ago Up 17 minutes demo.2.uc3tn3coc8q39izu3to58z9or manager机器查看work机器工作状态 [root@manager55 ~]# docker service lsID NAME MODE REPLICAS IMAGE PORTSob8p30vdkhnn demo replicated 5/5 busybox:latest 其中REPLICAS 5/5 前者表示当前一共运行多少了容器，后者表示一共复制了多少了容器 尝试关闭work233机器上的一台容器，查看工作状态 [root@work233 ~]:~# docker rm -f 837720ea43f8837720ea43f8 [root@manager55 ~]# docker service lsID NAME MODE REPLICAS IMAGE PORTSob8p30vdkhnn demo replicated 4/5 busybox:latest# some times later[root@manager55 ~]# docker service lsID NAME MODE REPLICAS IMAGE PORTSob8p30vdkhnn demo replicated 5/5 busybox:latest 在manger55上面发现运行机器已经被done了一台，但是一段时间后(不久，相当于重开一台机器的时间)会刷新成5/5 因为scale会检测并重新部署一台新的上去 水平扩展后容器的网络问题之前的docker容器全部都是运行在本地的，于是容器与容器之间是可以通过使用名叫docker0的bridge进行互相通信，但是使用docker swarm之后，容器已经分布式的部署在了多台ip的机器上面，他们的网络是否互相通信呢 # 查看work233 上的 ip[work233]:~# docker exec 69d08591e255 ip a1: lo: mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever266: eth0@if267: mtu 1500 qdisc noqueue link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# 查看manager 其中一个容器的ip[root@manager55 ~]# docker exec 0c154e8873c7 ip a1: lo: mtu 65536 qdisc noqueue qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever17: eth0@if18: mtu 1500 qdisc noqueue link/ether 02:42:ac:11:00:04 brd ff:ff:ff:ff:ff:ff inet 172.17.0.4/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever# 测试ping[root@manager55 ~]# docker exec 0c154e8873c7 ping 172.17.0.2PING 172.17.0.2 (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.186 ms# 但是ping 容器名就不可达，没有做link[root@manager55 ~]# docker exec 0c154e8873c7 ping 69d08591e255ping: bad address '69d08591e255' Q: 如果解决ping容器名不可达的问题这是因为在service启动和部署的过程中没有做link，在之后可以部署的过程中指定自己的网桥new-bridge,达到互相通信的效果具体可以看https://blog.noback.top/posts/20783356/#linux%E7%9A%84%E7%BD%91%E7%BB%9C%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4namesapce 关于服务查看只能在manager上进行查看，不能在node机上查看，会报错 [root@work196]# docker service lsError response from daemon: This node is not a swarm manager. Worker nodes can't be used to view or modify cluster state. Please run this command on a manager node or promote the current node to a manager.","link":"/posts/8f65/"},{"title":"docker容器的资源限制","text":"learn docker 🐳 docker容器的资源限制在虚拟机中我们可以对所创建的机器在资源上进行限制，比如内存等等同样的，在docker中也能对容器进行资源上的配置 # 分配400M的内存给容器 指定给memory的话是200M 但其实swap也会得到200M 因此是400Mdocker run --memory=200M new/ubuntu-stress 使用stress进行压力测试# dockerfileFROM ubuntuRUN apt-get update && apt-get install stress -yENTRYPOINT [\"/usr/bin/stress\"]# ENTRYPOINT [\"/bin/bash\",\"-c\",\"stress\"]CMD [] 先分配给他400M 然后使用stress做压力测试，stress 会开启进程，进程默认为256M 然后不断的开启不断的释放 # -m 开一个进程 --verbos 详细信息 默认开启256M --vm-bytes 指定开启多少大小的内存进程docker run --memory=200M new/ubuntu-stress -m 1 --verbos # 超范围运行root:~# docker run --memory=200M new/ubuntu-stress -m 1 --verbose --vm-bytes 500Mstress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hddstress: dbug: [1] using backoff sleep of 3000usstress: dbug: [1] --> hogvm worker 1 [6] forkedstress: dbug: [6] allocating 524288000 bytes ...stress: dbug: [6] touching bytes in strides of 4096 bytes ...stress: FAIL: [1] (415)","link":"/posts/8aa524f6/"},{"title":"k8s常见错误","text":"learn docker 🐳🕸️ ️ k8s常见错误由于k8s的使用过程中，会出现很多的问题，预计篇幅会很大，在这里做一个记录 k8s错误初始化环境过程中node子节点出现已加入master集群的情况W0210 13:47:24.391420 9455 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not set.[preflight] Running pre-flight checks [WARNING IsDockerSystemdCheck]: detected \"cgroupfs\" as the Docker cgroup driver. The recommended driver is \"systemd\". Please follow the guide at https://kubernetes.io/docs/setup/cri/ [WARNING Hostname]: hostname \"work233\" could not be reached [WARNING Hostname]: hostname \"work233\": lookup work233 on 114.114.114.114:53: no such hosterror execution phase preflight: [preflight] Some fatal errors occurred: [ERROR DirAvailable--etc-kubernetes-manifests]: /etc/kubernetes/manifests is not empty [ERROR FileAvailable--etc-kubernetes-kubelet.conf]: /etc/kubernetes/kubelet.conf already exists[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`To see the stack trace of this error execute with --v=5 or higher 解决方法重置k8s kubeadm reset 另外 WARNING不大影响，可以选择不修改，ERROR的错误会直接导致无法初始化环境 k8s pods拉取镜像时，出现证书错误的问题FailedSynError syncing pod, skipping: failed to \"StartContainer\" for \"POD\" with ErrImagePull: \"image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)\" 13m 11s 56 {kubelet 127.0.0.1} Warning FailedSync Error syncing pod, skipping: failed to \"StartContainer\" for \"POD\" with ImagePullBackOff: \"Back-off pulling image \\\"registry.access.redhat.com/rhel7/pod-infrastructure:latest\\\"\"Error syncing pod, skipping: failed to \"StartContainer\" for \"POD\" with ErrImagePull: \"image pull failed for registry.access.redhat.com/rhel7/pod-infrastructure:latest, this may be because there are no credentials on this request. details: (open /etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt: no such file or directory)\" 大致意思就是：未能通过ErrImagePull为“POD”启动“StartContainer”：“对于registry.access.redhat.com/rhel7/pod-infrastructure:latest，图像拉出失败，这可能是因为此请求上没有证书 检查发现：/etc/docker/certs.d/registry.access.redhat.com/redhat-ca.crt这个目录中是一个软连接 但是在系统中没有这个文件的存在 安装证书 yum remove *rhsm* -y yum install *rhsm* -y 使用包安装 wget http://mirror.centos.org/centos/7/os/x86_64/Packages/python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpmrpm2cpio python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpm | cpio -iv --to-stdout ./etc/rhsm/ca/redhat-uep.pem | tee /etc/rhsm/ca/redhat-uep.pemwget http://mirror.centos.org/centos/7/os/x86_64/Packages/python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpmrpm2cpio python-rhsm-certificates-1.19.10-1.el7_4.x86_64.rpm | cpio -iv --to-stdout ./etc/rhsm/ca/redhat-uep.pem | tee /etc/rhsm/ca/redhat-uep.pem docker错误docker安装过程中发生错误sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repoFile \"/bin/yum-config-manager\", line 133except yum.Errors.RepoError, e: 解决办法,python环境问题 sudo vim /bin/yum-config-manager#!/usr/bin/python -tt 改成 #!/usr/bin/python2 -tt","link":"/posts/6e725c12/"},{"title":"git基础","text":"流程工作区(我们当前的文件夹)暂存区(add 提交之后文件所存在的位置)仓库(commit 之后将暂存区提交到的地方) 首先是init初始化我们的工作区，这时候当前存在.git文件的就是我们的工作区，当前路径为我们的根目录在工作区创建一个新的文件test.txt，git add 之后文件上传到暂存区，我们可以用git status 会记录当前暂存区的操作git diff可以比较工作区和暂存区的差异，当然这里是没有任何差异的，因为他们是同样的两份文件修改test.txt 之后再去git diff 你会发现他们之间存在着差异，因为这个时候他们已经不是同样两份文件了假如你再次 使用Git add . 再用git diff 时又没有差异了 安装# ubuntusudo apt-get install git# centos yum install git -y# mac brew install git 全局声明用户git config –global user.name “your name”git config –global user.email “xxx@xxx.com“ 声明仓库 必须mkdir testcd testgit init 会生成一个.git的仓库管理文件,如果你使用了zsh的主题，你会发现多了一个master 这是你当前的分支，也仅仅只有这个分支 git add . —> 将文件放到暂存区git commit —> 将文件提交到当前分支 master 声明仓库内容 不一定既然是作为开源共享的项目或者说是线上多平台交互的私库，那一定需要一个专门解释这个仓库是做什么的文件—> README.mdgit add README.md 提交并提供信息将文件提交到仓库 git commit -m \"your message\" 添加文件git add xxx.txtgit add . #添加当前文件夹所有文件 ``` ## 查看状态git status```bash# 添加文件后的状态 alpaca@hzj  ~/hzj/tu   master ●  git add README.md alpaca@hzj  ~/hzj/tu   master ✚  git statusOn branch masterChanges to be committed: (use \"git reset HEAD ...\" to unstage) modified: README.md# 提交 commit 后的状态 alpaca@hzj  ~/hzj/tu   master ✚  git commit -m \"update some file\"[master ff070f9] update some file 1 file changed, 2 insertions(+) alpaca@hzj  ~/hzj/tu   master # 状态 alpaca@hzj  ~/hzj/tu   master  git statusOn branch masternothing to commit, working tree clean 查看日志当你每一次使用commit 将文件提交到当前分支的时候，记录下每一个步骤查看使用 # 查看日志git logcommit bb3c0e3a1e850af0c70d3ce3a22995eaae177e82 (HEAD -> master)Author: alpaca Date: Thu Nov 21 11:46:24 2019 +0800 updatecommit ff070f92dee18935752e5a98b2310d275e1191b6Author: alpaca Date: Thu Nov 21 11:42:58 2019 +0800 update some filecommit 230660d585a95b90e3c6176ad21664c1b10f746aAuthor: alpaca Date: Thu Nov 21 10:37:04 2019 +0800 update some markdown file# 仅查看版本号git log --pretty=oneline# 指定版本号 如果你装了zsh 按tab就会出来commit_idgit log commit_id 由随机码(版本号) + 作者 + 日期 + commit_message 组成 回退操作版本回退，首先我们要知道一个事情 git log 只会记录下commit的过程，也就是上传到当前分支的过程，因此回退操作他并不会记录，但是他会重载之前的log状态，也就是当你一共提交了3次内容，你回退到了第三次提交前的版本。那么你的第三次提交log并不会被记录 # 回退add操作 checkout -- file 暂存区 --> 工作区git checkout -- file# 回退connit操作上 仓库 ---> 暂存区git reset --hard commit_id # 查看回退日志git reflog 提交远程仓库之前的操作都是本地的，包括最后一步git commit 也只是提交到了本地的仓库。为了更好的保存内容，我们已经引入云仓库或者说托管我们的项目 # 添加远程仓库地址git remote add origin https://gitee.com/Alpaca-H/how-to-learn-git.git # 提交当前分支到远程仓库git push origin master# 建议第一次使用push -u# Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来 在以后的推送或者拉取时就可以简化命令。 从远程仓库下载git clone https://gitee.com/Alpaca-H/how-to-learn-git.git 第一次提交的存在的问题 ! [rejected] master -> master (fetch first)error: failed to push some refs to 'https://gitee.com/Alpaca-H/how-to-learn-git.git'hint: Updates were rejected because the remote contains work that you dohint: not have locally. This is usually caused by another repository pushinghint: to the same ref. You may want to first integrate the remote changeshint: (e.g., 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 如果你是在 码云上创建的项目，它本身就存在两个README文件，也就是说仓库中本身就存在文件了，这时候你删掉这两个也没用，(github上好像没这个问题)我们需要同步远程仓库，也就是拉取下来并用–allow-unrelated-histories 合并 git pull origin master --allow-unrelated-histories git commit -m \"xxx\" #重新提交git push origin master 从远程仓库下载 – 指定分支git clone -b hzj_branch https://gitee.com/Alpaca-H/how-to-learn-git.git 分支管理# 创建分支 git branch hzj# 切换分支git checkout hzj# 创建并切换分支git checkout -b hzj# 查看当前分支git branch 记住上面的只是分支管理，他只是在你的本地有了分支，在你没有push之前所有的一切都是本地操作 分支管理2# 切换到新的分支 git swicth -c dev# 切换到已有分支git swicth dev # 添加文件echo \"我是hzj分支\" > README2.mdgit add README2.mdgit commit -m \"update hzj\"git push -u origin hzj # 提交到hzj的分支 合并分支进入master git merge hzj # 合并在本地仓库的文件 删除分支git branch -d hzj 强制覆盖本地代码$ git fetch --all$ git reset --hard origin/master $ git pull git 关于Git每次进入都需要输入用户名和密码的问题解决cd your-projectgit config --global credential.helper store git pull 输过一遍以后就不用再输入了 分支同步主干# 切换到master分支git checkout master # 下拉mastergit pull origin master# 切换分支git checkout hzj# 同步分支git merge master 主干同步分支(慎用)# 切换到主分支git checkout master# 同步分支git merge hzj# 提交git push origin master inventory操作 拉取项目git clone https://gitlab.s.upyun.com/infrastructure/inventory.git 查看当前分支git branch 切换分支git checkout hzj 修改内容… 上传git commit -am “update”git push到web端创建合并请求 更新首先切换到master，拉取最新git pull切换次分支 git checkout hzj合并更新分支到hzj分支 git merge origin hzj 发消息给有master权限的人，交由master来合并","link":"/posts/9891ebc8/"},{"title":"linux-daily","text":"learn linux 🐧 linux-daily查看内核数量top1","link":"/posts/40a08bb8/"},{"title":"swagger-ui使用","text":"SwaggerUi使用django搭建swagger-uidjango2.0之前使用django-rest-swaggerdjango2.0之后使用drf-yasg这里主要记录一些使用drf-yasg安装的过程 Qucik-Start# 安装yum install drf-yasg# setting设置INSTALLED_APPS = [ ... ' drf_yasg '， ... ]# urls.py设置...from rest_framework import permissionsfrom drf_yasg.views import get_schema_viewfrom drf_yasg import openapi...schema_view = get_schema_view( openapi.Info( title=\"Snippets API\", default_version='v1', description=\"Test description\", terms_of_service=\"https://www.google.com/policies/terms/\", contact=openapi.Contact(email=\"contact@snippets.local\"), license=openapi.License(name=\"BSD License\"), ), public=True, permission_classes=(permissions.AllowAny,),)urlpatterns = [ url(r'^swagger(?P\\.json|\\.yaml)$', schema_view.without_ui(cache_timeout=0), name='schema-json'), url(r'^swagger/$', schema_view.with_ui('swagger', cache_timeout=0), name='schema-swagger-ui'), url(r'^redoc/$', schema_view.with_ui('redoc', cache_timeout=0), name='schema-redoc'), ...] 生成地址 A JSON view of your API specification at /swagger.json A YAML view of your API specification at /swagger.yaml A swagger-ui view of your API specification at /swagger/ A ReDoc view of your API specification at /redoc/ 自定义其他验证请求方法# setting.pySWAGGER_SETTINGS = { 'SECURITY_DEFINITIONS': { # 默认验证 'basic': { 'type': 'basic' }, # 在header中以Authorization验证TOKEN 'Bearer': { 'type': 'apiKey', 'name': 'Authorization', 'in': 'header' } }} 以密码的形式输出，则为basic另外在UI界面输入,需要加入Bearer标识 网址官方网址https://swagger.io/tools/swagger-ui/drf-yasg gitbook文档https://drf-yasg.readthedocs.io/en/stable/drf-yasg gitbook地址https://github.com/axnsan12/drf-yasg","link":"/posts/a2d15b23/"},{"title":"数据库总结","text":"learn mysql 📚 登陆数据库ssh 10.0.6.55mysql -uroot -p123456 mysql 基本操作语句数据库语句操作 创建一个名为 tc 的数据库 create database tc;查看有哪些数据库 show databases; 查看数据库的创建细节 show create database tc; 创建一个使用gbk字符集的数据库 create database tc set gck;修改字符集 alter database tc character set utf8;删除创建的某个数据库 drop database tc; 表结构 use tc; # 切换数据库create table employee(_id int,name varchar(100),gender varchar(20),birthday date,entry_day date,salary flot(8,2),resume text); # 创建员工信息表show tables; # 查看当前数据库中的所有表show create table employee; # 查看表的创建心结alter table employee add image blob; # 在员工表上添加image列alter table employee modify job varchar(60); # 修改员工表中的job列，使其长度我饿60alter table employee drop image; 删除image列rename table employee to user; 表名字修改为useralter table user character set gbk; 修改表的字符集为utf-8 查看表 # 创建一个学生表create table student(id int primary key auto_increment,name varchar(20) unique not null ,chinese float,english float,math float);# 往学生表中添加一些信息insert into student(name,chinese,english,math) values ('wangba',93,22,77)insert into student (name,chinese,english,math) values('lisi',80,90,29);insert into student (name,chinese,english,math) values('wangwu',55,99,98);insert into student (name,chinese,english,math) values('zhaoliu',99,30,57);insert into student (name,chinese,english,math) values('zhouqi',78,22,77);#查询所有学生信息select * from user# 查询学生员工的姓名和对应的英语成绩select name,english from student# 过滤表中的重复数据select distinct english from student # 在所有学生分数上加10分的特长分 数据库可视化 navicatnavicat连接远程服务器的几种方式 直接连接数据库 Connection Name : hzj #随便写 主要记录的上这条连接的别名Host 10.0.6.55 # 远程服务器ipPort 3306 # 端口User Name root # 数据库账号Passwd #数据库密码 先登陆ssh 之后在连接本地的数据库 先连接ssh Host # 远程Port 22User Name # 连接数据库的用户名Authentication Method # 验证方法Private key # id_rsaPassphrase # 验证短密 选择密钥后自动生成 再连接数据库 Connection Name : hzj #随便写 主要记录的上这条连接的别名Host localhost # 远程服务器ipPort 3306 # 端口User Name root # 数据库账号Passwd #数据库密码 出现的错误 2013 - Lost connection to MySQL server at 'reading initial communication packet', system error: 0 \"Internal error/check (Not system error)\" 解决办法https://www.jb51.net/article/51480.htm","link":"/posts/3086330/"},{"title":"docker视频","text":"learn docker 🐳 https://gitlab-demo.com/xiaoquwl/dokcer-k8s-devops","link":"/posts/d99f9929/"},{"title":"wireshark网络抓包工具","text":"learn wireshark 🌍 wireshark网络抓包工具下载地址https://www.wireshark.org/download.html","link":"/posts/f633fc00/"},{"title":"笔记本","text":"future study 🌲🌲 django3.0 is supposed ASGIhttps://juejin.im/post/5de689b25188251237519c70","link":"/posts/f2caabf2/"},{"title":"nginx基础","text":"learn nginx nginxnginx安装 直接安装yum install nginx # 查看版本nginx -v 编译安装安装gcc、make、wget、g++这些软件 创建一个临时目录下载安装所需要的内容cd /tmpmkdir gen_nginx 下载安装openssl,主要用于ssl模块加密，支持htps wget https://www.openssl.org/source/openssl-1.0.2s.tar.gz 下载pcre来实现对地址重定向，地址重写功能和localtion指令以及正则表达式的支持wget https://ftp.pcre.org/pub/pcre/pcre-8.43.tar.gz 下载zlib gzip压缩模块wget https://zlib.net/zlib-1.2.11.tar.gz 下载nginxwget http://nginx.org/download/nginx-1.17.1.tar.gz 解压所有的文件ls *.tar.gz | xargs -n1 tar xzvf 使用configure编译安装具体的编译内容可以自己决定./configure \\ --with-openssl=../openssl-1.0.2s \\ --with-pcre=../pcre-8.43 \\ --with-zlib=../zlib-1.2.11 \\ --with-pcre-jit --user=admin \\ --prefix=/home/admin/nginx \\ --with-http_ssl_module \\ --with-http_v2_module 编译安装make && make install 分配权限sudo chown root nginx sudo chmod u+s nginx 正向代理局域网通过代理服务器访问Internet上的内容，这个过程叫做正向代理 反向代理客户端发送请求到反向代理服务器，由反向代理服务器选择目标服务器获取数据后，在返回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址，隐藏了真实服务器IP的地址 负载均衡通过反向代理服务器，将多个请求平均分配到目标服务器上 动静分离动态资源与动态资源分开放，由反向代理服务器来根据请求内容，将请求转发到指定目标服务器 nginx常用命令首先要进入到Nginx的目录下,如果是编译安装的话，nginx的目录应该在/usr/local/sbin/nginx中，如果是直接安装下载的话，nginx的目录应该在/usr/sbin/nginx cd /usr/sbin/nginx# 查看Nginx进程ps -ef | grep nginx# 查看nginx的版本号./nginx -v# 强制关闭Nginx./nginx -s stop# 退出nginx./nginx -s quit# 启动nginx./nginx# 重新加载nginx./nginx -s reload nginx配置文件如果是直接安装，则配置文件在/etc/nginx/nginx.conf，如果是编译安装，则配置文件在/usr/local/nginx中查找nginx配置文件 find / | grep nginx.conf \bnginx配置文件的组成主要分成3大块内容 第一部分: 全局模块 user nginx; # 用户 用户组 ; 一般只有类unix系统有,windows不需要worker_processes auto; # 工作进程，一般配置为cpu核心数的2倍，值越大，可以支持的并发处理量越多error_log /var/log/nginx/error.log; # 错误日志的配置路径pid /run/nginx.pid; # 进程ID存放路径include /usr/share/nginx/modules/*.conf; 第二部分: events模块主要影响nginx服务器与用户的网络连接 events { # 使用epoll的I/O 模型；epoll 使用于Linux内核2.6版本及以后的系统 use epoll; # 每一个工作进程的最大连接数量； 理论上而言每一台nginx服务器的最大连接数为： worker_processes*worker_connections worker_connections 1024; # 超时时间 keepalive_timeout 60 # 客户端请求头部的缓冲区大小，客户端请求一般会小于一页； 可以根据你的系统的分页大小来设定， 命令 getconf PAGESIZE 可以获得当前系统的分页大小（一般4K） client_header_buffer_size 4k; # 为打开的文件指定缓存，默认是不启用； max指定缓存数量，建议和打开文件数一致；inactive是指经过这个时间后还没有被请求过则清除该文件的缓存。 open_file_cache max=65535 inactive=60s; # 多久会检查一次缓存的有效信息 open_file_cache_valid 80s; # 如果在指定的参数open_file_cache的属性inactive设置的值之内，没有被访问这么多次（open_file_cache_min_uses），则清除缓存 # 则这里指的是 60s内都没有被访问过一次则清除 的意思 open_file_cache_min_uses 1;} 第三部分1: http模块http全局配置的指令包括文件引入、MIME-TYPE定义、日志自定义、连接超时时间、单链请求数上限等。 http { # 日志发送 # 日志格式 其中main是日志文件的名字 # -------------------------------------------------------------------------- # # 日志格式设置： # $remote_addr、$http_x_forwarded_for 可以获得客户端ip地址 # $remote_user 可以获得客户端用户名 # $time_local 记录访问的时区以及时间 # $request 请求的url与http协议 # $status 响应状态成功为200 # $body_bytes_sent 发送给客户端主体内容大小 # $http_referer 记录从哪个页面过来的请求 # $http_user_agent 客户端浏览器信息 # # 注意事项： # 通常web服务器(我们的tomcat)放在反向代理(nginx)的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。 # 反向代理服务器(nginx)在转发请求的http头信息中，可以增加$http_x_forwarded_for信息，记录原有客户端的IP地址和原来客户端的请求的服务器地址。 # -------------------------------------------------------------------------- # log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; # 指定日志文件存储地址 access_log /var/log/nginx/access.log main; # sendfile 指定 nginx 是否调用sendfile 函数（零拷贝 方式）来输出文件； # 对于一般常见应用，必须设为on。 # 如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # 负载均衡 START>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> # upstream 指令定义的节点可以被proxy_pass指令引用；二者结合用来反向代理+负载均衡配置 # 【内置策略】：轮询、加权轮询、ip_hash、最少连接 默认编译进了nginx # 【扩展策略】：fair、通用hash、一致性hash 默认没有编译进nginx #-----------------------------------------------------------------------------------------------# # 【1】默认是轮询；如果后端服务器down掉，能自动剔除。 # upstream bakend { # server 192.168.75.130:8080; # server 192.168.75.132:8080; # server 192.168.75.134:8080; # } # #【2】权重轮询(加权轮询)：这样配置后，如果总共请求了3次，则前面两次请求到130，后面一次请求到132 # upstream bakend { # server 192.168.75.130:8080 weight=2; # server 192.168.75.132:8080 weight=1; # } # #【3】ip_hash：这种配置会使得每个请求按访问者的ip的hash结果分配，这样每个访客固定访问一个后端服务器，这样也可以解决session的问题。 # upstream bakend { # ip_hash; # server 192.168.75.130:8080; # server 192.168.75.132:8080; # } # #【4】最少连接：将请求分配给连接数最少的服务器。Nginx会统计哪些服务器的连接数最少。 # upstream bakend { # least_conn; # server 192.168.75.130:8080; # server 192.168.75.132:8080; # } # # #【5】fair策略(需要安装nginx的第三方模块fair)：按后端服务器的响应时间来分配请求，响应时间短的优先分配。 # upstream bakend { # fair; # server 192.168.75.130:8080; # server 192.168.75.132:8080; # } # #【6】url_hash策略（也是第三方策略）：按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 # 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method指定hash算法 # upstream bakend { # server 192.168.75.130:8080; # server 192.168.75.132:8080; # hash $request_uri; # hash_method crc32; # } # #【7】其他设置，主要是设备的状态设置 # upstream bakend{ # ip_hash; # server 127.0.0.1:9090 down; # down 表示该机器处于下线状态不可用 # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # # # max_fails 默认为1； 最大请求失败的次数，结合fail_timeout使用； # # 以下配置表示 192.168.0.100:8080在处理请求失败3次后，将在15s内不会受到任何请求了 # # fail_timeout 默认为10秒。某台Server达到max_fails次失败请求后，在fail_timeout期间内，nginx会认为这台Server暂时不可用，不会将请求分配给它。 # server 192.168.0.100:8080 weight=2 max_fails=3 fail_timeout=15; # server 192.168.0.101:8080 weight=3; # server 192.168.0.102:8080 weight=1; # # 限制分配给某台Server处理的最大连接数量，超过这个数量，将不会分配新的连接给它。默认为0，表示不限制。注意：1.5.9之后的版本才有这个配置 # server 192.168.0.103:8080 max_conns=1000; # server 127.0.0.1:7070 backup; # 备份机；其他机器都不可用时，这台机器就上场了 # server example.com my_dns_resolve; # 指定域名解析器；my_dns_resolve需要在http节点配置resolver节点如：resolver 10.0.0.1; # } # # # #负载均衡 END","link":"/posts/21215442/"},{"title":"nginx配置实例","text":"learn nginx nginx配置实例nginx配置实例–反向代理1配置内容1台Nginx代理服务器(10.0.5.233)、一个网页效果: 客户机在浏览器中输入www.123.com 由nginx代理进行转发到我们自己的网页上 # 首先 在客户机端做域名与ip的映射echo \"10.0.5.255 www.123.com\" >> /etc/hosts# 配置nginx文件 /etc/nginx/nginx.confserver { listen 80; server_name 10.0.5.233; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { root html; proxy_pass http://127.0.0.1:8001; index index.html index.htm; } } # 上面是nginx服务器的配置，表示的是监听10.0.5.233:80 将收到的请求转发到 http://127.0.0.1:8001本地端口# 当我们在浏览器输入www.123.com:80 --> 10.0.5.233:80 --> server127.0.0.1:8001 nginx配置–反向代理2配置内容1台Nginx代理服务器(10.0.5.233)、2个网页效果: 客户机在浏览器中输入www.123.com/web1/ 跳转到第一个web页面 ; 输入www.123.com/web2/ 跳转到第二个web页面 # web页面自行配置,分别是# 127.0.0.1:8080/web1/ -> web1# 127.0.0.1:8081/web2/ -> web2# 配置nginx文件 /etc/nginx/nginx.confserver { listen 80; server_name 10.0.5.233; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; # ～ 表示后面的为正则表达式 location ~ /web1/ { proxy_pass http://127.0.0.1:8080; } location ~ /web2/ { proxy_pass http://127.0.0.1:8081; } } nginx配置–负载均衡配置内容1台Nginx代理服务器(10.0.5.233) 2个web服务器 upstream myserver { server 10.0.5.197:8001; server 10.0.5.198:8001;} server { listen 80; server_name 10.0.5.233; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; # ～ 表示后面的为正则表达式 location / { proxy_pass http://myserver; } } 策略： 默认策略为轮询每个请求按时间顺序逐一分配到后端服务器，如果后端服务器down掉，能自动剔除 权重策略weight代表权重，权重默认为1，权重越高被分配的用户越多upstream myserver { server 10.0.5.197:8001 weight=10; server 10.0.5.198:8001 weight=20;} ip_hash策略每个请求按照按访问ip的hash结果分配，每个访客固定访问一个后端服务器，可以解决session的问题upstream myserver { ip_hash; server 10.0.5.197:8001; server 10.0.5.198:8001;} fair策略科举服务器响应时间来分配，响应的越快则优先分配upstream myserver { server 10.0.5.197:8001; server 10.0.5.198:8001; fair;} nginx配置实例–动静分离动态请求与静态请求分开，用nginx处理静态页面，django处理动态页面 静态文件放在静态资源管理服务器上，动态资源放在另外的服务器上，有Nginx做转发 静态文件和动态资源一起发布在同一个服务器上，由nginx做分离 server { listen 80; server_name 10.0.5.233; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location /image/ { root /image/; # 静态文件路径 index index.html index.htm; } location /data/ { root /data/; # 静态文件路径 autoindex on; # 自动列出目录 } } nginx配置实例–高可用集群keepalived+nginx配置需求：master机器(main nginx) slave机器(backup nginx) 两台web服务器做轮询负载均衡 、 一个虚拟IP+4个机器IP nginx活性检测脚本 #!/bin/bash# 检测nginx进程数量status=`ps -C nginx --no-header | wc -l`# 如果没有进程，则重启之后再次检测nginx数量,如果依旧没有则杀掉所有keepalived的进程if [ $status -eq 0 ];then /usr/sbin/nginx sleep 2 if [ `ps -C nginx --no-header | wc -l ` -eq 0 ]; then killall keepalived fifi keepalived配置,根据主机与从机的不通，只需要修改几个参数即可router_id 、 state 、interface 、 virtual_router_id 、priority # 安装keepalivedyum install keepalived# 修改配置文件! Configuration File for keepalivedglobal_defs { notification_email { acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id nginx_master vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0}# nginx活性检测vrrp_script chk_http_port{ script \"/usr/local/src/nginx_check.sh\" interval 2 # 检测脚本执行的间隔 weight 2 # 权重}vrrp_instance VI_1 { state BACKUP # DS-backup机器 BACKUP MASTER interface eno1 virtual_router_id 51 priority 10 # 优先级别 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.196/20 }} nginx配置 upstream myserver { server 10.0.5.197:8001; server 10.0.5.198:8001;} server { listen 80; server_name 10.0.5.196; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; # ～ 表示后面的为正则表达式 location / { proxy_pass http://myserver; } } 当用户访问10.0.5.196:80端口的时候，由于196是vip 此时正在master主机上面，因此他会读取master主机上面的nginx配置文件，后续因为nginx的负载均衡(轮询的配置)，当你不断的访问10.0.5.196时，页面会在10.0.5.197:8001 与10.0.5.198:8001直接来回的跳动 nginx原理https://www.bilibili.com/video/av68136734?p=17https://www.cnblogs.com/dongye95/p/11096785.html#_label0_0","link":"/posts/12ec35da/"},{"title":"linux就该这么学","text":"Linux就该这么学yum软件仓库 yum简化rpm管理软件难度，yum能够根据用于的要求分析出所需软件包及其相关依赖，自动从服务器上下载软件包并安装到系统 |-----> 客户机yum仓库 ---->| ----> 客户机 |-----> 客户机 yum仓库的配置文件都必须要以.repo结尾并放在/etc/yum.repos.d/目录中 [rhel-media]:yum 源的名称,可自定义baseurl=file://media/cdrom : 提供方式包括 FTP(ftp://..) 、HTTP(http://) 、本地(file://)enabled = 1 : 设置次元是否可用，1 为可用 0 为禁用gpgcheck = 1 : 设置此源是否校验文件，1为校验 0 为不校验gpgkey = file:///media/cdrom/RPM-GPG-KET-redhat-release 若为校验请指定公钥文件地址 YUM仓库中的RPM软件包可以由红帽官方发布，也可以是第三方组织发布 # 命令yum repolist all # 列出所有仓库yum list all # 列出仓库中所有软件包# 以上列出的是线上的还是本地的yum info 软件包名称 # 查看软件包信息yum install 软件包名称 # 安装软件包yum reinstall 软件包名称 # 重新安装yum remove 软件包名称 # 删除软件包yum update 软件包名称 # 升级yum clean alla # 清楚所有仓库缓存yum check-update # 检查可更新的软件包yum grouplist # 查看系统已经安装的软件包组yum groupinstall 软件包组 # 安装指定的软件包组yum groupremove 软件包组 # 移除指定的软件包组yum groupinfo 软件包组 # 查询指定的软件包信息 常用指令echo 用于在终端上显示字符或变量 , 格式为 echo [字符串|变量][root@localhost ~]# echo $SHELL/bin/bash[root@localhost ~]# echo namename[root@localhost ~]# echo $HOSTNAMElocalhost.localdomain data 命令用于显示/设置系统的时间或日期, 格式为: \"data[选项][+指定的格式]\"%t 制表符(表示一个TAB键)%H 小时(00-23)%I 小时(1-12)%M 分钟%S 秒%X 相当于%H:%M:%S%Z 显示时区%p 显示本地AM或PM%A 星期%a 星期[root@localhost ~]# date +%aWed[root@localhost ~]# date +%AWednesday reboot 命令用于重启系统(仅root用户可以使用)reboot wget 命令用于下载网络文件，格式为wegt[参数] 下载地址-b 后台下载模式-O 指定目录-t 最大尝试次数-c 断点续传 # 断点续传啥意思-p 下载页面内所有资源，包括图片,视频等-r 递归下载 elinks 在终端上访问网页yum install elinks -yelinks www.baidu.com ifconfig 用于获取网卡配置与网络状态等信息: 格式为 ifconfig [网络设备] [参数]# 在Centos7中，初始系统已经不在带有ifconfig命令,需要安装yum install net-tools -y [root@localhost ~]# ifconfig eth0: flags=4163 mtu 1500 inet 10.0.5.30 netmask 255.255.240.0 broadcast 10.0.15.255 inet6 fe80::546f:27ff:fe92:5 prefixlen 64 scopeid 0x20 ether 56:6f:27:92:00:05 txqueuelen 1000 (Ethernet) RX packets 2789743 bytes 2021122197 (1.8 GiB) RX errors 0 dropped 40085 overruns 0 frame 0 TX packets 255991 bytes 349383987 (333.1 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 uname 命令用于查看系统内核版本等信息，格式为\"uanme [-a]\"内核名称、内核发行版本、内核版本、节点名、硬件名称、硬件平台、处理器类型、操作系统等信息[root@localhost ~]# uname -aLinux localhost.localdomain 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux查看详细版本cat /etc/redhat-release uptime 查看系统的负载情况 系统当前时间、系统已运行时间、当前在线用户、平均负载均衡(1,5,15分钟)[root@localhost ~]# uptime 11:02:21 up 23:49, 2 users, load average: 0.00, 0.01, 0.05# 每秒刷新一次获得当前的系统负载均衡情况[root@localhost ~]# watch -n 1 uptime free 命令用于显示当前系统中内存的使用情况,格式为 free[-m/-g]以m或g显示当前系统中内存的使用情况[root@localhost ~]# free total used free shared buff/cache availableMem: 1995208 132640 813324 6520 1049244 1780360Swap: 2097148 0 2097148[root@localhost ~]# free -m total used free shared buff/cache availableMem: 1948 129 794 6 1024 1738Swap: 2047 0 2047[root@localhost ~]# free -g total used free shared buff/cache availableMem: 1 0 0 0 1 1Swap: 1 0 1 who 命令用于查看当前登录主机的用户情况,格式为: who[参数][root@localhost ~]# whoroot tty1 2019-08-14 11:25root pts/0 2019-08-15 10:38 (10.0.3.12) last命令用于查看所有系统的登入记录: 格式为 last[参数][root@localhost ~]# lastroot pts/1 10.0.3.12 Thu Aug 15 10:41 - 10:41 (00:00) root pts/0 10.0.3.12 Thu Aug 15 10:38 still logged in root pts/0 10.0.3.12 Thu Aug 15 10:33 - 10:37 (00:04) root pts/1 10.0.3.12 Wed Aug 14 14:40 - 21:38 (06:57) root pts/0 10.0.3.12 Wed Aug 14 14:11 - 21:38 (07:26) root pts/3 10.0.3.12 Wed Aug 14 11:30 - 21:37 (10:06) root pts/2 10.0.5.175 Wed Aug 14 11:26 - 11:33 (00:06) root tty1 Wed Aug 14 11:25 still logged in root pts/1 10.0.3.12 Wed Aug 14 11:19 - 11:32 (00:12) root pts/0 10.0.3.12 Wed Aug 14 11:15 - 11:32 (00:16) root tty1 Wed Aug 14 11:12 - 11:15 (00:02) reboot system boot 3.10.0-957.el7.x Wed Aug 14 11:12 - 11:12 (23:59) wtmp begins Wed Aug 14 11:12:34 2019 history命令用于显示历史执行过的命令,格式为： history [-c][root@localhost ~]# history # 清除历史记录[root@localhost ~]# history -c# 默认历史记录保存1000条，修改最大值vim /etc/profile HISTSIZE = xxx pwd用于查看当前的工作路径pwd cd用于切换工作路径,格式: cd[目录名称]cd - 切换到上一次目录cd ~ 切换到家目录cd ~username 切换到其他用户的家目录cd .. 切换到上级目录 cat 命令查看纯文本文件(较短的), 格式为:cat[选项][文件]-n 显示行号-b 显示行号(不包括空行)-A 显示出不可见的符号 more 命令用于查看纯文本文件(较长的),格式为 more[选项] 文件 -数字 预先显示的行数(要在文件前面输入)-d 显示提示语与报错信息[root@localhost ~]# more -5 test.txt head 命令用于查看纯文本文档的前N行，格式为 head[选项][文件]查看文本前10行head -n 10 文件名正常输出，不显示最后10行head -n -10 tail 命令用于查看纯文本文档的后N行,格式为 tail [选项][文件]查看文本文件后20行tail -n 20 文件名不断刷新文件最后一行tail -n 1 -f 文件名 od命令用于对查看特殊格式的文件,格式为 od[选项][文件]-t a 默认字符-t c ASCII字符-t o 八进制-t d 十进制-t x 十六进制-t f 浮点数 tr命令用于转换文本文件中的字符,格式为 tr[原始字符][目标字符]将小写字符改成大写cat test.txt | tr [a-z][A-Z] wc 命令用于统计指定文本的行数、字数、字节数, 格式为 wc[参数] 文本-l 只显示行数-w 只显示单词数-c 只显示字节数统计当前用户中的个数wc -l /etc/passwd cut 命令通过列来提取文本字符 cut[参数] 文本-d 分隔符 指定分隔符,默认为Tab-f 指定显示的列数-c 单位改为字符获取当前系统中所有用户的名称cut -d: -f1 /etc/passwd获取root用户的默认shell解释器grep ^root /etc/passwd | cut -d: -f 7 diff 命令用于比较多个文本文件的差异,格式为diff[参数] 文件-b 忽略空格引起的差异-B 忽略空行引起的差异--brief 或者 -q 仅返回是否存在差异 (没有差异，则无返回)-c 使用上下文输出格式 touch 创建空白文件和修改文件时间 ,格式为 touch[选项][文件]对于在linux中的文件有三种时间: 更改时间(mtime):内容修改时间(不包括权限) 更改权限(ctime):更改权限和属性的时间 读取时间(atime):读取文件内容的时间","link":"/posts/4d6061df/"},{"title":"额外知识","text":"额外知识盲打练习https://www.typingclub.com/sportal/program-3/116.playhttps://pqrs.org/osx/karabiner/https://vim-adventures.com/ 总线https://baike.baidu.com/item/%E6%80%BB%E7%BA%BF oss与cdn的区别xxx webapi框架哪个是最快的web框架https://github.com/the-benchmarker/web-frameworks python高性能web框架https://falconframework.org/","link":"/posts/4904e4f5/"},{"title":"深拷贝与浅拷贝","text":"数据类型数据分为 基本数据类型(String, Number, Boolean, Null, Undefined，Symbol) 对象数据类型。 基本数据类型的特点: 直接存储在栈(stack)中的数据 引用数据类型的特点：存储的是该对象在栈中引用，真实的数据存放在堆内存里引用数据类型在栈中存储了指针，该指针指向堆中该实体的起始地址。当解释器寻找引用值时，会首先检索其在栈中的地址，取得地址后从堆中获得实体。 [图] 深拷贝和浅拷贝深拷贝和浅拷贝是只针对Object和Array这样的引用数据类型的。浅拷贝只复制指向某个对象的指针，而不复制对象本身，新旧对象还是共享同一块内存。但深拷贝会另外创造一个一模一样的对象，新对象跟原对象不共享内存，修改新对象不会改到原对象。是和Linux中的软硬链接有关系吗 赋值和浅拷贝的区别 当我们把一个对象赋值给一个新的变量时，赋的其实是该对象的在栈中的地址，而不是堆中的数据。也就是两个对象指向的是同一个存储空间，无论哪个对象发生改变，其实都是改变的存储空间的内容，因此，两个对象是联动的。 浅拷贝是按位拷贝对象，它会创建一个新对象，这个对象有着原始对象属性值的一份精确拷贝。如果属性是基本类型，拷贝的就是基本类型的值；如果属性是内存地址（引用类型），拷贝的就是内存地址 ，因此如果其中一个对象改变了这个地址，就会影响到另一个对象。即默认拷贝构造函数只是对对象进行浅拷贝复制(逐个成员依次拷贝)，即只复制对象空间而不复制资源。 浅拷贝与深拷贝 https://www.runoob.com/w3cnote/python-understanding-dict-copy-shallow-or-deep.htmlhttps://juejin.im/post/5b5dcf8351882519790c9a2e#heading-7","link":"/posts/23ccefd3/"},{"title":"extra-net","text":"Supplementary Info 额外知识私网地址有三个网段：10.x.x.x172.16.x.x至172.31.x.x192.168.x.x","link":"/posts/2a24e761/"},{"title":"图解算法","text":"这个博文可能跟图解算法的内容讲的不一样，一般都是看了书之后换一种自己认为更加形象的比喻去理解内容，如果想要看图解算法的可以去购买或者查找一些PDF的书籍，笔记对于算法和数据结构并不像语言那样，对于版本的更迭有一定程度的影响。另外，算法图解这本书中的实例都是依靠Python编写的。 二分查找其实二分法在我们生活中已经出现过了很多次，比如玩一个猜价格游戏，规定价格在500-1000之内，如果我们一个一个的去猜，则需要猜1000-500-2次，但是使用二分法猜测价格时，即每次对半猜测价格，那么每次都可以减去一半的错误价格，就像一张白纸对半折一样，最后的区域则会越来越小。而使用的次数则是log2n步。同样的例子也存在于字典中，查字典的手法同样也可以使用二分法。 概念:最多需要猜测的次数与列表长度相同，这被称为线性时间 例子1创建一个函数，接受一个有序数组和一个元素，如果指定的元素出现在数组中，则返回其位置 def filter_number(list,keywords): for i in range(len(list)): if list[i] == keywords: print(i)if __name__ == \"__main__\": list = [1,2,4,5,343,67,86,656] keywords = 343 filter_number(list,keywords) 如上所示是普通的遍历方法，遍历5次后得到343这个参数。但如果匹配的数字是656，则需要匹配7次，如果数组的长度是1000,匹配的结果是最后一个，则需要匹配1000次，这样就增加了负担 # 二分查找匹配def filter_number(list,keywords): first = 0 end = len(list) - 1 while first","link":"/posts/90ec9eea/"},{"title":"rust的简介与安装","text":"learn Rust 🦀️ rust的简介与安装什么是rust语言Rust 是一种静态和强类型的系统编程语言。 静态 意味着，所有类型在编译时都是已知的，强类型 意味着，这些类型的设计使得编写不正确的程序变得更加困难。 一个成功的汇编语言意味着你比牛仔语言(像 C 语言)更好地保证正确性。 系统 意味着通过完全控制内存，生成最佳机器码。 所以可以接受的硬件就很多啦: 操作系统，设备驱动程序和甚至可能没有操作系统的嵌入式系统。 然而，Rust 也能编写普通的应用程序代码，实际上来说，Rust 也是一种非常愉快的语言。 Rust 幕后统一原则是: 严格执行数据的 安全借用 在数据上，用函数，方法和闭包来操作 用元组，结构和枚举来聚合数据 模式匹配来选择和解构数据 trait 来定义 数据的 行为 Installurl https://www.rust-lang.org/zh-CN/tools/install curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh while you input enter ，will install rust default 上面这条命令会安装一些内容，比如 cargo rustup如果你想要使用他们，需要将他们添加到环境变量中 # 方法1source $HOME/.cargo/env# 方法2export PATH=\"$HOME/.cargo/bin:$PATH\" # 其实env里面写的就是方法2# 查看是否安装完成rustc --versionrustc 1.39.0 (4560ea788 2019-11-04) update更新版本, rustup用来管理rust的版本,rust每6个礼拜会进行一次版本迭代，使用rustup update更新版本 rustup update cargo工具Cargo：Rust 的构建工具和包管理器 cargo build #构建项目cargo run # 构建并运行项目cargo test # 测试项目cargo doc # 为项目构建文档cargo publish # 将库发布到cartes.io cargo new xxproject # 创建xxproject项目# cargo 开发者社区 cargo 使用cargo new helloworld # 创建一个项目helloworld # 生成如下文件[root@dev rustttt]# tree ..└── helloworld ├── Cargo.toml └── src └── main.rs Cargo.toml中包含了编译你项目时所需要的内容清单 src/main.rs 中包含了主程序 使用cargo build 构建项目,编译完成之后，会在生成一个编译后的可执行文件，执行他们 [root@dev helloworld]# ./target/debug/helloworldHello, world! 使用cargo run 构建项目并运行。 [root@dev helloworld]# cargo run Compiling helloworld v0.1.0 (/root/rustttt/helloworld) Finished dev [unoptimized + debuginfo] target(s) in 0.51s Running `target/debug/helloworld`Hello, world! 具体是使用文档https://doc.rust-lang.org/cargo/guide/index.html 编译rust文件 rustc# 使用cargo build创建helloworld目录cargo build helloworldcd helloworld/src/# 编译文件rustc main.rs ./main# 输出内容hello wolrd other不下载环境，直接测试代码https://play.rust-lang.orgRust官方文档https://www.rust-lang.org/zh-CN/tools/install","link":"/posts/4fbe8671/"},{"title":"Python爬YouTube视频","text":"learn python 🐍 youtube视频爬虫缘由最近想学习nginx，无奈没有好的视频，网上的教程也是零零散散的，慕课网 51CTO 淘宝上又买不到太好的教程，主要还是贵，买来要是讲的烂还不能退QAQ 于是，在YouTobe上搜索了一下nginx的教程，我的天哪！油管简直就是一块宝地，好多付费的视频上面都能找到，长期混迹B站找视频的我，决定赶紧下下来，生怕待会就没了，那么问题来了，如何批量下载这些视频呢？ 当然拉，能不白嫖还不是不要白嫖，要是讲的好，赞助一下也很重要 使用you-getGithub地址: https://github.com/soimort/you-get不得不说，光看他的star，又是一块宝藏QAQ 编写脚本既然有了下载器，接下来就是使用脚本批量下载了。you-get是根据油管的视频网页地址去下载视频的，那么我们需要记录这一组视频列表中的url地址。https://www.youtube.com/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzDhttps://www.youtube.com/watch?v=wZAf-aE2KoI&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzDhttps://www.youtube.com/watch?v=ULcqKLwf6fE&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD如上是三个测试地址，很不幸的是他们之间存在规律，但唯一发生变化的v=uid 其中的id是一串随机字符，但当我们不断刷新当前页面时会发现，uid并没有改变，也就是说在他们的数据库中存在一个key-value的值，每一个视频对一个随机uid,并且当这相对的关系生成之后，随机uid不会再发生改变。 获取uid既然不会发生改变，那么我们就用爬虫来获取这些uid把注意 像这样的页面虽然在他的右侧出现了列表，但这样的情况在当我们使用爬虫+正则的时，会被下方的视频连接干扰，因此最好先进入播放列表后再爬取像当前页面这样，我们所获取出来的uid就相对于完整一些 整理循环下载OK,有了uid再加上之前我们发现的不变的元素，那么一条条完整的视频链接就有了 源码#!/usr/bin/python3from you_get import common as you_getimport sysimport osimport timeimport requestsimport restatic_url = \"https://www.youtube.com{0}list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD\"file_path = \"D:\\\\video\\youtobe_nginx_mooc\"# file_path = \"F:\\\\video\\youtobe_nginx_mooc\"resp = requests.get(\"https://www.youtube.com/playlist?list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD\")pattern = \"\\/watch\\?v=[0-9a-zA-Z_-]{11}&\"video_url_lists = re.findall(pattern,resp.text)# 去重video_url_lists = list(set(video_url_lists))print(len(video_url_lists))for list in video_url_lists: format_url = static_url.format(list) print(format_url) print(\"start get video from YouTobe\") sys.argv = ['you-get','-o',file_path,format_url] you_get.main() time.sleep(1)print(\"download finished\")# print(type(resp)) ## 由于这是返回的类型是 # 但是在正则表达式中，要求是为str类型，因此如果我们使用pattern = re.findall('index' resp)时候就会报错# 报错内容为TypeError: expected string or bytes-like object# 修改 pattern = re.findall('index=',str(resp))# 或者使用pattern = re.findall('index=',resp.text)\"\"\"\"https://www.bilibili.com/read/cv4360/https://www.jianshu.com/p/e323cf85bd3d\"\"\"\"\"\"https://www.youtube.com/watch?v=5i9Ce9vzGxE&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1https://www.youtube.com/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1https://www.youtube.com/watch?v=R4p7xxd3BTo&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=4https://www.youtube.com/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1https://www.youtube.com/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1/watch?v=Do1Opl6DbvM&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=1https://www.youtube.com/watch?v=0JwSFgWUUQE&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzDhttps://www.youtube.com/watch?v=fvxAQsRy8Kk&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=8https://www.youtube.com/watch?v=R4p7xxd3BTo&list=PLAyxoOmo7O7eoz-Wkii_bwtBEbPwCWQzD&index=4\"\"\"","link":"/posts/b3a48f7b/"},{"title":"rust基础","text":"learn rust 🦀️ rust基础hello world任何一门语言的开始都用”hello,world”来作为开始的标记 fn main() { println!(\"hello,world\") //输出完毕后 额外添加一次回车 print!(\"hello.world\") // 无回车 } 如果你有任何的语法错误，rust会给足一定的智能提示来纠正这些错误 error[E0423]: expected function, found macro `print` --> src/main.rs:3:5 |3 | print(\"hello,world\"); | ^^^^^ help: use `!` to invoke the macro: `print!`error: aborting due to previous errorFor more information about this error, try `rustc --explain E0423`.error: could not compile `untitled`.To learn more, run the command again with --verbose. rust希望你能够在print后面添加！ 变量与打印fn main() { let number = 1; // 不可变 let mut number2 = 2; //可变 println!(\"{}\",number2+1); println!(\"{}\",number);} 他也支持格式化输出，与python类似fmt格式化 断言fn main() { let number = \"hello world\"; println!(\"{}\",number); assert_eq!(number,\"xsxs\");} hello worldthread 'main' panicked at 'assertion failed: `(left == right)` left: `\"hello world\"`, right: `\"xsxs\"`', src/main.rs:5:5note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace. 循环与条件fn main() { for i in 0..5 { if i % 2 == 0 { println!(\"even {}\", i); } else { println!(\"odd {}\", i); } }} 其中这里只包括0-4 不包括5 fn main() { for i in 0..5{ let res = if i % 2 == 0 { println!(\"is {}\",i) } else { println!(\"not {}\",i )}; }} 累加0-100 fn main() { let mut number = 0; for i in 0..101 { number += i; } println!(\"{}\",number);} 数据类型转换为了保持数据的一致，需要一些类型转换的工具 fn main() { let mut sum = 0.0; for i in 0..5 { sum += i as f64; } println!(\"sum is {}\", sum);} 引用与解引用fn by_ref(x: &i32) -> i32{ *x + 1}fn main() { let i = 10; let res1 = by_ref(&i); let res2 = by_ref(&41); println!(\"{} {}\", res1,res2);} 调用包use std::f64::consts;fn main() { let number :f64 = consts::PI; println!(\"{}\",number);} 数组与切片数组 fn main() { let arr = [10, 20, 30, 40]; let first = arr[0]; println!(\"first {}\", first); for i in 0..4 { println!(\"[{}] = {}\", i,arr[i]); } println!(\"length {}\", arr.len());} 切片切片(Slice)是一种没有所有权的数据类型。 切片引用连续的内存分配而不是整个集合。 它允许安全，高效地访问数组而无需复制。 切片不是直接创建的，而是从现有变量创建的。 切片由长度组成，并且可以是可变的或不可变的。 切片的行为与数组相同。//原文出自【易百教程】，商业转载请联系作者获得授权，非商业请保留原文链接：https://www.yiibai.com/rust/rust-slices.html 使用切片 fn main() { let words = \"hello wolrd\"; // 获取字符串长度 let words_numbers = words.len(); // 获取所有字符串 let words1 = &words[0..]; // 字符串切片 let words2 = &words[0..2]; println!(\"words is '{}'\\nwords_numbers is '{}' \\nwords1 is '{}'\\n\",words,words_numbers, words1); println!(\"words2 is '{}'\",words2);} // 累加和fn main() { let arr = [10,20,30,40]; let res = sum_numbers(&arr[0..]); println!(\"{}\",res)}// 获取一个数组切片 类型为i32，返回一个i32fn sum_numbers(arr: &[i32]) -> i32{ let mut res = 0; for i in 0..arr.len(){ res += arr[i]; } res} 切片的get方法 get方法返回一个option值 如果给定位置，则返回对该位置处元素的引用或None超出范围。 如果给定范围，则返回对应于该范围的子切片，或者None超出范围。 fn main() { let ints = [1, 2, 3, 4, 5]; let slice = &ints; let first = slice.get(0); let last = slice.get(5); println!(\"first {:?}\", first); println!(\"last {:?}\", last);}// first Some(1)// last None 向量fn main() { let mut v = Vec::new(); v.push(10); v.push(20); v.push(30); let first = v[0]; // 同样，超出范围也会 panic let maybe_first = v.get(0); println!(\"v is {:?}\", v); println!(\"first is {}\", first); println!(\"maybe_first is {:?}\", maybe_first);} 迭代器fn main() { let mut iter = 0..3; assert_eq!(iter.next(), Some(0)); assert_eq!(iter.next(), Some(1)); assert_eq!(iter.next(), Some(2)); assert_eq!(iter.next(), None);} 迭代器很容易定义。 下面是一个”对象”，它使用next方法返回一个Option。只要这个值不是None，我们就一直next下去:使用迭代进行循环 fn main() { let arr = [10, 20, 30]; for i in arr.iter() { println!(\"{}\", i); } // 切片将隐式转换为迭代器... let slice = &arr; for i in slice { println!(\"{}\", i); }} 使用迭代进行数字累加 fn main() { let sum: i32 = (0..5).sum(); println!(\"sum was {}\", sum); let sum: i64 = [10, 20, 30].iter().sum(); println!(\"sum was {}\", sum);} 更多切片方法 Option值fn main() { let ints = [1, 2, 3, 4, 5]; let slice = &ints; let first = slice.get(0); let last = slice.get(5); println!(\"first {:?}\", first); println!(\"last {:?}\", last); println!(\"some is { }\",first.unwrap()); let first = if first.is_some(){ *first.unwrap() } else { -1 }; println!(\"{}\",first);}// first Some(1)// last None // some is 1// 1 注意* - Some内部的精确类型是&i32，这是一个引用。 我们需要解引用回到一个i32的值. 字符串fn dump(s: &str) { println!(\"str '{}'\", s);}fn main() { let text = \"hello dolly\"; // string 切片 这里已经是切片 let s = text.to_string(); // 这里不是切片 &s 是引用 dump(text); dump(&s);} 获取命令行参数fn main() { for arg in std::env::args() { println!(\"'{}'\", arg); }} let args: Vec = std::env::args().skip(1).collect(); 匹配match multilingual.find('п') { Some(idx) => { let hi = &multilingual[idx..]; println!(\"Russian hi {}\", hi); }, None => println!(\"couldn't find the greeting, Товарищ\") }; 只匹配一次 if let Some(idx) = multilingual.find('п') { println!(\"Russian hi {}\", &multilingual[idx..]); } 类似于switch用法 let text = match n { 0 => \"zero\", 1 => \"one\", 2 => \"two\", _ => \"many\", }; 定义匹配范围 let text = match n { 0...3 => \"small\", 4...6 => \"medium\", _ => \"large\", };","link":"/posts/e385a1/"},{"title":"rust猜谜游戏","text":"learn Rust 🦀️ rust猜谜游戏走完了hello world的流程之后，来做一个猜数字的游戏 rust项目结构生成一个基本项目 cargo new guessing_nametree . ➜ guessing_game git:(master) ✗ tree ..├── Cargo.toml└── src └── main.rs Cargo.toml文件➜ guessing_game git:(master) ✗ cat Cargo.toml[package]name = \"guessing_game\"version = \"0.1.0\"authors = [\"alpaca \"]edition = \"2018\"# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html 这个里面存储了该项目的信息, name表示项目名字 version 表示cargo 版本 authors 表示作者信息 edition 表示年份 main.rs文件这个文件就是你写的程序 运行该程序运行该程序有两种方法 一种是先编译后执行 rustc src/main.rs 另外一种是直接用cargo运行 cargo run ➜ guseeing_game git:(master) ✗ tree ..├── Cargo.lock├── Cargo.toml├── src│ └── main.rs└── target └── debug ├── build ├── deps │ ├── guseeing_game-0ed5a31a6f15733b │ ├── guseeing_game-0ed5a31a6f15733b.d │ └── guseeing_game-0ed5a31a6f15733b.dSYM │ └── Contents │ ├── Info.plist │ └── Resources │ └── DWARF │ └── guseeing_game-0ed5a31a6f15733b ├── examples ├── guseeing_game ├── guseeing_game.d ├── guseeing_game.dSYM -> deps/guseeing_game-0ed5a31a6f15733b.dSYM └── incremental └── guseeing_game-1u6x8rdyd2mj5 ├── s-fiv8l6i4ic-1486aks-139msrfhaunjd │ ├── 1651w9kfz3huxj9a.o │ ├── 24om6g1u5n10ayrw.o │ ├── 2hv2ystwqwaqr9uj.o │ ├── 3701sophdbnzpjeb.o │ ├── 407p5s5dk77zb92h.o │ ├── 4eavspy520jyuwpr.o │ ├── dep-graph.bin │ ├── query-cache.bin │ └── work-products.bin └── s-fiv8l6i4ic-1486aks.lock 你会发现这两种运行的结果所创建的文件结构是不同的 获取屏幕内容并输出use std::io;fn main() { println!(\"Guess the number!\"); println!(\"Please input your guess.\"); let mut guess = String::new(); io::stdin().read_line(&mut guess) .expect(\"Failed to read line\"); println!(\"You guessed: {}\", guess);} 包含语句和表达式的函数体 函数体有一系列的语句和一个可选的结尾的表达式构成 rust是基于表达式的语言 用分号区分语句和表达式 语句是执行一些操作但不返回值的指令 表达式计算并产生一个值返回 用let关键字创建变量并绑定一个值是一个语句 比如let y = 6; 于是当我们使用如下 fn main(){ let x = (let y =6);} let y = 6 是一个语句并不会返回一个值来使得x绑定，所以会报错 let y = 6; 是一个表达式 ，返回6 函数调用是一个表达式 {} 是一个表达式 具有返回值的函数 函数可以向调用它的代码返回值。我们并不对返回值命名，但要在箭头（->）后声明它的类型 函数的返回值等同于函数体最后一个表达式的值 使用 return 关键字和指定值，可从函数中提前返回；但大部分函数隐式的返回最后的表达式。这是一个有返回值的函数的例子： fn five() -> i32{ 5 } fn main(){ let x = five(); println!(\"the value of x is {} \",x )} 以上代码等同于， {}是表达式 返回5给five()函数， let x = five();是语句，不返回值，于是let x = 5; fn main(){ let x =5 ;} fn plus_one (x: i32) -> i32{ x + 1} fn main(){ let x = plus_one(5) println!(\"the value of x is :{}\",x);} 注释 rust中是用// 进行注释 控制 逻辑操作if语句 fn main() { let number = 3; if number < 5 { println!(\"condition was true\"); } else { println!(\"condition was false\"); } if number!=0{ println!(\"nuf mber was something other than zero\") } else if number != 2{ println!(\"the number was something other than two\") } else { println!(\"the number go\") }} 在let中使用iffn main(){ let } loop语句 fn main() { loop { println!(\"again!\"); }} fn main() { let mut counter = 0; let result = loop { counter += 1; if counter == 10 { break counter * 2; } }; println!(\"The result is {}\", result);} while条件循环 fn main() { let mut number = 3; while number != 0 { println!(\"{}!\", number); number = number - 1; } println!(\"LIFTOFF!!!\");} for 遍历循环 fn main() { let a = [10, 20, 30, 40, 50]; for element in a.iter() { println!(\"the value is: {}\", element); }} fn main() { // .rev()反转 1..4 4取不到 for number in (1..4).rev() { println!(\"{}!\", number); } println!(\"LIFTOFF!!!\");}","link":"/posts/93aa081f/"},{"title":"rust定义枚举","text":"learn rust 🦀️ rust定义枚举fn main() { enum IpAddKind { v4, v6, } println!(\"hello,world\"); let four = IpAddKind::v4; let six = IpAddKind::v6;} 枚举就是定义了一系列的字段，类似于数组，但又区别与数组，枚举是具有个体概念的，数组并不具有，在枚举中，所有参数内容其类型为其枚举名，内容为枚举参数 调用的方式如下 // 创建enum xxlist { world, music, art,}// 调用let world = xxlist::world;let music = xxlist::music; 创建方法，规定枚举类型 fn router (ip_kind:IpAddKind){}//调用route(IpAddrKind::V4);route(IpAddrKind::V6); 枚举+结构体+方法 // 创建枚举，类型为xxlistenum xxlist { music, math, art, other,}// 创建结构体，指定类型struct weekend { xtype: xxlist, time: i32,}fn main() { let fre = weekend { xtype: xxlist::music, time: 45, }; let sud = weekend{ xtype: xxlist::art, time: 45, };} enum IpAddr { V4(String), V6(String),}let home = IpAddr::V4(String::from(\"127.0.0.1\"));let loopback = IpAddr::V6(String::from(\"::1\")); 错误 枚举should have an upper camel case namewarning: variant `v4` should have an upper camel case name --> src/main.rs:3:9 |3 | v4, | ^^ help: convert the identifier to upper camel case (notice the capitalization): `V4` | = note: `#[warn(non_camel_case_types)]` on by default 枚举中需要有一个大写字母","link":"/posts/a944d431/"},{"title":"match控制流运算符","text":"learn rust 🦀️ match控制流运算符enum Coin { Penny, Nickel, Dime, Quarter,}fn value_in_cents(coin: Coin) -> u8 { match coin { Coin::Penny => 1, Coin::Nickel => 5, Coin::Dime => 10, Coin::Quarter => { println!(\"ok,you macth quarter\"); 20 }, }}// 如果coin=penny 则返回1 // 如果coin=nickel则返回5 // 等等// 类似于switch// 所做的比较 coin 是否等于 Coin::xxxfn main() { let coin = Coin::Dime; let res = value_in_cents(coin); println!(\"{}\",res)} 多级枚举#[derive(Debug)]enum city { xiaoshan, hangzhou,}enum Coin { Penny, Nickel, Dime, Quarter(city),}fn value_in_cents(coin: Coin) -> u8 { match coin { Coin::Penny => 1, Coin::Nickel => 5, Coin::Dime => 10, Coin::Quarter(tscity) => { println!(\"{:?}\",tscity); 20 } }}fn main() { let coin = Coin::Quarter(city::xiaoshan); let res = value_in_cents(coin); println!(\"{}\",res);} _通配符Rust 也提供了一个模式用于不想列举出所有可能值的场景。例如，u8 可以拥有 0 到 255 的有效的值，如果我们只关心 1、3、5 和 7 这几个值，就并不想必须列出 0、2、4、6、8、9 一直到 255 的值。所幸我们不必这么做：可以使用特殊的模式 _ 替代 let some_u8_value = 0u8;match some_u8_value { 1 => println!(\"one\"), 3 => println!(\"three\"), 5 => println!(\"five\"), 7 => println!(\"seven\"), _ => (),}","link":"/posts/75d1ed92/"},{"title":"rust包管理","text":"learn rust 🦀️ rust包管理Rust 有许多功能可以让你管理代码的组织，包括哪些内容可以被公开，哪些内容作为私有部分，以及程序每个作用域中的名字。这些功能。这有时被称为 “模块系统（the module system）”，包括： 包（Packages）： Cargo 的一个功能，它允许你构建、测试和分享 crate。 Crates ：一个模块的树形结构，它形成了库或二进制项目。 模块（Modules）和 use： 允许你控制作用域和路径的私有性。 路径（path）：一个命名例如结构体、函数或模块等项的方式","link":"/posts/b7fae75a/"},{"title":"rust错误处理","text":"learn rust 🦀️ rust错误处理Rust 将错误组合成两个主要类别：可恢复错误（recoverable）和 不可恢复错误（unrecoverable）。可恢复错误通常代表向用户报告错误和重试操作是合理的情况，比如未找到文件。不可恢复错误通常是 bug 的同义词，比如尝试访问超过数组结尾的位置。 错误级别1: panic！ 不可恢复的错误突然有一天，代码出问题了，而你对此束手无策。对于这种情况，Rust 有 panic!宏。当执行这个宏时，程序会打印出一个错误信息，展开并清理栈数据，然后接着退出。出现这种情况的场景通常是检测到一些类型的 bug，而且程序员并不清楚该如何处理它。 对于panic!错误，rust有两种处理的形式，一种是展开(unwinding) ,另外一种是终止(abort)对于展开: 这意味着 Rust 会回溯栈并清理它遇到的每一个函数的数据，不过这个回溯并清理的过程有很多工作。对于终止，rust会直接退出程序,使用终止的方法，在Cargo.toml文件中添加 [profile.release]panic = 'abort' 手动发生panic！错误 fn main() { panic!(\"crash and burn\"); } 错误级别2: Result 可恢复错误rust定义了一个Result的泛型来做错误的判别 enum Result { OK(T), Err(E),} 其中有OK成员和Err成员，T和E是Result泛型类型的参数。比如现在我们来制造一个错误 use std::fs::File;fn main() { let f:i32 = File::open(\"hello.txt\");} 会出现如下报错: ➜ desc_Result git:(master) ✗ cargo run Compiling desc_Result v0.1.0 (/Users/alpaca/rust🦀/cargoing/rust🦀️ /desc_Result)error[E0308]: mismatched types --> src/main.rs:5:17 |5 | let f:i32 = File::open(\"hello.text\"); | --- ^^^^^^^^^^^^^^^^^^^^^^^^ expected `i32`, found enum `std::result::Result` | | | expected due to this | = note: expected type `i32` found enum `std::result::Result` 上面写到期待一个i32的类型，但是返回的是Result的类型 修改: use std::fs::File;fn main() { let f = File::open(\"hello.txt\"); let f = match f { Ok(file) => file, Err(error) => { panic!(\"Problem opening the file: {:?}\", error) }, };} 匹配不同的错误use std::fs::File;use std::io::ErrorKind;fn main() { let f = File::open(\"hello.txt\"); let f = match f { Ok(file) => file, Err(error) => match error.kind() { ErrorKind::NotFound => match File::create(\"hello.txt\") { Ok(fc) => fc, Err(e) => panic!(\"Problem creating the file: {:?}\", e), }, other_error => panic!(\"Problem opening the file: {:?}\", other_error), }, };} 使用unwarp和expectmatch 能够胜任它的工作，不过它可能有点冗长并且不总是能很好的表明其意图。Result 类型定义了很多辅助方法来处理各种情况。其中之一叫做 unwrap，它的实现就类似于示例 9-4 中的 match 语句。如果 Result 值是成员 Ok，unwrap 会返回 Ok 中的值。如果 Result 是成员 Err，unwrap 会为我们调用 panic!。这里是一个实践 unwrap 的例子： use std::fs::File;fn main() { let f = File::open(\"hello.txt\").unwrap();} expect可以修改panic!的错误信息 use std::fs::File;fn main() { let f = File::open(\"hello.txt\").expect(\"Failed to open hello.txt\");}","link":"/posts/d7ebac7d/"},{"title":"rust作用域规则","text":"learn rust 🦀️ rust作用域规则作用域在所有权（ownership）、借用（borrow）和生命周期（lifetime）中起着重要 作用。也就是说，作用域告诉编译器什么时候借用是合法的、什么时候资源可以释放、以及 变量何时被创建或销毁。 防止内存泄露Rust 的变量不只是在栈中保存数据：它们也占有资源，比如 Box 占有 堆（heap）中的内存。Rust 强制实行 RAII（Resource Acquisition Is Initiallization，资源获取即初始化），所以任何对象在离开作用域时，它的析构 函数（destructor）就被调用，然后它占有的资源就被释放。这种行为避免了资源泄漏（resource leak），所以你再也不用手动释放内存或者担心 内存泄漏（memory leak）！下面是个快速入门示例： Rust上的值一般是在栈上分配的，而box可以将数据装箱放到堆上内存存储, 当变量离开自己的作用域的时候，调用析构函数释放内存 // raii.rsfn create_box() { // 在堆上分配一个整型数据 let _box1 = Box::new(3i32); // `_box1` 在这里被销毁，内存得到释放}fn main() { // 在堆上分配一个整型数据 let _box2 = Box::new(5i32); // 嵌套作用域： { // 在堆上分配一个整型数据 let _box3 = Box::new(4i32); // `_box3` 在这里被销毁，内存得到释放 } // 创建一大堆 box（只是因为好玩）。 // 完全不需要手动释放内存！ for _ in 0u32..1_000 { create_box(); } // `_box2` 在这里被销毁，内存得到释放 } 使用vlagrind对内存错误进行仔细检查 $ rustc raii.rs && valgrind ./raii==26873== Memcheck, a memory error detector==26873== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.==26873== Using Valgrind-3.9.0 and LibVEX; rerun with -h for copyright info==26873== Command: ./raii==26873====26873====26873== HEAP SUMMARY:==26873== in use at exit: 0 bytes in 0 blocks==26873== total heap usage: 1,013 allocs, 1,013 frees, 8,696 bytes allocated==26873====26873== All heap blocks were freed -- no leaks are possible==26873====26873== For counts of detected and suppressed errors, rerun with: -v==26873== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 2 from 2) 防止资源重复—-所有权因为变量要负责释放它们拥有的资源，所以资源只能拥有一个所有者。这也防止了 资源的重复释放。注意并非所有变量都拥有资源（例如引用）。 在了解所有权之间，要先了解rust中的两种数据类型 基本数据类型： 如：bool（布尔），char（字符）,integer（整数）,floating（浮点）,arrays（数组），tuples(元组)，slice(切片),字符串（str），函数指针(functions) 非基本数据类型 也就是引用类型引用类型数据，内存存放在堆上面let s1 = String::from(\"hello\"); 引用类型在存储到堆中时，会指定三个部分 分别时指针，长度和容量，并且指针指向堆上存放内存的内存地址,长度表示 String 的内容当前使用了多少字节的内存。容量是 String 从操作系统总共获取了多少字节的内存。长度是已经使用的，容量是总共可用的 对所有权有两种动作状态 moved 和 copy 资源的复制当将a赋值给b的时候，首先rust会对原来a的元数据进行复制，并将复制的数据赋值给b，并把a的所有权状态 设置为“已复制（ copied ）”状态。 fn main (){ let s1 = \"hello\"; let s2 = s1; println!(\"{},{}\",s1,s2);}// 只发生了copied 且 x的状态是已复制// 会返回2个hello ![2019-12-28-23-32-47](http://img.noback.top/2019-12-28-23-32-47.png复制行为中，拷贝了一整份内容，包括指针长度和容量，于是他们共用同一个内存，而不是分别指向相等的两个内存 二次释放的问题当变量离开作用域的使用,Rust自动调用drop函数并清理变量的堆内存，于是当出现复制行为的时候，他们执行的内存地址是相同的，当s1离开后，s2执行的内存地址无。当s1离开后，s2执行的内存地址无，这个叫做二次释放的错误，也是之前提到过的内存安全性 bug 之一。两次释放（相同）内存会导致内存污染，它可能会导致潜在的安全漏洞。 资源的移动当将a赋值给b的时候，rust会把原来对a的原数据的所有权移动给b，并把a的所有权状态 设置为“已移动（ moved ）”状态。资源的移动: 在通过值来传递函数参数（foo(x)）的时候，资源 的所有权（ownership）会发生转移。在移动资源后，原来的所有者不能再被使用，这可避免悬挂指针的产生 如果将原变量指针移向另外一个变量指针，原变量指针失效。当你再次调用s1变量时，由于指针的失去，没有指向存储数据的内存地址，报错无效引用 fn main() { let s1 = String::from(\"hello\"); // 这个是引用类型。数据在堆上面 let s2 = s1; println!(\"Hello, world!{}\",s2); println!(\"{}\",s1)}// inputerror[E0382]: borrow of moved value: `x` --> src/main.rs:5:19 |2 | let x = String::from(\"hello\"); | - move occurs because `x` has type `std::string::String`, which does not implement the `Copy` trait3 | let y = x; | - value moved here4 | println!(\"Hello, world!{}\",y);5 | println!(\"{}\",x) | ^ value borrowed here after moveerror: aborting due to previous errorFor more information about this error, try `rustc --explain E0382`.error: could not compile `xx`.To learn more, run the command again with --verbose.// 指针报错指针状态已经更新成了moved 再来看一个 // 此函数取得堆分配的内存的所有权// Box 内存在堆上 引用类型fn destroy_box(c: Box) { println!(\"Destroying a box that contains {}\", c); // `c` 被销毁且内存得到释放}fn main() { // 栈分配的整型 let x = 5u32; // 将 `x` *复制*到 `y`——不存在资源移动 let y = x; // 两个值各自都可以使用 println!(\"x is {}, and y is {}\", x, y); // `a` 是一个指向堆分配的整数的指针 let a = Box::new(5i32); println!(\"a contains: {}\", a); // *移动* `a` 到 `b` let b = a; // 把 `a` 的指针地址（而非数据）复制到 `b`。现在两者都指向 // 同一个堆分配的数据，但是现在是 `b` 拥有它。 // 报错！`a` 不能访问数据，因为它不再拥有那部分堆上的内存。 //println!(\"a contains: {}\", a); // 试一试 ^ 去掉此行注释 // 此函数从 `b` 中取得堆分配的内存的所有权 destroy_box(b); // 此时堆内存已经被释放，这个操作会导致解引用已释放的内存，而这是编译器禁止的。 // 报错！和前面出错的原因一样。 //println!(\"b contains: {}\", b); // 试一试 ^ 去掉此行注释} 资源的克隆对于基础类型来说，变量的数据交互形式是复制对于引用类型来说，变量的数据交互形式无法复制，只能移动。但是如果我们需要使用到复制堆上的数据，可以使用clone的通用函数如果我们想要保留原来的引用类型变量，又要使用其值，可以使用clone fn main() { let x = String::from(\"hello\"); // 这个是引用类型。数据在堆上面 let y = x.clone(); println!(\"Hello, world!{}\",y); println!(\"{}\",x)} 可变性当所有权转移时，数据的可变性可能发生改变 fn main() { let immutable_box = Box::new(5u32); println!(\"immutable_box contains {}\", immutable_box); // 不可变，报错 //*immutable_box = 4; // *移动* box，改变所有权（和可变性） let mut mutable_box = immutable_box; println!(\"mutable_box contains {}\", mutable_box); // 修改 box 的内容 *mutable_box = 4; println!(\"mutable_box now contains {}\", mutable_box);} 借用多数情况下，我们更希望能访问数据，同时不取得其所有权。为实现这点，Rust 使用 了借用（borrowing）机制。对象可以通过引用（&T）来传递，从而取代通过 值（T）来传递。 // 此函数取得一个 box 的所有权并销毁它fn eat_box_i32(boxed_i32: Box) { println!(\"Destroying box that contains {}\", boxed_i32);}// 此函数借用了一个 i32 类型fn borrow_i32(borrowed_i32: &i32) { println!(\"This int is: {}\", borrowed_i32);}fn main() { // 创建一个装箱的 i32 类型，以及一个存在栈中的 i32 类型。 let boxed_i32 = Box::new(5_i32); let stacked_i32 = 6_i32; // 借用了 box 的内容，但没有取得所有权，所以 box 的内容之后可以再次借用。 // 译注：请注意函数自身就是一个作用域，因此下面两个函数运行完成以后， // 在函数中临时创建的引用也就不复存在了。 borrow_i32(&boxed_i32); borrow_i32(&stacked_i32); { // 取得一个对 box 中数据的引用 let _ref_to_i32: &i32 = &boxed_i32; // 报错！ // 当 `boxed_i32` 里面的值之后在作用域中被借用时，不能将其销毁。 eat_box_i32(boxed_i32); // 改正 ^ 注释掉此行 // 在 `_ref_to_i32` 里面的值被销毁后，尝试借用 `_ref_to_i32` //（译注：如果此处不借用，则在上一行的代码中，eat_box_i32(boxed_i32)可以将 `boxed_i32` 销毁。） borrow_i32(_ref_to_i32); // `_ref_to_i32` 离开作用域且不再被借用。 } // `boxed_i32` 现在可以将所有权交给 `eat_i32` 并被销毁。 //（译注：能够销毁是因为已经不存在对 `boxed_i32` 的引用） eat_box_i32(boxed_i32);} 冻结当数据被不可变地借用时，它还会冻结（freeze）。已冻结的数据无法通过原始 对象来修改，直到对这些数据的所有引用离开作用域为止 fn main() { let mut _mutable_integer = 7i32; { // 借用 `_mutable_integer` let large_integer = &_mutable_integer; // 报错！`_mutable_integer` 在本作用域被冻结 _mutable_integer = 50; // 改正 ^ 注释掉此行 println!(\"Immutably borrowed {}\", large_integer); // `large_integer` 离开作用域 } // 正常运行！`_mutable_integer` 在这作用域没有冻结 _mutable_integer = 3;}","link":"/posts/af92563b/"},{"title":"rust 结构 枚举 引用","text":"learn rust 🦀️ rustrust引用fn main () { let name1 = \"hzj\"; //切片, 不在堆上 -> 与&name2类似 let name2 = \"hzj\".to_string() ;//String 类型 在堆上 let name3 = String::from(\"hzj\"); // String类型 在堆上 let name4 = &name2; // 引用类型 let name5 = name1; // 复制切片 let name6 = name2; // 复制String类型 println!(\"{}\",name2)} 会显示name2被moved了 。我们不会看到像数字这样的”原始”类型不能复制，因为它们只是数值; 他们被允许复制，因为他们复制成本堪称便宜。 但，String是已经分配了包含”Hello dolly”的内存，而要复制这内容，将涉及分配更多内存还要复制字符{char}。Rust 才不会静悄悄地做这样的事情。 隐式移动 fn dump(s: String) { println!(\"{}\", s);}fn main() { let s1 = \"hello dolly\".to_string(); dump(s1); println!(\"s1 {}\", s1); // (f64,f64) { (x + y, x * y)}fn main() { let t = add_mul(2.0,10.0); // 可以 调试打印 println!(\"t {:?}\", t); // 可以 给出值'索引' println!(\"add {} mul {}\", t.0,t.1); // 可以 _提取_ 值 let (add,mul) = t; println!(\"add {} mul {}\", add,mul);}// t (12, 20)// add 12 mul 20// add 12 mul 20 元组能包含 不同 类型，这也是它与数组的主要区别。 结构体// struct1.rsstruct Person { first_name: String, last_name: String}fn main() { let p = Person { first_name: \"John\".to_string(), last_name: \"Smith\".to_string() }; println!(\"person {} {}\", p.first_name,p.last_name);} 结构体中的关联函数 struct Person { first_name: String, last_name: String}impl Person { fn new(first: &str, name: &str) -> Person { Person { first_name: first.to_string(), last_name: name.to_string() } }}fn main() { let p = Person::new(\"John\",\"Smith\"); println!(\"person {} {}\", p.first_name,p.last_name);} 结构体与引用struct Person{ name: String, age: i32,}fn main() { let p = Person::new(\"hhh\",12); println!(\"{} {}\",p.name,p.age);}impl Person{ fn new(name: &str,age: i32) -> Person { Person { name: name.to_string(), age: age, } }} rust是不是动态语言，在变量的类型上会有严格的要求，以上代码，我们确定了一个Person的结构体，其中name变量是String类型，在编译的过程中，rust回去找Person的方法体，Person方法体要求加入一个name变量的切片或者说引用类型， 但是结构体内的是String类型std::string::String，于是会要求转换转换 name.to_string() 因此，在不考虑其他元素的情况下，你的代码还可以这样写 struct Person{ name: String, age: i32,}fn main() { let p = Person::new(String::from(\"hhh\"),12); println!(\"{} {}\",p.name,p.age);}impl Person{ fn new(name: String,age: i32) -> Person { Person { name: name, age: age, } }} 或者这样写 struct Person{ name: String, age: i32,}fn main() { let p = Person::new(&String::from(\"hhh\"),12); println!(\"{} {}\",p.name,p.age);}impl Person{ fn new(name: &str,age: i32) -> Person { Person { name: name.to_string(), age: age, } }} 结构体的自我调用struct Person{ name: String, age: i32,}fn main() { let p = Person::new(&String::from(\"hhh\"),12); println!(\"{} {}\",p.name,p.age); println!(\"{}\",p.full_info());}impl Person{ fn new(name: &str,age: i32) -> Person { Person { name: name.to_string(), age: age, } } fn full_info(&self) -> String{ format!(\"my name is {}, my age is {}\",self.name,self.age) }} 明确使用该self，并作为引用传递。 (你可以把&self想成self: &Person简写。 ) 还有，关键字Self(自身：注意首大写)指的是结构类型 - 你可以在脑海中用Person替换掉Self: // struct4.rsuse std::fmt;#[derive(Debug)]struct Person { first_name: String, last_name: String}impl Person { fn new(first: &str, name: &str) -> Person { Person { first_name: first.to_string(), last_name: name.to_string() } } fn full_name(&self) -> String { format!(\"{} {}\",self.first_name, self.last_name) } fn set_first_name(&mut self, name: &str) { self.first_name = name.to_string(); } fn to_tuple(self) -> (String,String) { (self.first_name, self.last_name) }}fn main() { let mut p = Person::new(\"John\",\"Smith\"); println!(\"{:?}\", p); p.set_first_name(\"Jane\"); println!(\"{:?}\", p); println!(\"{:?}\", p.to_tuple()); // p has now moved.}// Person { first_name: \"John\", last_name: \"Smith\" }// Person { first_name: \"Jane\", last_name: \"Smith\" }// (\"Jane\", \"Smith\") 没有self相关参数: 您可以将函数与结构关联，如new“构造函数”。 &self参数: 可以使用结构体的值，但不能改变它们。 &mut self参数: 可以修改这些值。 self参数: 将消耗值，因它移动了 恐怖的生命周期如果不知道一个‘引用’的生命周期，是不允许你存储它。 所有引用{&}都是从某个值那里借用{borrowed}的，而且所有的值都是有生命周期{lifetimes}的。引用的生命周期不能长于该值的生命周期。Rust 不能允许这种 引用可能突然失效 的情况 现在我们在一个结构体里面引用一个字符串的切片 struct A { s: &str}fn main() { let a = A { s: \"hello dammit\" }; println!(\"{:?}\", a);} 会出现如下错误，报错内容就是超出了生命周期 error[E0106]: missing lifetime specifier --> src/main.rs:2:8 |2 | s: &str | ^ expected lifetime parametererror: aborting due to previous error 字符串切片是从 字符串常量 借用的，像”hello”或是String值。 字符串常量在整个程序期间都存在，也称为”静态{static}”生命周期但是在结构体中，我们尝试借用字符串常量的内容，紧接着s 编程了借用值，rust为了内存的安全，给他添加了生命周期，在离开结构体的生命周期时，就结束了生命 既然这样，为了保证一些变量的生命周期相同，rust为他们提供了一些生命周期标示,如下 // life2.rs#[derive(Debug)]struct A { s: &'static str}fn main() { let a = A { s: \"hello dammit\" }; println!(\"{:?}\", a);}// A { s: \"hello dammit\" } 不过嘛，我们也可以指定引用{&}的生命周期，与结构本身 至少一样长 。 #[derive(Debug)]struct A","link":"/posts/bbe17d1/"},{"title":"rust常见集合","text":"learn rust 🦀️ rust常见集合 vector 允许我们一个挨着一个地储存一系列数量可变的值 字符串（string）是一个字符的集合。我们之前见过 String 类型，不过在本章我们将深入了解。 哈希 map（hash map）允许我们将值与一个特定的键（key）相关联。这是一个叫做 map 的更通用的数据结构的特定实 vector 允许我们在一个单独的数据结构中储存多于一个的值，它在内存中彼此相邻地排列所有的值。vector 只能储存相同类型的值。 Vector集合创建一个vector集合 fn main() { let v: Vec = Vec::new();}// 或者fn main() { let v = vec![1, 2, 3];}// 增加元素v.push(\"5\");v.push(\"6\"); 离开作用域被丢弃 { let v = vec![1, 2, 3, 4]; // 处理变量 v} // println!(\"None\"), Some(numbers) => println!(\"{:?}\",numbers), };} 遍历vector fn main(){ let v = vec![100, 32, 57]; for i in &v { println!(\"{}\", i); }} 遍历循环并累加 fn main () {let mut v = vec![100, 32, 57];for i in &mut v { *i += 50;}} 首先是可变引用，再次是累加需要使用*解引用 String字符串fn main (){let mut s = String::new();let s = \"xxxx\".to_string();//等同于let s = String::from(\"xxx\");} 更新字符串push_str是直接引用psuh 会添加所有权 fn main() { // 引用类型 let mut s1 = String::from(\"foo\"); let sq = String::from(\"bar\"); let s2 = \"bar\"; // 添加一个字符串 s1.push_str(&sq); s1.push_str(s2); println!(\"{}\",s1); println!(\"{}\",s2); // 可以输出s2 并没有在push_str中将所有权传递给s1 // 添加一个字符 let mut s3 = String::from(\"foo\"); s3.push('q'); println!(\"s3 is {}\",s3); println!(\"s1 is {}\", s1);} 使用+运算符或format宏拼接字符串fn main (){let s1 = String::from(\"Hello, \");let s2 = String::from(\"world!\");let s3 = s1 + &s2; // 注意 s1 被移动了，不能继续使用} format宏 fn main(){ let s1 = String::from(\"tic\");let s2 = String::from(\"tac\");let s3 = String::from(\"toe\");let s = format!(\"{}-{}-{}\", s1, s2, s3);} 获取长度fn main() { let len = String::from(\"Hola\").len(); } 字符串切片rust不支持使用单个序号来获取字符串中的值，但允许对string进行范围的切片 fn main() { let hello = \"Здравствуйте\"; let s = &hello[0..4];} 遍历字符串遍历字符串输出单个元素 fn main() { for c in \"नमस्ते\".chars() { println!(\"{}\", c);} } 遍历字符串输出单个字节 fn main() { for b in \"नमस्ते\".bytes() { println!(\"{}\", b);}} hash-map最后介绍的常用集合类型是哈希map（hash map）。HashMap 类型储存了一个键类型 K 对应一个值类型 V 的映射。 新建一个哈希mapuse std::collections::HashMap; fn main() { let mut scores = HashMap::new(); scores.insert(String::from(\"Blue\"), 10); scores.insert(String::from(\"Yellow\"), 50);} 数组转换成哈希mapfn main() { use std::collections::HashMap; // 数组1 let teams = vec![String::from(\"Blue\"), String::from(\"Yellow\")]; // 数组2 let initial_scores = vec![10, 50]; let scores: HashMap = teams.iter().zip(initial_scores.iter()).collect();} 哈希map与所有权fn main() { use std::collections::HashMap; let field_name = String::from(\"Favorite color\"); let field_value = String::from(\"Blue\"); let mut map = HashMap::new(); map.insert(field_name, field_value); println!(field_name,field_value)} 这里field_name field_value 在加入hashmap之后，会被moved但如果是引用值被insert 那还可以使用 访问哈希map中的值fn main() {use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from(\"Blue\"), 10);scores.insert(String::from(\"Yellow\"), 50);let team_name = String::from(\"Blue\");let score = scores.get(&team_name);} 返回键值对fn main() { use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from(\"Blue\"), 10);scores.insert(String::from(\"Yellow\"), 50);for (key, value) in &scores { println!(\"{}: {}\", key, value);}} 覆盖值#![allow(unused_variables)]fn main() {use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from(\"Blue\"), 10);scores.insert(String::from(\"Blue\"), 25);println!(\"{:?}\", scores);} 没有对应键时插入use std::collections::HashMap;let mut scores = HashMap::new();scores.insert(String::from(\"Blue\"), 10);scores.entry(String::from(\"Yellow\")).or_insert(50);scores.entry(String::from(\"Blue\")).or_insert(50);println!(\"{:?}\", scores); 根据旧值更新一个值#![allow(unused_variables)]fn main() {use std::collections::HashMap;let text = \"hello world wonderful world\";let mut map = HashMap::new();for word in text.split_whitespace() { let count = map.entry(word).or_insert(0); *count += 1;}println!(\"{:?}\", map);} 这会打印出 {“world”: 2, “hello”: 1, “wonderful”: 1}，or_insert 方法事实上会返回这个键的值的一个可变引用（&mut V）。这里我们将这个可变引用储存在 count 变量中，所以为了赋值必须首先使用星号（*）解引用 count。这个可变引用在 for 循环的结尾离开作用域，这样所有这些改变都是安全的并符合借用规则","link":"/posts/a81913b8/"},{"title":"rust智能指针","text":"learn rust 🦀️ 智能指针使用Box指向数据的堆Box允许您将数据存储在堆而不是堆栈上。堆栈上剩下的是指向堆数据的指针。 在堆上存储一个值 fn main() { let numbers = BOX::new(5); println!(\"{}\",numbers);}","link":"/posts/2e99e72c/"},{"title":"rust闭包","text":"learn rust 🦀️ rust闭包语法格式//标准写法fn add_one(x: &str) -> &str{ x} let add_number = add_one(&str);// 闭包写法let add_number = |x: &str| -> &str {x}; let add_number2 = |x| xlet add_number3 = |x| {x} 使用 fn main () { let numbers = add_one(2); println!(\"{}\",numbers); let numbers = |i| -> i32 {i}; let numbers2 = numbers(8); println!(\"{}\",numbers2);}fn add_one(i: i32) -> i32{ i + 1} 在一个程序中不能推导两种类型的","link":"/posts/d95b1b33/"},{"title":"标准库类型","text":"learn rust 🦀️ 标准库类型String类型String类型表示字符串类型 # 创建字符串类型let name = String::from(\"hzj\");# 提取包含整个String的字符串切片。let name = name.as_str(); 选项类型有时候想要捕捉到程序某部分的失败信息，而不是调用 panic!；这可使用 Option 枚举类型来实现。 Option 包含两个变量 None，表明失败或缺少值 Some(value)，元组结构体，封装了一个T类型的值 value fn checked_division(dividend: i32, divisor: i32) -> Option { if divisor == 0 { // 失败表示成 `None` 取值 None } else { // 结果 Result 被包装到 `Some` 取值中 Some(dividend / divisor) }}// 此函数处理可能失败的除法fn try_division(dividend: i32, divisor: i32) { // `Option` 值可以进行模式匹配，就和其他枚举类型一样 match checked_division(dividend, divisor) { None => println!(\"{} / {} failed!\", dividend, divisor), Some(quotient) => { println!(\"{} / {} = {}\", dividend, divisor, quotient) }, }}// 传入两个参数，计算checked_division的结果，将结果进行match匹配fn main() { try_division(4, 2); try_division(1, 0); // 绑定 `None` 到一个变量需要类型标注 let none: Option = None; let _equivalent_none = None::; let optional_float = Some(0f32); // 解包 `Some` 将取出被包装的值。 println!(\"{:?} unwraps to {:?}\", optional_float, optional_float.unwrap()); // 解包 `None` 将会引发 `panic!`。 println!(\"{:?} unwraps to {:?}\", none, none.unwrap());}","link":"/posts/30cab582/"},{"title":"rust常见规范","text":"learn rust 🦀️ rust常见规范悬挂指针的问题悬挂指针的问题指的是原指针消失，但你原指针所指向的另一个变量b依旧还存在，但是这个变量的内存地址无法获得 fn main() { let r; let q; { ¦ let x = 5; ¦ r = &x; ¦ q = x; ¦ println!(\"{}\",&x); } println!(\"{}\",q); //println!(\"{}\",r); println!(\"Hello, world!\");} 如图，变量x离开作用域后就会消失， 他使用了两种赋值的方法，一种是r=&x是引用这张图能够很好的解释什么是引用 原s1 指向于内存地址，也就是 let s1 = “hello”当我们使用引用的时候 s = &s1 rust会创建一个s的对象，并创建一条指向某一对象的引用，再由引用对象指向数据所在内存地址，在以上的代码中，r=&x会创建一条指向r对象的引用以及rr对象当作用域结束之后。x所指向的 5这个内存地址消失，则指向r再指向5这个内存地址也消失，最后失败 而q=x是赋值的行为rust会创建一个q并同x一起执行内存地址，离开作用域后，x的指针消失，但q的指针还存在 rust中的生命周期问题标定生命周期 &i32 // 引用&'a i32 // 带有显式生命周期的引用&'a mut i32 // 带有显式生命周期的可变引用 例子一 fn main() { let string1 = String::from(\"abcd\"); let string2 = \"xyz\"; let result = longest(string1.as_str(), string2); println!(\"The longest string is {}\", result);}fn longest(x: &str, y: &str) -> &str { if x.len() > y.len() { ¦ x } else { ¦ y }} 出现报错 error[E0106]: missing lifetime specifier --> src/main.rs:9:33 |9 | fn longest(x: &str, y: &str) -> &str { | ^ expected lifetime parameter | = help: this function's return type contains a borrowed value, but the signature does not say whether it is borrowed from `x` or `y`error: aborting due to previous error 出现报错的主要原因是，当longest执行以后，会返回一个参数，这个参数是x或者y中的其中一个，但是当离开这个作用域的时候，引用消失，rust无法判断result指向的变量是x还是y 最后报错 那如果我们值返回一个参数x呢 fn main() { let x = String::from(\"xxx\"); let y = String::from(\"yyy\"); let res = return_str(&x,&y); println!(\"{}\",res);}fn return_str(x: &str,y: &str) -> &str{ x} 还是报同样的错误，无法判断x和y。 统一生命周期以后 fn main() { let string1 = String::from(\"abcd\"); let string2 = \"xyz\"; let result = longest(string1.as_str(), string2); println!(\"The longest string is {}\", result);}fn longest y.len() { ¦ x } else { ¦ y }} 编译通过 再来看一个例子 fn main() { let string1 = String::from(\"abcd\"); let string2 = \"xyz\"; let result = longest(string1.as_str(), string2); println!(\"The longest string is {}\", result);}fn longest(x: &str, y: &str) -> &str { let abc = String::from(\"new world\"); abc;} 在这里longest返回的一个参数是&str，这个返回的内容就是变量abc，但是变量abc离开作用域的时候，引用就消失了而result则读取不到数据，就会报错，在这里longest返回的结果就是一个悬垂引用，为了保证他们的生命周期相同，必须添加生命周期标识别 生命周期进阶了解到上面几个内容后，我们再来看一下 rust在函数返回的同时，到底是怎么回事，我们来传入一个返回一个参数看看  buffersfn main() { let x = String::from(\"xxx\"); let y = String::from(\"yyy\"); let res = return_str(&x); println!(\"{}\",res);}fn return_str(x: &str) -> &str{ let res = String::from(\"str\"); &res;} 报错 error[E0308]: mismatched types --> src/main.rs:11:27 |11 | fn return_str(x: &str) -> &str{ | ---------- ^^^^ expected `&str`, found `()` | | | implicitly returns `()` as its body has no tail or `return` expressionerror: aborting due to previous errorFor more information about this error, try `rustc --explain E0308`.error: could not compile `desc_test2`.To learn more, run the command again with --verbose. 这里提醒，本身要返回一个str的引用型内容，但是找到的确实空值，也就是说指向的内存地址被删除了，因为离开了作用域，res的生命周期结束了 再来返回x fn main() { let x = String::from(\"xxx\"); let y = String::from(\"yyy\"); let res = return_str(&x); println!(\"{}\",res);}fn return_str(x: &str) -> &str{ let res = String::from(\"str\"); x} 这里面返回的是x 而这个x指向的是在main函数中的内容，他的生命周期在main函数结束的时候，也就是程序终止的时候才会结束，因此不会报错 在结构体中声明生命周期的定义struct ImportantExcerpt & ‘a i32。 第三个规则是, 如果有多个输入寿命参数，但其中一个是 & self 或 & mut self，因为这是一种方法，自身的寿命分配给所有的输出寿命参数。 第三条规则使方法更易于读写，因为需要的符号更少","link":"/posts/d4e04a97/"},{"title":"rust基础2","text":"learn Rust 🦀️ rust基础变量常量rust采用多种变量的定义形式，同时在定义的同时区分了变量与常量的区别 定义变量使用let xx=xx # 默认immutable定义可变变量 let mut xx=xx # mut 可变定义常量 const xx: u32 = 10000 # 常量定义 名为xx 类型为int32 值为10000 其中常量默认不变 fn main() { let x = 5; println!(\"The value of x is:{}\",x); let mut y = 6; println!(\"The mut value of y is:{}\",y); //修改不可变量x 报错 //x = 7 //println!(\"i upadte the x value 5 to {}\",x) y = 10; println!(\"i update the y value 6 to {}\",y); //定义常量,他的名字是MAX_POINTS const MAX_POINTS: u32 = 100_000; println!(\"is constants value MAX_POINTS: {}\",MAX_POINTS); //变量迭代 隐藏 //对变量的隐藏，也就是不断的对x进行隐藏 //虽然变量x是不可变的immutable 但是重复使用let可以多次进行隐藏，生成之后的仍就是immutable let q = 5; let q = q + 5; let q = q + 10; println!(\"q:{}\",q) // let spaces = \" \"; let spaces_line = spaces.len(); println!(\"spance_lines_number:{}\",spaces_line) // let mut numbers = \" \"; numbers = numbers.len(); println!(\"{}\",numbers)} 可变量mut 和隐藏shadowing有什么区别?mut 与隐藏的另一个区别是，当再次使用 let 时，实际上创建了一个新变量，我们可以改变值的类型，并且复用这个名字。例如，假设程序请求用户输入空格字符来说明希望在文本之间显示多少个空格，然而我们真正需要的是将输入存储成数字（多少个空格） datatype数据类型rust是静态类型语言(statically typed)也就是说在编译时就必须知道所有变量的类型。 整型 度 有符号 无符号8-bit i8 u816-bit i16 u1632-bit i32 u3264-bit i64 u64128-bit i128 u128arch isize usize 有符号和无符号代表数字能否为负值，有符号数以补码形式（two’s complement representation）[https://kaisery.github.io/trpl-zh-cn/ch03-02-data-types.html] 存储。 浮点型它们是带小数点的数字。Rust 的浮点数类型是 f32 和 f64，分别占 32 位和 64 位。默认类型是 f64，因为在现代 CPU 中，它与 f32 速度几乎一样，不过精度更高。 fn main(){ let x = 2.0; //f64 let y: f32 = 3.0; //f32} 数值运算fn main(){ let sum = 5 + 32; let difference = 95.5 - 4.3; let product = 4 * 30; let quotient = 56.7 / 32.2; let remainder = 43 % 5;} 布尔型fn main(){ let t = true ; let f: boole = false; // 显式指定类型注解} 字符型char使用单引号 string使用双引号 fn main() { let c = 'z'; let z = 'ℤ'; let heart_eyed_cat = '😻';} 元组类型元组是一个将多个其他类型的值组合进一个复合类型的主要方式。元组长度固定：一旦声明，其长度不会增大或缩小。 fn main() { let tup: (i32, f64, u8) = (500, 6.4, 1);} fn main() { let tup = (500, 6.4, 1); let (x, y, z) = tup; println!(\"The value of y is: {}\", y);} 使用解构拆分元祖tup 对应元祖值 fn main() { let x: (i32, f64, u8) = (500, 6.4, 1); let five_hundred = x.0; let six_point_four = x.1; let one = x.2;} 数组类型fn main() { # 定义方法1 let a = [1, 2, 3, 4, 5]; # 定义方法2 let a: [i32; 5] = [1, 2, 3, 4, 5]; # 定义方法3 let a = [3;5] # => [3,3,3,3,3]} fn main() { let a = [1, 2, 3, 4, 5]; let first = a[0]; let second = a[1];} 函数方法fn main() { println!(\"Hello, world!\"); another_function();}fn another_function() { println!(\"Another function.\");} # 加参数fn main() { another_function(5);}fn another_function(x: i32) { println!(\"The value of x is: {}\", x);}# 多参数fn main() { another_function(5, 6);}fn another_function(x: i32, y: i32) { println!(\"The value of x is: {}\", x); println!(\"The value of y is: {}\", y);}","link":"/posts/bb04cef6/"},{"title":"Rust概念-所有权","text":"learn Rust 🦀 Rust概念-所有权变量类型可以看一下这两篇文章https://learning-rust.github.io/docs/a6.variable_bindings,constants_and_statics.htmlhttp://wiki.jikexueyuan.com/project/rust/primitive-types.html 在rust中变量模式是不可变的，因此我们叫做变量绑定，为了使他们可变，使用mut关键字即可rust是一种静态类型的语言；它在编译时检查数据类型。并不需要在声明变量绑定时指定一个具体的数据类型。编译器会检查使用情况并为其设置更好的数据类型。但是对于 常量和静态变量，必须注释type。类型在冒号（:)之r 变量绑定// 变量绑定let a = true;let b: bool = true; // 以上可以声明具体的数据类型，也可以不指定let (x,y) = (1,2);let mut z = 5;z = 6;// 常数 必须指定const N: i32 = 5;// 静态变量static N: i32 = 6; 所有权在rust中，一共分为两种数据类型 基本数据类型： 如：bool（布尔），char（字符）,integer（整数）,floating（浮点）,arrays（数组），tuples(元组)，slice(切片),字符串（str），函数指针(functions) 非基本数据类型 也就是引用类型 在rust中，对于所有权一共有两种动作状态 移动和copy 复制当将a赋值给b的时候，首先rust会对原来a的元数据进行复制，并将复制的数据赋值给b，并把a的所有权状态 设置为“已复制（ copied ）”状态。 移动当将a赋值给b的时候，rust会把原来对a的原数据的所有权移动给b，并把a的所有权状态 设置为“已移动（ moved ）”状态。let x = 5;let y = x;// 基本数据类型 只发生了copiedlet x = String::from(\"hello world\");let y = x;// 引用数据类型，发生了moved 引用类型在存储到堆中时，会指定三个部分 分别时指针，长度和容量，并且指针指向堆上存放内存的内存地址长度表示 String 的内容当前使用了多少字节的内存。容量是 String 从操作系统总共获取了多少字节的内存。长度与容量的区别是很重要的， 复制行为复制行为中，拷贝了一整份内容，包括指针长度和容量，于是他们共用同一个内存，而不是分别指向相等的两个内存二次释放错误当变量离开作用域的使用,Rust自动调用drop函数并清理变量的堆内存，于是当出现复制行为的时候，他们执行的内存地址是相同的，当s1离开后，s2执行的内存地址无。当s1离开后，s2执行的内存地址无，这个叫做二次释放的错误，也是之前提到过的内存安全性 bug 之一。两次释放（相同）内存会导致内存污染，它可能会导致潜在的安全漏洞。但是我在代码中试了一下，没有报错。。。 fn main() { let x = 1; let y = x; println!(\"Hello, world!{}\",y); println!(\"{}\",x)} // inputHello, world!11 移动行为如果将原变量指针移向另外一个变量指针，原变量指针失效。当你再次调用s1变量时，由于指针的失去，没有指向存储数据的内存地址，报错无效引用 fn main() { let x = String::from(\"hello\"); // 这个是引用类型。数据在堆上面 let y = x; println!(\"Hello, world!{}\",y); println!(\"{}\",x)}// inputerror[E0382]: borrow of moved value: `x` --> src/main.rs:5:19 |2 | let x = String::from(\"hello\"); | - move occurs because `x` has type `std::string::String`, which does not implement the `Copy` trait3 | let y = x; | - value moved here4 | println!(\"Hello, world!{}\",y);5 | println!(\"{}\",x) | ^ value borrowed here after moveerror: aborting due to previous errorFor more information about this error, try `rustc --explain E0382`.error: could not compile `xx`.To learn more, run the command again with --verbose.// 指针报错指针已经被move 克隆行为对于基础类型来说，变量的数据交互形式是复制对于引用类型来说，变量的数据交互形式无法复制，只能移动。但是如果我们需要使用到复制堆上的数据，可以使用clone的通用函数 fn main() { let x = String::from(\"hello\"); // 这个是引用类型。数据在堆上面 let y = x.clone(); println!(\"Hello, world!{}\",y); println!(\"{}\",x)} 引用和借用不可变引用跳过所有权，引用对象数据，这里就要用到rust中的引用关键字&&关键字作用是创建了一条指向某一对象的引用，再由引用对象指向数据所在内存地址当引用本身&s1离开作用域后，调用drop函数，指向s1对象的指针被丢弃同时，rust的引用本身也是不可变的， fn main() { let s1 = String::from(\"hello\"); let len = calculate_length(&s1); println!(\"The length of '{}' is {}.\", s1, len);}//参数类型需要引用类型fn calculate_length(s: &String) -> usize { s.len()} 以上 &s1的过程称为引用，获取因果那个作为函数参数称为借用 可变引用可变引用同不可变类似，但要保证被引用类型为可变类型引用为可变函数参数为可变引用 fn main() { let mut s = String::from(\"hello\"); change(&mut s);}fn change(some_string: &mut String) { some_string.push_str(\", world\");}``` 在特定作用域中的特定数据有且只有一个可变引用。这些代码会失败;但可以有多个不可变引用,并且不可变引用和可变引用不能同时存在，可以在其中一个小时后再调用解决```rustlet mst s = String::from(\"hello\"){ let r1 = &mut s;} let r2 = &mut s; slice 切片let s = String::from(\"hello world\") let hello = &s[..5];// let hello = &s[0..5];let world = &s[6..11];// let world = &s[6..len];let helloworld = &s[..];let helloworld = &s[0..len];","link":"/posts/27cd4fcb/"},{"title":"rust结构体","text":"learn Rust 🦀️ 定义实例化结构体定义结构体，需要使用 struct 关键字并为整个结构体提供一个名字。结构体的名字需要描述它所组合的数据的意义.在结构体中需要有相应的属性和属性对应的类型 fn main() {// 创建实例模版struct User { username: String, email: String, sign_in_count: u64, active: bool,}// 实例化不可变模型let user1 = User { email: String::from(\"someone@example.com\"), username: String::from(\"someusername123\"), active: true, sign_in_count: 1,};}// 实例化可变模型let mut user2 = User { email: String::from(\"someone@example.com\"), username: String::from(\"someusername123\"), active: true, sign_in_count: 1,};}// 调用与修改println!(\"{}\", user2.email)user2.email = String::from(\"other@example.com\") 使用函数来返回并创建实例化模型fn main() { let user = return_struct(String::from(\"xx\"),2); println!(\"{}\",user.name);}struct User { name: String, age: i32, active: bool, sigin_in_count: i32,}fn return_struct(name: String,age: i32 ) -> User { User { //同名字段 //1. name: name, //2. name, name, age, active: true, sigin_in_count: 1, }} 实例更新let user2 = User { email: String::from(\"another@example.com\"), username: String::from(\"anotherusername567\"), ..user1}; 元组结构体没有字段名 只有字段类型 fn main() {struct Color(i32, i32, i32);struct Point(i32, i32, i32);let black = Color(0, 0, 0);let origin = Point(0, 0, 0);} 方法语法方法语法同函数类似，但是方法实在结构体的上下文中被定义的，并且他们的第一个参数是self，它代表了调用该方法的结构体实例 我们将某个实例能做的所有事情一起放在impl(implementation)中 struct Rectangle{ width: u32, height: u32,}// 必须同名impl Rectangle{ fn area(&self) -> u32{ self.width * self.height }}fn main() { let rect1 = Rectangle{width: 30,height: 50}; println!( \"the area is {}\",rect1.area() );} 其中self表示调用该方法的结构体实例","link":"/posts/a02a083e/"},{"title":"Rust概念-所有权","text":"learn Rust 🦀 Rust概念-所有权变量类型可以看一下这两篇文章https://learning-rust.github.io/docs/a6.variable_bindings,constants_and_statics.htmlhttp://wiki.jikexueyuan.com/project/rust/primitive-types.html 在rust中变量模式是不可变的，因此我们叫做变量绑定，为了使他们可变，使用mut关键字即可rust是一种静态类型的语言；它在编译时检查数据类型。并不需要在声明变量绑定时指定一个具体的数据类型。编译器会检查使用情况并为其设置更好的数据类型。但是对于 常量和静态变量，必须注释type。类型在冒号（:)之r 变量绑定// 变量绑定let a = true;let b: bool = true; // 以上可以声明具体的数据类型，也可以不指定let (x,y) = (1,2);let mut z = 5;z = 6;// 常数 必须指定const N: i32 = 5;// 静态变量static N: i32 = 6; 所有权在rust中，一共分为两种数据类型 基本数据类型： 如：bool（布尔），char（字符）,integer（整数）,floating（浮点）,arrays（数组），tuples(元组)，slice(切片),字符串（str），函数指针(functions) 非基本数据类型 也就是引用类型 在rust中，对于所有权一共有两种动作状态 移动和copy 复制当将a赋值给b的时候，首先rust会对原来a的元数据进行复制，并将复制的数据赋值给b，并把a的所有权状态 设置为“已复制（ copied ）”状态。 移动当将a赋值给b的时候，rust会把原来对a的原数据的所有权移动给b，并把a的所有权状态 设置为“已移动（ moved ）”状态。let x = 5;let y = x;// 基本数据类型 只发生了copiedlet x = String::from(\"hello world\");let y = x;// 引用数据类型，发生了moved 引用类型在存储到堆中时，会指定三个部分 分别时指针，长度和容量，并且指针指向堆上存放内存的内存地址长度表示 String 的内容当前使用了多少字节的内存。容量是 String 从操作系统总共获取了多少字节的内存。长度与容量的区别是很重要的， 复制行为复制行为中，拷贝了一整份内容，包括指针长度和容量，于是他们共用同一个内存，而不是分别指向相等的两个内存二次释放错误当变量离开作用域的使用,Rust自动调用drop函数并清理变量的堆内存，于是当出现复制行为的时候，他们执行的内存地址是相同的，当s1离开后，s2执行的内存地址无。当s1离开后，s2执行的内存地址无，这个叫做二次释放的错误，也是之前提到过的内存安全性 bug 之一。两次释放（相同）内存会导致内存污染，它可能会导致潜在的安全漏洞。但是我在代码中试了一下，没有报错。。。 fn main() { let x = 1; let y = x; println!(\"Hello, world!{}\",y); println!(\"{}\",x)} // inputHello, world!11 移动行为如果将原变量指针移向另外一个变量指针，原变量指针失效。当你再次调用s1变量时，由于指针的失去，没有指向存储数据的内存地址，报错无效引用 fn main() { let x = String::from(\"hello\"); // 这个是引用类型。数据在堆上面 let y = x; println!(\"Hello, world!{}\",y); println!(\"{}\",x)}// inputerror[E0382]: borrow of moved value: `x` --> src/main.rs:5:19 |2 | let x = String::from(\"hello\"); | - move occurs because `x` has type `std::string::String`, which does not implement the `Copy` trait3 | let y = x; | - value moved here4 | println!(\"Hello, world!{}\",y);5 | println!(\"{}\",x) | ^ value borrowed here after moveerror: aborting due to previous errorFor more information about this error, try `rustc --explain E0382`.error: could not compile `xx`.To learn more, run the command again with --verbose.// 指针报错指针已经被move 克隆行为对于基础类型来说，变量的数据交互形式是复制对于引用类型来说，变量的数据交互形式无法复制，只能移动。但是如果我们需要使用到复制堆上的数据，可以使用clone的通用函数 fn main() { let x = String::from(\"hello\"); // 这个是引用类型。数据在堆上面 let y = x.clone(); println!(\"Hello, world!{}\",y); println!(\"{}\",x)} 引用和借用不可变引用跳过所有权，引用对象数据，这里就要用到rust中的引用关键字&&关键字作用是创建了一条指向某一对象的引用，再由引用对象指向数据所在内存地址当引用本身&s1离开作用域后，调用drop函数，指向s1对象的指针被丢弃同时，rust的引用本身也是不可变的， fn main() { let s1 = String::from(\"hello\"); let len = calculate_length(&s1); println!(\"The length of '{}' is {}.\", s1, len);}//参数类型需要引用类型fn calculate_length(s: &String) -> usize { s.len()} 以上 &s1的过程称为引用，获取因果那个作为函数参数称为借用 可变引用可变引用同不可变类似，但要保证被引用类型为可变类型引用为可变函数参数为可变引用 fn main() { let mut s = String::from(\"hello\"); change(&mut s);}fn change(some_string: &mut String) { some_string.push_str(\", world\");}``` 在特定作用域中的特定数据有且只有一个可变引用。这些代码会失败;但可以有多个不可变引用,并且不可变引用和可变引用不能同时存在，可以在其中一个小时后再调用解决```rustlet mst s = String::from(\"hello\"){ let r1 = &mut s;} let r2 = &mut s; slice 切片let s = String::from(\"hello world\") let hello = &s[..5];// let hello = &s[0..5];let world = &s[6..11];// let world = &s[6..len];let helloworld = &s[..];let helloworld = &s[0..len];","link":"/posts/27cd4fcb/"},{"title":"drf-filter","text":"Introducing drf-filterhow to use it django-filterhttps://juejin.im/post/5d22e20f6fb9a07efb69a875","link":"/posts/933b28f1/"},{"title":"jwt","text":"Introducing drfhow to use it 使用drf-jwt# 安装jwtsource /bin/activepip install djangorestframework-jwt # 配置setting.pyREST_FRAMEWORK = { 'DEFAULT_PERMISSION_CLASSES': ( 'rest_framework.permissions.IsAuthenticated', ), 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework_jwt.authentication.JSONWebTokenAuthentication', 'rest_framework.authentication.SessionAuthentication', 'rest_framework.authentication.BasicAuthentication', ),}# 配置url.pyfrom rest_framework_jwt.views import obtain_jwt_tokenurlpatterns = [ '', # ... url(r'^api-token-auth/', obtain_jwt_token),]# 测试curl -X POST -d \"username=admin&password=password123\" http://localhost:8000/api-token-auth/# 返回jsoncurl -X POST -H \"Content-Type: application/json\" -d '{\"username\":\"admin\",\"password\":\"password123\"}' http://localhost:8000/api-token-auth/# 定义验证方式curl -H \"Authorization: JWT \" http://localhost:8000/protected-url/ //settings.py# jwt token 有效期import datetimeJWT_AUTH = { # jwt 验证码有效期 'JWT_EXPIRATION_DELTA': datetime.timedelta(days=365), # jwt 验证头部 'JWT_AUTH_HEADER_PREFIX': 'Bearer',} django-jwt 自定义用户认证//settings.pyAUTHENTICATION_BACKENDS = ( 'django.contrib.auth.backends.ModelBackend', 'guardian.backends.ObjectPermissionBackend', 'users.views.CustomBackend',)JWT_AUTH = { 'JWT_AUTH_HEADER_PREFIX': 'JWT', 'JWT_EXPIRATION_DELTA': datetime.timedelta(days=7)}//users views.pyfrom django.db.models import Qfrom django.contrib.auth.backends import ModelBackendfrom django.contrib.auth import get_user_modelUser = get_user_model()# Create your views here.class CustomBackend(ModelBackend): \"\"\" 自定义用户验证 \"\"\" def authenticate(self, request, username=None, password=None, **kwargs): try: user = User.objects.get(Q(username=username) | Q(mobile=username)) if user.check_password(password): return user except Exception as e: return None https://zhuanlan.zhihu.com/p/30524397https://jpadilla.github.io/django-rest-framework-jwt/#security vue中使用token验证https://blog.csdn.net/baiqiangdoudou/article/details/100174505 curl -H \"Authorization: JWT eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VyX2lkIjoxLCJ1c2VybmFtZSI6ImFkbWluIiwiZXhwIjoxNTc0OTMwMjYyLCJlbWFpbCI6IjEwOTc2OTAyNjhAcXEuY29tIn0.cxzZhCOStN_w9OpVcq7rO-bcA_vWA172DtQaNdeGF3A\" http://localhost:8000/switch/ 为什么要用token 与其他的差别","link":"/posts/8d17cdf0/"},{"title":"django实际项目中的模块设计","text":"learn django 🐢 django实际模块设计多级联动菜单设计数据库设计 class MenusModel(models.Model): \"菜单类别\" MENU_TYPE=( (1, \"一级类目\"), (2, \"二级类目\"), ) name = models.CharField(max_length=10,verbose_name=\"菜单栏名字\") icon = models.CharField(max_length=20,verbose_name=\"菜单栏图标\") path = models.CharField(max_length=20,verbose_name=\"菜单栏指向路径\") menu_type = models.CharField(choices=MENU_TYPE,verbose_name=\"菜单类别\",max_length=1) parent = models.ForeignKey('self', default=0, null=True, blank=True, related_name='children', \\ verbose_name='父分类',on_delete=models.CASCADE) class Meta: verbose_name = \"菜单栏名字\" verbose_name_plural = verbose_name 序列化设计 # 二级菜单筛选class MenusSerializer2(serializers.ModelSerializer): class Meta: model = MenusModel fields = \"__all__\"# 一级菜单筛选class MenusSerializer(serializers.ModelSerializer): children = MenusSerializer2(many=True) class Meta: model = MenusModel fields = \"__all__\" view视图设计 class MenuVeiw(viewsets.GenericViewSet, mixins.ListModelMixin): queryset = MenusModel.objects.filter(menu_type=1) serializer_class = MenusSerializer 效果 多级联动菜单设计2数据库设计 class GoodsCategory(BaseModel): # \"\"\" # 商品类别 # \"\"\" class MenusModel(models.Model): \"菜单类别\" MENU_TYPE=( (1, \"一级类目\"), (2, \"二级类目\"), ) name = models.CharField(max_length=10,verbose_name=\"菜单栏名字\") icon = models.CharField(max_length=20,verbose_name=\"菜单栏图标\") path = models.CharField(max_length=20,verbose_name=\"菜单栏指向路径\") menu_type = models.CharField(choices=MENU_TYPE,verbose_name=\"菜单类别\",max_length=1) parent = models.ForeignKey('self', default=0, null=True, blank=True, related_name='children', \\ verbose_name='父分类',on_delete=models.CASCADE) class Meta: db_name = menu_db verbose_name = \"菜单栏名字\" verbose_name_plural = verbose_name 序列化设计，利用数据库的反向查询 from rest_framework import serializersfrom .models import GoodsCategoryclass CategorySerializer3(serializers.ModelSerializer): class Meta: model = GoodsCategory fields = \"__all__\"class CategorySerializer2(serializers.ModelSerializer): sub_cat = CategorySerializer3(many=True) class Meta: model = GoodsCategory fields = \"__all__\"class CategorySerializer(serializers.ModelSerializer): sub_cat = CategorySerializer2(many=True) class Meta: model = GoodsCategory fields = \"__all__\" view设计 class CategoryInfoView(mixins.ListModelMixin,GenericAPIView): queryset = GoodsCategory.objects.filter(parent=None) serializer_class = CategorySerializer def get(self,request): return self.list(request) 效果 报错$ python3 manage.py runserver 0.0.0.0:8888Watching for file changes with StatReloader 端口被占用 kill或者重启其他端口","link":"/posts/88888022/"},{"title":"drf-model","text":"drf-model drf-modelclass TestViewSet(viewsets.ModelViewSet): serializer_class = TestSerializer queryset = test_Model.objects.all() # create @action(methods=['post'],detail=False) def create_field(self, request, *args, **kwargs): request.data['name'] = \"hzj默认\" serializer = self.get_serializer(data=request.data) serializer.is_valid(raise_exception=True) self.perform_create(serializer) headers = self.get_success_headers(serializer.data) return Response(serializer.data, status=status.HTTP_201_CREATED, headers=headers) # update @action(methods=['patch'], detail=False) def update_field(self, request, *args, **kwargs): request.data[\"text\"] = \"更新dsdsd\" instance = test_Model.objects.get(id=request.data['id']) # instance = self.get_object() 会报错 # https://docs.djangoproject.com/en/2.2/ref/class-based-views/mixins-single-object/#django.views.generic.detail.SingleObjectMixin.get_object # 默认使用id查找 serializer = self.get_serializer(instance,data=request.data,partial=True) serializer.is_valid() serializer.save() return Response(serializer.data,status=status.HTTP_200_OK) # delete @action(methods=['delete'],detail=False) def delete_field(self,request,*args,**kwargs): instance = test_Model.objects.get(id=request.data['id']) if instance: self.perform_destroy(instance) return Response({\"flag\":\"删除成功\"},status=status.HTTP_200_OK) else: return Response(status=status.HTTP_400_BAD_REQUEST)","link":"/posts/4b10b818/"},{"title":"drf-pagination","text":"Introducing drf-paginationhow to use it django-rest-framework 分页drf一共有三种分页的方式 PageNumberPagination此分页样式在请求查询参数中接受单个数字页码，事先规定好每一页的数量,url中定义分页的标识 ,每一页最大数量等等形式 https://api.example.org/accounts/?page=3 全局设置 REST_FRAMEWORK = { 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.LimitOffsetPagination'} LimitOffsetPagination这种分页样式反映了查找多个数据库记录时使用的语法。客户端同时包括“限制”和“偏移”查询参数。该限制指示要返回的最大项目数，并且与page_size其他样式相同。偏移量表示查询相对于未分页项的完整集合的开始位置。形式 https://api.example.org/accounts/?limit=100&offset=300 全局设置 REST_FRAMEWORK = { 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination', 'PAGE_SIZE': 100} 自定义设置page_size 指示页面大小的数值。如果设置，则此PAGE_SIZE设置将覆盖设置。默认值为与PAGE_SIZE设置键相同的值。page_query_param -一个字符串值，指示用于分页控件的查询参数的名称。page_size_query_param-如果设置，则这是一个字符串值，指示查询参数的名称，该参数允许客户端根据每个请求设置页面大小。默认为None，表示客户端可能无法控制请求的页面大小。max_page_size-如果设置，这是一个数字值，表示请求的最大允许页面大小。只有page_size_query_param同时设置了此属性，该属性才有效。last_page_strings-字符串值的列表或元组，指示可与一起使用page_query_param以请求集合中的最后一页的值。默认为(‘last’,) ## setting.pyREST_FRAMEWORK = { 'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',}# 设置分页样式class LargeResultsSetPagination(PageNumberPagination): page_size = 1000 page_size_query_param = 'page_size' max_page_size = 10000# 使用样式---> 局部样式class BillingRecordsView(generics.ListAPIView): queryset = Billing.objects.all() serializer_class = BillingRecordsSerializer pagination_class = LargeResultsSetPagination# 请求格式curl http://localhost:8000/switch/?page=1 CursorPagination光标分页","link":"/posts/10ccc76d/"},{"title":"drf-note","text":"drf如何使用django-rest-framework 1.首先下载 pip3 install django-rest-framework 2.应用在setting中添加 INSTALLED_APPS = ( ... 'rest_framework',) 3.在drf中使用登陆登出的功能 urlpatterns = [ ... url(r'^api-auth/', include('rest_framework.urls'))] 序列化创建model 与 django类似创建serializer 序列化model数据，以json的形式展示 （serializer modelserialzier）创建view 与django类似 使用httpie查看 pip install httpiehttp http://localhost:8000/snippets/","link":"/posts/437192d0/"},{"title":"DRF框架","text":"rust风格Representational State Transfer 表现层状态转化（ 资源定位及资源操作）表象层面说就是通过get,post,put,delete方式来实现前后台通信的一种轻量级,跨平台,跨语言架构设计风格的web服务 http不仅仅是传输协议，更是一种应用协议。REST，即Representational State Transfer的缩写。意为是”表现层状态转化”。RESTful表示一种风格，理解REST前需要理解资源，何谓资源，广义的资源是指可以操作的所有对象。可能是一个系统资源，如txt、jgp、xml …，亦可以是诸如自己定义的虚拟集合的抽象，如books、usrs、times。RESTfutl代表一种简洁、方便、快捷、高效、透明的架构，这取决于你怎样组合。具有如下特点： 1、规范化接口访问方式。这些http操作方法包括GET/POST/PUT/DELETE/OPTIONS等，每个操作方法都代表一个相同意义的操作，它向所有人透明地表明操作方式。比如GET只能读取/拉数据，当然你也可以是添加数据，但建议不要这么做，不然这样就失去了REST的意义。GET 读取POST 添加PUT 修改DELETE 删除2、资源标识唯一。通过URI表示一个资源名称，形式/resource/patch。如/users，表示用户的组合，或用户群。当然还可以继续标识某个具体的一个用户，/users/11，表示id为11的用户。当然，你也可以又用一组/usrgroup/11的URI代表操作用户组，不过不建议这么做，因为这样从字面上重复了/users/11资源表示的内容。一个资源URI总是包含第一条实现的方法：GET /users/11POST /users/11PUT /users/11DELETE /users/11当然，仅有这些还不足以包括资源操作的所有需求，所以还可以包含请求参数，如GET /users?type=list&page=1。3、状态的转化。这就是REST的真实含义，指它允许资源URI具有不同的表现形式。同一个URI，根据不同请求方式，执行的动作不同；还可以根据请求的Header Accept的不同返回不同的结果，如text/html、text/css、text/xml等等。也可以理解为body不同。如查询快递一般，可以上次查询，物品还在仓库，而过一段时间已经在路上了。它表示的是一个互动过程。4、所有信息都包含在当前请求中。请求的方式包含在 Request Header的Method中，还可以包含Accept、Accept-Encoding、Accept-Language，使用Authentication、Cookie等信息表明身份。同样，服务端通过发送Content-Length、Content-Type响应执行情况。最重要的是，需要返回Status Code通知执行状态，如200 201 400 404 500等http code。REST认为，所有信息都能通过请求一次性发送，而不必再采用方式保存状态，请求的信息本身已经说明了请求的意义。5、无状态性。这是REST最重要的特性之一，这个状态指的是客户端与服务端无需为每次保存请求状态，客户端请求不必考虑当前状态，不必考虑上下文。具体上说，就是不必使用session等工具跟踪、保存请求的特殊性。比如，无论是谁，从哪里发送，几时发送，对同一个URI资源发送请求的结果都是一样的。据传，这样的设计是为当一台服务器宕机时，另一台服务器可以无差别地响应对方的请求。客户端请求只认URI，而不需理后台的设计。实际上，在如今执行的RESTful设计当中，完全能执行这个要求的很少，最彻底的云服务，大部份为RESTful-like的风格。6、可实现请求缓存。通过缓存减少请求次数，在HTTP响应里利用Cache-Control、Expires、Last-Modified三个头字段，可以让浏览器缓存资源一段时间。 drf的视图集ViewSet类只是一种类型的基于类的视图，即不提供任何方法的处理程序，例如.get()或.post()，而是提供操作，如.list()和.create()。http://www.sinodocs.cn/api-guide/viewsets.html drf字段更新默认只有list和create 对应的方法就是get 和postpartial = True 局部更新 class TestViewSet(viewsets.ModelViewSet): serializer_class = TestSerializer queryset = test_Model.objects.all() @action(methods=['patch'], detail=False) def update_field(self, request, *args, **kwargs): request.data[\"text\"] = \"更新dsdsd\" instance = test_Model.objects.get(id=request.data['id']) # instance = self.get_object() 会报错 # https://docs.djangoproject.com/en/2.2/ref/class-based-views/mixins-single-object/#django.views.generic.detail.SingleObjectMixin.get_object # 默认使用id查找 serializer = self.get_serializer(instance,data=request.data,partial=True) serializer.is_valid() serializer.save() return Response(serializer.data,status=status.HTTP_200_OK) @action(methods=['delete'],detail=False) def delete_field(self,request,*args,**kwargs): instance = test_Model.objects.get(id=request.data['id']) if instance: self.perform_destroy(instance) return Response({\"flag\":\"删除成功\"},status=status.HTTP_200_OK) else: return Response(status=status.HTTP_400_BAD_REQUEST) 基本的视图集使用viewsets.ModelViewSet + DefaultRouter其中base-name表示基础url lookup表示查询参数(只根据主键查找)获取局部地址 http://localhost:8080/{base-name}/{lookup} drf路由集为了更加便捷的开发项目,drf设计了路由集的内容，免去了路由配置中的麻烦，当然他也同时兼容django的路由设计https://www.django-rest-framework.org/api-guide/routers/ 使用from rest_framework import routersrouter = DefaultRouter(trailing_slash=False) # 是否以斜杠/结尾# 声明注册路由# 同path('switch/',views.per_switch.as_view()),router.register(prefix='users', viewset=UserViewSet,basename=\"another_name\")router.register('accounts', AccountViewSet)# 添加规则，django主动扫描urlpatterns变量获取路由urlpatterns = router.urls 以上 prefix定义前缀 viewset定义视图 basename定义前缀别名 形成url格式(本地) —>http://localhost:8080/user/http://localhost:8000/accounts/ 兼容使用framework rest_framework.routers import DefaultRouterrouter = DefaultRouter()router.register('test',viewset=TestViewSet,base_name=\"test\")urlpatterns = [ path('switch/',views.switch_list.as_view()),]# 变量累加urlpatterns += router.urls 路由集urldjango的路由集是真滴变态，当你使用带值参数去查找列表中的特定内容时候，他所表现的url是^users/{pk}/set_password/$注意 pk在中间 set_password是你方法的名字如果你需要修改这些内容，可以在@action中指定url_path = set_passwordurl_name = change_password class SwitchViewSet(viewsets.GenericViewSet, mixins.ListModelMixin): serializer_class = SwitchSerializer queryset = SwitchModel.objects.all() # get @action(detail=True,url_path=\"xx\") def list_peer(self, request, pk): queryset = SwitchModel.objects.get(name=pk) print(queryset) # page = self.paginate_queryset(queryset) # if page is not None: # serializer = self.get_serializer(page, many=True) # return self.get_paginated_response(serializer.data) serializer = self.get_serializer(queryset) return Response(serializer.data) 如上一个列表查询的地址是 http://localhost:8080/{pk}/xx drf过滤drf通用过滤# setting.py# 全局设置过滤器REST_FRAMEWORK = { 'DEFAULT_FILTER_BACKENDS': ['django_filters.rest_framework.DjangoFilterBackend']}# views.py# 单视图设置过滤器 filter_backends = [django_filters.rest_framework.DjangoFilterBackend] https://www.django-rest-framework.org/api-guide/filtering/ drf分页https://www.django-rest-framework.org/api-guide/pagination/ drf过滤器https://www.django-rest-framework.org/api-guide/serializers/ drf解析器与渲染器视图的有效解析器集始终定义为类列表。当 request.data被访问时，REST框架将检查Content-Type传入请求上的标头，并确定使用哪个解析器来解析请求内容。如果您未设置内容类型，则大多数客户端将默认使用’application/x-www-form-urlencoded’例如，如果要json使用jQuery和.ajax（）方法发送编码数据，则应确保包括该contentType: ‘application/json’设置。 设置解析器仅允许json的内容 # setting.py# 全局设置解析REST_FRAMEWORK = { 'DEFAULT_PARSER_CLASSES': [ 'rest_framework.parsers.JSONParser', ]} # 单视图设置解析class modelview(): parser_classes = [JSONParser] 其他各类解析https://www.django-rest-framework.org/api-guide/parsers/ 渲染器既然有收的解析器，那也有发出数据的渲染器，REST框架包括许多内置的Renderer类，使您可以返回各种媒体类型的响应。还支持定义自己的自定义渲染器，这使您可以灵活地设计自己的媒体类型。 设置渲染器# setting.py# 全局设置解析REST_FRAMEWORK = { 'DEFAULT_RENDERER_CLASSES': [ 'rest_framework.renderers.JSONRenderer', 'rest_framework.renderers.BrowsableAPIRenderer', ]} # 单视图设置解析class modelview() renderer_classes = [JSONRenderer] 其他渲染器https://www.django-rest-framework.org/api-guide/renderers/","link":"/posts/7068483c/"},{"title":"drf框架解析","text":"drf框架解析1在drf的view视图中，我们经常会用到viewset视图集的内容。引用的方法有很多种 直接引用 我们可以使用ModelViewSet 根据不同的需求添加不同的mixins # 列出列表class SwitchViewSet(viewsets.GenericViewSet, mixins.ListModelMixin): serializer_class = SwitchSerializer queryset = SwitchModel.objects.all() 其中mixins有很多种 ListModelMixin UpdateModelMixin CreateModelMixin RetrieveModelMixin DestroyModelMixin这些mixins本身就已经提供了最基础的功能，如果我们需要添加附加的需求，可以重写这些方法mixins中的内容 class SwitchViewSet(viewsets.GenericViewSet, mixins.ListModelMixin): # 获取序列化工具 serializer_class = SwitchSerializer # 获取集合 queryset = SwitchModel.objects.all() ListModelMixinclass ListModelMixin: \"\"\" List a queryset. \"\"\" def list(self, request, *args, **kwargs): queryset = self.filter_queryset(self.get_queryset()) page = self.paginate_queryset(queryset) if page is not None: serializer = self.get_serializer(page, many=True) return self.get_paginated_response(serializer.data) serializer = self.get_serializer(queryset, many=True) return Response(serializer.data) ListModelMixin 也就是get请求返回当前模型所有列表,filter_queryset达成过滤 get_queryset获取集合第二段判断是否有做分类功能第三段返回serializer def filter_queryset(self, queryset): \"\"\" Given a queryset, filter it with whichever filter backend is in use. You are unlikely to want to override this method, although you may need to call it either from a list view, or from a custom `get_object` method if you want to apply the configured filtering backend to the default queryset. \"\"\" for backend in list(self.filter_backends): queryset = backend().filter_queryset(self.request, queryset, self) return queryset","link":"/posts/23293bb2/"},{"title":"linux常用脚本","text":"daily script linux脚本记录 删除文档中的所有带#的行sed -i -r '/^#.*/s:::g' /etc/ntp.conf","link":"/posts/705ac99d/"},{"title":"linux初始化","text":"learn linux 初始化脚本#!/bin/sh# ---> 脚本初始化export LC_ALL=en_US.utf8 # 全局设置为en_US.utf8,为了防止出现乱码echo -e 'nameserver 192.168.147.20\\nnameserver 192.168.21.20\\nnameserver 114.114.114.114' > /etc/resolv.conf# 写入DNS到/etc/resolv.conf 保证能ping通外网# ---> 设置变量KERNEL=\"kernel-ml\"# 设置KERNEL变量，一开始为无 ，reload后为无HOST=\"DCK-ZJ-SAD-xxx\"# 设置HOST变量ZONE=\"Asia/Shanghai\"# 设置时区变量# ---> 直接设置hostnamectl --static set-hostname $HOST# 修改主机名 也可以直接修改# echo \"DCK-ZJ-SAD-xxx\" > /etc/hostnametimedatectl set-timezone $ZONE# 设置本地时间timedatectl set-ntp 0# 关闭ntp同步timedatectl set-local-rtc 0# 设置硬件时钟为UTC setenforce 0 # 暂时取消selinux 高安全模式sed -r -i '/^SELINUX=/s^=.*^=disabled^g' /etc/selinux/config# 永久取消selinuxsed -r -i '/^[^root]/s:/bin/bash:/sbin/nologin:g' /etc/passwd# -r 支持正则# -i 直接修改文件# 匹配所有不是root开头的行 将后面的/bin/bash 修改成/sbin/nologin 收回所有除root用户以外的管理者登陆权限# /^[^root]/ 取反，不是root的行sed -r -i '/#Port 22/s^.*^Port 65422^g;/^PasswordAuthentication/s^yes^no^g' /etc/ssh/sshd_config#[root@localhost ~]# sed -r -n '/#Port 22/s^.*^Port 65422^p;/^PasswordAuthentication/s^yes^no^p' /etc/ssh/sshd_config#Port 65422#PasswordAuthentication no# 将登陆端口22 改成65422# 将密码验证从yes改成no# --------> ??????????????sed -r -i -e '/DefaultLimitCORE/s^.*^DefaultLimitCORE=infinity^g' -e '/DefaultLimitNOFILE/s^.*^DefaultLimitNOFILE=100000^g' -e '/DefaultLimitNPROC/s^.*^DefaultLimitNPROC=100000^g' /etc/systemd/system.conf #[root@localhost ~]# sed -r -n -e '/DefaultLimitCORE/s^.*^DefaultLimitCORE=infinity^p' -e '/DefaultLimitNOFILE/s^.*^DefaultLimitNOFILE=100000^p' -e '/DefaultLimitNPROC/s^.*^DefaultLimitNPROC=100000^p' /etc/systemd/system.conf#DefaultLimitCORE=infinity#DefaultLimitNOFILE=100000#DefaultLimitNPROC=100000# -e 多点编辑# 好像也可以写成 # sed -r -i 'xxxx:g;xxx:g;xx:g‘# /etc/systemd/system.conf 有啥用# 为什么要这样设置# 适当放大系统里的资源限制配额# 还是不懂？sed -r -i 's@weekly@daily@g;s@^rotate.*@rotate 7@g;s@^#compress.*@compress@g' /etc/logrotate.conf#root@localhost ~]# sed -r -n 's@weekly@daily@p;s@^rotate.*@rotate 7@p;s@^#compress.*@compress@p ' /etc/logrotate.conf# rotate log files daily#daily#rotate 7#compress#将logrotate日志系统设置为 每天执行 保留7天日志 日志进行压缩 等功能开启# ----------------> ??????????????????sed -r -i -e '/Compress=/s@.*@Compress=yes@g; /SystemMaxUse=/s@.*@SystemMaxUse=4G@g; ' -e '/SystemMaxFileSize=/s@.*@SystemMaxFileSize=256M@g; /MaxRetentionSec=/s@.*@MaxRetentionSec=2week@g' /etc/systemd/journald.conf#[root@localhost ~]# sed -r -n -e '/Compress=/s@.*@Compress=yes@p; /SystemMaxUse=/s@.*@SystemMaxUse=4G@p; ' -e '/SystemMaxFileSize=/s@.*@SystemMaxFileSize=256M@p; /MaxRetentionSec=/s@.*@MaxRetentionSec=2week@p' /etc/systemd/journald.conf#Compress=yes#SystemMaxUse=4G#SystemMaxFileSize=256M#MaxRetentionSec=2week# /etc/systemd/journald.conf 有啥用localectl set-locale LANG=en_US.utf8# 声明语言环境，zh_CN.utf8 中文请款下可能会出现各种乱码cat > /etc/locale.conf < EOF /etc/security/limits.d/20-nproc.conf","link":"/posts/1d7a61af/"},{"title":"shell脚本","text":"shell脚本简单的介绍shell脚本的使用 规范shell脚本对空格有一定的规定 空格的使用 赋值语句中等号=两边不能有空格，而字符串比较中等号= == 两边必须有空格 中括号[] [[]] 前后一定要加空格 i=1if [ $a == $b ] ;then 括号的使用常见的三种括号 (()) [] [[]] () 只能进行整数比较，不能用于字符串比较，括号中变量可以省略前缀 [] [[]] [] 与test等价都是命令，而[[]]是关键字, && || < > 不能存在于[] 中，只能粗在于[[]]中 [[[] 支持算术扩展 [] 不支持 [[]] 支持字符串匹配，[] 不支持if [[ $a != 1 && $a != 2 ]], 对if [ $a != 1 ] && [ $a != 2] 对if [[ 1+2 -eq 3 ]] 对 字符串对比对比字符串只能使用=、==、、!=、-z、-n。其中，-n 表示字符串不为空，即长度大于0，-z 表示字符串为空，即长度为0 对比数字，只能使用==、=、!=，或者 -eq、-ne、-gt、-ge、-lt、-le。其中-eq的意思是 equal，-ne是 unequal，-gt是 greater than，-ge是 greater than or equal to，-lt是 less than，-le是 less than or equal to。 https://blog.csdn.net/HappyRocking/article/details/90476264 语法判断 ifif 条件; then command1else command2fi 举例 if [[ $a == $b ]]; then echo \"equal\"fi","link":"/posts/d0a69eae/"},{"title":"linux文本编辑三剑客","text":"linux文本编辑三剑客，awk、grep、sed是linux操作文本的三大利器，合称文本三剑客，也是必须掌握的linux命令之一。三者的功能都是处理文本，但侧重点各不相同，其中属awk功能最强大，但也最复杂。grep更适合单纯的查找或匹配文本，sed更适合编辑匹配到的文本，awk更适合格式化文本，对文本进行较复杂格式处理 关于”三剑客”的特长什么是三剑客的特长= grep 更适合单纯的查找和匹配文本 sed 更适合编辑匹配的文本 awk 更适合格式化文本,对文本进行较复杂格式处理 linux文本编辑三剑客grep基础grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来 grep (选项) pattern flie-A 除了显示符合匹配行，也显示匹配行后的n行-B 除了显示符合匹配行，也显示匹配行前的n行-C 除了显示符合匹配行，也显示匹配行前后的n行 但不显示每一行的行数-c 仅显示统计匹配行数的总数-e 实现多个选项件的逻辑关系 or-E 扩展的正则表达式-f FILE：从FILE获取匹配参数格式-i --ignore-case 忽略字符大小写的差别-n 显示匹配的行号-o 仅显示匹配到的字符串-v 反向匹配，显示不被匹配的内容-w 只显示全字符合的列 正则表达式匹配内容.匹配全部字符，不匹配空行[]匹配指定范围内的任意单个字符[^] 取反[:alnum:] [0-9a-zA-Z][:alpha:] [a-zA-Z][:upper:] 或 [A-Z][:lower:] 或 [a-z][:blank:] 匹配空白字符[:punct:] 标点符号匹配次数 *匹配任意次 0-n次 ,贪婪模式(尽可能多匹配).*匹配任意次 1-n次 \\?匹配 0-1次\\+至少匹配1次 位置确定 ^ 行首$ 行尾^$ 空白行 划组匹配在正则表达示中使用之前匹配到的内容，即划组匹配 # 分组形式 \\(\\)# 读取方式 \\1 \\2 \\3 实例#多文件查找grep \"match_pattern\" file1 file2 file3 #反项查找grep -v \"macth_pattern\" file1 file2 file3 #匹配项标记颜色grep \"macth_pattern\" file1 --color=auto #正则匹配grep -E \"[1-9]+\"或egrep \"[1-9]+\"#只显示匹配到的字符串echo this is a test line. | grep -o -E \"[a-z]+\\.\"#统计匹配到的内容数量grep -c \"text\" file1 #显示匹配到的行号grep -n \"text\" file1 #多级目录中递归搜索grep \"text\" . -r -n #忽略大小写echo \"hello world\" | grep -i \"HELLO\" sed基础sed [参数][地址commands][inputfile] sed 工作流程一次处理一行内容。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（patternspace ）.接着用sed 命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。然后读入下行 参数:--version 查看版本--help 查看帮助-n 不输出模式空间内容到屏幕，即不自动打印,如上工作流程中说到，sed在输出的时候会先经过模式空间，在模式空间中处理完当前行后才会输出，而-n选项则是控制问在在模式空间输出完以后，不再输出-e 多点编辑，允许多个脚本指令被执行-r 支持正则-i 修改原文件内容-i.bak 在将处理的结果写入文件之前备份一份-f 支持使用脚本文件 Command匹配段sed 提供了一些匹配的手法来匹配内容后传入到模式空间的内容匹配大致的规则如下sed一共分为5段内容，第一段是匹配的内容，用来确定当前段是否需要被传入模式空间中修改 不给地址 :对全文进行处理单地址 : - #: 由数字指定第几行,但是数字指定的时候，不需要用分隔符隔开 # 如 sed -n '1p' 第一行 - /pattern/: # 如sed -n '/root/p' - #,# # 如 sed -n '1,2p' 第一行到第二行 - /part1/,/part2/ # 如 sed -n '/root/,/docker/p' /etc/passwd步进 ～ - sed -n '1~2p' 只打印奇数行,起始为1 步进为2 - sed -n '2~2p' 只打印偶数行 - # 单次步进 #,+# 如 sed -n '1,+2p' 第一行到第三行 处理规则第二段是处理规则的内容，经过第一段筛选过后，会根据不同的处理规则进行转换 s 替换 # s/pattern/pattern1/ 将pattern 替换成pattern1 只有在s替换的时候才可以把/ 换成其他的内容# sed -n '/bbb/s#bb#aa#p' yy.shd 删除 # sed '1d' xx.sh sed '/bbb/d' xx.sh 删除匹配行，删除模式空间匹配到的行i\\ 从当前行前插入 # sed '1 i xx' xx.sh sed '/bbb/i\\xx' xx.sh a\\ 在当前行后插入 # sed '1 a xx' xx.sh # sed '/bbb/a\\xx' xx.sh # sed '/bbb/axx' xx.sh c\\ 替换匹配行# sed '1 c xx' xx.sh# sed '/bbb/c\\xx' xx.sh# sed '/bbb/cxx' xx.shy 对应替换，与s 不一样的是y需要对应字符数量# sed '/bbb/y/BBB/' xx.sh i a c三个内容需要注意，他们后面并没有第三段和第四段以及第五段内容,且只能加反斜杆表转义 处理方式最后一个段是选择处理方式 g 匹配所有行p 打印当前模式空间内容，追加到默认输出之后w 写入一个文件# sed '/My/w' xx.sh 写入到xx.sh文件里面r 读取一个文件# sed '/My/r' xx.sh 读取xx.sh文件里面的My 可以一起使用 使用案例[root@hzj ~]# cat demoaaabbbbAABBCCDD# 匹配/aaa/行[root@hzj ~]# sed \"/aaa/p\" demo #aaa进入模式空间，/p打印模式空间内容。出现两遍aaaaaaaaabbbbAABBCCDD # 匹配aaa行并仅输出[root@hzj ~]# sed -n \"/aaa/p\" demo #-n关闭自动输出，/p打印模式空间内容，出现一遍aaaaaa[root@hzj ~]# sed -e \"s/a/A/\" -e \"s/b/B/\" demo #-e多点编辑AaaBbbbAABBCCDD[root@hzj ~]# cat sedscript.txts/A/a/g[root@hzj ~]# sed -f sedscript.txt demo #-f使用文件处理aaabbbbaaBBCCDD[root@hzj ~]# sed -n \"p\" demo #关闭默认输出。p输出模式空间内容aaabbbbAABjBCCDD[root@hzj ~]# sed \"2s/b/B/g\" demo #替换第2行的b->BaaaBBBBAABBCCDD[root@hzj ~]# sed -n '1,3p' /etc/passwd # 输出第1,3行[root@hzj ~]# sed -n '/^root/,/daemon/p' # 输出passwd文件的root～daemon行[root@hzj ~]# sed -n '/x:[0:1]:/p' /etc/passwd #输出passwd文件中uid是0或1的行# 删除第一行sed '1d' /etc/passwd 删除第一行和第三行sed -e '1d' -e '3d' /etc/passwdsed '1d;3d' /etc/passwd保留第一行 删除其他行sed '1!d' 在第二行后加123sed \"2a123\" demo 在第一行前加123sed \"1i123\" demo保存第三行的内容到demo3文件中sed -n \"3w/root/demo3\" demo读取demo3的内容到第1行后sed \"1r/root/demo3\" demo 先匹配后替换sed -e '/^root/s/^1/2' /etc/passwd匹配第一个并修改sed 's/root/ROOT' /etc/passwd匹配第二个并修改sed 's/root/ROOT' /etc/passwd匹配所有并修改sed 's/root/ROOT/g' /etc/passwd匹配修改成功后，打印变动行sed -n 's/root/ROOT/pg' /etc/passwd修改后另存为其他文件sed -n 's/root/ROOT/pg;w passwd.md' /etc/passwdsed -n 's/root/ROOT/pgw passwd.md' /etc/passwd在文件的每行前面添加#注释sed -n 's/^/#/p' /etc/passwd删除文件的第1个字符sed 's/^.//1' /etc/passwd删除文件的第二个字符sed 's/.//2' /etc/passwd在每一行的上面添加hello sed 'i hello' /etc/passwd在第一行的上面添加hellosed '1a hello' /etc/passwd将a~z替换成A～Z sed 'y/abcdefghijklmnopqrstuvwxyz/ABCDEFGHIJKLMNOPQRSTUVWXYZ/' /etc/passwd替换匹配行sed -n '1c hello' /etc/passwd输出1行sed -n '1q' /etc/passwd打印奇数行sed -n 'p;n' /etc/passwd打印偶数行sed -n 'n;p' /etc/passwd打印匹配字符串的下一行sed -n '/^root/{n;p}' /etc/passwd # 打印包含pattern的行sed 'root/p' /etc/passwd | less # 输出匹配行+全文sed -n 'root/p' /etc/passwd # 输出匹配行sed -n '/^root/p' /etc/passwd # 输出以root开头行sed -n 'root/!p' /etc/passwd # 输出以root开头以外的行# 删除pattern的行sed '/^root/,/shutdown/d' /etc/passwd # 步进多次sed -n '/^root/,~3p' /etc/passwd # 步进一次 sed -n '/^root/,+3p' /etc/passwd # 匹配行的下一行sed '/^root/{n;d}' /etc/passwd # 行插入 追加 修改sed -r '/^root/i\\>>>> test by geminis' /etc/passwdsed -r '/^root/a\\>>>> test by geminis' /etc/passwdsed -r '/^root/c\\>>>> test by geminis' /etc/passwd# 删除空格sed s/[[:space:]]//g file# 删除空格 sed /^$/d file awk基础awk是由Alfred Aho 、Peter Weinberger 和 Brian Kernighan这三个人创造的，awk由这个三个人的姓氏的首个字母组成。awk其实可以看成是一门独立的编程语言，他支持条件判断、数组、循环等功能。awk共有两个版本(gawk与nawk版本),在linux中我们最常使用的是gawk,同时awk、grep、sed被称为Linux中的三剑客 [root@CodeSheep ~]# ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 Feb 15 2019 /usr/bin/awk -> gawk 语法awk [options] ‘{pattern + action}’ {filenames}其中的action 我们最常用的就是print以及prinf,对于action来说，每次经过一行，都会当前行执行一边action比如 awk '{print \"1\",NR}' /etc/passwd 你会发现有多少行，他就输出了多少个1 每行一个 awk的工作流程首先awk并不是列操作，而是行操作，同样的他也是一行一行的处理的，其中$0表示当前行，比如在正常情况下我们输出全文是用cat来查看的，那么用awk的操作是这样的,另外awk的接受标准输入和文件 cat /etc/passwdawk '{print $0}' /etc/passwd# 如上的内容是一样的 awk中的分隔符为了处理好每一行中的每一个字段，awk引入了分隔符的概念，分隔符有三种表现的形式，一种是不输入任何不指定任何，则默认为空格一种是自定义的分隔符 使用 -F 指定 比如 -F:另外一种是使用 内置变量指定 -v FS=’#’ 自定义分隔符既然默认的分隔符是空格,那么当然还有自定义的分隔符咯。我们使用-F选项来指定我们的分隔符 # 使用#分隔符[root@CodeSheep ~]# cat demo3.text 123#123#dsdshj#dlsj#[root@CodeSheep ~]# awk -F# '{print $1}' demo3.text 123[root@CodeSheep ~]# cat demo3.text 123#123#dsdshj#dlsj#[root@CodeSheep ~]# awk -v FS='#' '{print $1}' demo3.text 123 其实在awk中不仅仅有输入的分割符,还有输出的分隔符，默认也为空格 [root@CodeSheep ~]# awk -F# '{print $1,$2}' demo3.text 123 123 OFS(output field separator)可以指定输出的分隔符,用法与FS相同 [root@CodeSheep ~]# awk -v FS='#' -v OFS='++++' '{print $1,$2}' demo3.text 123++++123 awk重定向awk 'BEGIN { print \"Hello, World !!!\" > \"/tmp/message.txt\" }' awk的内建变量awk支持内建变量和自定义变量 内建变量 $0 当前行 $1~$n 第n个字段 $NF 最后一个字段 NF 当前行被分割字段总数 NR 当前行行号 FNR 各文件分别计数的行号 FS 输入分隔符 OFS 输出分隔符 RS 输入换行符 ORS 输出换行符 FILENAME 当前文件名 ARGC 命令行参数的个数 ARGV 数组,保存的命令行所给定的各参数 # 给每一行添加行号,输出当前行号，以及当前行的内容[root@CodeSheep ~]# df | awk '{print NR,$0}'1 Filesystem 1K-blocks Used Available Use% Mounted on2 /dev/vda1 41147472 6848400 32395580 18% /3 devtmpfs 930656 0 930656 0% /dev4 tmpfs 941116 0 941116 0% /dev/shm5 tmpfs 941116 452 940664 1% /run6 tmpfs 941116 0 941116 0% /sys/fs/cgroup7 tmpfs 188224 0 188224 0% /run/user/0# 多个文件使用NR时,会根据的文件顺序累加序号# FNR则会分开标序# ARGV,ARGC[root@CodeSheep ~]# awk 'BEGIN{print ARGV[0],ARGV[1],ARGV[2],ARGC}' demo1.txt demo2.text awk demo1.txt demo2.text 3# 其中ARGV作为数组,第一个参数是awk 自定义变量名自定义变量的两种形式,一种是在action外面 使用选项指定变量，比如 -v name=”hzj”另外一种则是在action前的pattern中定义，比如 {name=”hzj”; action->print name} [root@CodeSheep ~]# awk -v name=\"hzj\" 'BEGIN{print name}'hzj[root@CodeSheep ~]# awk 'BEGIN{name=\"hzj\";print name}'hzj[root@CodeSheep ~]# name=hzj[root@CodeSheep ~]# awk -v name=$name 'BEGIN{print name}'hzj awk 参数options-v name=”xx” -v外部定义变量###s## pattern+action抛开Pattern 我们先来使用{action} # 输出文本内容[root@CodeSheep ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/vda1 41147472 6848500 32395480 18% /devtmpfs 930656 0 930656 0% /devtmpfs 941116 0 941116 0% /dev/shmtmpfs 941116 452 940664 1% /runtmpfs 941116 0 941116 0% /sys/fs/cgrouptmpfs 188224 0 188224 0% /run/user/0[root@CodeSheep ~]# df | awk '{print $1}'Filesystem/dev/vda1devtmpfstmpfstmpfstmpfstmpfs awk是逐行处理的,也就是说当awk处理一个文本的时候，他会一行一行的处理内容。其中awk默认以 换行符 为标记识别每一行。另外对于每一行的处理中 awk会按照用户指定的 分隔符 去分隔当前行，如果没有指定，则默认使用空格作为分隔符，当出现多个空格的时候,awk会自动将连续的空格理解成为一个分隔符。其中 我们将被awk处理后的每一行都使用了特定的变量标记$0表示当前处理的整行$1表示第一个字段$2表示第二个字段$NF表示最后一个字段NF表示当前行被分割后字段总数因此 假设一行文本被空格分为8段，则$NF表示$8 NF=8 则$7=$(NF-1) # 输出多行[root@CodeSheep ~]# df | awk '{print $1 $2 $3}'Filesystem1K-blocksUsed/dev/vda1411474726848536devtmpfs9306560tmpfs9411160tmpfs941116452tmpfs9411160tmpfs1882240[root@CodeSheep ~]# df | awk '{print $1, $2 ,$3}'Filesystem 1K-blocks Used/dev/vda1 41147472 6848536devtmpfs 930656 0tmpfs 941116 0tmpfs 941116 452tmpfs 941116 0tmpfs 188224 0# 自己添加字段[root@CodeSheep ~]# df | awk '{print $1 ,\"this print test\"}'Filesystem this print test/dev/vda1 this print testdevtmpfs this print testtmpfs this print testtmpfs this print testtmpfs this print testtmpfs this print test[root@CodeSheep ~]# df | awk '{print \"$1=\"$1 , \"testfield:\"\"this print test\"}'$1=Filesystem testfield:this print test$1=/dev/vda1 testfield:this print test$1=devtmpfs testfield:this print test$1=tmpfs testfield:this print test$1=tmpfs testfield:this print test$1=tmpfs testfield:this print test$1=tmpfs testfield:this print test#看上面的案例我们可以发现,当$1被双引号包裹的时候，他就是一个字符串,不再是变量 awk中的Pattern其实action的主要操作就是print输出,简单来用就是输出内容，更复杂的就是对输出的内容进行格式化的操作。而Pattern所存在的两种模式,愈加加强了awk的能力。 awk中的逻辑为了更好的格式化,awk中也带有逻辑参数，其中包括开始BEGIN和结尾END,他们之间用{}分隔,比如 awk -v test=\"test\" 'BEGIN{print \"1\",NR}{print test}END{print \"input end\" }' /etc/passwd 你会发现他输出了很多个test，首先begin进入，然后输出1和行号0 紧接着不断的进入行输出test 在最后一行输入时 执行input end 特殊模式下的BEGIN与END BEGIN 模式指定了处理文本之前需要执行的操作 END 模式指定了处理完所有行之后所需要执行的操作 [root@CodeSheep ~]# df | awk 'BEGIN{print \"$1\",\"$2\"}'$1 $2[root@CodeSheep ~]# df | awk 'BEGIN{print \"$1\",\"$2\"} {print $1,$2}'$1 $2Filesystem 1K-blocks/dev/vda1 41147472devtmpfs 930656tmpfs 941116tmpfs 941116tmpfs 941116tmpfs 188224[root@CodeSheep ~]# df | awk 'BEGIN{print \"$1\",\"$2\"} {print $1,$2} END{print \"end for file\"}'$1 $2Filesystem 1K-blocks/dev/vda1 41147472devtmpfs 930656tmpfs 941116tmpfs 941116tmpfs 941116tmpfs 188224end for file 在BEGIN的模式下，首先awk会执行BEGIN中的action 之后才做去执行其他的action,同理,在执行完所有的action之后,awk回去执行END模式下面的action。需要注意的是两个特殊的模式BEGIN以及END都需要大写 于是 awk的格式化能力表露无疑了,提取字段再加上BEGIN与END的两种特殊模式，一张完整的表不就出来了嘛 关系运算符 < 小于 x < y=y> 大于 x>y~ 正则匹配 x ~ /正则/!~ 正则不匹配 x !~ /正则/ awk中的正则模式既然上面的关系运算符中出现了正则，那我们就来讲一讲正则模式需要注意的是 当使用{x,y}这种次数匹配的正则表达式时，需要配合–posix选项或者–re-interval选项 # 匹配/etc/passwd 中以 tss开头的行[root@CodeSheep ~]# cat /etc/passwd | awk '/tss/{print $0}'tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin# 匹配/etc/passwd 中以 /bin/bash结尾的行[root@CodeSheep ~]# cat /etc/passwd | awk '/\\/bin\\/bash$/{print $0}'root:x:0:0:root:/root:/bin/bash# 匹配/etc/passwd 中以/bin/bash结尾的行 到以 tss开头的行[root@CodeSheep ~]# cat /etc/passwd | awk '/\\/bin\\/bash$/,/^tss/{print $0}'root:x:0:0:root:/root:/bin/bashbin:x:1:1:bin:/bin:/sbin/nologindaemon:x:2:2:daemon:/sbin:/sbin/nologinadm:x:3:4:adm:/var/adm:/sbin/nologinlp:x:4:7:lp:/var/spool/lpd:/sbin/nologinsync:x:5:0:sync:/sbin:/bin/syncshutdown:x:6:0:shutdown:/sbin:/sbin/shutdownhalt:x:7:0:halt:/sbin:/sbin/haltmail:x:8:12:mail:/var/spool/mail:/sbin/nologinoperator:x:11:0:operator:/root:/sbin/nologingames:x:12:100:games:/usr/games:/sbin/nologinftp:x:14:50:FTP User:/var/ftp:/sbin/nologinnobody:x:99:99:Nobody:/:/sbin/nologinsystemd-network:x:192:192:systemd Network Management:/:/sbin/nologindbus:x:81:81:System message bus:/:/sbin/nologinpolkitd:x:999:998:User for polkitd:/:/sbin/nologinsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologinpostfix:x:89:89::/var/spool/postfix:/sbin/nologinchrony:x:998:996::/var/lib/chrony:/sbin/nologinntp:x:38:38::/etc/ntp:/sbin/nologintcpdump:x:72:72::/:/sbin/nologinnscd:x:28:28:NSCD Daemon:/:/sbin/nologinmysql:x:27:27:MySQL Server:/var/lib/mysql:/bin/falsedockerroot:x:997:994:Docker User:/var/lib/docker:/sbin/nologintss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin# 匹配行号大于2 且小于6的行[root@CodeSheep ~]# cat /etc/passwd | awk 'NR>2 && NR","link":"/posts/ec496181/"},{"title":"keepalive+haproxy负载均衡","text":"haproxy负载均衡 # yum安装yum install haproxy -y # centos7默认版本是1.5# 查看包信息rpm -qi haproxy# 查看包所创建的目录rpm -ql haproxy —->主要目录主程序：/usr/sbin/haproxy配置文件：/etc/haproxy/haproxy.cfg启动服务：systemctl start haproxy停止服务：systemctl stop haproxy开机启动：systemctl enable haproxy —->配置文件结构 haproxy配置文件可分为全局配置（globalsettings）和 代理配置（proxies），而代理段配置包含defaults、frontend、backend、listen。 global settings：#全局参数配置，主要用于定义haproxy进程管理安全及性能相关的参数defaults < name >：#默认配置参数，下面的段继承该配置，名称是可选的,这配置默认配置参数可由下一个”defaults”所重新设定frontend < name >：#前端配置，定义一系列监听的套接字，这些套接字可接受客户端请求并与之建立连接，可以监听多个端口。backend < name >：#后端配置，定义后台服务器，前端代理服务器将会把客户端的请求调度至这些服务器，类似nginx中的upstreamlisten < name >：#定义一组前端和后端的完整代理，可理解为frontend+backend，通常用于tcp流量代理 —->配置参数可支持的时间单位 us : 微秒. 1 microsecond = 1/1000000 s ms : 毫秒. 1 millisecond = 1/1000 s s : 秒 1s = 1000ms m : 分 1m = 60s = 60000ms h : 小时 1h = 60m = 3600s = 3600000ms d : 天 1d = 24h = 1440m = 86400s = 86400000ms haproxy配置文件 全局配置参数(global) chroot: #修改haproxy的工作目录至指定的目录，并在放弃权限之前执行chroot（）操作，可以提升haproxy的安全级别，不过需要注意的是确保指定的目录为空目录且任何用户均不能有写权限;daemon: #让haproxy以守护进程的方式工作于后台，其等同于\"-D\"选项的功能，当然，也可以在命令行中以\"-db\"选项将其禁用;gid: #以指定的GID运行haproxy，建议使用专用于运行haproxy的GID，以避免因权限带来的风险;group: #同gid，不过这里为指定的组名;uid: #已指定的UID身份运行haproxy进程;user: #同uid，但这里使用的为用户名;log: #定义全局的syslog服务器，最多可以定义两个;nbproc: #指定启动的haproxy进程个数，只能用于守护进程模式的haproxy；默认为止启动一个进程，鉴于调试困难等多方面的原因，一般只在但进程仅能打开少数文件描述符的场中才使用多进程模式;pidfile: #pid文件的存放位置;ulimit-n: #设定每个进程所能够打开的最大文件描述符，默认情况下其会自动进行计算，因此不建议修改此选项;node: #定义当前节点的名称，用于HA场景中多haproxy进程共享同一个IP地址时;description: #当前实例的描述信息;maxconn: #设定每个haproxy进程所接受的最大并发连接数，其等同于命令行选项\"-n\"，\"ulimit-n\"自动计算的结果正式参照从参数设定的;maxpipes: #haproxy使用pipe完成基于内核的tcp报文重组，此选项用于设定每进程所允许使用的最大pipe个数，每个pipe会打开两个文件描述符，因此，\"ulimit -n\"自动计算的结果会根据需要调大此值，默认为maxcoon/4;noepoll: #在linux系统上禁用epoll机制;nokqueue: #在BSE系统上禁用kqueue机制;nopoll: #禁用poll机制;nosepoll: #在linux系统上禁用启发式epoll机制;nosplice: #禁止在linux套接字上使用tcp重组，这会导致更多的recv/send调用，不过，在linux2.6.25-28系列的内核上，tcp重组功能有bug存在;spread-checks: #在haprorxy后端有着众多服务器的场景中，在紧缺是时间间隔后统一对中服务器进行健康状况检查可能会带来意外问题，此选项用于将检查的时间间隔长度上增加或减少一定的随机时长，为当前检查检测时间的%;maxconnrate：#设置每个进程每秒种所能建立的最大连接数量，速率，一个连接里可以有多个会话，也可以没有会话maxsessrate：#设置每个进程每秒种所能建立的最大会话数量maxsslconn：#每进程支持SSL 的最大连接数量tune.bufsize: #设定buffer的大小，同样的内存条件下，较小的值可以让haproxy有能力接受更多的并发连接，较大的值了可以让某些应用程序使用较大的cookie信息，强烈建议使用默认值;tune.chksize: #设定检查缓冲区的大小，单位为字节，更大的值有助于在较大的页面中完成基于字符串或模式的文本查找，但也会占用更多的系统资源，不建议修改;tune.maxaccept: #设定haproxy进程内核调度运行时一次性可以接受的连接的个数，较大的值可以带来较大的吞吐量。tune.maxpollevents: #设定一次系统调用可以处理的事件最大数，默认值取决于OS,其至小于200时可介于带宽，但会略微增大网络延迟，但大于200时会降低延迟，但会稍稍增加网络带宽的占用;tune.maxrewrite: #设定在首部重写或追加而预留的缓存空间，建议使用1024左右的大小，在需要更大的空间时，haproxy会自动增加其值;tune.rcvbuf.client: #设定内核套接字中客户端接收缓存区的大小，单位为字节，强烈推荐使用默认值;tune.rcvbuf.server: #设定内核套接字中服务器接收缓存区的大小，单位为字节，强烈推荐使用默认值;tune.sndbuf.client: #设定内核套接字中客户端发送缓存区的大小，单位为字节，强烈推荐使用默认值;tune.sndbuf.server: #设定内核套接字中服务器端发送缓存区的大小，单位为字节，强烈推荐使用默认值;debug: #调试模式，输出启动信息到标准输出;quiet: #安装模式，启动时无输出; global默认配置 # 全局配置global log 127.0.0.1 local0 # 设置日志 log 127.0.0.1 local1 notice maxconn 4000 # 最大连接数 chroot /usr/local/haproxy # 安装目录 user haproxy group haproxy daemon # 守护进程运行 #nbproc 1 # 进程数量，只能用于守护进程模式的haproxy；默认启动一个进程，一般只在单进程仅能打开少数文件描述符的场景中才使用多进程模式； pidfile /var/run/haproxy.pid # pid文件的存放位置 defaults默认配置 defaults mode http #默认负载均衡模式为http log global #日志定义 option httplog #启用日志记录HTTP请求，默认不记录http log option dontlognull #不记录空日志 option httpclose # 每次请求完毕后主动关闭http通道 option forwardfor except 127.0.0.0/8 #插入x-forward标记，反向代理时候可以通过该字段获取客户端真实IP balance roundrobin # 负载均衡算法,轮询 retries 3 # 定义连接后端服务器的失败重连次数 timeout http-request 10s：#在客户端建立连接但不请求数据时，关闭客户端连接 timeout queue 1m : #服务器的maxconn时，连接在队列中保持挂起状态而设置的超时时间，想客户端返回503错误 timeout connect 10s： #定义haproxy将客户端请求转发至后端服务器所等待的超时时长 timeout client 1m：#客户端非活动状态的超时时长 timeout server 1m：#客户端与服务器端建立连接后，等待服务器端的超时时长 timeout http-keep-alive 10s: #定义保持连接的超时时长 timeout check 10s: #健康状态监测时的超时时间，过短会误判，过长资源消耗 maxconn 3000: #每个server最大的连接数 # 超时参数 timeout http request ：#在客户端建立连接但不请求数据时，关闭客户端连接 timeout queue ：#等待最大时长 timeout connect： #定义haproxy将客户端请求转发至后端服务器所等待的超时时长 timeout client：#客户端非活动状态的超时时长 timeout server：#客户端与服务器端建立连接后，等待服务器端的超时时长， timeout http-keep-alive ：#定义保持连接的超时时长 timeout check：#健康状态监测时的超时时间，过短会误判，过长资源消耗 listen默认配置 # 监听页面配置listen admin_stats bind 0.0.0.0:50000 # 监听IP和端口，为了安全可以设置本机的局域网IP及端口； mode http option httplog # 采用http日志格式 stats refresh 30s # 统计页面自动刷新时间 stats enable # 启用状态统计报告 stats uri /stats # 状态管理页面，通过 ip+port/stats来访问 如10.0.5.92:9999/stats stats realm \"LOGIN\" # 密码框上显示的文本 stats auth admin:psadmin # 统计页面用户名和密码设置 stats hide-version # 隐藏统计页面上HAProxy的版本信息 #errorfile 403 /usr/local/haproxy/examples/errorfiles/ #设置haproxy 错误页面 stats admin_stats if TRUE #如果认证通过就做管理功能，可以管理后端的服务器 前端配置 frontend http_main bind 0.0.0.0:80 # http请求的端口，会被转发到设置的ip及端口 # bind :80 # 监听本机所有ip80端口 # bind *:80 # bind 192.168.12.1:8080,10.1.0.12:8090 # 转发规则 #acl url_yuming path_beg www.yuming.com #use_backend server_yuming if url_yuming # 默认跳转项，当上面都没有匹配上，就转到backend的http_default上； default_backend http_default # 提升失败的时候的用户体验 #errorfile 502 /usr/local/haproxy/examples/errorfiles/502.http #errorfile 503 /usr/local/haproxy/examples/errorfiles/503.http #errorfile 504 /usr/local/haproxy/examples/errorfiles/504.http 后端配置 backend http_default # 额外的一些设置，按需使用 option forwardfor option forwardfor header Client-IP option http-server-close option httpclose # 负载均衡方式 #source 根据请求源IP #static-rr 根据权重 #leastconn 最少连接先处理;在有着较长时间会话的场景中推荐使用此算法，如LDAP、SQL等，其并不太适用于较短会话的应用层协议，如HTTP；此算法是动态的， #uri 根据请求的uri #url_param 根据请求的url参数 #rdp-cookie 据据cookie(name)来锁定并哈希每一次请求 #hdr(name) 根据HTTP请求头来锁定每一次HTTP请求 #roundrobin 轮询方式 balance roundrobin # 负载均衡的方式,轮询方式 # 设置健康检查页面 #option httpchk GET /index.html #传递客户端真实IP option forwardfor header X-Forwarded-For # 需要转发的ip及端口 # inter 2000 健康检查时间间隔2秒 # rise 3 检测多少次才认为是正常的 # fall 3 失败多少次才认为是不可用的 # weight 30 权重 server node1 192.168.1.101:8080 check inter 2000 rise 3 fall 3 weight 30 server node2 192.168.1.101:8081 check inter 2000 rise 3 fall 3 weight 30 常用参数bind 用于监听 bind []: [,...] [param*] # 仅在frontend和listen区域使用bind 0.0.0.0:80 # http请求的端口，会被转发到设置的ip及端口 # bind :80 # 监听本机所有ip80端口 # bind *:80 # bind 192.168.12.1:8080,10.1.0.12:8090 单台haproxy+两台RS服务器配置haproxy 服务器 10.0.5.93RS 服务器1 10.0.5.90RS 服务器2 10.0.5.91 初始化准备如果对防火墙没有太大的要求，可以直接关闭防护墙 所有机器都关闭 # 关闭防火墙systemctl stop firewalldsystemctl status firewalld# 安装haproxyyum install haproxy -y# 配置vi /etc/haproxy/haproxy.cfg haproxy服务器 DS # 基础配置global log 127.0.0.1 local0 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/statsdefaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 balance roundrobin timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 # 开启监听端口listen Status # 名字随便用 bind 10.0.5.93:9999 # 绑定监听端口 mode http stats enable stats uri /stats stats realm \"LOGIN\" stats refresh 6s stats auth upyun:upyun123# 端口转发listen web_server # 名字随便用 mode tcp #采用7层模式 bind *:7777 # 转发端口 请求7777 -> RS:8888 上面 因此这里的*:7777 可做vip -> keepalive balance roundrobin #负载均衡算法，这里是轮换 # 轮询算法 #option httpchk GET /test.test #健康检测 # 健康检测 server web1 10.0.5.91:8888 weight 3 check inter 500 fall 3 server web2 10.0.5.90:8888 weight 2 check inter 500 fall 3 查看haproxy 监听端状态不断请求10.0.5.93:7777 会发现ip会在90 与91 之间不断改变，因为我们采用了轮询的机制，相应的图中web total也会不断增加 while 1; do curl http://10.0.5.93:7777/|grep \"< h2 >.*< /h2 >\" ;sleep 1; done over keepalive+haproxy就是在上面的单台haproxy机器上 添加一台haproxy机器，同时利用keepalived的特性，使用vip在两台haproxy机器上漂移，无论vip漂移到哪个地方，都有对应的haproxy机器去对下面的两台RS机器进行负载均衡 keepalive 提高 haproxy的稳定性haproxy 提高 RS的稳定性 配置DS1 keepalive + haproxy 10.0.5.93DS2 keepalive + haproxy 10.0.5.92 RS1 10.0.5.91RS2 10.0.5.90 VIP 10.0.5.96监控端口 10.0.5.96:9999/statsVIP端口 10.0.5.96:8888 —- > 10.0.5.91:8888 DS1 keepalive配置 # 声明一下身份和vip就醒了! Configuration File for keepalivedglobal_defs { router_id LVS_DEVEL}vrrp_instance VI_1 { state MASTER interface eno1 virtual_router_id 51 priority 1000 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }} DS2 keepalived配置 ! Configuration File for keepalivedglobal_defs { router_id LVS_DEVEL}vrrp_instance VI_1 { state BACKUP interface eno1 virtual_router_id 51 priority 10 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }} 这时候你可以先测试一下keepalived是否成功，两边开起来，然后关掉DS-master机器，如果VIP漂移到DS-BACKUP上面则表示成功 DS1 haproxy配置 与 DS2 haproxy相同 global log 127.0.0.1 local0 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/statsdefaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 balance roundrobin timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000# 监听端口listen Status bind 10.0.5.96:9999 mode http stats enable stats uri /stats stats realm \"LOGIN\" stats refresh 6s stats auth upyun:upyun123# 这个80端口有什么用listen web_server mode tcp #采用7层模式 bind *:7777 balance roundrobin #负载均衡算法，这里是轮换 #option httpchk GET /test.test #健康检测 server web1 10.0.5.91:8888 weight 3 check inter 500 fall 3 server web2 10.0.5.90:8888 weight 2 check inter 500 fall 3 RS机器将VIP写入回源地址 ifconfig enp4s0:0 10.0.5.96 broadcast 10.0.5.96 netmask 255.255.240.0 up 另外，当我切断master-keepalived的是否，会有一定时间的延迟","link":"/posts/14c89e63/"},{"title":"keepalive+lvs 四层负载均衡","text":"关键词LB (Load Balancer 负载均衡)HA (High Available 高可用)Failover (失败切换)Cluster (集群)LVS (Linux Virtual Server Linux 虚拟服务器)DS (Director Server)，指的是前端负载均衡器节点RS (Real Server)，后端真实的工作服务器VIP (Virtual IP)，虚拟的 IP 地址，向外部直接面向用户请求，作为用户请求的目标的 IP 地址DIP (Director IP)，主要用于和内部主机通讯的 IP 地址RIP (Real Server IP)，后端服务器的 IP 地址CIP (Client IP)，访问客户端的 IP 地址 仅使用lvs单节点lvs 、 vip 两台RS服务器 vip: 10.0.5.97/20lvs-director: 10.0.5.92RS1: 10.0.5.90RS2: 10.0.5.91 在lvs上进行操作 # 安装lvsyum install ipvsadm -y # 安装net-toolsyum install net-tools# 在网卡上绑定vipifconfig eno1:0 10.0.5.97 broadcast 10.0.5.97 netmask 255.255.240.0 up# 添加路由route add -host 10.0.5.97 dev eno1# 启用系统的包转发功能echo \"1\" > /proc/sys/net/ipv4/ip_forward# 清空系统之前所有的ipvsadm规则ipvsadm --clearipvsadm -C# 增加虚拟ip (-s rr 表述轮询)ipvsadm -A -t 10.0.5.97:8888 -s rr# ipvsadm -D -t 10.0.5.97:8888 # 删除规则# 添加服务对象 -g表示工作模式为直接路由 端口必须一致ipvsadm -a -t 10.0.5.97:8888 -r 10.0.5.91:8888 -gipvsadm -a -t 10.0.5.97:8888 -r 10.0.5.92:8888 -g 在RS机上进行操作 # //RS1# 绑定VIP ifconfig eno1:0 10.0.5.91 broadcast 10.0.5.91 netmask 255.255.240.0 up# 添加路由route add -host 10.0.5.91 dev eno1:0#//RS2 同 lvs搭建成功后查看搭建状态 [root@lvs-web1 ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -> RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 10.0.5.97:8888 rr -> 10.0.5.90:8888 Route 1 0 0 -> 10.0.5.91:8888 Route 1 0 0 当你访问VIP地址的时候，VIP会指向其所服务的两个真实IP地址 在轮询模式下，一定时间后指向另一个ip 单节点lvs可能会出现错误，需要使用Keepalive+lvs 仅使用keepalive不使用RS服务器，仅使用两台DS服务器测试vip在两台DS之间保持活性的过程目的—-> 保证vip的活性 vip 10.0.5.96DS1: 10.0.5.93DS2: 10.0.5.90 在DS-Master机器上操作 # 安装keepalivedyum install keepalived# 修改配置文件! Configuration File for keepalivedglobal_defs { //全局配置 notification_email { //通知邮件， 当keepalived中master和backup身份改变的是否会发送邮件 acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL_master // 集群名字 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_instance VI_1 { //vrrp实例 + 名字(同集群名字需要相同) state MASTER // 当前机器身份 只能有一个master interface enp10s0 //当前网络接口 virtual_router_id 51 // 虚拟路由序号 主从需要相同 priority 100 // 优先级别 主> 从 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { //虚拟ip 10.0.5.96/20 }} 在DS-Backup机器上的操作 # 安装keepalivedyum install keepalived# 修改配置文件! Configuration File for keepalivedglobal_defs { notification_email { acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id LVS_DEVEL vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0}vrrp_instance VI_1 { state BACKUP // DS-backup机器 interface eno1 virtual_router_id 51 priority 10 //优先级别 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }} 主从机器启动keepalived后 可以发现现在的vip是在DS-master上的，为了验证master主机出现错误的时候，vip会漂移到DS-backup的现象，我们可以在master关闭keepalived以上，当master出现错误的时候，backup机器上出现vip，从而保证vip的活性，以此来保证lvs的稳定性 另外，当master机器再次重启的时候，vip又会飘回到master身上 keepalive+lvs 主从方式高可用主从模式需要准备四台服务器，均开启httpd服务 配置 vip 10.0.5.96DS1: 10.0.5.90 lvs-masterDS2: 10.0.5.93 lvs-slaveRS1: 10.0.5.91 lvs-web1RS2: 10.0.5.92 lvs-web2 # 测试ping lvs-master 首先保证 90 93两台机器的keepalive搭建成功，配置参考上面的keepalived Keepalived主备配置文件区别： 01. router_id 信息不一致 02. state 状态描述信息不一致 03. priority 主备竞选优先级数值不一致 master机器上配置lvs vi /etc/keepalived/keepalived.confvirtual_server 10.0.5.96 8888 { //vip delay_loop 3 lb_algo rr // 负载均衡模式 rr--轮询 lb_kind DR // 负载均衡连接形式 直连路由 !persistence_timeout 50 protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 //连接端口 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }} backup机器上配置lvs vi /etc/keepalived/keepalived.confvirtual_server 10.0.5.96 8888 { delay_loop 3 lb_algo rr lb_kind DR !persistence_timeout 50 protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }} RS机器上配置只要是作为lvs服务的对象，这些步骤都要做，包括后面如果我们把ds-master机器在作为keepalived调度机的同时，也提供web服务的时候，就需要做这些步骤 # 绑定VIPifconfig lo:0 10.0.5.96 netmask 255.255.240.0 broadcast 10.0.5.96 up # 添加路由route add -host 10.0.5.96 dev lo:0# 抑制arpecho 2 > /proc/sys/net/ipv4/conf/all/arp_announce echo 2 > /proc/sys/net/ipv4/conf/lo/arp_announceecho 1 > /proc/sys/net/ipv4/conf/all/arp_ignoreecho 1 >/proc/sys/net/ipv4/conf/lo/arp_ignore ## 永久抑制arpvi /etc/sysctl.confnet.ipv4.conf.lo.arp_ignore = 1net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_ignore = 1net.ipv4.conf.all.arp_announce = 2 同时启动keepalived，查看lvs连接状态 systemctl start keepalivedipvsadm -ln[root@localhost ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags -> RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 10.0.5.96:8888 rr -> 10.0.5.91:8888 Route 1 0 0 -> 10.0.5.92:8888 Route 1 0 0 while 1; do curl http://10.0.5.96:8888/| grep '< h2 >.* ' ;sleep 1; done 可以看到 双主方式互为主从：主从都在工作；其中一个宕机了，VIP漂移到另一个上，提供服务 配置 vip1: 10.0.5.96vip2: 10.0.5.97RS1: 10.0.5.91RS2: 10.0.5.92DS1: 10.0.5.90DS2: 10.0.5.93 DS1 配置: ! Configuration File for keepalivedglobal_defs { router_id LVS_DEVEL_master}vrrp_instance VI_1 { state MASTER interface enp10s0 virtual_router_id 51 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }}virtual_server 10.0.5.96 8888 { delay_loop 3 lb_algo rr lb_kind DR protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }}vrrp_instance VI_2 { state BACKUP interface enp10s0 virtual_router_id 52 priority 11 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.97/20 }}virtual_server 10.0.5.97 8888 { delay_loop 3 lb_algo rr lb_kind DR protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }} DS2配置 ! Configuration File for keepalivedglobal_defs { router_id LVS_DEVEL}vrrp_instance VI_1 { state BACKUP interface eno1 virtual_router_id 51 priority 10 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.96/20 }}virtual_server 10.0.5.96 8888 { delay_loop 3 lb_algo rr lb_kind DR protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }}vrrp_instance VI_2 { state MASTER interface eno1 virtual_router_id 52 priority 101 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 10.0.5.97/20 }}virtual_server 10.0.5.97 8888 { delay_loop 3 lb_algo rr lb_kind DR protocol TCP real_server 10.0.5.91 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } } real_server 10.0.5.92 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 3 nb_get_retry 3 delay_before_retry 3 } }}``` 两个配置都差不多，无非就是两台机器都作为对方机器的Master和Backup机器，同时拥有两个vip，注意权重的大小RS上的配置```bash#配置VIP到本地回环网卡lo上，并只广播自己ifconfig lo:0 172.17.100.100 broadcast 172.17.100.100 netmask 255.255.255.255 upifconfig lo:1 172.17.100.101 broadcast 172.17.100.101 netmask 255.255.255.255 up #配置本地回环网卡路由route add -host 172.17.100.100 lo:0route add -host 172.17.100.101 lo:1# 关闭arpvim /etc/sysctl.confnet.ipv4.conf.lo.arp_ignore = 1net.ipv4.conf.lo.arp_announce = 2net.ipv4.conf.all.arp_ignore = 1net.ipv4.conf.all.arp_announce = 2 查看结果 关闭其中一个DS机器时，另外一台DS机器上出现三个IP ，自身IP+2个VIP https://www.cnblogs.com/f-ck-need-u/p/8492298.html#2-keepalived-lvs- sorry_server 和local RS如果RS都在同一刻down掉了的话，外界就无法访问网站了。因为vip已经没有了RS的去处，这里提供了两种解决方法 使用keepalived来配置一个服务页面。例如告诉外界客户端网站正在维护状态.使用sorry_server 来指向 某一个ip+端口, 因为是在所有RS都宕机的情况下sorry server提供的临时服务才生效，因此通常将sorry server配置在virtual_server中而非real_server中。 需要在master和backup节点上都配置sorry_server virtual_server 192.168.100.10 8888 { delay_loop 6 lb_algo wrr lb_kind DR protocol TCP sorry_server 127.0.0.1 8888# 也可以指向本地，需要开启httpd服务 开启keepalived 然后将两台RS的机器上的httpd服务全部停掉，会发现vip会漂移到两台DS中的其中一台上 使用local RS对于集群系统不大的情况下，DS 一般会比较空闲，这样就比较浪费资源。这时通常会将LVS Director自身也作为一个RS，一边提供web服务，一边提供调度功能，不过应该将它的调度权重设置低一点，以免影响负载均衡的性能。这称为local RS，local RS的RIP可以写Director上的任意地址(127.0.0.1都可以)。例如：virtual_server 192.168.100.10 8888 { .... real_server 127.0.0.1 8888 { weight 1 TCP_CHECK { connect_port 8888 connect_timeout 1 nb_get_retry 2 delay_before_retry 1 }}} 两个不应该同时配置，因为如果local RS 坏了，sorry server肯定无法调度 脑裂解决方法在高可用（HA）系统中，当联系2个节点的“心跳线”断开时，本来为一整体、动作协调的HA系统，就分裂成为2个独立的个体。由于相互失去了联系，都以为是对方出了故障。两个节点上的HA软件像“裂脑人”一样，争抢“共享资源”、争起“应用服务”，就会发生严重后果——或者共享资源被瓜分、2边“服务”都起不来了；或者2边“服务”都起来了，但同时读写“共享存储”，导致数据损坏（常见如数据库轮询着的联机日志出错）。 添加冗余的心跳线，例如：双线条线（心跳线也HA），尽量减少“裂脑”发生几率； 设置仲裁机制。例如设置参考IP（如网关IP），当心跳线完全断开时，2个节点都各自ping一下参考IP，不通则表明断点就出在本端。不仅“心跳”、还兼对外“服务”的本端网络链路断了，即使启动（或继续）应用服务也没有用了，那就主动放弃竞争，让能够ping通参考IP的一端去起服务。更保险一些，ping不通参考IP的一方干脆就自我重启，以彻底释放有可能还占用着的那些共享资源。 脑裂原因： Keepalived配置里同一 VRRP实例如果 virtual_router_id两端参数配置不一致也会导致裂脑问题发生。 RS上开启了 iptables防火墙阻挡了心跳消息传输。 高可用服务器上心跳网卡地址等信息配置不正确，导致发送心跳失败。 其他服务配置不当等原因，如心跳方式不同，心跳广插冲突、软件Bug等 解决: 做好对裂脑的监控报警（如邮件及手机短信等或值班）.在问题发生时人为第一时间介入仲裁，降低损失。例如，百度的监控报警短倍就有上行和下行的区别。报警消息发送到管理员手机上，管理员可以通过手机回复对应数字或简单的字符串操作返回给服务器.让服务器根据指令自动处理相应故障，这样解决故障的时间更短. 强行关闭一个节点保证，避免争夺 检测当前服务器上是否存在vip 要赋予执行权限 while truedoif [ `ip a show eth0 |grep 10.0.0.3|wc -l` -ne 0 ]then echo \"keepalived is error!\"else echo \"keepalived is OK !\"fidone 自定义健康状态检测keepalived可以通过设置vrrp_script自定义 # 自定义VRRP实例健康检查脚本 keepalived只能做到对自身问题和网络故障的监控，Script可以增加其他的监控来判定是否需要切换主备vrrp_script chk_sshd { script \"killall -0 sshd\" # 示例为检查sshd服务是否运行中 interval 2 # 检查间隔时间 weight -4 # 检查失败降低的权重} keepalived自动配置# /keepalived.conf! Configuration File for keepalivedglobal_defs {router_id SLB-SAD}vrrp_script chk_upyun { ¦ ¦ ¦ script \"/etc/keepalived/bin/check_vip.sh\" ¦ ¦ ¦ interval 3}vrrp_instance upyun_lb { ¦ state MASTER ¦ interface eth3 ¦ virtual_router_id 20 ¦ priority 100 ¦ advert_int 1 ¦ notify_master /etc/keepalived/bin/change_master.sh ¦ notify_backup /etc/keepalived/bin/change_backup.sh ¦ authentication { ¦ ¦ ¦ auth_type PASS ¦ ¦ ¦ auth_pass upyun.com ¦ } ¦ track_script { ¦ ¦ ¦ chk_upyun ¦ } ¦ virtual_ipaddress { ¦ ¦ ¦ 192.168.147.20 label eth3:9 ¦ }} include /etc/keepalived/virserver.conf# virserver.confvirtual_server 192.168.147.20 8600 { ¦ delay_loop 2 ¦ lb_algo wrr ¦ lb_kind DR ¦ protocol UDP ¦ #persistence_timeout 5 ¦ real_server 192.168.13.250 8600 { ¦ ¦ ¦ weight 1 ¦ ¦ ¦ connect_port 8600 ¦ ¦ ¦ connect_timeout 5 ¦ ¦ ¦ nb_get_retry 1 ¦ ¦ ¦ delay_before_retry 1 ¦ }} 状态检测脚本 # check_backup # 修改状态从master-> backup 权重 100 -> 80 注销 notify_backup 注销include echo \"--- I am BACKUP #`date`\" >> /tmp/keepalived.logsed -r -i '/state/s^MASTER^BACKUP^g;/priority/s^100^80^g;/notify_backup/s@^@#@g;/include/s@^@#@g;' /etc/keepalived/keepalived.confsystemctl restart keepalived# check_masterecho \"+++ I am MASTER #`date`\" >> /tmp/keepalived.logsed -r -i '/state/s^BACKUP^MASTER^g;/priority/s^80^100^g;/notify_backup/s@#@@g;' /etc/keepalived/keepalived.confipvsadm --set 100 15 15systemctl restart keepalived 报错解决方案keepalived报错信息在/usr/log/messages下面 主服务器停止后，备用服务没有启用监控主服务器上的日志Jun 28 09:18:32 rust Keepalived_vrrp: receive an invalid ip number countassociated with VRID!Jun 28 09:18:32 rust Keepalived_vrrp: bogus VRRP packet received on eth0 !!!Jun 28 09:18:32 rust Keepalived_vrrp: VRRP_Instance(VI_1) Dropping receivedVRRP packet.HA 解决方案：改变配置文件/etc/keepalived/keepalived.conf 中virtual_route_id的值virtual_router_id 60 主从方都要改，默认为51 lvs默认超时时间过程，导致框架已经搭建成功，但是效果看不出来900 120 300这三个数值分别是TCP TCPFINUDP的时间.也就是说一条tcp的连接经过lvs后,lvs会把这台记录保存15分钟，就是因为这个时间过长，所以大部分人都会发现做好LVS DR之后轮询现象并没有发生，而且我也看到大部分的教程是没有说明这一点的，巨坑！！！！！！因为是实验性质，所以将此数值调整为非常小，使用以下命令调整在两台DS服务器上修改[root@DR1 keepalived]# ipvsadm -L --timeoutTimeout (tcp tcpfin udp): 900 120 300 [root@DR1 ~]# ipvsadm --set 1 2 1 概念篇Keepalived软件起初是专为LVS负载均衡软件设计的，用来管理并监控LVS集群系统中各个服务节点的状态，后来又加入了可以实现高可用（HA）的VRRP功能。于是keepalived除了能够管理LVS软件外，还可以作为其他服务（例如：Nginx、Haproxy、MySQL等）的高可用解决方案软件 Keepalived软件主要是通过VRRP协议实现高可用功能的。 官网https://www.keepalived.org/ 主要功能–> 管理LVS负载均衡–> 实现LVS集群节点的健康检查–> 作为系统网络服务的高可用性（failover） 运行流程在 Keepalived服务正常工作时，主 Master节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备Backup节点自己还活看，当主 Master节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master节点的心跳了，于是调用自身的接管程序，接管主Master节点的 IP资源及服务。而当主 Master节点恢复时，备Backup节点又会释放主节点故障时自身接管的IP资源及服务，恢复到原来的备用角色。 配置文件说明全局配置，一般保留路由标识信息就可以了 global_defs { #全局配置 notification_email { #定义报警邮件地址 acassen@firewall.loc failover@firewall.loc # 收件人 sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc #定义发送邮件的地址 smtp_server 192.168.200.1 #邮箱服务器 smtp_connect_timeout 30 #定义超时时间 router_id LVS_DEVEL #定义路由标识信息，相同局域网唯一 } 虚拟ip配置 brrp vrrp_instance VI_1 { #定义实例 state MASTER #状态参数 master/backup 只是说明 interface eth0 #虚IP地址放置的网卡位置 virtual_router_id 51 #vrrp_instance的唯一标识 priority 100 # keepalived权重,数值越大权重越大,MASTER应大于BACKUP advert_int 1 #发送心跳间隔,如果backup1秒收不到心跳就接管,单位是秒 authentication { # ↓ auth_type PASS #↓ auth_pass 1111 #认证 } #↑ virtual_ipaddress { #↓ 192.168.200.16 #vip 192.168.200.17 192.168.200.18 } nopreempt # 设置不抢占功能 #nopreempt 表示主节点故障恢复后不再切回到主节点，让服务一直在备用节点下工作，直到备用节点出现故障才会进行切换。 preemtp_delay 300 # 设置抢占延时时间，单位是秒。} lvs配置 #相当于 ipvsadm -A -t 192.168.0.89:80 -s wrr virtual_server 192.168.0.89 80 { delay_loop 6 #服务健康检查周期,单位是秒 lb_algo wrr #调度算法 lb_kind DR #模式 nat_mask 255.255.255.0 persistence_timeout 50 #回话保持时间,单位是秒 protocol TCP #TCP协议转发 sorry_server # 当所有 real server 失效后，指定的 Web 服务器的虚拟主机地址。#添加后端realserver#相当于 ipvsadm -a -t 192.168.0.89:80 -r 192.168.0.93:80 -w 1 real_server 192.168.0.93 80 { #realserver的真实IP weight 1 #权重 #健康检查 TCP_CHECK { connect_timeout 8 #超时时间 nb_get_retry 3 #重试次数 delay_before_retry 3 #重试间隔 connect_port 80 #检查realserver的80端口,如果80端口没监听,就会从集群中剔除 } } real_server 192.168.0.94 80 { weight 1 TCP_CHECK { connect_timeout 8 nb_get_retry 3 delay_before_retry 3 connect_port 80 } }} ipvsadm 概念篇添加虚拟服务器 语法:ipvsadm -A [-t|u|f] [vip_addr:port] [-s:指定算法] -A:添加 -t:TCP协议 -u:UDP协议 -f:防火墙标记 -D:删除虚拟服务器记录 -E:修改虚拟服务器记录 -C:清空所有记录 -L:查看添加后端RealServer 语法:ipvsadm -a [-t|u|f] [vip_addr:port] [-r ip_addr] [-g|i|m] [-w 指定权重] -a:添加 -t:TCP协议 -u:UDP协议 -f:防火墙标记 -r:指定后端realserver的IP -g:DR模式 -i:TUN模式 -m:NAT模式 -w:指定权重 -d:删除realserver记录 -e:修改realserver记录 -l:查看通用: ipvsadm -ln:查看规则 service ipvsadm save:保存规则 lvs的几种调度算法 RR：roundrobin轮询,后端RS均摊所有的请求 WRR weighted RR加权轮询，根据权值来分配请求的数量 SH：Source Hashin[root@lvs-web1 ~]# ipvsadm -lnIP Virtual Server version 1.2.1 (size=4096)Prot LocalAddress:Port Scheduler Flags-> RemoteAddress:Port Forward Weight ActiveConn InActConnTCP 10.0.5.97:8888 rr-> 10.0.5.90:8888 Route 1 0 0-> 10.0.5.91:8888 Route 1 0 0g DH：Destination Hashing LC：least connections WLC：Weighted LC 具体的调度算法 其他概念什么是VRRPVRRP是Virtual Router RedundancyProtocol(虚拟路由器冗余协议）的缩写，VRRP出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行。VRRP通过一种竞选机制来将路由的任务交给某台VRRP路由器的。https://www.cnblogs.com/f-ck-need-u/p/8483807.html keepalived官网http://www.keepalived.org keepalived高可用架构图 网址高并发场景 LVS 安装及高可用实现https://www.cnblogs.com/clsn/p/7920637.html#auto_id_30VRRP原理和分析https://www.jianshu.com/p/4b46586e79aaHaproxy+Keepalived高可用环境部署梳理（主主和主从模式）https://blog.51cto.com/dengaosky/2129856 https://www.cnblogs.com/f-ck-need-u/p/8492298.html#3-keepalived-lvs-Keepalived+LVS的高可用集群网站架构https://www.cnblogs.com/along21/p/7841132.html#auto_id_6","link":"/posts/a33a1a7d/"},{"title":"ipv6部署","text":"ipv6部署部署案例由于ipv4快要用完了，很多交换机需要更换ipv6的地址，这里做一些配置的过程 西安光通高防 ipv6配置 要求西安光通高防业务ipv6 240e:bf:b800:1900::/64互联 对端:240e:bf:b800:19ff::100/127 公司:240e:bf:b800:19ff::101/127 # 先配置互联地址，看和机房是否互通，默认vlan1为业务vlan ,其他vlan为互联vlan[CTN-SN-XIY-S01]dis int briefBrief information on interfaces in route mode:Link: ADM - administratively down; Stby - standbyProtocol: (s) - spoofingInterface Link Protocol Primary IP DescriptionInLoop0 UP UP(s) --NULL0 UP UP(s) --Vlan1 UP UP 1.81.5.161Vlan10 DOWN DOWN --Vlan101 UP UP 192.168.100.2# 配置互联地址Interface vlan-interface 101ipv6 address 240e:bf:b800:19ff::101/127 # 测试互联是否互通ping ipv6 240e:bf:b800:19ff::100# 配置业务地址和静态路由interface vlan-interface 1ipv6 address 240e:bf:b800:1900::1/64undo ipv6 nd ra halt# 配置静态路由ipv6 route-static :: 0 240e:bf:b800:19ff::100 四川成华移动机房 要求四川成华移动机房（自有节点）IPV6资源：2409:8C62:410:6::/64，互联： 对端2409:8062:3000:0201:: C/127 公司2409:8062:3000:0201:: D/127 对端2409:8062:3000:0202:: 6/127 公司2409:8062:3000:0202:: 7/127 dis int briefBrief information on interfaces in route mode:Link: ADM - administratively down; Stby - standbyProtocol: (s) - spoofingInterface Link Protocol Primary IP DescriptionVlan1 UP UP 117.172.22.129Vlan200 UP UP 117.172.4.50Vlan201 UP UP 117.172.4.54# 配置互联地址interface Vlan-interface200 ip address 117.172.4.50 255.255.255.252 ipv6 address 2409:8062:3000:201::D/127interface Vlan-interface201 ip address 117.172.4.54 255.255.255.252 ipv6 address 2409:8062:3000:202::7/127# 测试互联ping ipv6 2409:8062:3000:201::Cping ipv6 2409:8062:3000:202::6# 配置业务vlaninterface Vlan-interface1 ip address 117.172.22.129 255.255.255.224 ipv6 address 2409:8C62:410:6::1/64 undo ipv6 nd ra halt# 配置静态[CMN-SC-CTU4-S01]dis current-configuration | include ipv6.ro ipv6 route-static :: 0 2409:8062:3000:201::C ipv6 route-static :: 0 2409:8062:3000:202::6# 测试路由tracert ipv6 2409:8062:3000:201::Ctraceroute to 2409:8062:3000:201::C (2409:8062:3000:201::C), 30 hops at most, 60 byte packets, press CTRL_C to break 1 2409:8062:3000:201::C 2.934 ms 2.345 ms 2.336 mstracert ipv6 2409:8062:3000:202::6traceroute to 2409:8062:3000:202::6 (2409:8062:3000:202::6), 30 hops at most, 60 byte packets, press CTRL_C to break 1 2409:8062:3000::202 3.957 ms 3.125 ms 3.879 ms# 测试外网能否访问 check-listipv6配置完成以后需要确认内容 测试互联是否正确，ping ipv6 对端互联ip 业务地址是否配了 undo ipv6 nd ra halt 静态路由配置以后是否正确，本地是否通，外网是否通这里以西安高防为例子，如果是内网机器，比如互联ip是fe这种，那就是内网机器，找cdn那边要机器测mtr ipv6 240e:bf:b800:1900::1如果是外网机器，找其他的交换机测tracert ipv6 240e:bf:b800:1900::1 另外还要注意的是如果掩码是/72的只能自己分配ip不能dhcp","link":"/posts/82cf9f4/"},{"title":"二层交换机","text":"二层交换机知识 图片笔记 somethings二层交换机，只能在相同vlan间通信，因此在业务上配置二层交换机的同时，需要知道对端交换机的vlan是如何划分的对于多vlan之间的交互，需要在端口上设置trunk的模式，另外服务器在端口上只允许access的模式，也就是说switch — 上联switch(trunk)switch — 下联server(access) 如果交换机对端设置了dynamic,则本端也需要设置dynamic模式 dynamic与static两种聚合模式的区别 首先需要明确链路聚合的概念：链路聚合是将两个或更多数据信道结合成一个单个的信道，该信道以一个单个的更高带宽的逻辑链路出现。链路聚合一般用来连接一个或多个带宽需求大的设备，例如连接骨干网络的服务器或服务器群。 区别如下： 静态聚合模式：配置聚合的端口数量是固定的，聚合后的带宽也是固定的； 动态聚合模式：实际聚合的端口数量是根据流量策略动态调整的，聚合带宽也会随之变化。例如在低负载时有2个端口参与聚合，高负载时会有4个端口参与聚合，从而更好的满足应用的要求。 静态聚合，就是人工设定把多条信道分开或者合并动态聚合就是系统自动分配信道 h3c文档 look..look 直接透传和间接透传 直接透传就是某个数据包在两个直连链路的两个端口间传输，数据包的VLAN标记没有发生任何变化。如两个直连的Trunk口，两个端口的PVID 都是vlan 1，VLAN 2的数据包从Trunk口A发送出来，被另一端的Trunk口B接收，收发之间，VLAN 2的数据包无任何改变。 间接透传就是数据包在两个直连端口链路间传输时，在两个端口收发时，数据包的VLAN标签会发生改变，但是最终数据包的VLAN还是没变。如两个直连的Trunk口，两个端口的PVID 都是vlan 1，VLAN 1的数据包从Trunk口A发送出来，此时被剥除VLAN 1的信息，被另一端的Trunk口B接收，此时又被添加VLAN 1的信息。收发之间，VLAN 2的数据包先是被剥离VLAN信息，然后在接收端又被打上原先的VLAN1信息。不管是哪种方式透传，透传的结果都是数据包的最终VLAN信息在经历端口收发后，都不改变。 vlan与交换机端口模式Access，Hybrid，TrunkVLAN（Virtual Local Area Network）的中文名为”虚拟局域网”。VLAN是一种将局域网设备从逻辑上划分成一个个网段，从而实现虚拟工作组的新兴数据交换技术。这一新兴技术主要应用于交换机和路由器中，但主流应用还是在交换机之中。但又不是所有交换机都具有此功能，只有VLAN协议的第二层以上交换机才具有此功能。802.1Q的标准的出现打破了虚拟网依赖于单一厂商的僵局，从一个侧面推动了VLAN的迅速发展。交换机端口有三种工作模式，分别是Access，Hybrid，Trunk。 Access类型的端口只能属于1个VLAN，一般用于连接计算机的端口； Trunk类型的端口可以允许多个VLAN通过，可以接收和发送多个VLAN的报文，一般用于交换机之间连接的端口； Hybrid类型的端口可以允许多个VLAN通过，可以接收和发送多个VLAN的报文，可以用于交换机之间连接，也可以用于连接用户的计算机。Hybrid端口和Trunk端口在接收数据时，处理方法是一样的，唯一不同之处在于发送数据时：Hybrid端口可以允许多个VLAN的报文发送时不打标签，而Trunk端口只允许缺省VLAN的报文发送时不打标签。 untag就是普通的ethernet报文，普通PC机的网卡是可以识别这样的报文进行通讯；tag报文结构的变化是在源mac地址和目的mac地址之后，加上了4bytes的vlan信息，也就是vlan tag头；一般来说这样的报文普通PC机的网卡是不能识别的因此对于Pc机来说，只允许使用在传输数据时，不带标签的模式access Access、Trunk、Hybrid三种端口模式接收发数据状态在网络的分层结构和宽带的合理分配方面，TRUNK被解释为“端口汇聚”，是带宽扩展和链路备份的一个重要途径。TRUNK把多个物理端口捆绑在一起当作一个逻辑端口使用，可以把多组端口的宽带叠加起来使用。TRUNK技术可以实现TRUNK内部多条链路互为备份的功能，即当一条链路出现故障时，不影响其他链路的工作，同时多链路之间还能实现流量均衡，就像我们熟悉的打印机池和MODEM池一样。 Acess端口收报文: 收到一个报文,判断是否有VLAN信息：如果没有则打上端口的PVID，并进行交换转发,如果有则直接丢弃（缺省） trunk端口收报文： 收到一个报文，判断是否有VLAN信息：如果没有则打上端口的PVID，并进行交换转发，如果有判断该trunk端口是否允许该 VLAN的数据进入：如果允许则报文携带原有VLAN标记进行转发，否则丢弃该报文。 hybrid端口收报文： 收到一个报文,判断是否有VLAN信息：如果没有则打上端口的PVID，并进行交换转发，如果有则判断该hybrid端口是否允许该VLAN的数据进入：如果可以则转发，否则丢弃 Acess端口发报文：将报文的VLAN信息剥离，直接发送出去 trunk端口发报文：比较端口的PVID和将要发送报文的VLAN信息，如果两者相等则剥离VLAN信息，再发送，否则报文将携带原有的VLAN标记进行转发。 hybrid端口发报文：1、判断该VLAN在本端口的属性 2、如果是untag则剥离VLAN信息，再发送，如果是tag则比较端口的PVID和将要发送报文的VLAN信息，如果两者相等则剥离VLAN信息，再发送，否则报文将携带原有的VLAN标记进行转发 实践经过实验，我们可以知道一些配置在某些情况下是相同的比如上联的信息是这样的 interface Ten-GigabitEthernet1/0/9 port link-mode bridge description CCM@UPYUN-KC-ALS-06 port link-type trunk undo port trunk permit vlan 1 port trunk permit vlan 1000 port trunk pvid vlan 1000 从上面的内容可以知道，只允许标签为1000的数据进入 可以这样配置 vlan 1000ip address 10.0.5.124 20ip router-static 0.0.0.0 0 10.0.0.130 也可以这样配置 int bridge 1000int g1/0/5port link-aggretion group 1000int g 1/0/6port link-aggretion group 1000int bridge 1000[10.0.5.125-Bridge-Aggregation1000]dis this#interface Bridge-Aggregation1000 port link-type trunk undo port trunk permit vlan 1 port trunk permit vlan 1000 port trunk pvid vlan 1000#return trunk在对端相同vlan-id的时候同样会剥离vlan的id信息 级连、堆叠、集群级连https://baike.baidu.com/item/%E7%BA%A7%E8%BF%9E 什么是pvidPVID英文为Port-base VLAN ID，是表示网络通信中基于端口的VLAN ID，一个端口可以属于多个VLAN，但是只能有一个PVID，收到一个不带tag头的数据包时，会打上PVID所表示的VLAN号，视同该VLAN的数据包处理一个物理端口只能拥有一个PVID，当一个物理端口拥有了一个PVID的时候，必定会拥有和PVID相等的VID，而且在这个VID上，这个物理端口必定是Untagged Port。PVID的作用只是在交换机从外部接受到可以接受Untagged 数据帧的时候给数据帧添加TAG标记用的，在交换机内部转发数据的时候PVID不起任何作用https://baike.baidu.com/item/PVID 网址交换机三种端口模式Access、Hybrid和Trunk的理解http://www.word666.com/zhishi/62797.html","link":"/posts/9bb9b12b/"},{"title":"交换机状态检测","text":"交换机状态检测记录交换机上的一些状态检测指令，以及流程 查看端口上的流量dis int Bri 100dis int T 1/0/1display interface XGigabitEthernet 2/0/0 XGigabitEthernet2/0/0 current state : UPLine protocol current state : UPDescription:connet to f5-2Switch Port, PVID : 1, TPID : 8100(Hex), The Maximum Frame Length is 9216IP Sending Frames' Format is PKTFMT_ETHNT_2, Hardware address is f84a-bf70-3d00Last physical up time : 2014-03-09 18:12Last physical down time : 2014-03-09 18:12Current system time: 2014-03-09 18:12Port Mode: COMMON FIBERSpeed : 10000, Loopback: NONEDuplex: FULL, Negotiation: DISABLEMdi : NORMALLast 300 seconds input rate 1602936 bits/sec, 1784 packets/secLast 300 seconds output rate 1393224 bits/sec, 1732 packets/secInput peak rate 142352400 bits/sec, Record time: 2014-03-09 18:12Output peak rate 136841800 bits/sec, Record time: 2014-03-09 18:12Input: 26101952708 packets, 3055712267640 bytes 其中INPUT和OUTPUT部分就是交换机的进出口流量 查看交换机上下联状态dis link s","link":"/posts/845aaf29/"},{"title":"网络部署需求分析","text":"learn switch 网络部署需求分析后面需要根据tower给出的内容对网络环境，机器上架规划内容由于tower中给出的大部分都是纸上信息，这里做几个例子进行一下总结 凡是没有提到2层或者3层需求的，都按照3层需求来处理 *****基础配置基础配置 二三层通用 # 用户配置local-user admin class manage service-type ssh authorization-attribute user-role level-3 authorization-attribute user-role network-admin authorization-attribute user-role network-operator#local-user root class manage service-type ssh authorization-attribute user-role level-3 authorization-attribute user-role network-admin authorization-attribute user-role network-operatoruser-interface vty 0 4authentication-mode scheme user-role network-adminprotocol inbound allquit# 不显示版本信息undo copyright-info enable# 公钥导入public-key peer pub public-key-code begin 30820122300D06092A864886F70D01010105000382010F003082010A0282010100D37D67EC 5A9466CD38895097E74386EBBEFA9EC59236DF5E96D7514B2903C21F09C6D47D74792B5E3D C1F99DB4D43614AE3AD61DEFFAF35CED9B94DBD85DE174598C491FA043F8C700DA686BFFCA 227E4E7417A251CD7590673B4C1A227962F65CBA6017329479484EF8FE48A8E2FED636C846 5765801A0D62C821906FF8E7188DA69D716FD392E8C0D4D0618E9020670FFA24CF083E2EF7 690EABCA43AA4341D798A72B6FFB5A0A1BEF0F4B14B6B66E5F7126582BD11A11F4220EA3FF C1A5DF36E86E76A8EF6A97949158F094CBAD09725069A090CBA36D95CB6A9531A5AB8B3ED5 8D6C63C8138320F0F1ECD7B25203A1B79FC82635B0F53475BC428B3B741F0203010001 public-key-code end peer-public-key endpublic-key peer upyun public-key-code begin 30820122300D06092A864886F70D01010105000382010F003082010A0282010100BEF4DB4E 5224F5FFE95AF67CC1753592979F6C1379E0A1FB8519C0E6E626B50F221957806B64384173 F2B370254381D583D3EC70D4211CC599CF6C1615754E985895D1E78E1E62788A9BC2E4D2EB 55A18FD20D2B692813114C650FE4FC883DB5467039264C2478332C2C967F3DAE83AFBDFAB3 D794F38DCB2E112184127A151741947DFBB00E8E66B9037131C54A27DE703B2E80A3D8D3C6 79CFC9E851D9C76610228790D7E2253D7E7735481D2EA61AA71D6DFD2EAC037203CE08943E 43DF88AC1ECCB77433358B5ABDF080616D6B6C40AEBEEEDD64D8B8718F091CAA0EA8D5A6A0 2B6106D931E45717C94DBC0F3FF6608CB609C4DA4860C8C48EE67CB304470203010001 public-key-code end peer-public-key end# 用户公钥认证ssh user admin service-type stelnet authentication-type publickey assign publickey pubssh user root service-type stelnet authentication-type publickey assign publickey upyun# acl过滤acl number 2000description Login IP Controlrule 1 permit source 192.168.0.0 0.0.255.255rule 5 permit source 115.238.93.82 0rule 10 permit source 115.231.100.64 0.0.0.63rule 15 permit source 121.52.226.192 0.0.0.63rule 20 permit source 115.238.54.160 0.0.0.15rule 25 permit source 124.160.114.192 0.0.0.15rule 30 permit source 106.186.117.158 0.0.0.255rule 35 permit source 157.119.232.0 0.0.0.31rule 40 permit source 218.205.64.19 0.0.0.31rule 45 permit source 112.17.251.0 0.0.0.31rule 50 permit source 121.52.250.193 0.0.0.31rule 55 permit source 183.131.0.65 0.0.0.31rule 60 permit source 43.230.89.160 0.0.0.31rule 65 permit source 111.1.32.0 0.0.0.127rule 70 permit source 115.231.97.0 0.0.0.31rule 1000 deny source anyquitundo ip http enable# ssh过滤ssh server enablessh server acl 2000# 接口过滤user-interface vty 0 4acl 2000 inbound# snmp监控snmp-agentsnmp-agent local-engineid 800063A203snmp-agent community read hgE6ofdZ3bsnmp-agent sys-info version v2c v3 # 机器时间同步interface Vlan-interface1ntp-service unicast-server 218.189.210.4 source Vlan-interface 1ntp-service unicast-server 137.189.4.10 source Vlan-interface 1clock timezone beijing add 8# 路由追踪ip ttl-expires enableip unreachables enableipv6 unreachables enable ***二层环路检测配置h3c 5130配置 loopback-detection global enable vlan all# 端口定时器shutdown-interval 120 # 环路检测报文发送周期loopback-detection interval-time 5# 接口内部配置# 环路检测接口配置loopback-detection action shutdownloopback-detection enable vlan all h3c 5120配置 loopback-detection multi-port-mode enableloopback-detection enable# 端口定时器shutdown-interval 120 # 环路检测报文发送周期loopback-description interval-time 5# 接口内配置# 环路检测接口配置loopback-detection action shutdownloopback-detection enable vlan all h3c 5820配置 loopback-detection global enable vlan all# 端口定时器shutdown-interval 120 # 环路检测报文发送周期loopback-detection interval-time 5# 接口内部配置# 环路检测接口配置loopback-detection global action shutdownloopback-detection gloabl enable vlan all 走二层与走三层的关系交换机的二三层决定取决于OSI模型 ，二层走数据链路层 三层在二层基础上添加网络层另外交换机是否走三层，应该取决于网络的规划 首先是二层交换机走二层，路由在核心交换机上，不转发多网段的数据(Vlan)数据走数据链路层以上说明二层交换机不能跨网段传输信息，在划分vlan的情况下，只能走同vlan下的数据 需要测试 # 在同vlan下，不通网段ip需要默认路由？# 在同vlan下，同网段ip不需要默认路由？ # 静态路由的功能除了 规定流量转发还有什么？ 静态路由指向核心交换机上的网关 其次是三层交换机三层交换机就是在二层交换机的基础上加了路由功能，交换机走三层，路由在当前三层交换机上三层交换机能转发多网段的数据,路由器转发数据是基于IP地址进行转发的！！而二层交换机是基于MAC地址转发的！！让基于MAC地址转发的交换机实现基于IP地址转发 ===> 三层交换机 三层交换机可以转发多网段的数据，不局限于同vlan下的数据转发， 静态路由指向网关 虽然三层交换机有路由功能，但不能完全取代路由器，基础原理不同 二层架构于三层架构的区别https://blog.51cto.com/fenggao/1582958https://www.cnblogs.com/sunada2005/articles/2666902.html 举例比如你现在有两台交换机 A BA 作为核心交换机B 作为核心机下面的机器 要走二层的话，则同vlan走个静态就ok了 要走三层的话，也就是说B下面有多个网段的机器 两台机器的vlan是不需要相同的，三层交换机会动态配置 福建厦门联通CUN-FJ-XMN-S01如图以上信息 ip信息 36.248.208.224/27机器信息 15台1U服务器 1台5130交换机(52口) 2个万兆多模 30根网线 16根电源线-->-->-->也就是说 15台服务器每台2根网线 5130交换机前面30个电口做汇聚interface bridge-aggregation 1interface GigabitEthernet1/0/1port link-aggregation group 1interface GigabitEthernet1/0/2port link-aggregation group 1# 可以用脚本生成两个万兆多模，交换机上联接入一个，上联一个 ****走二层不走vlan1 指定vlan 2250# 配置vlan2250vlan 2250int vlan-interface 2250ip address 36.248.208.226 255.255.255.224# 端口汇聚interface bridge-aggregation 1interface GigabitEthernet2/0/1port link-aggregation group 1interface GigabitEthernet2/0/2port link-aggregation group 1...int range Bridge-Aggregation 1 to Bridge-Aggregation 15port access vlan 2250# 配置上联口interface ten1/0/49port link-type trunk # 接入trunk模式，对应trunk模式undo port trunk permit vlan 1port trunk permit vlan 2250# 关闭端口stp生成树功能int range g1/0/1 to g1/0/30 undo stp enable# 二层环路检测配置 四川成都联通CMN-SC-CTU4-S01ZA-16030782 1 2 口ZA-16030781 3 4 口ZA-16031259 5 6 口ZA-16031257 7 8 口ZA-16030285 9 10 口ZA-15041213 11 12 口ZA-15041819 13 14 口ZA-15041852 15 16 口ZA-15070367 17 18 口ZA-19010018 19 20 口 6300 47 48上联口 # 走三层10 台交换机 汇聚 走1-20口 走47 48口 # 这个需要问，图里没给 *****走三层# 基础配置 复制粘贴# 配置vlan 200 201vlan 200int vlan-interface 200ip address 117.172.4.50 255.255.255.252vlan 201 int vlan-interface 201ip address 117.172.4.54 255.255.255.252vlan 1int vlan-interface 1ip address 117.172.22.129 255.255.255.224# 配置静态路由ip route-static 0.0.0.0 0 117.172.4.49ip route-static 0.0.0.0 0 117.172.4.53# 配置上联int ten 1/0/47port access vlan 200int ten 1/0/49port access vlan 201# 二层环路检测配置 自动生成汇聚端口配置脚本import osimport json# 指定端口类型 有些做过堆叠的交换机 MemberID是不同的port_type = \"1\"for i in range(1,16): print(\"interface bridge-aggregation %s\"%i) print(\"interface GigabitEthernet%s/0/%s\"%(port_type,int(i*2-1))) print(\"port link-aggregation group %s\"%i) print(\"interface GigabitEthernet%s/0/%s\"%(port_type,int(i*2))) print(\"port link-aggregation group %s\"%i)## REANME.md##交换机的配置需要批量配置管理端口##用这个脚本生成就ok了 check-list 基础配置是否完成基础配置主要是上面打*的部分，一般情况下复制粘贴就可以了 互联是否已通ping 下自己，ping 下对端 如果机房临时有事，导致交换机时间内无法连上网络，可以先试着ping一下loopback 接口3.","link":"/posts/291d4679/"},{"title":"jwt原理与实战应用","text":"jwt原理与实战应用 基于传统的token认证用户登陆，服务端给返回token,并将token保存在服务端，以后用户访问时，需要携带token，服务端获取token后，再去数据库中获取token认证校验 jwt形式的token认证用户登录，服务端给用户返回一个token(服务端不保存)，以后用户再来访问，需要携带token，服务端获取token后，再做token认证 不用在服务端保存token jwt实现过程 用户提交用户名和密码给服务器，如果登录成功，使用jwt创建一个token，并给用户返回。 jwt-token组成由三段字符串组成，并且用.连接 加密过程 第一段字符串 header 内部包含算法/token类型.json 转换成字符串，然后做base64url加密(base64加密) { \"alg\": \"HS256\", # 算法 \"typ\": \"JWT\", # 类型} 第二段字符串payload 自定义值json转换成字符串，然后做base64url加密(base64加密) { \"id\": \"12343242\", \"name\": \"hzj\", \"exp\": 323212423 # 超时时间} 第三段字符串:拼接1,2部分内容，并对其进行HS256加密 + 加盐(加随机字符串)对HS256加密后的密文再做base64url加密 返回给用户，用户下次访问带着jwt-token来访问 解密过程用户第二次访问，带着jjwt-token来访问，后端需要对token进行验证 获取token，根据.对token进行切割 对第二段进行base64url解密，并获取payload信息{ \"id\": \"1234343\", \"name\": \"hzj\", \"exp\": 432423 # 超时时间} 第三步: 把第一二段拼接，再次HS256加密后对base64url解密后的内容进行比较(认证通过)在 jwt实现原理 底层使用pyjwt drf封装库使用的是django-estframework-jwt pyjwt使用# 安装pip install pyjwt 生成token # 配置import jwtimport datetimefrom django.conf import settings# 生成tokendef create_token(payload,timeout=1): # 随机符号，这里写了该项目的secret_key salt = settings.SECRET_KEY # 构造header headers = { 'typ': 'jwt', 'alg': 'HS256', } # 构造payload payload = { 'user_id': \"ud\", 'username': \"username\", 'exp': datetime.datetime.utcnow() + datetime.timedelta(minutes=timeout) } token = jwt.encode(payload=payload, key=salt, algorithm=\"HS256\", headers=headers).decode('utf-8') return token 验证token from rest_framework.authentication import BaseAuthenticationimport thisimport jwtimport datetimefrom rest_framework.response import Responsefrom django.conf import settingsfrom rest_framework import exceptionssalt = settings.SECRET_KEYclass JwtQueryParamsAuthentication(BaseAuthentication): def authenticate(self, request): # 获取token 并判断token的合法性 token = request.query_params.get(\"token\") # 1。切割 # 2. 解密第二段/判断过期 # 3. 验证第三段合法性 playload = None msg = None try: payload = jwt.decode(token,salt,True) except exceptions: msg = 'token已经失效' except jwt.DecodeError: msg = \"token认证失败\" except jwt.InvalidTokenError: msg = \"非法的token\" if not playload: pass else: return (playload,msg) views编写 # views编写 from api.extensions.auth import JwtQueryParamsAuthenticationclass ProOrderView(ApiView): authentication_classes = [JwtQueryParamsAuthentication,] djangorestframework-jwt使用djangorestframework-jwt本质是调用pyjwt实现的 # 安装pip install djangorestframework-jwt 地址jwt认证http://yangjianhua.me/2020/01/django-drf-8/ https://shuke163.github.io/2019/02/24/Django-REST-framework-API%E8%AE%A4%E8%AF%81-%E5%8C%85%E5%90%ABJWT%E8%AE%A4%E8%AF%81/https://www.cnblogs.com/ruhai/p/11311852.htmlhttps://www.cnblogs.com/chichung/p/9967325.html","link":"/posts/e8b3a2c2/"},{"title":"hexo博客优化","text":"handsome博客优化修改右侧栏sidebar.php 此处直接去除了 热门文字 、 最新评论 、 随机文字 这三个模块（他们在一个 Tab 里） 这里是我的个人小站：猫之三千岁，用以记录生活中的点点滴滴，我一直认为有一个安静的、温馨的小窝是一件很快乐的事情。最后欢迎您不经意间的光临~ 🐾 部分修改网站https://szyink.com/archives/229/ 如何获取自己的备案号https://icp.chinaz.com/noback.top 改成CDN的内容public static function whenSwitchHeaderImgSrc($index = 0, $howToThumb, $attach, $content, $thumbField) { $options = mget(); //$randomNum = unserialize(INDEX_IMAGE_ARRAY); // 随机缩略图路径 // $random = \"http://image.noback.top/\" . @$randomNum[$index] . '.jpg';//如果有文章置顶，这里可能会导致index not undefined $random = 'http://image.noback.top/'.rand(1, 69).'.jpg'; $pattern = '/\\]*>/i'; 突然又想了一个骚操作 只要把bing 4k壁纸上的https://bing.lylares.com/detail/cnjX2Vj0.html 后缀拿到 弄一个列表 随机一下 这样CDN流量钱都省了～ 网站测速https://developers.google.com/speed/pagespeed/insights/?hl=zh-cn&url=http%3A%2F%2Fnoback.top%2F hexo博客优化end of the stream or a document separator is expected at line 8, column 1:报错内容 没有添加---title:tags:---等头部内容","link":"/posts/83186147/"},{"title":"mac配置","text":"mac配置Mac OS 中如何优雅的创建定时任务mac 可以像linux一样使用crontab来使用定时任务.另外还有一个launchctl的工具 配置文件 xxx.plist Label cn.rayjun..plist ProgramArguments /path/to/programer StartCalendarInterval Minute 00 Hour 22 StandardOutPath /path/to/log/x.log StandardErrorPath /path/to/err/x.err 在 Plist 中，支持两种定时任务的设置： StartInterval：定义任务多长时间（单位，秒）执行一次 StartCalendarInterval：这个配置类似在 crontab 中的配置，指定具体的执行日期、星期、每月、每日的各个时间点，具体参照上面的配置文件。月份和天数的配置类似。 存放点在 Mac 系统中，可以将需要处理的事情都写在 plist 文件中，plist 是一个 xml 格式的文件。plist 文件根据不同的需要可以放在不同的目录底下。Mac OS X 中支持放 plist 的目录如下： /Library/LaunchDaemons: 系统启动后就会执行 /Library/LaunchAgents: 当用户登录系统后才会执行 ~/Library/LaunchAgents: 用户自定义的 plist /System/Library/LaunchAgents: 由 Mac OS X 为用户定义的任务 /System/Library/LaunchDaemons: 由 Mac OS X 定义的守护进程任务 命令行 launchctl load xx.plist # 启动程序launchctl unload xx.plist # 停止程序 解决讨厌的.DS_Store.DS_Store (Desktop Services Store) 是一种由苹果公司的 Mac OS X 操作系统所创造的隐藏文件，目的在于存贮目录的自定义属性，例如文件们的图标位置或者是背景色的选择。相当于 Windows 下的 desktop.ini 为什么要解决？如果不处理，每次拷贝给你同事的文件里都会包含有这个文件，或者上传网页的时候，应该把这个文件删除比较妥当，因为里面包含了一些你不一定希望别人看见的信息。（尤其是网站，通过 .DS_Store 可以知道这个目录里面所有文件的清单，很多时候这是一个不希望出现的问题。） 解决 删除当前目录的.DS_Storefind . -name '*.DS_Store' -type f -delete 删除所有目录的.DS_Storesudo find / -name \".DS_Store\" -depth -exec rm {} \\; 禁止.DS_Store生成defaults write com.apple.desktopservices DSDontWriteNetworkStores -bool TRUE 恢复.DS_Store生成defaults delete com.apple.desktopservices DSDontWriteNetworkStores git上传忽略全局文件，并且在gitconfig中引入touch ~/.gitigonre_global# .gitignore_global############################################ OS generated files ############################################.DS_Store.DS_Store?*.swp._*.Spotlight-V100.TrashesIcon?ehthumbs.dbThumbs.db################################################# packages #################################################*.7z*.dmg*.gz*.iso*.jar*.rar*.tar*.zip #.gitconfig[filter \"lfs\"] required = true clean = git-lfs clean %f smudge = git-lfs smudge %f[user] name = bingozb email = 454113692@qq.com[core] excludesfile = /Users/bingo/.gitignore_global","link":"/posts/76ec0771/"},{"title":"Vimrc配置","text":"配置NERDtree配置\" ---------------------文件树\" \\\"表示注视\" 关闭NERDTree快捷键map t :NERDTreeToggle\" 当NERDTree为剩下的唯一窗口时自动关闭autocmd bufenter * if (winnr(\"$\") == 1 && exists(\"b:NERDTree\") && b:NERDTree.isTabTree()) | q | endif\" 修改树的显示图标let g:NERDTreeDirArrowExpandable = '►'let g:NERDTreeDirArrowCollapsible = '▼'let NERDTreeAutoCenter=1\" 显示行号let NERDTreeShowLineNumbers=1\" 是否显示隐藏文件let NERDTreeShowHidden=1\" 设置宽度let NERDTreeWinSize=25\" 在终端启动vim时，共享NERDTreelet g:nerdtree_tabs_open_on_console_startup=1\" 忽略一下文件的显示let NERDTreeIgnore=['\\.pyc','\\~$','\\.swp']let g:NERDTreeIndicatorMapCustom = { \\ \"Modified\" : \"✹\", \\ \"Staged\" : \"✚\", \\ \"Untracked\" : \"✭\", \\ \"Renamed\" : \"➜\", \\ \"Unmerged\" : \"═\", \\ \"Deleted\" : \"✖\", \\ \"Dirty\" : \"✗\", \\ \"Clean\" : \"✔︎\", \\ 'Ignored' : '☒', \\ \"Unknown\" : \"?\" \\ }\" 打开NERDTree的快捷键设置为F6map :NERDTreeToggle tmux配置安装Tumx# 先安装Homebrew，有则跳过ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"# 安装tmuxbrew install tmux tmux的配置文件在～/.tmux.conf退出tmux后生成配置 source .tmux.conf tmux简介对于tmux来说,最好能了解一些概念,在tmux中,一共分为 窗口（windows)，会话(session) 以及 面板(pane)三块内容, tumx 使用指南（会话篇）tumx # 新建一个无名称的会话tmux new -s demo # (-s -session) 新建一个名称为demo的会话tmux detach # 断开当前会话，会话在后台运行tmux ls # 查看当前会话列表tmux a # 默认进入第一个会话tmux a -t demo # 进入到名称为demo的会话 (-t -tmux)tmux kill-session -t demo #关闭demo会话tmux kill-server # 关闭服务器，即所有的会话都将关闭tmux ls # 查看所有会话 tmux使用指南（窗口篇）c-b d # 断开当前窗口，后台运行c-b s # 在当前窗口打来其他正在运行的tmuxc-b ? # 显示快捷键帮助文档c-b d # 断开当前会话c-b c+z # 挂起当前会话c-b r # 强制重载当前会话c-b s # 显示会话列表用于选择并切换c-b [ # 进入复制模式 按q退出c-b ] # 粘贴复制模式中的文本c-b c # 新建窗口c-b & # 关闭当前窗口 需要输入y n 确认c-b 0~9 # 切换到指定窗口c-b p # 切换到指定窗口c-b n # 切换到下一个窗口c-b w # 打开窗口列表，用于切换窗口c-b , # 重命名当前窗口c-b . # 修改当前窗口编号c-b f # 快速定位到窗口 Tmux使用手册地址：http://louiszhai.github.io/2017/09/30/tmux/ 还需要在记录一下 tmux美化篇tumx配置篇首先tmux默认将作为启动功能的前缀按键，当然我们可以自定义修改这个前缀按键，具体配置可以参照下面的配置文件 常用按键在具体配置之前我们先来了解一下tmux常用按键,这里我已经把前缀按键替换成了c-z # 常用按键c-z ？显示快捷键帮助c-z c-o 调换窗口位置c-z space 采用上下布局或左右布局c-z u 纵向分割窗口c-z v 横向分割窗口c-z q 显示分割窗口的编号c-z hjkl 上下左右选择窗口c-z c 创建新窗口c-z 0-9 选择几号窗口c-z n 切换下一个窗口c-z p 选择前一个窗口c-z w 以菜单方式显示及选择窗口c-z t 显示时钟c-z x 关闭面板c-z d 退出当前窗口，丢到缓存 , tmux a 进入指定会话c-z s 以菜单形式显示和选择会话c-z $ 修改当前会话名字tmux new -s xxx 创建并指定session名字tmux ls 列出sessiontmux a -t xxx进入已经在的sessiontmux kill-session -t session_name 删除指定session 具体配置# Tumx配置文件# from hzj# remap prefix from 'C-b' to 'C-a'# 修改前缀权限unbind C-b # 取消Ctrl-Bset -g prefix C-z # 添加Ctrl-zbind-key C-z send-prefix 绑定ctrl+z为新的前缀 # split panes using | and -# 使用c-u c-v分割面板bind u split-window -hbind v split-window -vunbind '\"'unbind %# 使用c-(hijk)选择面板bind h select-pane -Lbind l select-pane -Rbind j select-pane -Dbind k select-pane -U bind-key e setw synchronize-panes # Set the default terminal mode to 256color modeset -g default-terminal \"screen-256color\" # Set scrollback buffer to 10000set -g history-limit 10000# resize panebind -r ^k resizep -U 10 # upward (prefix Ctrl+k)bind -r ^j resizep -D 10 # downward (prefix Ctrl+j)bind -r ^h resizep -L 10 # to the left (prefix Ctrl+h)bind -r ^l resizep -R 10 # to the right (prefix Ctrl+l) # app# htop (prefix !)bind ! splitw htop # python bind / command-prompt \"splitw 'exec python3 %%'\" # reload config (prefix r)bind r source ~/.tmux.conf \\; display \"Configuration reloaded!\" #-- statusbar --#set -g status-interval 1set -g status-keys vi setw -g mode-keys visetw -g automatic-rename off #-- colorscheme --##https://github.com/daethorian/conf-tmux/blob/master/colors/zenburn.conf# mouse# 支持鼠标set-option -g mouse on # 支持复制粘贴连续到剪切板bind C-c run \"tmux save-buffer - | reattach-to-user-namespace pbcopy\"bind C-v run \"reattach-to-user-namespace pbpaste | tmux load-buffer - \\; paste-buffer\"bind-key -T copy-mode-vi 'y' send-keys -X copy-pipe-and-cancel 'reattach-to-user-namespace pbcopy'bind-key -T copy-mode-vi MouseDragEnd1Pane send -X copy-pipe-and-cancel \"pbcopy\"set -g status-utf8 on # 状态栏支持utf8set -g status-interval 1 # 状态栏刷新时间set -g status-justify left # 状态栏列表左对齐setw -g monitor-activity on # 非当前窗口有内容更新时在状态栏通知set -g status-bg black # 设置状态栏背景黑色set -g status-fg yellow # 设置状态栏前景黄色set -g status-style \"bg=black, fg=yellow\" # 状态栏前景背景色set -g status-left \"#[bg=#FF661D] ❐ #S \" # 状态栏左侧内容set -g status-right 'Continuum status: #{continuum_status}' # 状态栏右侧内容set -g status-left-length 300 # 状态栏左边长度300set -g status-right-length 500 # 状态栏左边长度500set -wg window-status-format \" #I #W \" # 状态栏窗口名称格式set -wg window-status-current-format \" #I:#W#F \" # 状态栏当前窗口名称格式(#I：序号，#w：窗口名称，#F：间隔符)set -wg window-status-separator \"\" # 状态栏窗口名称之间的间隔set -wg window-status-current-style \"bg=red\" # 状态栏当前窗口名称的样式set -wg window-status-last-style \"fg=red\" # 状态栏最后一个窗口名称的样式set -g message-style \"bg=#202529, fg=#91A8BA\" # 指定消息通知的前景、后景色set -g default-terminal \"screen-256color\"","link":"/posts/b4afac26/"},{"title":"软件配置","text":"设备本文主要记录一些设备上的变动，包括快捷键的设置等等 vscodevscode设置代码块1.由于markdown不是什么编程语法，vscode不支持自动提示和补全,所以我们要现在用户设置中打开markdown的自动补全ctrl+shift+p打开设置—> setting —-> 在其中添加 \"[markdown]\": { \"editor.wordWrap\": \"on\", \"editor.quickSuggestions\": true,}, 2.添加补全代码块ctrl+shift+p —> 输入markdown –> 打开markdown.json —> 添加内容 \"Print to console\": { \"prefix\": \"fcr\", \"body\": [ \"$1\" ], \"description\": \"change font-color to red sign import \" } 其中prefix 是指你代码块的简洁写法,在你输入的时候会出现代码块的提示body是主体内容,也就是我们添加的代码块description 是注释，你可以标注一下这代码块是用来干嘛的 vscode 绑定vim自定义快捷键在vscode中自定义vim快捷键“vim.insertModeKeyBindings”: [ { “before”: [“j”, “j”], “after”: [““] }]https://github.com/VSCodeVim/Vim/#key-remapping chrome清除特定网址的缓存打开开发者工具（F12），选择 Network——Disable cache 即可。需要清除某网站缓存时 F12 打开开发者工具就会自动清除这个网站的缓存，而不必清除所有网站的缓存了 ssss加强模式 Mac电脑使用shadowsocks无法连接公司内网问题最近换了mac但是发现无法连接mac电脑，主要原因是在mac电脑中ss无法对所有软件都支持端口转发,这时候需要用到一个软件 proxifier,在这个上面做全局的端口转发即可 看到socks5的监听端口为 1086 添加代理 添加规则 macmac连接交换机由于在mac中没有像windows中xshell这样简单方便的串口连接工具，因此我们只能使用screen来连接交换机 首先用串口线连接交换机，然后查看接入的串口设备，他们放在/dev下面 由于不同的串口线命名不同，但是他们应该都会带有usb字样 ls /dev | grep -i tty.*usbscreen /dev/tty.usbxxxxx 9600 这里9600为交换机的默认波特率，但你也可以在交换机更换波特率的内容 mac下使用ftp由于新的Mac系统去调了自带的telnet命令和ftp命令，所以第一步我们要安装ftp命令。我的系统是10.13.6 ftp的安装需要很多的软件依赖 brew install telnetbrew install inetutilsbrew link --overwrite inetutils 登陆- # 方式一ftp ip# 方式二ftp open ip https://www.jianshu.com/p/10c4e46c77f1ftp使用方法https://blog.csdn.net/tianlesoftware/article/details/5818990 mac下改键记录使用karabiner-element修改mac按键修改内容为:切换输入法 由之前的caps lock改成 shift之前的caps 改成了 control 下载karabiner-element 在simple modifitions 中修改映射from key caps_lockto_key left_control 修改shift和caps由于karabiner-element不支持在窗口中修改，但可以指定json形式的配置文件vi /Users/alpaca/.config/karabiner/karabiner.json \"rules\": [ { \"manipulators\": [ { \"description\": \"Change left_shift to control+space when used alone\", \"from\": { \"key_code\": \"left_shift\", \"modifiers\": { \"optional\": [ \"any\" ] } }, \"to\": [ { \"key_code\": \"left_shift\" } ], \"to_if_alone\": [ { \"key_code\": \"spacebar\", \"modifiers\": [ \"left_control\" ] } ], \"type\": \"basic\" } ] } ] mac /usr/bin/python 权限问题operation not permitted一般情况下我们在使用mac系统过程中下载一些文件、新建一些项目之后，这些文件都会默认是只读状态，这时我们只需要简单的一句权限设置命令就可以解决 sudo chmod -R 777 filename /usr/bin下面的文件在mac中会出现一下的错误 operation not permitted 这是因为mac启用了SIP（System Integrity Protection），增加了rootless机制，导致即使在root权限下依然无法修改文件，在必要时候为了能够修改下面的文件，我们只能关闭该保护机制 1) 重启 开机过程中按住command+R 进入保护模式2) 打开终端 csrutil disable 3) 再次重启，就可以修改/usr/bin下的目录文件 4)恢复保护机制 csrutil enable","link":"/posts/cd35325c/"},{"title":"又拍云","text":"又拍云工作记录交换机命名格式三大运营商缩写 + 附近机场代码 + S01等 移动 CMN电信 CTN联通 CUN 交换机ipv6检测内容原因 内网机器比如全是移动的，交换机配的移动的ip，下面配的也是移动的ip这样ping的通，但是联通的服务器ip ping不同。也就是说是内网通，外网不同。内网ping 网关肯定通 检测：用移动的交换机下面的服务器（出问题的交换机） 去mtr外网的ip，去看是哪里断掉的而不是用外网的机器来mtr内网的ip，这样截止的地方会看不出来，因为不是内网的机器 ipv6配置#业务vlaninterface Vlan-interface1ipv6 address +业务vlan ipundo ipv6 nd ra halt#互联vlaninterface Vlan-interface200ipv6 address +互联本地ip#默认路由ipv6 route-static :: 0 + 互联对端ip 配置案例广东广州移动机房（自有机房NM）：2409:8C54:B000:0704::/64 互联地址 机房：FEC0::C/127， 我司 FEC0::D/127vlan 1 ip address 2409:8C54:B000:0704::/64 undo ipv6 nd ra haltvlan 20ipv6 address FEC0::D/127router-staticipv6 route-static :: 0 FEC0::C山东济南移动机房（自有节点NM）：2409:8C3C:0004:000C::/64，互联地址为：2409:8C3C:00FF:0004::000E/127、 我司 2409:8C3C:00FF:0004::0010/127vlan 1ip address 2409:8C3C:0004:000C::/64undo ipv6 nd ra haltvlan 20ipv6 address 2409:8C3C:00FF:0004::0010/127route-staticipv6 route-static :: 0 2409:8C3C:00FF:0004::000Evlan 1ipv6 address 240E:E9:B804:3:400::1/72undo ipv6 nd ra haltvlan 30 ipv6 address 240E:E9:B804:3:200::A3/127ipv6 address 240E:E9:B804:3:200::B3/127router-staticipv6 route-static :: 0 240E:E9:B804:3:200::A3 无法联网 首先ping交换机ip 看是否通 串口线连接交换机 ping网关是否通不通 10.0.0.130 查看端口状态dis int brief聚合口是否起来 端口是否起来 pvid是否对应1000(统一是1000 除个别外可以在上联交换机上看10.0.0.130) 硬件问题看模块是否发光 看跳线是否发光 整理香港ntt点ip对应关系 登陆netop服务器 登陆香港ntt交换机 查看vlan1 对应ip 其中157.xxx/27 [NTT-CN-HKG-S01-Vlan-interface1]display this#interface Vlan-interface1 ip address 157.119.232.1 255.255.255.224 ip address 10.81.0.254 255.255.255.0 sub ip address 103.211.192.221 255.255.255.252 sub ip address 103.251.128.1 255.255.255.224 sub ip address 157.119.232.65 255.255.255.224 sub ip address 192.168.1.1 255.255.255.0 sub ip address 192.168.128.1 255.255.255.0 sub ip address 192.168.232.1 255.255.255.224 sub ipv6 address 2405:FD80:110::1/52#return 在netop服务器上用fping -g 157.119.231.1/27 来查看对应ip的状态 [root@NETOPS machines]# fping -g 157.119.232.65/27157.119.232.65 is alive157.119.232.66 is alive157.119.232.67 is alive157.119.232.68 is alive157.119.232.69 is alive157.119.232.70 is alive157.119.232.71 is alive157.119.232.72 is alive157.119.232.73 is alive157.119.232.74 is alive157.119.232.75 is alive157.119.232.85 is alive157.119.232.87 is alive157.119.232.86 is alive157.119.232.88 is alive157.119.232.89 is alive157.119.232.90 is alive157.119.232.91 is alive157.119.232.76 is unreachable157.119.232.77 is unreachable157.119.232.78 is unreachable157.119.232.79 is unreachable157.119.232.80 is unreachable157.119.232.81 is unreachable157.119.232.82 is unreachable157.119.232.83 is unreachable157.119.232.84 is unreachable157.119.232.92 is unreachable157.119.232.93 is unreachable157.119.232.94 is unreachable[root@NETOPS machines]# fping -g 157.119.232.1/27157.119.232.1 is alive157.119.232.2 is alive157.119.232.3 is alive157.119.232.4 is alive157.119.232.5 is alive157.119.232.6 is alive157.119.232.7 is alive157.119.232.8 is alive157.119.232.9 is alive157.119.232.10 is alive157.119.232.11 is alive157.119.232.12 is alive157.119.232.13 is alive157.119.232.14 is alive157.119.232.15 is alive157.119.232.16 is alive157.119.232.17 is alive157.119.232.19 is alive157.119.232.18 is alive157.119.232.20 is alive157.119.232.21 is alive157.119.232.22 is alive157.119.232.23 is alive157.119.232.24 is alive157.119.232.25 is alive157.119.232.26 is alive157.119.232.27 is alive157.119.232.28 is alive157.119.232.29 is alive157.119.232.30 is alive 查看inventory中对应关系 [root@NETOPS machines]# grep 157.119.232.73 /root/mingtao/inventory/machines/*/root/mingtao/inventory/machines/lists-upapp-01:157.119.232.73[root@NETOPS machines]# grep 157.119.232.30 /root/mingtao/inventory/machines/*/root/mingtao/inventory/machines/lists-cdn-v406:# NTT-CN-HKG-030 ansible_ssh_host=157.119.232.30/root/mingtao/inventory/machines/lists-openstack:# NTT-CN-HKG-030 ansible_ssh_host=157.119.232.30/root/mingtao/inventory/machines/lists-openstack:OPK-HKG-M30 ansible_ssh_host=157.119.232.30/root/mingtao/inventory/machines/lists-upops:NTT-CN-HKG-030 ansible_ssh_host=157.119.232.30[root@NETOPS machines]# grep 157.119.232.29 /root/mingtao/inventory/machines/*/root/mingtao/inventory/machines/lists-cdn-v406:# NTT-CN-HKG-029 ansible_ssh_host=157.119.232.29/root/mingtao/inventory/machines/lists-openstack:# NTT-CN-HKG-029 ansible_ssh_host=157.119.232.29/root/mingtao/inventory/machines/lists-upapp-01:157.119.232.29[root@NETOPS machines]# grep 157.119.232.20 /root/mingtao/inventory/machines/*[root@NETOPS machines]# grep 157.119.232.24 /root/mingtao/inventory/machines/*[root@NETOPS machines]# grep 157.119.232.21 /root/mingtao/inventory/machines/* 记录机器的对应名字 ntt机器对应脚本#!/usr/bin/bash# add ip (active and unknown)fping -g 157.119.232.65/27 > ntt_machinefping -g 157.119.231.1/27 >> ntt_machine# filter active to tmp.txtawk '{if($3==\"alive\"){print $1}}' > tmp.txt ntt_machine# Calculate the totalnums=`cat tmp.txt | wc -l`# reset result.txt to blankecho \"result:\" > result.txt# filter ipfor i in `seq 1 $nums`do ip=`awk \"NR==$i\" tmp.txt` link=`grep -w $ip mingtao/inventory/machines/machines/*` link=`echo $link | awk -F\":\" '{print $2}' ` link=`echo $link | awk '{if($1==\"#\"){print $2}else{print $1}}'` echo $ip ,\"active\" , $link >> result.txtdone# add unknown to tmp.txtawk '{if($3!=\"alive\"){print $1,$3}}' >> result.txt ntt_machine~ 底层设备到网络配置通过该tower截图来获取网络配置需求15台1U服务器1台5130交换机2个万兆多模模块30根网线16根电源线 1个万兆口 1-30口汇聚49口接上联 走trunk","link":"/posts/899b698f/"},{"title":"常见错误","text":"linux错误yum不支持python3[root@gogogo alpaca]# yum File \"/bin/yum\", line 30 except KeyboardInterrupt, e: ^SyntaxError: invalid syntax File \"/usr/libexec/urlgrabber-ext-down\", line 28 except OSError, e: 解决办法 sed -i 's:bin/python:bin/python2.7:' /usr/bin/yumsed -i 's:bin/python:bin/python2.7:' /usr/libexec/urlgrabber-ext-down 可以通外网，但是无法ping百度包括无法使用yum wget 等下载工具或者报错 cannot find a valid baseurl for repo:base/7/x86_64 的解决方法 解决办法原因 - > DNS的问题 echo nameserver 114.114.114.114 > /etc/reslov.conf linux中如何恢复到后台进程linux 下我们如果想一个任务或者程序进行调度bg 将一个后台暂停的命令，变成继续执行fg 将后台的命令调至前台继续运行jobs 查看当前在后台运行的命令c-z 将前台命令放到后台运行 并且暂停nohup command & 在后台不断运行command命令 ssh配置的问题这个问题主要是存在于交换机ssh登陆交换机的过程ssh配置过程中，配置了密码登陆，但是出现下面的错误 ssh 10.0.0.166The server's host key does not match the local cached key. Either the server administrator has changed the host key, or you connected to another server pretending to be this server. Please remove the local cached key, before logging in! 主要问题是一开始用ssh登陆交换机的时候，选择了保存key ssh 10.0.0.166Username: ttPress CTRL+C to abort.Connecting to 10.0.0.166 port 22.The server is not authenticated. Continue? [Y/N]:yDo you want to save the server public key? [Y/N]:y 这样导致的问题就是在当前交换机上会保存一个登陆另一个交换机的key #public-key peer 10.0.0.166 public-key-code begin 30819F300D06092A864886F70D010101050003818D0030818902818100DF3E1240D158E197 CE0712173C8591883F88CC925B1C0CFC63C779E9F531C3B7E409BBB2CCED954C09A339BE78 46B1497E4771EDD7E88D2E380C50F37A6EC9254E6B27EC7AFFE6DCDFC1EA230D16C4DC9BB8 B831A2F0CB578B736566052E830A582836AA9BFFE0821CE7CB43F74077D38B20437479F260 A5D0550CA7D3D0747F0203010001 public-key-code end peer-public-key end# 于是当你下次选择使用ssh+密码登陆交换机的时候就会发现错误 解决删除当前交换机的key 并在下次登陆的时候选择 ssh 10.0.0.166Username: ttPress CTRL+C to abort.Connecting to 10.0.0.166 port 22.The server is not authenticated. Continue? [Y/N]:yDo you want to save the server public key? [Y/N]:n","link":"/posts/c10f304f/"},{"title":"mysql安装","text":"learn mysql 📚 mysql安装配置环境 检查是否存在mysql,有则删除rpm -qa | grep mysqlrpm -e --nodeps xxx 安装mysql实例 添加yum源，为了下载的速度，我们添加一个阿里源wget https://mirrors.tuna.tsinghua.edu.cn/mysql/yum/mysql-connectors-community-el7/mysql-community-release-el7-5.noarch.rpm 安装镜像源rpm -ivh mysql-community-release-el7-5.noarch.rpm 安装后/etc/yum.repos.d/目录下多了两个文件[root@work196 yum.repos.d]# ll grep 'mysql' --color-rw-r--r--. 1 root root 1060 Jan 29 2014 mysql-community-source.repo-rw-r--r--. 1 root root 1209 Jan 29 2014 mysql-community.repo 清理yum缓存，重新建立缓存yum clean allyum makecache 关闭8.0镜像,开启5.7镜像yum-config-manager --disable mysql80-communityyum-config-manager --enable mysql57-community# 查看当前启用的仓库yum repolist enable | grep mysql 下载安装yum install mysql-community-server 启动systemctl start mysqld mysql配置-- 查看编码show variables like 'character%'-- 设置编码 /etc/my.conf[mysqld]character_set_server=utf8init-connect='SET NAMES utf8'-- 设置开机启动systemctl enable mysqldsystemctl daemon-reload","link":"/posts/b99fc7e4/"},{"title":"mysql基础","text":"learn mysql 📚 mysql基础准备mysqlmysql常用数据类型mysql 大致可以分为三类： 数值 日期/时间 字符串(字符)类型 https://www.runoob.com/mysql/mysql-data-types.html 数值类型类型 大小 范围（有符号） 范围（无符号） 用途TINYINT 1 字节 (-128，127) (0，255) 小整数值SMALLINT 2 字节 (-32 768，32 767) (0，65 535) 大整数值MEDIUMINT 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值INT或INTEGER 4 字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值BIGINT 8 字节 (-9,223,372,036,854,775,808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值FLOAT 4 字节 (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度浮点数值DOUBLE 8 字节 (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度浮点数值DECIMAL 对DECIMAL(M,D) ，如果M>D，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 时间类型类型 大小 范围 格式 用途 (字节)DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值TIME 3 ‘-838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间YEAR 1 1901/2155 YYYY 年份值DATETIME 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值TIMESTAMP 41970-01-01 00:00:00/2038 结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038年1月19日 凌晨 03:14:07 YYYYMMDD HHMMSS 混合日期和时间值，时间 字符串类型类型 大小 用途CHAR 0-255字节 定长字符串VARCHAR 0-65535 字节 变长字符串TINYBLOB 0-255字节 不超过 255 个字符的二进制字符串TINYTEXT 0-255字节 短文本字符串BLOB 0-65 535字节 二进制形式的长文本数据TEXT 0-65 535字节 长文本数据MEDIUMBLOB 0-16 777 215字节 二进制形式的中等长度文本数据MEDIUMTEXT 0-16 777 215字节 中等长度文本数据LONGBLOB 0-4 294 967 295字节 二进制形式的极大文本数据LONGTEXT 0-4 294 967 295字节 极大文本数据 验证数据类型 TINYINT创建表 create table testType( -> number TINYINT -> ); 查看表 desc testType;+--------+------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+--------+------------+------+-----+---------+-------+| number | tinyint(4) | YES | | NULL | |+--------+------------+------+-----+---------+-------+1 row in set (0.00 sec) 插入数据 insert into testType values (127);Query OK, 1 row affected (0.00 sec)insert into testType values (128);ERROR 1264 (22003): Out of range value for column 'number' at row 1 在插入128的时候报错，因为已经超越了要求的值 基本语法-- 显示所有数据库show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec)-- 创建数据库CREATE DATABASE test;Query OK, 1 row affected (0.00 sec)-- 切换数据库use test;Database changed-- 显示数据库中的所有表show tables;Empty set (0.00 sec)-- 创建数据表mysq> CREATE TABLE pet( name VARCHAR(20), owner VARCHAR(20), species VARCHAR(20), sex CHAR(1), birth DATE, death DATE);Query OK, 0 rows affected (0.03 sec)-- 查看数据表结构desc pet;+---------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+---------+-------------+------+-----+---------+-------+| name | varchar(20) | YES | | NULL | || owner | varchar(20) | YES | | NULL | || species | varchar(20) | YES | | NULL | || sex | char(1) | YES | | NULL | || birth | date | YES | | NULL | || death | date | YES | | NULL | |+---------+-------------+------+-----+---------+-------+6 rows in set (0.00 sec)-- 查询表select * from pet;Empty set (0.00 sec)-- 插入数据INSERT INTO pet VALUES ('puffball', 'Diane', 'hamster', 'f', '1990-03-30', NULL);Query OK, 1 row affected (0.00 sec)-- 修改数据UPDATE pet SET name = 'squirrel' where owner = 'Diane';Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0-- 删除数据DELETE FROM pet where name = 'squirrel';-- 删除表DROP TABLE pet; 建表约束主键约束他能够唯一确定一张表中的每一条记录，也就是我们通过给某个字段添加约束，就可以使得该字段不重复且不为空创建有主键约束的表 create table user( id int primary key, name varchar(25)); 查看表结构 desc user;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | NO | PRI | NULL | || name | varchar(25) | YES | | NULL | |+-------+-------------+------+-----+---------+-------+2 rows in set (0.00 sec) 这里key上有一个Primary的就是主键插入两条值 insert into user values(1,'张三'); insert into uservalues(1,'李四');insert into user values(1,'李四');ERROR 1062 (23000): Duplicate entry '1' for key 'PRIMARY' 报错，主键重复 联合主键只要联合的主键值加起来不重复就可以出现 create table user2( id int, name varchar(20), password varchar(20), primary key (id,name)); 插入值 insert into user2 values (1,'王五','hzjqq');insert into user2 values (2,'王五','hzjqq'); -- 可以插入 insert into user2 values (1,'王五','hzjqq'); -- 无法插入 联合组一摸一样 自增约束创建表 create table user3 ( id int primary key auto_increment, name varchar(20)); 插入值 insert into user3 (name) values(\"hzj\");insert into user3 (name) values(\"zh\");insert into user3 (name) values(\"qqq\"); 使用alter修改表属性创建表 create table user4( id int , name varchar(20)); 使用Alter修改表属性来添加主键 alter table user4 add primary key (id); 使用alter修改表属性来添加表头 alter table user4 add column sex varchar(20); 使用alter修改表属性来删除主键 alter table user4 drop primary key ; 使用alter修改表属性来修改主键 （名字+type id int） alter table user4 modify id int primary key; 唯一约束约束修饰的字段的值不可以重复 主键约束唯一且不允许为空，但是唯一约束保证唯一允许为空 create table user5( id int, name varchar(20)); 修改主键添加唯一主键约束 alter table user5 add unique(name);-- 或者alter table user5 modify name varchar(20) unique;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || name | varchar(20) | YES | UNI | NULL | |+-------+-------------+------+-----+---------+-------+2 rows in set (0.00 sec) 插入值 insert into user5 value (1,NULL); -- successinsert into user5 value (1,Null); -- success insert into user5 value (2,NULL); -- successinsert into user5 value (2,'hzj'); -- faildinsert into user5 value (2,'hzj'); -- faildselect * from user5;+------+------+| id | name |+------+------+| 1 | NULL || 1 | NULL || 2 | NULL |+------+------+ 之前说过unique会保证唯一性，但是允许为空，对于空的字段，则不保证唯一性，可以插入 创建唯一约束的另外的方法 create table user7( id int, name varchar(20) unique, age int) 组合键不重复即可 unique(id,name) 表示两个键在一起不重复就可以通过 删除唯一约束 -- index 指定是删除唯一约束的命令-- user5 指定表-- name 指定表项alter table use5 drop index name 非空约束修饰的字段不能为空 NULL创建表 create table user9( id int, name varchar(10) NOT NULL); 查看表 mysql> desc user9;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || name | varchar(10) | NO | | NULL | |+-------+-------------+------+-----+---------+-------+2 rows in set (0.00 sec) 默认约束约束某个字段的默认值 \bcreate table user10( id int, name varchar(20), age int Default 10); 查看表 mysql> desc user10;+-------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+-------------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || name | varchar(20) | YES | | NULL | || age | int(11) | YES | | 10 | |+-------+-------------+------+-----+---------+-------+3 rows in set (0.00 sec) 移除默认约束 alter table user10 modify age int; 外键约束表与表之间的联系 创建教室表 create table classes( id int primary key, name varchar(20));创建学生表create table students( id int primary key, name varchar(20), age int NOT Null, class_id int , foreign key(class_id) references classes(id) ); 插入数据 insert into classes values(1,\"one\");insert into classes values(2,\"two\");insert into classes values(3,\"there\");insert into classes values(4,\"four\"); 插入学生表 insert into students values(1,\"hzj\",1);insert into students values(2,\"hzj\",2);insert into students values(3,\"hzj\",3);insert into students values(5,\"hzj\",5); -- 报错，因为没有5班-- ERROR 1136 (21S01): Column count doesn't match value count at row 1insert into students values(4,\"hzj\",4); 主表classes 中没有的数据值，在副表中，是不可以使用的主表中的记录被副表引用时，是不可以被删除的。只有将引用的副表删除了以后，才能删除主表 数据库的三大设计范式 1NF只要字段值还可以继续拆分，就不满足第一范式。范式设计得越详细，对某些实际操作可能会更好，但并非都有好处，需要对项目的实际情况进行设定举例: 创建一个表create table selinfo ( id int primary key auto_increment, name varchar(20), address varchar(20)); 插入数据insert into selinfo values('hzj','杭州市萧山区xx街道'); 这样是不行的，因为address还可以再分，因此可以设计成为create table selinfo ( id int primary key auto_increment, name varchar(20), city varchar(20), address varchar(20)); 2NF在满足第一范式的前提下，其他列都必须完全依赖于主键列。如果出现不完全依赖，只可能发生在联合主键的情况下：举例,单表创建一个订单表-- 订单表CREATE TABLE myorder ( product_id INT, customer_id INT, product_name VARCHAR(20), customer_name VARCHAR(20), PRIMARY KEY (product_id, customer_id)); 实际上，在这张订单表中，product_name 只依赖于 product_id ，customer_name 只依赖于 customer_id 。也就是说，product_name 和 customer_id 是没用关系的，customer_name 和 product_id 也是没有关系的。 创建多张表 -- 主表CREATE TABLE myorder ( order_id INT PRIMARY KEY, product_id INT, customer_id INT);-- 产品表CREATE TABLE product ( id INT PRIMARY KEY, name VARCHAR(20));-- 用户表CREATE TABLE customer ( id INT PRIMARY KEY, name VARCHAR(20)); 也就是说一个主键要对应一段信息拆分之后，myorder 表中的 product_id 和 customer_id 完全依赖于 order_id 主键，而 product 和 customer 表中的其他字段又完全依赖于主键。满足了第二范式的设计！ 3NF在满足第二范式的前提下，除了主键列之外，其他列之间不能有传递依赖关系。CREATE TABLE myorder ( order_id INT PRIMARY KEY, product_id INT, customer_id INT, customer_phone VARCHAR(15)); 表中的 customer_phone 有可能依赖于 order_id 、 customer_id 两列，也就不满足了第三范式的设计：其他列之间不能有传递依赖关系。CREATE TABLE myorder ( order_id INT PRIMARY KEY, product_id INT, customer_id INT);CREATE TABLE customer ( id INT PRIMARY KEY, name VARCHAR(20), phone VARCHAR(15)) 修改后就不存在其他列之间的传递依赖关系，其他列都只依赖于主键列，满足了第三范式的设计！ 查询准备数据-- 创建数据库CREATE DATABASE select_test character set utf8 collate utf8_general_ci;-- 切换数据库USE select_test1;-- 创建学生表CREATE TABLE student ( no VARCHAR(20) PRIMARY KEY, name VARCHAR(20) NOT NULL, sex VARCHAR(10) NOT NULL, birthday DATE, -- 生日 class VARCHAR(20) -- 所在班级);-- 创建教师表CREATE TABLE teacher ( no VARCHAR(20) PRIMARY KEY, name VARCHAR(20) NOT NULL, sex VARCHAR(10) NOT NULL, birthday DATE, profession VARCHAR(20) NOT NULL, -- 职称 department VARCHAR(20) NOT NULL -- 部门);-- 创建课程表CREATE TABLE course ( no VARCHAR(20) PRIMARY KEY, name VARCHAR(20) NOT NULL, t_no VARCHAR(20) NOT NULL, -- 教师编号 -- 表示该 tno 来自于 teacher 表中的 no 字段值 FOREIGN KEY(t_no) REFERENCES teacher(no) );-- 成绩表CREATE TABLE score ( s_no VARCHAR(20) NOT NULL, -- 学生编号 c_no VARCHAR(20) NOT NULL, -- 课程号 degree DECIMAL, -- 成绩 -- 表示该 s_no, c_no 分别来自于 student, course 表中的 no 字段值 FOREIGN KEY(s_no) REFERENCES student(no), FOREIGN KEY(c_no) REFERENCES course(no), -- 设置 s_no, c_no 为联合主键 PRIMARY KEY(s_no, c_no));-- 查看所有表SHOW TABLES;-- 添加学生表数据INSERT INTO student VALUES('101', '曾华', '男', '1977-09-01', '95033');INSERT INTO student VALUES('102', '匡明', '男', '1975-10-02', '95031');INSERT INTO student VALUES('103', '王丽', '女', '1976-01-23', '95033');INSERT INTO student VALUES('104', '李军', '男', '1976-02-20', '95033');INSERT INTO student VALUES('105', '王芳', '女', '1975-02-10', '95031');INSERT INTO student VALUES('106', '陆军', '男', '1974-06-03', '95031');INSERT INTO student VALUES('107', '王尼玛', '男', '1976-02-20', '95033');INSERT INTO student VALUES('108', '张全蛋', '男', '1975-02-10', '95031');INSERT INTO student VALUES('109', '赵铁柱', '男', '1974-06-03', '95031');-- 添加教师表数据INSERT INTO teacher VALUES('804', '李诚', '男', '1958-12-02', '副教授', '计算机系');INSERT INTO teacher VALUES('856', '张旭', '男', '1969-03-12', '讲师', '电子工程系');INSERT INTO teacher VALUES('825', '王萍', '女', '1972-05-05', '助教', '计算机系');INSERT INTO teacher VALUES('831', '刘冰', '女', '1977-08-14', '助教', '电子工程系');-- 添加课程表数据INSERT INTO course VALUES('3-105', '计算机导论', '825');INSERT INTO course VALUES('3-245', '操作系统', '804');INSERT INTO course VALUES('6-166', '数字电路', '856');INSERT INTO course VALUES('9-888', '高等数学', '831');-- 添加添加成绩表数据INSERT INTO score VALUES('103', '3-105', '92');INSERT INTO score VALUES('103', '3-245', '86');INSERT INTO score VALUES('103', '6-166', '85');INSERT INTO score VALUES('105', '3-105', '88');INSERT INTO score VALUES('105', '3-245', '75');INSERT INTO score VALUES('105', '6-166', '79');INSERT INTO score VALUES('109', '3-105', '76');INSERT INTO score VALUES('109', '3-245', '68');INSERT INTO score VALUES('109', '6-166', '81');-- 查看表结构mysql> SELECT * FROM course;+-------+-----------------+------+| no | name | t_no |+-------+-----------------+------+| 3-105 | 计算机导论 | 825 || 3-245 | 操作系统 | 804 || 6-166 | 数字电路 | 856 || 9-888 | 高等数学 | 831 |+-------+-----------------+------+4 rows in set (0.00 sec)mysql> SELECT * FROM score;+------+-------+--------+| s_no | c_no | degree |+------+-------+--------+| 103 | 3-105 | 92 || 103 | 3-245 | 86 || 103 | 6-166 | 85 || 105 | 3-105 | 88 || 105 | 3-245 | 75 || 105 | 6-166 | 79 || 109 | 3-105 | 76 || 109 | 3-245 | 68 || 109 | 6-166 | 81 |+------+-------+--------+9 rows in set (0.00 sec)mysql> SELECT * FROM student;+-----+-----------+-----+------------+-------+| no | name | sex | birthday | class |+-----+-----------+-----+------------+-------+| 101 | 曾华 | 男 | 1977-09-01 | 95033 || 102 | 匡明 | 男 | 1975-10-02 | 95031 || 103 | 王丽 | 女 | 1976-01-23 | 95033 || 104 | 李军 | 男 | 1976-02-20 | 95033 || 105 | 王芳 | 女 | 1975-02-10 | 95031 || 106 | 陆军 | 男 | 1974-06-03 | 95031 || 107 | 王尼玛 | 男 | 1976-02-20 | 95033 || 108 | 张全蛋 | 男 | 1975-02-10 | 95031 || 109 | 赵铁柱 | 男 | 1974-06-03 | 95031 |+-----+-----------+-----+------------+-------+9 rows in set (0.00 sec)mysql> SELECT * FROM teacher;+-----+--------+-----+------------+------------+-----------------+| no | name | sex | birthday | profession | department |+-----+--------+-----+------------+------------+-----------------+| 804 | 李诚 | 男 | 1958-12-02 | 副教授 | 计算机系 || 825 | 王萍 | 女 | 1972-05-05 | 助教 | 计算机系 || 831 | 刘冰 | 女 | 1977-08-14 | 助教 | 电子工程系 || 856 | 张旭 | 男 | 1969-03-12 | 讲师 | 电子工程系 |+-----+--------+-----+------------+------------+-----------------+4 rows in set (0.00 sec) 基础查询-- 查询 student 表的所有行SELECT * FROM student;-- 查询 student 表中的 name、sex 和 class 字段的所有行SELECT name, sex, class FROM student;-- 查询 teacher 表中不重复的 department 列-- department: 去重查询SELECT DISTINCT department FROM teacher;-- 查询 score 表中成绩在60-80之间的所有行（区间查询和运算符查询）-- BETWEEN xx AND xx: 查询区间, AND 表示 \"并且\"SELECT * FROM score WHERE degree BETWEEN 60 AND 80;SELECT * FROM score WHERE degree > 60 AND degree < 80;-- 查询 score 表中成绩为 85, 86 或 88 的行-- IN: 查询规定中的多个值SELECT * FROM score WHERE degree IN (85, 86, 88);-- 查询 student 表中 '95031' 班或性别为 '女' 的所有行-- or: 表示或者关系SELECT * FROM student WHERE class = '95031' or sex = '女';-- 以 class 降序的方式查询 student 表的所有行-- DESC: 降序，从高到低-- ASC（默认）: 升序，从低到高SELECT * FROM student ORDER BY class DESC;SELECT * FROM student ORDER BY class ASC;-- 以 c_no 升序、degree 降序查询 score 表的所有行SELECT * FROM score ORDER BY c_no ASC, degree DESC;-- 查询 \"95031\" 班的学生人数-- COUNT: 统计SELECT COUNT(*) FROM student WHERE class = '95031';-- 查询 score 表中的最高分的学生学号和课程编号（子查询或排序查询）。-- (SELECT MAX(degree) FROM score): 子查询，算出最高分SELECT s_no, c_no FROM score WHERE degree = ( SELECT MAX(degree) FROM score);-- 排序查询-- LIMIT r, n: 表示从第r行开始，查询n条数据SELECT s_no, c_no, degree FROM score ORDER BY degree DESC LIMIT 0, 1; 分组查询 查询每门课的平均成绩-- AVG: 平均值SELECT AVG(degree) FROM score WHERE c_no = '3-105';SELECT AVG(degree) FROM score WHERE c_no = '3-245';SELECT AVG(degree) FROM score WHERE c_no = '6-166';-- GROUP BY: 分组查询SELECT c_no, AVG(degree) FROM score GROUP BY c_no;-- 计算每一门课程拥有的报名人数，这里以c_no分组，其他列默认选第一条数据的内容mysql> select c_no,s_no,degree, COUNT(c_no) from score group by c_no;+-------+------+--------+-------------+| c_no | s_no | degree | COUNT(c_no) |+-------+------+--------+-------------+| 3-105 | 103 | 92 | 3 || 3-245 | 103 | 86 | 3 || 6-166 | 103 | 85 | 3 |+-------+------+--------+-------------+3 rows in set (0.00 sec) 查询 score 表中至少有 2 名学生选修，并以 3 开头的课程的平均分数。简答的分析一下，首先是求平均数 avg(degree)其次是以课程为分组 group by c_no然后是 2名以上学生参加 3开头的课程mysql> select avg(degree) from score group by c_no having c_no like '3%' and count(c_no)>2;+-------------+| avg(degree) |+-------------+| 85.3333 || 76.3333 |+-------------+ 多表查询 查询所有学生的 name，以及该学生在 score 表中对应的 c_no 和 degree 。-- 查看所有学生mysql> select * from student;+-----+-----------+-----+------------+-------+| no | name | sex | birthday | class |+-----+-----------+-----+------------+-------+| 101 | 曾华 | 男 | 1977-09-01 | 95033 || 102 | 匡明 | 男 | 1975-10-02 | 95031 || 103 | 王丽 | 女 | 1976-01-23 | 95033 || 104 | 李军 | 男 | 1976-02-20 | 95033 || 105 | 王芳 | 女 | 1975-02-10 | 95031 || 106 | 陆军 | 男 | 1974-06-03 | 95031 || 107 | 王尼玛 | 男 | 1976-02-20 | 95033 || 108 | 张全蛋 | 男 | 1975-02-10 | 95031 || 109 | 赵铁柱 | 男 | 1974-06-03 | 95031 |+-----+-----------+-----+------------+-------+9 rows in set (0.00 sec)-- 查询所有成绩mysql> select * from score;+------+-------+--------+| s_no | c_no | degree |+------+-------+--------+| 103 | 3-105 | 92 || 103 | 3-245 | 86 || 103 | 6-166 | 85 || 105 | 3-105 | 88 || 105 | 3-245 | 75 || 105 | 6-166 | 79 || 109 | 3-105 | 76 || 109 | 3-245 | 68 || 109 | 6-166 | 81 |+------+-------+--------+9 rows in set (0.00 sec) 其中这里no与score中的s_no做了对应,首先做一个聚合，8*8一共会出现81条数据然后在做条件筛选mysql > select s_no,no,name from student,score ;...81 rows in set (0.00 sec)mysql> select name,c_no,degree from student,score where student.no = score.s_no ;+-----------+-------+--------+| name | c_no | degree |+-----------+-------+--------+| 王丽 | 3-105 | 92 || 王丽 | 3-245 | 86 || 王丽 | 6-166 | 85 || 王芳 | 3-105 | 88 || 王芳 | 3-245 | 75 || 王芳 | 6-166 | 79 || 赵铁柱 | 3-105 | 76 || 赵铁柱 | 3-245 | 68 || 赵铁柱 | 6-166 | 81 |+-----------+-------+--------+ 查询所有学生的 no 、课程名称 ( course 表中的 name ) 和成绩 ( score 表中的 degree ) 列。mysql> select * from course;+-------+-----------------+------+| no | name | t_no |+-------+-----------------+------+| 3-105 | 计算机导论 | 825 || 3-245 | 操作系统 | 804 || 6-166 | 数字电路 | 856 || 9-888 | 高等数学 | 831 |+-------+-----------------+------+4 rows in set (0.01 sec)mysql> select * from score;+------+-------+--------+| s_no | c_no | degree |+------+-------+--------+| 103 | 3-105 | 92 || 103 | 3-245 | 86 || 103 | 6-166 | 85 || 105 | 3-105 | 88 || 105 | 3-245 | 75 || 105 | 6-166 | 79 || 109 | 3-105 | 76 || 109 | 3-245 | 68 || 109 | 6-166 | 81 |+------+-------+--------+9 rows in set (0.00 sec) -- 增加一个查询字段 name，分别从 score、course 这两个表中查询。-- as 表示取一个该字段的别名。SELECT s_no, name as c_name, degree FROM score, courseWHERE score.c_no = course.no;+------+-----------------+--------+| s_no | c_name | degree |+------+-----------------+--------+| 103 | 计算机导论 | 92 || 105 | 计算机导论 | 88 || 109 | 计算机导论 | 76 || 103 | 操作系统 | 86 || 105 | 操作系统 | 75 || 109 | 操作系统 | 68 || 103 | 数字电路 | 85 || 105 | 数字电路 | 79 || 109 | 数字电路 | 81 |+------+-----------------+--------+ 查询所有学生的 name 、课程名 ( course 表中的 name ) 和 degree 。由于name字段名在student表中以及course表中都出现过了，因此使用 “表名.字段名 as 别名” 代替。mysql> SELECT student.name as s_name, course.name as c_name, degree -> FROM student, score, course -> WHERE student.NO = score.s_no -> AND score.c_no = course.no;+-----------+-----------------+--------+| s_name | c_name | degree |+-----------+-----------------+--------+| 王丽 | 计算机导论 | 92 || 王芳 | 计算机导论 | 88 || 赵铁柱 | 计算机导论 | 76 || 王丽 | 操作系统 | 86 || 王芳 | 操作系统 | 75 || 赵铁柱 | 操作系统 | 68 || 王丽 | 数字电路 | 85 || 王芳 | 数字电路 | 79 || 赵铁柱 | 数字电路 | 81 |+-----------+-----------------+--------+9 rows in set (0.00 sec) 子查询 查询 95031 班学生每门课程的平均成绩 SELECT c_no, AVG(degree) FROM scoreWHERE s_no IN (SELECT no FROM student WHERE class = '95031')GROUP BY c_no;+-------+-------------+| c_no | AVG(degree) |+-------+-------------+| 3-105 | 82.0000 || 3-245 | 71.5000 || 6-166 | 80.0000 |+-------+-------------+ 首先筛选出课堂号为 3-105 ，在找出所有成绩高于 109 号同学的的行。 mysql> select * from score where c_no = 3-105 and degree >(select degree from score where s_no = 109 and c_no = '3-105');+------+-------+--------+| s_no | c_no | degree |+------+-------+--------+| 103 | 3-105 | 92 || 105 | 3-105 | 88 |+------+-------+--------+2 rows in set (0.00 sec) 查询所有成绩高于109号同学的3-105课程成绩记录 -- 不限制课程号，只要成绩大于109号同学的3-105课程成绩就可以。SELECT * FROM scoreWHERE degree > (SELECT degree FROM score WHERE s_no = '109' AND c_no = '3-105'); YEAR 函数与带 IN 关键字查询 查询所有和 101 、108 号学生同年出生的 no 、name 、birthday 列。SELECT no, name, birthday FROM studentWHERE YEAR(birthday) IN (SELECT YEAR(birthday) FROM student WHERE no IN (101, 108)); 多层嵌套子查询 查询 ‘张旭’ 教师任课的学生成绩表。先查询老师的id 然后通过反查课程id 再通过课程id反查成绩mysql> SELECT * FROM score WHERE c_no = ( -> SELECT no FROM course WHERE t_no = ( -> SELECT no FROM teacher WHERE NAME = '张旭' -> ) -> );+------+-------+--------+| s_no | c_no | degree |+------+-------+--------+| 103 | 6-166 | 85 || 105 | 6-166 | 79 || 109 | 6-166 | 81 |+------+-------+--------+3 rows in set (0.00 sec) 查询某选修课程多于5个同学的教师姓名SELECT name FROM teacher WHERE no IN ( -- 最终条件 SELECT t_no FROM course WHERE no IN ( SELECT c_no FROM score GROUP BY c_no HAVING COUNT(*) > 5 )); 查询 “计算机系” 课程的成绩表。-- 根据筛选出来的课程号查询成绩表SELECT * FROM score WHERE c_no IN ( SELECT no FROM course WHERE t_no IN ( SELECT no FROM teacher WHERE department = '计算机系' ));+------+-------+--------+| s_no | c_no | degree |+------+-------+--------+| 103 | 3-245 | 86 || 105 | 3-245 | 75 || 109 | 3-245 | 68 || 101 | 3-105 | 90 || 102 | 3-105 | 91 || 103 | 3-105 | 92 || 104 | 3-105 | 89 || 105 | 3-105 | 88 || 109 | 3-105 | 76 |+------+-------+--------+ UNION 和 NOTIN 的使用 查询 计算机系 与 电子工程系 中的不同职称的教师。-- NOT: 代表逻辑非SELECT * FROM teacher WHERE department = '计算机系' AND profession NOT IN ( SELECT profession FROM teacher WHERE department = '电子工程系')-- 合并两个集UNIONSELECT * FROM teacher WHERE department = '电子工程系' AND profession NOT IN ( SELECT profession FROM teacher WHERE department = '计算机系'); ANY 表示至少一个 - DESC ( 降序 ) 查询课程 3-105 且成绩 至少 高于 3-245 的 score 表。-- ANY: 符合SQL语句中的任意条件。-- 也就是说，在 3-105 成绩中，只要有一个大于从 3-245 筛选出来的任意行就符合条件，-- 最后根据降序查询结果。SELECT * FROM score WHERE c_no = '3-105' AND degree > ANY( SELECT degree FROM score WHERE c_no = '3-245') ORDER BY degree DESC;+------+-------+--------+| s_no | c_no | degree |+------+-------+--------+| 103 | 3-105 | 92 || 105 | 3-105 | 88 || 109 | 3-105 | 76 |+------+-------+--------+ 表示所有的 ALL 查询课程 3-105 且成绩高于 3-245 的 score 表。-- 只需对上一道题稍作修改。-- ALL: 符合SQL语句中的所有条件。-- 也就是说，在 3-105 每一行成绩中，都要大于从 3-245 筛选出来全部行才算符合条件。SELECT * FROM score WHERE c_no = '3-105' AND degree > ALL( SELECT degree FROM score WHERE c_no = '3-245');+------+-------+--------+| s_no | c_no | degree |+------+-------+--------+| 103 | 3-105 | 92 || 105 | 3-105 | 88 |+------+-------+--------+2 rows in set (0.00 sec) 条件加组筛选 查询 student 表中至少有 2 名男生的 class 。SELECT class FROM student WHERE sex = '男' GROUP BY class HAVING COUNT(*) > 1; NOTLIKE 模糊查询取反查询 student 表中不姓 “王” 的同学记录。 -- NOT: 取反-- LIKE: 模糊查询mysql> SELECT * FROM student WHERE name NOT LIKE '王%';+-----+-----------+-----+------------+-------+| no | name | sex | birthday | class |+-----+-----------+-----+------------+-------+| 101 | 曾华 | 男 | 1977-09-01 | 95033 || 102 | 匡明 | 男 | 1975-10-02 | 95031 || 104 | 李军 | 男 | 1976-02-20 | 95033 || 106 | 陆军 | 男 | 1974-06-03 | 95031 || 108 | 张全蛋 | 男 | 1975-02-10 | 95031 || 109 | 赵铁柱 | 男 | 1974-06-03 | 95031 || 110 | 张飞 | 男 | 1974-06-03 | 95038 |+-----+-----------+-----+------------+-------+ YEAR 与 NOW 函数查询 student 表中每个学生的姓名和年龄。 -- 使用函数 YEAR(NOW()) 计算出当前年份，减去出生年份后得出年龄。SELECT name, YEAR(NOW()) - YEAR(birthday) as age FROM student;+-----------+------+| name | age |+-----------+------+| 曾华 | 42 || 匡明 | 44 || 王丽 | 43 || 李军 | 43 || 王芳 | 44 || 陆军 | 45 || 王尼玛 | 43 || 张全蛋 | 44 || 赵铁柱 | 45 || 张飞 | 45 |+-----------+------+ MAX 与 MIN 函数查询 student 表中最大和最小的 birthday 值。 SELECT MAX(birthday), MIN(birthday) FROM student;+---------------+---------------+| MAX(birthday) | MIN(birthday) |+---------------+---------------+| 1977-09-01 | 1974-06-03 |+---------------+---------------+ https://github.com/hjzCy/sql_node/blob/master/mysql/MySQL%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.mdhttps://www.bilibili.com/video/av39807944?p=23","link":"/posts/8e40d0ad/"},{"title":"mysql错误","text":"learn mysql📚 mysql错误mysql错误合集 mysql插入汉字的问题 创建数据库时使用utf8 CREATE DATABASE `mydb` CHARACTER SET utf8 COLLATE utf8_general_ci; 初始化服务器的密码问题MySQL服务器初始化（从MySQL 5.7开始）：在服务器初始启动时，如果服务器的数据目录为空，则会发生以下情况： 服务器初始化 在数据目录中生成SSL证书和密钥文件。 该validate_password插件安装并启用。 创建超级用户‘root’@’localhost’,超级用户的密码被设置并存储在错误日志文件中。 查询超级用户的密码 sudo grep 修改密码 -- 先登陆mysql -uroot -p123456-- 修改密码alter user 'root'@'localhost' identified by '123456';flush all privileges 修改密码出现simple password not passERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement. 解决方法,先修改密码策略 show variables like '%password%';set global validate_password_policy=0;set global validate_password_length=4; 忘记登陆密码 解决方法: -- 关闭mysqlsystemctl stop mysqld-- 在/etc/my.conf中添加在[mysqld]的段中加上一句：skip-grant-tables-- 重启systemctl restart mysqld-- 进入mysqlmysql-- 设置密码update user set authentication_string=password('123abc') where user='root';flush all privileges;-- 授予主机权限grant all pirvileges on *.* to 'root'@'localhost' identified by 'mysqlpassword';flush all privileges;-- 退出mysql 关闭mysql 删除skip-grant-tables 重新启动 root用户无法远程登陆 GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;flush privileges; mysql无法插入汉字 查看数据库 show VARIABLES like \"character%\"; 如果数据不重要的话，一劳永逸的解决办法是，使用 alert database tuanplus character set utf8 更改数据库的编码格式，再重新建表。 alert database tuanplus character set utf8; -- 这里tuanplus是数据库 如果项目中的数据是重要数据的话，使用 alter table address convert to character set utf8 转换需要插入汉字的数据表编码为utf8即可（此例中的数据表是address）: alter table address convert to character set utf8; -- 这里address 是表set character_set_results=utf8;set character_set_database=utf8;set character_set_server=utf8;set character_set_connection=utf8;set character_set_client=utf8; 但重启mysql服务后，又还原了，得添加my.ini文件。然后再重启。","link":"/posts/2db76fd/"},{"title":"linux故障问题及解决方案","text":"linux故障问题及解决方案linux系统使用过程中 会遇到很多的故障和报错，与之对应的是一些快速的解决方案这里记录一下 忘记root密码，无法登陆服务器 centos7 解决方案 重启服务器 进入启动界面后选择e进入编辑引导 修改内容,在尾部添加rd.breaklinux16 /vmlinuz-3.10.0-123.el7.x86_64 root=UUID=449d53d1-84c2-40c0-b05e-d1900591d71b ro rd.lvm.lv=vg_kvm7usb/swap crashkernel=auto vconsole.keymap=us crashkernel=auto vconsole.font=latarcyrheb-sun16 rd.lvm.lv=vg_kvm7usb/root rhgb quiet LANG=en_US.UTF-8 rd.break ctrl+x 以当前设定开机开机后的互动式命令环境，並不是正常开机的系統，正常开机系統挂载在 /sysboo 且挂载成只读，必須重新挂载成可写入，才能修改密碼 重新挂在 /sysroot 并改成可读可写mount –o remount,rw /sysroot chroot 工作目录到/sysrootchroot /sysroot 设定新的root 密码passwd rootupyun1upyun1 在此情況下，SELinux 並沒有启动，对所有文件的更改，可能会造成文档的context 不正确，为确保开机时重新设定SELinux context，必須在根目录下添加隐藏文件.autorelabel。 避开selinuxtouch /.autorelabel 重启reboot centos7 解决方案二 重启服务器 按e编辑引导 修改re 为 rw 添加 init=/bin/bash linux16 /vmlinuz-3.10.0-123.el7.x86_64 root=UUID=449d53d1-84c2-40c0-b05e-d1900591d71b rw rd.lvm.lv=vg_kvm7usb/swap crashkernel=auto vconsole.keymap=us crashkernel=auto vconsole.font=latarcyrheb-sun16 rd.lvm.lv=vg_kvm7usb/root rhgb quiet LANG=en_US.UTF-8 init=/bin/bash ctrl+x 以当前设定开机 重置密码passwd rootupyun1upyun1 避开selinuxtouch /.autorelabel 重启exec /sbin/init","link":"/posts/bc3af3e9/"},{"title":"linux磁盘管理2","text":"learn linux linux磁盘和文件系统swap 有什么用 内存交换空间(swap)为了防止某个程序过度或者说在某一个非常短的时间内用掉了额你大部分的内存，那你的系统恐怕会有损坏的情况。于是linux在安装的时候就被规定需要划分两个扇区1.根目录2.swap 内存交换空间 swap是如何工作的首先在内存足够的情况下,系统不会去调用swap中的内存，但是一旦内存不足时，就会把内存中暂时不实用的程序与数据放到swap中，此时主机的磁盘灯就会开始闪 创建内存交换空间(swap) 使用实体分区创建swap 使用虚拟内存创建swap 使用实体分区创建swap首先我们需要在磁盘中划分出一块分区作为swap fdisk /dev/sde设备 Boot Start End Blocks Id System/dev/sde1 2048 1026047 512000 83 Linux 其次我们需要对这个分区进行格式化 生成我们需要的文件系统mkswap [root@test-ceph ~]# mkswap /dev/sde1正在设置交换空间版本 1，大小 = 16380 KiB无标签，UUID=e9b11822-d90f-4fb4-9884-e2c3ae3c9dc6[root@test-ceph ~]# blkid /dev/sde1/dev/sde1: UUID=\"e9b11822-d90f-4fb4-9884-e2c3ae3c9dc6\" TYPE=\"swap\" 检测,首先我们可以用free来查看下当前swap的使用情况 [root@test-ceph ~]# free total used free shared buff/cache availableMem: 16202644 317340 15316776 17188 568528 15557328Swap: 8191996 0 8191996 used 是0 ,他的总量是8191996,接下来我们挂载这个新建的swap,这里不是使用mount 而是用swapon与swapoff swap /dev/sde1[root@test-ceph ~]# free total used free shared buff/cache availableMem: 16202644 316220 15317572 17188 568852 15558420Swap: 8208376 0 8208376 free的量已经上升了查看交换分区由哪些构成 [root@test-ceph ~]# swapon -s文件名 类型 大小 已用 权限/dev/dm-1 partition 8191996 0 -2/dev/sde1 partition 16380 0 -3 设置开机自动挂载 UUID=\"e9b11822-d90f-4fb4-9884-e2c3ae3c9dc6\" swap swap defaults 0 0","link":"/posts/af2754a4/"},{"title":"linux周期性任务","text":"learn linux linux任务型工作在linux长时间的工作中，为了各种各样的任务，我们把它分成两种任务形式 例行性任务调度，每隔一定周期执行任务 触发型或者说突发型任务调度 Linux下的定时任务什么是croncron是大多数linux发行版都自带的守护进程（daemon），用来重复运行某些被设定好了确定的运行时间的任务，这些任务可以是每个月运行、每周运行、每天运行，甚至是每一分钟运行。用cron执行的任务适合于24小时运行的机器，cron执行的任务会在设定好的时刻执行，当机器处于关机状态下并错过了任务执行的时间，cron任务就无法预期执行了。 什么是crontabcrontab(cron table的简称)既可以指cron用来定期执行特定任务所需要的列表文件，又可以指用来创建、删除、查看当前用户（或者指定用户）的crontab文件的命令。 什么是anacronanacron不是守护进程，可以看做是cron守护进程的某种补充程序，anacron是独立的linux程序，被cron守护进程或者其他开机脚本启动运行，可以每天、每周、每个月周期性地执行一项任务（最小单位为天）。适合于可能经常会关机的机器，当机器重新开机anacron程序启动之后，anacron会检查anacron任务是否在合适的周期执行了，如果未执行则在anacron设定好的延迟时间之后只执行一次任务，而不管任务错过了几次周期。举个例子，比如你设定了一个每周备份文件的任务，但是你的电脑因为你外出度假而处于关机状态四周，当你回到家中开机后，anacron会在延迟一定时间之后只备份一次文件。由于发行版的不同，cron守护进程如何运行anacron会有所不同。 编辑定时任务根据上面的介绍，我们可以发现cron只是一个工具，他通过被crond调用，调用定时任务并且执行这些任务，而crontab便是用来收集这些定时任务列表的工具在Centos7中,我们可以调用crond(后台守护进程名称，d表是daemon)来控制cron # 查看crondsystemctl | grep crond# 开启crondsystemctl start crond.service# 关闭crondsystemctl stop cornd.service# 重启crondsystemctl restart crond.service crontab开启cron定时任务之后，我们需要向定时列表中添加任务，这时候我们就要使用到我们的crontab # 查看现有的任务crontab -l 添加定时任务 # 进入任务列表crontab -e# 先写好.cron文件使用crontab 加入crontab jobs.cron# 删除所有定时任务crontab -r# 查看作业日志ls /var/log | grep cron# 任务编写格式# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 编写的格式基本如上所示，但是在不同的cron应用存在很大的差异，比如js中的cron模块 * 任意时间点都执行 ？ 不指定，任意。仅用于 日(月)和日(周)。0 0 5 * ? 代表每个月的第5天零点，不论星期几。0 0 ? * 1 代表每周一，不论是当月的哪天。 , 多个值的分隔符，比如 ? 1,5,10 * * * 表示每天的1点5点和10点 - 代表连续值 比如 ? 1-20 * * * 表示每天的1-20点 / 代表步长 比如 ？1/2 * * * 表示每天从1点开始过两个小时执行1次 */1 * * * * 每分钟执行一次 L 最后一天。可以是每月的最后一天或者每周的最后一天。如果用在 天(周)字段，并且前面加数字，则表示最后一个周N。例如5L，表示最后一个周五（5表示周五，L表示最后）。 W 工作日，指周一到周五的任意一天 # 表示第几个的意思，例如 6#3，表示当月第3个星期六（6表示周六，3表示第3个） crontab实例* * * * * echo 'xxx' > xx.log 每分钟执行后一次*/1 * * * * echo 'xxx' > xxx.log 每分钟执行一次30 * * * * echo 'xxx' > xxx.log 每30分钟执行一次0/5 * * * * 每5分钟执行一次，且仅在0,5,15,20...55分执行5 0 * * * 每天的00:05执行一次 注意添加定时任务时，最好不要在crontab -e下编辑任务列表，因为crontab -e只会记录当前登录用户的定时列表更好的解决办法是： 由于cron每次执行都会查询一边/var/spool/cron下的文件或者/etc/cron.d/下的cron文件，因此可以在/etc/cron.d/下创建一个用于记录定时列表的文件，然后重启crond服务","link":"/posts/af2754a4/"},{"title":"linux磁盘管理","text":"learn linux linux磁盘管理主要记录的是centos系统从分区开始到文件系统的初始化再到挂载和卸载1.磁盘的结构，什么是分区2.管理分区,文件系统格式化3.文件的挂载，以及自动挂载文件 磁盘磁盘结构以及磁盘分区机械硬盘(HHD): 1.传统磁盘 2 主要是由盘片，磁头以及盘片转轴组成 3 传输速度较慢固态硬盘(SSD): 1. 固态电子存储芯片阵列而制成 2.传输速度快 相较于HDD,SSD 在防震抗摔、传输速率、功耗、重量、噪音上有明显优势，SSD 传输速率性能是HDD 的2倍相较于SSD,HDD 在价格、容量、使用寿命上占有绝对优势。 磁盘接口不同的磁盘接口在linux的命名也不一样， SATA盘在linux中的名称是sda-sdz IDE接口的硬盘在linux中的名称为hda-hdz 常用语head 磁头track 磁道cylinder 柱面sector 扇区 分区方式MBR(Master Boot Record )分区方式 主引导记录，分区不超过2T，分区工具用fdiskGPT 支持128个分区 分区为2T以上的硬盘 分区工具用 gdisk 磁盘的物理组成部分？ 磁盘的分区linux下的分区有三种: 主分区，扩展分区和逻辑分区其中主分区最多只能有四个,扩展分区最多只有一个，主分区加扩展分区最多有四个prime为主分区，extend为扩展分区，分区总数最多4个。扩展分区不能写入数据只能包含逻辑分区逻辑分区可以写入数据和格式化http://img.noback.top/blog/img20191107/linux当我们已经创建了3个主分区和一个扩展分区之后，再次创建的时候会要求我们的扩展分区中创建逻辑分区。扩展分区是指一块被分成很多块区域的总和，但它其实并没有空间，只是一个统称。 扩展分区和主分区有什么区别和用处吗，为什么不直接规定能够创建4个主分区，不需要扩展分区 管理磁盘分区lsblk命令的英文是“list block”，即用于列出所有存储设备的信息，而且还能显示他们之间的依赖关系，但是它不会列出RAM盘的信息。除了lsblk外，fdisk -l 以及 cat /proc/partitions 也都可以列出块设备，另外blkid 可以查看设备的uuid数据 lsblk [参数] -d 仅列出磁盘本身-a 显示所有设备-f 显示文件系统信息-m 显示权限信息(rwx等)-l 以列表格式显示 默认以目录树形式显示-P 使用key=\"value\"格式显示-r 使用原始格式显示 -t 使用拓扑结构显示[root@test-ceph ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 447.1G 0 disk├─sda1 8:1 0 200M 0 part /boot/efi├─sda2 8:2 0 1G 0 part /boot└─sda3 8:3 0 446G 0 part ├─centos-root 253:0 0 50G 0 lvm / ├─centos-swap 253:1 0 7.8G 0 lvm [SWAP] └─centos-home 253:2 0 388.1G 0 lvm /homesdc 8:32 0 1.8T 0 disk└─sdc1 8:33 0 500M 0 partsdd 8:48 0 1.8T 0 disk[root@test-ceph ~]# blkid/dev/mapper/centos-root: UUID=\"2150883c-9314-4a74-be7e-9edf9f7ea5b7\" TYPE=\"xfs\"/dev/sda3: UUID=\"g0LdqD-NzAO-dxtL-GfHa-Yo93-rx84-axOrFw\" TYPE=\"LVM2_member\" PARTUUID=\"8e5051e5-fb1c-4176-a3b2-15a60633aa42\"/dev/mapper/centos-home: UUID=\"936625a5-486e-4984-92d4-f2dae5f5bda7\" TYPE=\"xfs\"/dev/sdd1: UUID=\"c1f2819c-4422-41bf-a0a0-5739732c236e\" TYPE=\"ext4\" NAME: 设备文件名MAJ:MIN 主要次要设备RM 是否为可卸载设备 0为否 1为是SIZE 容量RO 是否为可读设备TYPE 磁盘种类 disk磁盘 partition分区 rom只读存储器 lvm 逻辑分区MOUNTPOINT 挂载点 对磁盘进行分区磁盘分区主要使用到两个命令 分别是fdisk和gdisk fdiskfdisk是linux下硬盘的分区工具，但是fdisk只能划分小于2T的分区，如果大于2T则需要使用parted [root@gogogo ~]# fdisk --help用法： fdisk [选项] 更改分区表 fdisk [选项] -l 列出分区表 fdisk -s 给出分区大小(块数)选项： -b 扇区大小(512、1024、2048或4096) -c[=] 兼容模式：“dos”或“nondos”(默认) -h 打印此帮助文本 -u[=] 显示单位：“cylinders”(柱面)或“sectors”(扇区，默认) -v 打印程序版本 -C 指定柱面数 -H 指定磁头数 -S 指定每个磁道的扇区数 -l 后边不跟设备名会直接列出系统中所有的磁盘设备以及分区表，加上设备名会列出该设备的分区表 [root@gogogo ~]# fdisk -l磁盘 /dev/vda：21.5 GB, 21474836480 字节，41943040 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x0000aebb 设备 Boot Start End Blocks Id System/dev/vda1 * 2048 41929649 20963801 83 Linux磁盘 /dev/vdb：42.9 GB, 42949672960 字节，83886080 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节 如上表示有两块磁盘，其中磁盘vda有一个分区 [root@gogogo ~]# fdisk -l /dev/vda磁盘 /dev/vda：21.5 GB, 21474836480 字节，41943040 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0x0000aebb 设备 Boot Start End Blocks Id System/dev/vda1 * 2048 41929649 20963801 83 Linux 使用fdisk对小于2T的盘进行分区，fdisk 如果不加 “-l” 则进入另一个模式，在该模式下，可以对磁盘进行分区操作。 [root@gogogo ~]# fdisk /dev/vdb欢迎使用 fdisk (util-linux 2.23.2)。更改将停留在内存中，直到您决定将更改写入磁盘。使用写入命令前请三思。Device does not contain a recognized partition table使用磁盘标识符 0xa813628c 创建新的 DOS 磁盘标签。命令(输入 m 获取帮助)：命令(输入 m 获取帮助)：m a toggle a bootable flag # 一个可引导的标识 b edit bsd disklabel # 编辑bsd磁碟标签 d delete a partition # 删除一个分区 g create a new empty GPT partition table # 创建一个新的空GPT分区表 l list known partition types # 列出已知的分区类型 m print this menu # 打印这个菜单 n add a new partition # 增加一个新分区 p print the partition table # 打印分区表 q quit without saving changes # 在没有保存更改的情况下退出 t change a partitions system id # 改变分区的系统id 另外一种磁盘分区的方式 parted gdiskhttps://blog.csdn.net/qq_44714603/article/details/88659996https://www.cnblogs.com/huyuanblog/p/10120460.html linux文件系统在linux中所有硬盘都可以被看成一个一个的文件，使用者可以像访问文件一样浏览整个硬盘中的内容。因此这是硬盘转变称为文件需要做的内容.由于版本的更迭不断的更新.在Centos7中已经使用xfs作为默认的文件系统,而在这之前还有ext家族，对于xfs文件系统来说，我们使用到的格式化工具是mkfs这个指令，也就是我们说的make filesystem 对于ext家族来说常用的工具就是mke2fs这个指令,具体的内容你可以在man他们的时候出现 [root@test-ceph ~]# man mke2fsMKE2FS(8) System Manager's Manual MKE2FS(8)NAME mke2fs - create an ext2/ext3/ext4 filesystem[root@test-ceph ~]# man mkfs MKFS(8) System Administration MKFS(8)NAME mkfs - build a Linux filesystem 查看支持的文件系统查看支持的文件系统：/lib/modules/uname –r/kernel/fs [root@test-ceph ~]# cd /lib/modules/3.10.0-957.27.2.el7.x86_64/kernel/fs[root@test-ceph fs]# lsbinfmt_misc.ko.xz cifs ext4 gfs2 mbcache.ko.xz nls udfbtrfs cramfs fat isofs nfs overlayfs xfscachefiles dlm fscache jbd2 nfs_common pstoreceph exofs fuse lockd nfsd squashfs 设备文件名linux下所有硬件都是文件，dev目录下所有文件都是硬件 [root@test-ceph dev]# ls -al | grep sdabrw-rw---- 1 root disk 8, 0 11月 8 00:26 sdabrw-rw---- 1 root disk 8, 1 11月 8 00:26 sda1brw-rw---- 1 root disk 8, 2 11月 8 00:26 sda2brw-rw---- 1 root disk 8, 3 11月 8 00:26 sda3 sda1表示第一个SATA硬盘的第一个分区 创建文件系统(格式化)文件系统的创建过程也就是对磁盘的格式化，由于不同系统之间所设置的文件属性/权限并不相同，为了能够顺利的存取这些磁盘中的数据，就要对这些磁盘进行格式化 磁盘的格式化一共分为两种，分别是低级格式化和高级格式化,其中低级格式化主要由厂商完成，也就是硬盘的磁道划分，而高级格式化由我们来完成，他又称逻辑格式化，是根据用户选定的文件系统（Linux的文件系统：EXT2/EXT3/EXT4(CentOS6.3默认)），在磁盘的特定区域写入特定数据，在分区中划出一片用于存放文件分配表/目录表等用于文件管理的磁盘空间。假设磁盘是一个柜子，就是把一个柜子分为一个个等大的小个子，再EXT4中每个数据块默认大小是4KB，这时如果有个10KB的文件要写入，就需要分配三个数据块，多余的2KB不存数据，且这三个数据块分布在柜子里的随机小格子中而不是连续排列的。磁盘碎片整理：把保存同一个文件的数据块尽量放在一起。每个文件都有一个i节点号(inode号)，通过它可以建立inode列表，查找文件时通过寻找inode号在列表中找到文件条款，从而知道文件保存在哪几个数据块，从而打开数据块拼凑成完整文件。格式化的目的不是清空数据，而是写入文件系统。 什么是文件系统较新的操作系统的文件数据除了文件实际内容外， 通常含有非常多的属性，例如 Linux 操作系统的文件权限（rwx）与文件属性（拥有者、群组、时间参数等）。 文件系统通常会将这两部份的数据分别存放在不同的区块，权限与属性放置到 inode 中，至于实际数据则放置到 data block 区块中。 另外，还有一个超级区块 （superblock） 会记录整个文件系统的整体信息，包括 inode 与 block 的总量、使用量、剩余量等。 在上面有说到三个内容，其中 inode主要记录权限和属性，一个文件占用一个inode，同时记录此文件的数据所在的 block 号码，因此在实际使用的过程中，如果发现硬盘还有很多的余地，但是却不能写入数据，那又可能是inode的数量到达了上限，导致这个的原因可能是该磁盘中的文件小而多，如何改变可以看下面mke2fs的命令 block 实际记录的文件内容，如果文件太大，则会占用过多的block superblock 记录此 filesystem 的整体信息，包括inode/block的总量、使用量、剩余量， 以及文件系统的格式与相关信息等 linux中文件系统的存储方式linux中的存储方式被称为索引式存储方式。首先是linux的文件系统，经过格式化之后，磁盘出现inode以及block，其中inode记录权限属性以及存储了数据的block的位置id，如果我们要寻找，只需要知道inode下存储数据的位置节点，就可以快速的读取的数据。对比U盘的FAT格式来说，他并没有inode存在，FAT采用的存储方式是链式存储方式，也就是当前的block的位置id被上一个block记录，并且记录了下一个 block的位置，当我们寻找位于中间编号的block块时，都必须重头开始。什么是磁盘重组磁盘重组 需要磁盘重组的原因就是文件写入的 block 太过于离散了，此时文件读取的性能将会变的很差所致。 这个时候可以通过磁盘重组将同一个文件所属的 blocks 汇整在一起，这样数据的读取会比较容易啊！因此FAT 的文件系统需要三不五时的磁盘重组一下如何有利的安置block和inode ? xfs文件系统 mkfs.xfs [选项] [设备名称] -b + block容量-f 先强制格式化本身存在的文件系统-i 指定inode大小 size=数值 最小是256bytes 最大是2K 一般保留256就行了 internal=[0|1] log设备是否为内置，默认1为内置 ext家族文件系统mke2fs在磁盘分区上创建ext2 ext3 ext4 文件系统，默认情况下创建ext2当用man查询这四个命令的帮助文档时，您会发现我们看到了同一个帮助文档，这说明四个命令是一样的。mke2fs常用的选项 -b 分区时设定每个数据区块占用空间大小，目前支持1024,2048以及4096bytes每个块-i 设定inode的大小-N 设定inode的数量，默认的inode数量不够，就可以自定设置了。-c 在格式化前先检测一下磁盘是否有问题,加上这个选项后速度执行速度会慢-L 预设该分区的标签label-t y用来指定什么类型的文件系统 比如mke2fs -t ext4 /dev/sdd3 相当于mke2fs.ext4 /dev/sdd3 e2label用来查看或修改分区的标签 [root@test-ceph ~]# e2label /dev/sdb1/hzj[root@test-ceph ~]# e2label /dev/sdb1 Label[root@test-ceph ~]# e2label /dev/sdb1Label[root@test-ceph ~]# e2label /dev/sdb1 /tt[root@test-ceph ~]# e2label /dev/sdb1/tt 操作文件系统df列出文件系统的整体磁盘使用量 df [选项] [文件] [root@gogogo ~]# df文件系统 1K-块 已用 可用 已用% 挂载点devtmpfs 992496 0 992496 0% /devtmpfs 1019000 0 1019000 0% /dev/shmtmpfs 1019000 106028 912972 11% /runtmpfs 1019000 0 1019000 0% /sys/fs/cgroup/dev/vda1 20953560 6057836 14895724 29% /tmpfs 203800 0 203800 0% /run/user/0 df默认显示块使用量，-i 显示inode信息而非块使用量 [root@gogogo ~]# df -i文件系统 Inode 已用(I) 可用(I) 已用(I)% 挂载点devtmpfs 248124 319 247805 1% /devtmpfs 254750 1 254749 1% /dev/shmtmpfs 254750 413 254337 1% /runtmpfs 254750 17 254733 1% /sys/fs/cgroup/dev/vda1 20963776 112147 20851629 1% /tmpfs 254750 1 254749 1% /run/user/0 -h 选择合适的单位显示-k 以k为单位显示-m 以m为单位显示 https://cshihong.github.io/2018/06/20/Linux%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86/ du评估文件系统的磁盘使用两 du [-abckmsh] [文件或者目录名] -a(all) 全部文件与目录大小都列出来 ,默认情况下du 就是列出所有的目录-b(bytes) 列出的值以byte为的单位输出-k -m 分别以k和以m为单位。du默认单位k-h 自动调节单位-c 最后加总-s 只列出总和 软连接与硬链接同windows中的快捷键一样，linux中也存在着两种链接 软连接与硬链接硬链接 hard line [root@test-ceph alpaca]# ln /etc/xx .[root@test-ceph alpaca]# lsxx[root@test-ceph alpaca]# ll -i /etc/xxx100781634 -rw-r--r-- 2 root root 2 11月 11 19:26 /etc/xxx[root@test-ceph alpaca]# ll -i xx100781634 -rw-r--r-- 2 root root 2 11月 11 19:26 xx 在这之后你会发现当前目录下已经存在这/etc/xx的硬链接,且他们指向的inode节点序号是相同的。当我们输入cat xxx 或者cat /etc/xxx 的时候，首先他会先去目录中寻找对应的文件名，文件名与inode有对应表，再根据对应的表去寻找对应的内容，而硬链接的创建就是在目录上多添加了一条指向与/etc/xxx相同的inode节点序号，再由inode指向对应的内容，他是在目录层面的操作，因此当我们删掉了其中一个文件的时候，你会发现另外一个文件依旧能够访问，因为他删除这个操作仅仅只是把多条指向inode节点的线路慢慢减少到一条，对文件内容并没有任何的影响。硬连接在创建的过程中，由于本身的inode节点和文间内容已经存在，所以不会增加任何内存，即使有，也很小小小小软链接 [root@test-ceph alpaca]# ln -s /etc/xxx .[root@test-ceph alpaca]# lsxx xxx[root@test-ceph alpaca]# ll -allrwxrwxrwx 1 root root 8 11月 11 19:40 xxx -> /etc/xxx[root@test-ceph alpaca]# ll -i总用量 4100781634 -rw-r--r-- 2 root root 2 11月 11 19:26 xx35994196 lrwxrwxrwx 1 root root 8 11月 11 19:40 xxx -> /etc/xxx[root@test-ceph alpaca]# ll -i /etc/xxx100781634 -rw-r--r-- 2 root root 2 11月 11 19:26 /etc/xxx 当我们用软连接的时候，我们会发现他们的inode并不相同，当我们cat xxx的时候 同样的他会先去目录中查找inode,得到软连接后的xxx文件的inode后会发现他被指向了了/etc/xxx的inode，再由/etc/xxx的inode指向最后的/etc/xxx中的内容，他们是真正意义上的共用inode，当源文件被删除的时候，软链接也所指向的inode被删除，文件内容不可达 设备挂载与卸载分区和格式化之后，你的磁盘已经是一个文件系统了，这个时候该怎么去使用呢？这就涉及到了磁盘的挂载和卸载，格式化的后的磁盘是一个块设备文件，类型为b与挂载有关的目录/mnt /dev 挂载：在linux操作系统中， 挂载是指将一个设备（通常是存储设备）挂接到一个已存在的目录上，在挂载某个分区前要先建立一个挂载点，而这个已存在目录就是我们说的挂载点，之后再把我们需要的块设备文件挂载上去。 我们要访问存储设备中的文件，必须将文件所在的分区挂载到一个已存在的目录上， 然后通过访问这个目录来访问存储设备。这个目录可以不为空，但挂载后这个目录下以前的内容将不可用,取消挂载之后文件会出现,一般情况下我们将挂载文件放置在/mnt 下面https://www.cnblogs.com/zhang-jun-jie/p/9266810.html mount命令 mount -a [选项] mount [选项] [--source] | [--target] mount [选项] mount []选项： -a, --all 挂载 fstab 中的所有文件系统 -c, --no-canonicalize 不对路径规范化 -f, --fake 空运行；跳过 mount(2) 系统调用 -F, --fork 对每个设备禁用 fork(和 -a 选项一起使用) -T, --fstab /etc/fstab 的替代文件 -h, --help 显示此帮助并退出 -i, --internal-only 不调用 mount. 助手程序 -l, --show-labels 列出所有带有指定标签的挂载 -n, --no-mtab 不写 /etc/mtab -o, --options 挂载选项列表，以英文逗号分隔 -O, --test-opts 限制文件系统集合(和 -a 选项一起使用) -r, --read-only 以只读方式挂载文件系统(同 -o ro) -t, --types 限制文件系统类型集合 --source 指明源(路径、标签、uuid) --target 指明挂载点 -v, --verbose 打印当前进行的操作 -V, --version 显示版本信息并退出 -w, --rw, --read-write 以读写方式挂载文件系统(默认) -h, --help 显示此帮助并退出 -V, --version 输出版本信息并退出 分区的自动挂载文件/etc/fstab 当系统启动的时候，系统会自动地从这个文件读取信息，并且会自动将此文件中指定的文件系统挂载到指定的目录。下面我来介绍如何在此文件下填写信息在这个文件中，规定了一些在系统启动的时候，可以自动挂载的分区 [root@test-ceph ~]# cat /etc/fstab## /etc/fstab# Created by anaconda on Fri Aug 30 03:36:37 2019## Accessible filesystems, by reference, are maintained under '/dev/disk'# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info#/dev/mapper/centos-root / xfs defaults 0 0UUID=1803ca43-a22c-4626-9ee2-f8f585847536 /boot xfs defaults 0 0UUID=944B-59F3 /boot/efi vfat umask=0077,shortname=winnt 0 0/dev/mapper/centos-home /home xfs defaults 0 0/dev/mapper/centos-swap swap swap defaults 0 0 第一列就是分区的标识，可以写分区的label，也可以写uuid,也可以写分区名。 第二列是挂载点; 第三列是分区的格式 第四列是mount的一些挂载参数 一般情况下都是default,但也有其他的async/sync 异步写入,磁盘和内存不同步，系统每隔一段时间把内存数据写入磁盘中,而sync则会同步内存和磁盘中的数据auto/noauto 开机自动挂载/不自动挂载default 按照大多数永久文件系统的缺省值挂载自定义ro 仅只读权限挂载rw 按可读可写权限挂载exec/noexec 允许/不允许文件可执行，但千万不要把根分区挂载为noexecuser/nouser 允许/不允许root外的其他用户挂载分区suid/nosuid 允许/不允许分区有suid，一般设置nosuiduserquota 启动使用者磁盘匹配额模式grquota 启动群组磁盘匹配模式 数字表示是否被dump备份，1是 0否 开机是否自检磁盘 1，2都表示检测，0表示不检测，在Redhat/CentOS中，这个1，2还有个说法，/ 分区必须设为1，而且整个fstab中只允许出现一个1，这里有一个优先级的说法。1比2优先级高，所以先检测1，然后再检测2，如果有多个分区需要开机检测那么都设置成2吧,1检测完了后会同时去检测2。 于是我们可以添加一行需要执行的分区，比如在/etc/fstab下我们添加一行/dev/sdd /test1 ext3 default 0 0 这样系统在下次开启的时候就会将这个文件挂载上了，当然我们也可以用mount -a来挂载fastab下面所有的磁盘分区实战： # 创建一个文件夹 并进入mkdir /mnt/usb && cd /mnt/usb# 挂载u盘mount /dev/sad1 /mnt/usb# 查看u盘内容ls /mnt/usb# 解挂umount /dev/sda1 /mnt/usb 实例描述一个从创建分区–>格式化–>挂载 创建分区 # 首先查看当前可用块[root@test-ceph ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsdd 8:48 0 1.8T 0 disk└─sdd1 8:49 0 100G 0 part /mnt/usb# 对块分区root@test-ceph ~]# fdisk /dev/sdd欢迎使用 fdisk (util-linux 2.23.2)。更改将停留在内存中，直到您决定将更改写入磁盘。使用写入命令前请三思。命令(输入 m 获取帮助)：nPartition type: p primary (1 primary, 0 extended, 3 free) e extendedSelect (default p): p分区号 (2-4，默认 2)：2起始 扇区 (209717248-3907029167，默认为 209717248)：将使用默认值 209717248Last 扇区, +扇区 or +size{K,M,G} (209717248-3907029167，默认为 3907029167)：+100G分区 2 已设置为 Linux 类型，大小设为 100 GiB命令(输入 m 获取帮助)：wThe partition table has been altered!Calling ioctl() to re-read partition table.WARNING: Re-reading the partition table failed with error 16: 设备或资源忙.The kernel still uses the old table. The new table will be used atthe next reboot or after you run partprobe(8) or kpartx(8)正在同步磁盘。命令(输入 m 获取帮助)：p磁盘 /dev/sdd：2000.4 GB, 2000398934016 字节，3907029168 个扇区Units = 扇区 of 1 * 512 = 512 bytes扇区大小(逻辑/物理)：512 字节 / 512 字节I/O 大小(最小/最佳)：512 字节 / 512 字节磁盘标签类型：dos磁盘标识符：0xc39fa97e 设备 Boot Start End Blocks Id System/dev/sdd1 2048 209717247 104857600 83 Linux/dev/sdd2 209717248 419432447 104857600 83 Linux 格式化 [root@test-ceph ~]# mke2fs -t ext4 /dev/sdd1mke2fs 1.42.9 (28-Dec-2013)文件系统标签=OS type: Linux块大小=4096 (log=2)分块大小=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks6553600 inodes, 26214400 blocks1310720 blocks (5.00%) reserved for the super user第一个数据块=0Maximum filesystem blocks=2174746624800 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, 4096000, 7962624, 11239424, 20480000, 23887872Allocating group tables: 完成正在写入inode表: 完成Creating journal (32768 blocks): 完成Writing superblocks and filesystem accounting information: 完成 挂载 [root@test-ceph ~]# mount /dev/sdd1 /mnt/usb[root@test-ceph ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsdd 8:48 0 1.8T 0 disk└─sdd1 8:49 0 100G 0 part /mnt/usb[root@test-ceph ~]# df -T文件系统 类型 1K-块 已用 可用 已用% 挂载点/dev/sdd1 ext4 103080888 61464 97760160 1% /mnt/usb 特殊设备loop挂载如何挂载光盘/DVD镜像文件–>来自鸟哥的linux私房菜 [root@study ~]# ll -h /tmp/CentOS-7.0-1406-x86_64-DVD.iso-rw-r--r--. 1 root root 3.9G Jul 7 2014 /tmp/CentOS-7.0-1406-x86_64-DVD.iso[root@study ~]# mkdir /data/centos_dvd[root@study ~]# mount -o loop /tmp/CentOS-7.0-1406-x86_64-DVD.iso /data/centos_dvd[root@study ~]# df /data/centos_dvdFilesystem 1K-blocks Used Available Use% Mounted on/dev/loop0 4050860 4050860 0 100% /data/centos_dvd# 就是这个项目！ .iso 镜像文件内的所有数据可以在 /data/centos_dvd 看到！[root@study ~]# ll /data/centos_dvdtotal 607-rw-r--r--. 1 500 502 14 Jul 5 2014 CentOS_BuildTag &lt;==瞧！就是DVD的内容啊！drwxr-xr-x. 3 500 502 2048 Jul 4 2014 EFI-rw-r--r--. 1 500 502 611 Jul 5 2014 EULA-rw-r--r--. 1 500 502 18009 Jul 5 2014 GPLdrwxr-xr-x. 3 500 502 2048 Jul 4 2014 images.....（下面省略）.....[root@study ~]# umount /data/centos_dvd/ 注释在正常情况下我们所创建的文件像 \\root\\hzj\\test.txt \\home\\hzj\\test.txt的数据内容是存在于引导盘，也就是你装系统的那个盘的，而挂载的其他盘可以用来做存储的作用，先挂载后移动内容","link":"/posts/af2754a4/"},{"title":"linux用户权限","text":"learn linux 无论是在linux中还是windows中，用户权限管理一直是一个很重要的问题 用户权限了解一下/etc/passwd 和 /etc/shadow用户文件 /etc/passwd在linux系统中，所创建的用户帐号和其相关信息 (密码除外) 均是存放在/etc/passwd 配置文件中。由于所有用户对 passwd文件均可读的权限，因此密码信息并未保存在该文件中，而是保存在了/etc/shadow 的配置文件中。该文件除了root用户可以修改以外，其他用户无法修改，虽然所有用户都可以查看，但是内容是md5加密后的 [root@gogogo ~]# ls -al /etc | grep passwd-rw-r--r--. 1 root root 1545 11月 7 11:43 passwd-rw-r--r--. 1 root root 1545 11月 7 11:52 passwd-[root@gogogo ~]# ls -al /etc | grep shadow----------. 1 root root 548 11月 7 11:42 gshadow----------. 1 root root 535 11月 7 11:39 gshadow-----------. 1 root root 989 11月 7 12:01 shadow----------. 1 root root 798 11月 7 11:52 shadow- 在 passwd 文件中，一行定义一个用户帐号，每行均由多个不同的字段构成，各字段值间用 “:” 分隔，每个字段均代表该帐号某方面的信息。在刚安装完成的 linux 系统中，passwd 配置文件已有很多帐号信息了，这些帐号是由系统自动创建的，他们是 linux 进程或部分服务程序正常工作所需要使用的账户，这些账户的最后一个字段的值一般为/sbin/nologin，表示该帐号不能用来登录 linux 系统。 用户账号 : 用户密码 : 用户ID : 用户组ID : 用户名全称 : 用户主目录 : 用户所使用的shell 用户账户，即你创建的账号，在刚安装好的linux中会存在一些需要的账号身份 密码由于/etc/passwd下面的每个用户都可以改，所以密码是不会放在这里的，用x占位，用户真实的密码采用MD5加密算法加密后，保存在/etc/shadow配置文件中，只有root用户可以读取。 用户id指的是用户的uid，是用户身份的标识号，比如root的身份就是0，如果你创建了一个用户hzj，并把他的uid改成0，那么系统就会认为root和hzj是同一个账户身份。0是超级用户（root）的标识号，1~499由系统保留，作为管理账号，普通用户的标识号从500开始 用户组id叫做gid,与/etc/group中对应, 同样的gid也是从500开始，划分规则和uid类似。 用户主目录表示用户登陆后所处的目录 root的目录是/root，普通用户的家目录则是/home/username,如果你需要更改，在/etc/passwd下面更改就行了 用户组账号文件 /etc/group用户组账号文件保存在/etc/group中，任何用户都可以读取 用户密码 /ect/shadow [root@gogogo etc]# ls -al /etc/ | grep shadow----------. 1 root root 523 8月 21 10:39 gshadow----------. 1 root root 513 7月 12 17:57 gshadow-----------. 1 root root 737 9月 3 14:48 shadow----------. 1 root root 737 9月 3 14:48 shadow- 你会发现他们的文件属性是0000,但是root用户可以访问和更改 用户组密码 /etc/gshadow用户组的真实密码保存在/etc/gshadow配置文件中其中第一字段表示用户组的名称，第二字段为x,第三字段为用户组的ID号，第四个为该用户组的用户成员列表，逗号隔开 文件 /etc/shells系统某些服务在运行过程中，会去检查用户能够使用的 shells，而这些 shell 的查询就是借助 /etc/shells 这个文件，我们所创建的用户所使用的shells也都存放在/etc/shells这个文件中/bin/false本身是不存在/etc/shells中的,如果要使用，可以添加进去 echo '/bin/false' > /etc/shellsecho '/bin/true' > /etc/shells /bin/false是最严格的禁止login选项，一切服务都不能用。将用户的shell设置为/bin/false,用户会无法登录,并且不会有任何提示。sbin/nologin只是不允许login系统，即使给了密码也不行。所谓“无法登陆”指的仅是这个用户无法使用bash或其他shell来登陆系统而已，并不是说这个账号就无法使用系统资源。举例来说，各个系统账号中，打印作业有lp这个账号管理，www服务器有apache这个账号管理，他们都可以进行系统程序的工作，但就是无法登陆主机而已。 如果我想要让某个具有 /sbin/nologin 的用户知道，他们不能登陆主机时，可以新建 /etc/nologin.txt 这个文件，在文件内面写上不能登陆的原因，当用户登录时，屏幕上就会出现这个文件里面的内容。 touch /etc/nologin.txt && echo 'no permission login ..' > /etc/nologin.txt 用户和用户组的管理新增一个组 groupadd groupadd [-g gid] groupname 新增一个用户 useradd useradd username [-u uid] [-g gid] [-d home] [-s] -c 注释-d 家目录-m 若家目录不存在，则创建他-M 不建立家目录-e date指定账户过期的日期-g 用户组 指定将用户加入到哪个用户组，该用户组必须存在-G 用户组列表 指定用户同时加入的用户组列表，各组用逗分隔-n 不为用户创建私有用户组-s shell 指定用户登录时使用的 shell，默认为 / bin/bash-r 创建一个用户 ID 小于 500 的系统账户，默认不创建对应的主目录-u 用户 ID 手动指定新用户的 ID 值，该值必须唯一，且大于 499-p password 为新建用户指定登录密码。此处的 password 是对应登录密码经 MD5 加密后所得到的密码值，不实真实密码原文，因此在实际应用中，该参数选项使用较少，通常单独使用 passwd 命令来为用户设置登录密码。 删除一个用户 userdel userdel [-r] username -r 删除账户的时候连带账户的家目录一起删除 删除一个组 groupdel groupdel groupname 如果组下还存在其他的账户，则不能删除组 创建和修改一个用户的密码passwd [hzj@gogogo ~]$ passwd --help用法: passwd [选项...] -k, --keep-tokens 保持身份验证令牌不过期 -d, --delete 删除已命名帐号的密码(只有根用户才能进行此操作) -l, --lock 锁定指名帐户的密码(仅限 root 用户) -u, --unlock 解锁指名账户的密码(仅限 root 用户) -e, --expire 终止指名帐户的密码(仅限 root 用户) -f, --force 强制执行操作 -x, --maximum=DAYS 密码的最长有效时限(只有根用户才能进行此操作) -n, --minimum=DAYS 密码的最短有效时限(只有根用户才能进行此操作) -w, --warning=DAYS 在密码过期前多少天开始提醒用户(只有根用户才能进行此操作) -i, --inactive=DAYS 当密码过期后经过多少天该帐号会被禁用(只有根用户才能进行此操作) -S, --status 报告已命名帐号的密码状态(只有根用户才能进行此操作) --stdin 从标准输入读取令牌(只有根用户才能进行此操作)Help options: -?, --help Show this help message --usage Display brief usage message root可以修改其他账户的密码，其他账户只能修改自己的密码 密码生成器mkpasswd 密码生成工具,如果自己定义的密码并不完美，或者说容易被猜出来，那么你可以用密码生成器来生成无规律的密码 # 下载yum install -y expect# 使用[root@gogogo ~]# mkpasswdBmb2^Wuu4[root@gogogo ~]# mkpasswdWk05aOxj/ 用户权限命令介绍一些用户权限操作中经常用到的命令 切换用户su (选项) (参数)-c command user 切换成user并使用command后返回当前用户-user 改变成user后进入到user的家目录 查看当前用户名称whoami == id -un 显示用户的id以及群组idid (选项) user-g 显示用户所属群组的id-un 显示当前用户名称","link":"/posts/af2754a4/"},{"title":"linux常用命令","text":"learn linux linux常用命令整理系统查看linux版本信息1.使用lsb_release 查看 lsb_release -a# 出现错误 bash: lsb_release: command not found...# 安装lsb_releaseyum install -y readhat-lsblsb_release -a 2.uname 适合所有的linux发行版本 [root@CodeSheep ~]# unameLinux[root@CodeSheep ~]# uname -r3.10.0-957.5.1.el7.x86_64[root@CodeSheep ~]# uname -aLinux CodeSheep 3.10.0-957.5.1.el7.x86_64 #1 SMP Fri Feb 1 14:54:57 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux[root@CodeSheep ~]# 3.使用redhat-release [root@CodeSheep ~]# cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) 4.查看Cetnos版本于redhat对应版本的命令 [root@CodeSheep ~]# cat /proc/version Linux version 3.10.0-957.5.1.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-36) (GCC) ) #1 SMP Fri Feb 1 14:54:57 UTC 2019 查看系统内存cat /proc/meminfo | head -3 chrootchroot主要用于修改系统的根分区，linux系统中常常是以/为根目录的 功能: 在忘记root密码的时候，进入单用户修改密码 隔离环境在经过 chroot 之后，在新根下将访问不到旧系统的根目录结构和文件，这样就增强了系统的安全性。这个一般是在登录 (login) 前使用 chroot，以此达到用户不能访问一些特定的文件系统读取的是新根下的目录和文件，这是一个与原系统根下文件不相关的目录结构。在这个新的环境中，可以用来测试软件的静态编译以及一些与系统不相关的独立开发。 构建临时系统lfs系统构建中，为了隔离原系统的目录，会用到chroot 用chroot构建linux临时环境 # 复制依赖库cd /root/xxmkdir /root/xx/bincp -av /bin/bash /root/xx/bin/bashmkdir /root/xx/lib64/# 复制依赖库文件cp -av /lib64/ld-linux-x86-64.so.2 /lib64/ld-2.12.so \\> /lib64/libc.so.6 /lib64/libc-2.12.so /lib64/libdl.so.2 \\> /lib64/libdl-2.12.so /lib64/libtinfo.so.5 \\> /lib64/libtinfo.so.5.7 /mnt/123/lib64 \\> /mnt/123/lib64……chroot /root/xx https://www.ibm.com/developerworks/cn/linux/l-cn-chroot/index.htmlhttps://www.cnblogs.com/sparkdev/p/8556075.html dmesgdmesg 命令可以列出系统启动时硬件检测和驱动加载的情况，以及后续由内核生成的其他信息。 [root@gogogo ~]# dmesg[ 0.000000] Linux version 5.3.0-1.el7.elrepo.x86_64 (mockbuild@Build64R7) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC)) #1 SMP Mon Sep 16 08:44:46 EDT 2019[ 0.000000] Command line: BOOT_IMAGE=/boot/vmlinuz-5.3.0-1.el7.elrepo.x86_64 root=UUID=f13d84b4-c756-4d89-9d5e-6b534397aa14 ro console=tty0 crashkernel=auto console=ttyS0,115200[ 0.000000] Disabled fast string operations[ 0.000000] x86/fpu: Supporting XSAVE feature 0x001: 'x87 floating point registers'[ 0.000000] x86/fpu: Supporting XSAVE feature 0x002: 'SSE registers'[ 0.000000] x86/fpu: Supporting XSAVE feature 0x004: 'AVX registers'[ 0.000000] x86/fpu: xstate_offset[2]: 576, xstate_sizes[2]: 256[ 0.000000] x86/fpu: Enabled xstate features 0x7, context size is 832 bytes, using 'standard' format.[ 0.000000] BIOS-provided physical RAM map:[ 0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009bbff] usable[ 0.000000] BIOS-e820: [mem 0x000000000009bc00-0x000000000009ffff] reserved[ 0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved[ 0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000007fffcfff] usable[ 0.000000] BIOS-e820: [mem 0x000000007fffd000-0x000000007fffffff] reserved[ 0.000000] BIOS-e820: [mem 0x00000000fffbc000-0x00000000ffffffff] reserved[ 0.000000] NX (Execute Disable) protection: active[ 0.000000] SMBIOS 2.4 present.[ 0.000000] DMI: RDO Project OpenStack Nova, BIOS 0.5.1 01/01/2007[ 0.000000] Hypervisor detected: KVM[ 0.000000] kvm-clock: Using msrs 4b564d01 and 4b564d00 内核加载开始记录，记录时打印出来我们可以使用他来看是否有识别到一些外部加入的设备，比如识别USB 鼠标 串口等等[1206367.860755] usb 2-1.6: FTDI USB Serial Device converter now attached to ttyUSB0 比如这一条就是识别到了一个USB设备,检测设备是否可用,echo “test” >> /dev/ttyUSB0 常用命令因为dmesg是从内核加载开始后记录的，记录的内容太长，如果我们要过滤 ，还要加入管道和grep来筛选 dmesg | head -20 # 只输出前20行日志dmesg | tail -20 # 只输出后20行日志dmesg | grep -i usb # 只筛选出有usb日志行的 -i 忽略大小写dmesg | grep -E -i \"eth|sda\" # 只筛选包含字符串“eth”或“sda”的日志行 lspcilspci 命令可以列出系统中的 PCI 总线及其连接的设备。该命令的输出如下：什么是PCIhttps://zh.wikipedia.org/wiki/%E5%A4%96%E8%AE%BE%E7%BB%84%E4%BB%B6%E4%BA%92%E8%BF%9E%E6%A0%87%E5%87%86 [root@gogogo ~]# lspci00:00.0 Host bridge: Intel Corporation 440FX - 82441FX PMC [Natoma] (rev 02)00:01.0 ISA bridge: Intel Corporation 82371SB PIIX3 ISA [Natoma/Triton II]00:01.1 IDE interface: Intel Corporation 82371SB PIIX3 IDE [Natoma/Triton II]00:01.2 USB controller: Intel Corporation 82371SB PIIX3 USB [Natoma/Triton II] (rev 01)00:01.3 Bridge: Intel Corporation 82371AB/EB/MB PIIX4 ACPI (rev 03)00:02.0 VGA compatible controller: Cirrus Logic GD 544600:03.0 Ethernet controller: Red Hat, Inc. Virtio network device00:04.0 SCSI storage controller: Red Hat, Inc. Virtio block device00:05.0 SCSI storage controller: Red Hat, Inc. Virtio block device00:06.0 RAM memory: Red Hat, Inc. Virtio memory balloon 输出信息中包括声音（Multimedia audio controller），USB设备（USB controller），视频输出（VGA compatible controller），有线网卡（Ethernet controller）和磁盘（SATA controller）等。如需获取更详尽的信息，还可以在该命令后增加一至多个 -v 选项（如 -vvv）。 lsusb查看usb设备的情况 找出连接了多少usb设备 find /dev/bus 列出某台USB设备的详细信息 lsusb -D /dev/bus/usb/001/002 以树层结构列出 USB 设备 lsusb -t 如需获取更详尽的信息，还可以在该命令后增加一至多个 -v 选项（如 -vvv） lsblklsblk 命令用于列出所有可用块设备的信息，还能显示他们之间的依赖关系。块设备有硬盘，闪存盘，cd-ROM等等。 [root@test-ceph ~]# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTsda 8:0 0 447.1G 0 disk├─sda1 8:1 0 200M 0 part /boot/efi├─sda2 8:2 0 1G 0 part /boot└─sda3 8:3 0 446G 0 part ├─centos-root 253:0 0 50G 0 lvm / ├─centos-swap 253:1 0 7.8G 0 lvm [SWAP] └─centos-home 253:2 0 388.1G 0 lvm /homesdb 8:16 0 1.8T 0 disk├─sdb1 8:17 0 8G 0 part├─sdb2 8:18 0 4G 0 part├─sdb3 8:19 0 40G 0 part└─sdb4 8:20 0 1.8T 0 partsdc 8:32 0 1.8T 0 disksdd 8:48 0 1.8T 0 disksde 8:64 0 1.8T 0 disksdf 8:80 1 7.5G 0 disk├─sdf1 8:81 1 918M 0 part└─sdf2 8:82 1 8.5M 0 part NAME: 块设备名MAJ:MIN: 主要和次要设备号RM: 设备是否属于可移动设备，如sdb的RM值为1 ，是可移动设备SIZE: 设备的容量大小信息RO: 设备是否为只读TYPE: 设备是磁盘还是磁盘上的一个分区MOUNTPOINT: 设备的挂载点 sda 是盘 sda1是区 lsblk -m # 显示设备所有者相关的信息，包括文件的所属用户、所属组以及文件系统挂载的模式[root@gogogo ~]# lsblk -mNAME SIZE OWNER GROUP MODEvdb 40G root disk brw-rw----vda 20G root disk brw-rw----└─vda1 20G root disk brw-rw---- blkid显示关于块的信息 blkid # 显示所有可用信息 和唯一识别idblkid /dev/sad1 # 特指blkid -U # 设备blkid -g # 清除缓存 lscpulscpu 命令可以获得 CPU 的详细信息，如CPU架构（如 i686 或 x86_64）、运算模式（32bit 或 64bit）、核心数、每颗核心的线程数、型号、主频等。 lsmod如果你新增加了硬件，却不能被系统自动识别。可能你需要手动地加载对应的内核模块。内核模块安装在 /lib/modules/ 的子目录下，该子目录的名字对应内核的版本。即 /lib/modules/4.10.0-19-generic 目录下包含了 4.10.0-19-generic 内核的驱动程序 [root@gogogo ~]# lsmodModule Size Used bycrct10dif_pclmul 16384 1crc32_pclmul 16384 0ghash_clmulni_intel 16384 0aesni_intel 372736 0cirrus 16384 0crypto_simd 16384 1 aesni_intelcryptd 24576 2 crypto_simd,ghash_clmulni_intelglue_helper 16384 1 aesni_inteldrm_kms_helper 176128 3 cirrusjoydev 24576 0input_leds 16384 0drm 487424 3 drm_kms_helper,cirrusinput_leds 16384 0drm 487424 3 drm_kms_helper,cirrusvirtio_balloon 24576 0 获取已加载模块的信息，可以使用modinfo命令 modinfo drm[root@gogogo ~]# modinfo drmfilename: /lib/modules/5.3.0-1.el7.elrepo.x86_64/kernel/drivers/gpu/drm/drm.kolicense: GPL and additional rightsdescription: DRM shared core routinesauthor: Gareth Hughes, Leif Delgass, José Fonseca, Jon Smirllicense: GPL and additional rightsdescription: DRM bridge infrastructureauthor: Ajay Kumar license: GPL and additional rights 另外，还可以使用 modprobe 命令加载模块，rmmod 命令移除模块。 网络netstat命令可以帮助查找本机的网络状态netstat -pt #可以输出PID以及程序名 输出结果 Active Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 localhostname:16061 192.168.1.1:50060 ESTABLISHED 22000/java 是本机的16061端口在调192.168.1.1:50060上的服务，且本机16061端口上跑的是一个java程序，进程ID是22000 netstat -ant netstat -input traceroute 路由追踪\btraceroute可以追踪网络数据包，并展现路由途径 通过traceroute我们可以知道信息从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地(destination)走的路径可能会不一样，但基本上来说大部分时候所走的路由是相同的。linux系统中，我们称之为traceroute,在MS Windows中为tracert。 traceroute通过发送小的数据包到目的设备直到其返回，来测量其需要多长时间。一条路径上的每个设备traceroute要测3次。输出结果中包括每次测试的时间(ms)和设备的名称（如有的话）及其IP地址 https://tools.ipip.net/traceroute.php 使用首先你要下载tracerouteyum install traceroute -y traceroute [参数] 主机 实战[root@gogogo ~]# traceroute www.baidu.comtraceroute to www.baidu.com (180.101.49.11), 30 hops max, 60 byte packets 1 10.0.0.130 (10.0.0.130) 1.151 ms 1.582 ms 2.369 ms 2 10.255.106.1 (10.255.106.1) 1.056 ms 1.647 ms 2.266 ms 3 10.128.0.1 (10.128.0.1) 0.441 ms 0.421 ms 0.389 ms 4 115.231.100.65 (115.231.100.65) 2.023 ms 2.055 ms 2.201 ms 5 10.100.128.21 (10.100.128.21) 1.844 ms 1.977 ms 2.696 ms 6 172.31.110.249 (172.31.110.249) 0.632 ms 0.645 ms 0.630 ms 7 172.31.123.53 (172.31.123.53) 0.536 ms 0.685 ms 0.623 ms 8 * * * 9 61.164.31.120 (61.164.31.120) 2.390 ms 220.191.194.116 (220.191.194.116) 3.258 ms 61.164.31.122 (61.164.31.122) 2.264 ms10 220.191.200.201 (220.191.200.201) 6.861 ms 220.191.200.217 (220.191.200.217) 6.413 ms 220.191.200.201 (220.191.200.201) 5.955 ms11 202.97.76.10 (202.97.76.10) 13.005 ms 202.97.75.174 (202.97.75.174) 14.885 ms 202.97.22.6 (202.97.22.6) 19.543 ms12 58.213.95.118 (58.213.95.118) 19.171 ms 58.213.95.2 (58.213.95.2) 14.327 ms 58.213.94.118 (58.213.94.118) 15.157 ms13 * 58.213.95.126 (58.213.95.126) 20.922 ms 58.213.95.134 (58.213.95.134) 16.233 ms14 58.213.96.102 (58.213.96.102) 14.907 ms 58.213.96.94 (58.213.96.94) 15.467 ms 58.213.96.90 (58.213.96.90) 15.166 ms15 * * *16 * * *17 * * *18 * * *19 * * *20 * * *21 * * *22 * * *23 * * *24 * * *25 * * *26 * * *27 * * *28 * * *29 * * *30 * * * 最左边的是表示每一条的序号,从1开始，每一个序号表示一跳，每一跳表示一个网关第二个字段表示主机名和对应ip后面三个表示发送的三个包所返回的时间一行*号 有可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。 # 添加每次发送的数据包个数 traceroute -q 4 www.baidu.com# 不查主机名，仅显示ip地址traceroute -n www.baidu.com# 设置跳数数量traceroute -m 10 www.baidu.com# 发送到直连主机traceroute -r www.baidu.com 工作原理Traceroute程序的设计是利用ICMP及IP header的TTL（Time To Live）栏位（field）。首先，traceroute送出一个TTL是1的IP datagram（其实，每次送出的为3个40字节的包，包括源地址，目的地址和包发出的时间标签）到目的地，当路径上的第一个路由器（router）收到这个datagram时，它将TTL减1。此时，TTL变为0了，所以该路由器会将此datagram丢掉，并送回一个「ICMP time exceeded」消息（包括发IP包的源地址，IP包的所有内容及路由器的IP地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上，接着traceroute 再送出另一个TTL是2 的datagram，发现第2 个路由器…… traceroute 每次将送出的datagram的TTL 加1来发现另一个路由器，这个重复的动作一直持续到某个datagram 抵达目的地。当datagram到达目的地后，该主机并不会送回ICMP time exceeded消息，因为它已是目的地了，那么traceroute如何得知目的地到达了呢？ Traceroute在送出UDP datagrams到目的地时，它所选择送达的port number 是一个一般应用程序都不会用的号码（30000 以上），所以当此UDP datagram 到达目的地后该主机会送回一个「ICMP port unreachable」的消息，而当traceroute 收到这个消息时，便知道目的地已经到达了。所以traceroute 在Server端也是没有所谓的Daemon 程式。 Traceroute提取发 ICMP TTL到期消息设备的IP地址并作域名解析。每次 ，Traceroute都打印出一系列数据,包括所经过的路由设备的域名及 IP地址,三个包每次来回所花时间。 每次写到TTL值访问路由，每到达一个路由，TTL值减少1 到0返回， 重新装载比上次+1的TTL值访问路由，如此循环 记住他只记录路由, 如果是二层之间的机器访问是不是只有一条？ mtr 路由追踪MTR是Linux平台上一款非常好用的网络诊断工具，集成了traceroute、ping、nslookup的功能，用于诊断网络状态非常有用。下面请看简单介绍。一旦你运行mtr ，它将探测本地系统和你指定的远程主机之间的网络连接。 它首先建立主机之间的每个网络跳跃点（网桥，路由器和网关等）的地址，然后ping每个跳跃点（发送一个序列ICMP ECHO请求）以确定到每台机器的链路的质量。 使用方法 mtr ip或域名 My traceroute [v0.85]PG-VPN (0.0.0.0) Wed Oct 9 18:22:54 2019Resolver: Received error response 2. (server failure)er of fields quit Packets Pings Host Loss% Snt Last Avg Best Wrst StDev 1. 115.231.97.1 0.0% 20 0.8 1.0 0.8 1.3 0.0 2. 10.100.129.24 0.0% 20 0.9 0.9 0.9 1.0 0.0 3. 10.100.128.65 0.0% 20 0.9 1.0 0.9 1.1 0.0 4. 10.100.129.27 0.0% 20 1.3 1.1 1.0 1.3 0.0 5. 124.14.9.238 0.0% 20 4.0 4.1 3.8 4.3 0.0 第一列(Host) : IP地址和域名 按n键可以切换IP和域名第二列(Loss%): 丢包率第三列(Snt): 设置每秒发送数据包的数量，默认是10 可以通过参数-c来指定第四列(Last)： 最近一次的Ping值第五六七列(AVG BEST WRST) : 分别，是Ping的平均 最好 最差值第八列(StDev): 标准偏差，越大说明相应节点越不稳定。 判别 判断各区域是否存在异常，并根据各区域的情况分别处理。 区域 A：客户端本地网络，即本地局域网和本地网络提供商网络。针对该区域异常，客户端本地网络相关节点问题，请对本地网络进行排查分析；本地网络提供商网络相关节点问题，请向当地运营商反馈。 区域 B：运营商骨干网络。针对该区域异常，可根据异常节点 IP 查询归属运营商，然后直接或通过阿里云售后技术支持，向相应运营商反馈问题。 区域 C：目标服务器本地网络，即目标主机归属网络提供商网络。针对该区域异常，需要向目标主机归属网络提供商反馈问题。 查看节点丢包率，若 Loss% 不为零，则说明这一跳网络可能存在问题。 导致节点丢包的原因通常有两种： 人为限制了节点的 ICMP 发送速率，导致丢包。 节点确实存在异常，导致丢包 命令 -h #提供帮助命令-v #显示mtr的版本信息-r #已报告模式显示-s #用来指定ping数据包的大小-i #使用这个参数来设置ICMP返回之间的要求默认是1秒-4 #默认IPv4-6 # 指定IPv6-c --report-cycles COUNT # 指定发送多少个数据包-r --report # 结果显示，并不动态显示-n --no-dns #不对IP地址做域名解析-p --split # 将每次追踪的结果分别列出来，而非如 --report 统计整个结果-a #来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的 其他用法$ mtr -h #提供帮助命令$ mtr -v #显示mtr的版本信息$ mtr -r #已报告模式显示$ mtr -s #用来指定ping数据包的大小$ mtr --no-dns #不对IP地址做域名解析$ mtr -a #来设置发送数据包的IP地址 这个对一个主机由多个IP地址是有用的$ mtr -i #使用这个参数来设置ICMP返回之间的要求默认是1秒$ mtr -4 #IPv4$ mtr -6 #IPv6 域名查询工具 dig常用的域名查询工具，可以用来测试域名系统工作是否正常 dig (选项)(参数)alpaca@hzj  ~  dig www.baidu.com; DiG 9.10.6 www.baidu.com;; global options: +cmd;; Got answer:;; ->>HEADER /lib64/libselinux.so.1 (0x00007fedc8e77000) libcap.so.2 => /lib64/libcap.so.2 (0x00007fedc8c72000) libacl.so.1 => /lib64/libacl.so.1 (0x00007fedc8a69000) libc.so.6 => /lib64/libc.so.6 (0x00007fedc869b000) libpcre.so.1 => /lib64/libpcre.so.1 (0x00007fedc8439000) libdl.so.2 => /lib64/libdl.so.2 (0x00007fedc8235000) /lib64/ld-linux-x86-64.so.2 (0x00007fedc909e000) libattr.so.1 => /lib64/libattr.so.1 (0x00007fedc8030000) libpthread.so.0 => /lib64/libpthread.so.0 (0x00007fedc7e14000) alias 查看快捷输入alias 或者 ~/.bash_profile ls 查看当前目录文件# 语法ls [option] [name] -a 显示所有文件或目录-l 除文件名称外，亦将文件型态、权限、拥有者、文件大小等资讯详细列出-r 倒叙显示-t 时间顺序排列-R 递归显示-h 以可读大小显示-i 额外显示inode信息 # 常用ls -alls -altr #倒叙时间ls -lh # 列出详细信息并以可读大小显示文件大小 du查看目录或文件所占用磁盘大小# 语法du [option] [name] -h 以人类可读的方式显示-a：显示目录占用的磁盘空间大小，还要显示其下目录和文件占用磁盘空间的大小-s：显示目录占用的磁盘空间大小，不要显示其下子目录和文件占用的磁盘空间大小-c：显示几个目录或文件占用的磁盘空间大小，还要统计它们的总和–apparent-size：显示目录或文件自身的大小-l ：统计硬链接占用磁盘空间的大小-L：统计符号链接所指向的文件占用的磁盘空间大小 # 常用du -sh 查看当前目录总共占的容量。而不单独列出各子项占用的容量 du -lh --max-depth=1 : 查看当前目录下一级子文件和子目录占用的磁盘容量。du -sh * | sort -n 统计当前文件夹(目录)大小，并按文件大小排序du -sk filename 查看指定文件大小 文件传输 scp命令scp -h # 查看帮助scp -v # 显示进度scp -P # 选择端口scp -r # 传输目录 从本地将文件传输到服务器scp【本地文件的路径】【服务器用户名】@【服务器地址】：【服务器上存放文件的路径】scp /Users/mac_pc/Desktop/test.png root@192.168.1.1:/root 从本地将文件夹传输到服务器scp -r【本地文件的路径】【服务器用户名】@【服务器地址】：【服务器上存放文件的路径】sup -r /Users/mac_pc/Desktop/test root@192.168.1.1:/root 将服务器上的文件传输到本地scp 【服务器用户名】@【服务器地址】：【服务器上存放文件的路径】【本地文件的路径】scp root@192.168.1.1:/data/wwwroot/default/111.png /Users/mac_pc/Desktop 将服务器上的文件夹传输到本地scp -r 【服务器用户名】@【服务器地址】：【服务器上存放文件的路径】【本地文件的路径】sup -r root@192.168.1.1:/data/wwwroot/default/test /Users/mac_pc/Desktop 命令xargs命令xargs 将标准输入数据转换成命令行参数xargs默认命令是echo，空格是默认的定界符 参数 -n 选项多行输出-d 自定义一个定界符 使用 cat test.txta b c d e f gh i j k l m no p qr s tu v w x y z # 多行输入单行输出cat test.txt | xargsa b c d e f g h i j k l m n o p q r s t u v w x y z# -n选项多行输出cat test.txt | xargs -n3a b cd e fg h ij k lm n op q rs t uv w xy z# -d选项可以定义一个定界符echo \"nameXnameXnameXname\" | xargs -dXname name name name","link":"/posts/f6c82bc1/"},{"title":"linux文件权限","text":"learn linux 文件权限除了用户权限以外，linux还具有文件的权限，在ugo权限管理中,大部分的文件基本交由user,group,other三种操作权限, 同时他们的权限分别为read write execute三种权限 文件权限的表现方式当一个文件创建后，它具有读(r)、写(w)、执行(x)三种操作方式。UGO权限管理方式将访问文件的操作者简单分为三类：文件属主(u)、同组用户(g)与其他组用户(o) 举例： 现在我们创建一个文件，并且查看他的权限属性 touch a.txt && ls -al “-“表示文件是普通类型，如d表示文件夹“rw-“ 表示文件属主对文件具有读和写的权限，但没有执行权限“r–” 表示同组用户对文件只读，无写和执行权限“r–” 表示其他组用户对文件只读，无写和执行权限每一组权限都可以用二进制表示 每组“rwx”分别位”111” 十进制则是 7如”rw-“ 二进制是110 十进制则是6，”r–” 二进制是100 十进制则是4\b于是我们可以使用chmod+十进制来修改权限,修改成三组用户可读可写可执行权限 chmod 777 a.txt && ls -al 当然也可以通过另外一种形式 chmod ugo+rwx && ls -al 除了上面使用chmod修改权限之外，我们还可以在文件创建的时候就完成他的权限规划文件创建掩码当我们创建一个文件夹的时候，你会发现他的权限是775，但是当你创建一个文件的时候，他的权限是664，其实是系统掩码的问题。每次创建文件夹的时候，就是777和掩码做与操作，创建文件的时候就是666与掩码做与操作 # 查看系统掩码umask# 修改系统掩码umask u=, g=w, o=rwx# 查看当前新建文件夹的权限umask -S 改变文件权限和属性更改文件和目录的所属组 chgrp要求组本身在/etc/group中已经存在，对于已经有链接的文件来说，修改组的作用对象是链接的源文件，而不是链接文件本身 chgrp [option] group file # 修改组chgrp [option] --reference=dest_file file # 修改file的组为dest_file的组chgrp -R group file # 递归修改,即文件夹下面的所有文件都改变群主 修改文件所有者 chown chown -R 账号 文件或目录chown -R 账号:群组 文件或目录chown 账号.群组 文件-R 递归传递，同chgrp 修改文件所有者和所属组,对于链接文件，chown不会直接去修改源文件，而是修改当前文件 修改文件属性和权限chmod 有两种修改的形式第一种使用数字来修改 分别对应的是 6 4 2 r w x chmod 777 xxx.txtchmod rwx 另外一种是用ugo+rwx来修改，其中 +（加入） -（除去） =（设置） chmod ugo=rwxrwxrwx xxx.txt 2.3文件权限识别的本质首先，权限的元数据放在inode中，严格地说是放在inode table中，因为每个块组的所有inode组成一个inode table。在inode table中使用一列来存放数字型的权限，比如某文件的权限为644。每次用户要对文件进行操作时系统都会先查看权限，确认该用户是否有对应的权限来执行操作。当然，inode table一般都已经加载到内存中，所以每次查询权限的资源消耗是非常小的 2.4文件的扩展acl权限在计算机相关领域，所有的ACL(access control list)都表示访问控制列表。文件的owner/group/others的权限就是一种ACL，它们是基本的ACL。很多时候，只通过这3个权限位是无法完全合理设置权限问题的，例如如何仅设置某单个用户具有什么权限。这时候需要使用扩展ACL。扩展ACL是一种特殊权限，它是文件系统上功能，用于解决所有者、所属组和其他这三个权限位无法合理设置单个用户权限的问题。所以，扩展ACL可以针对单一使用者，单一档案或目录里的默认权限进行r,w,x的权限规范。需要明确的是，扩展ACL是文件系统上的功能，且工作在内核，默认在ext4/xfs上都已开启。 查看文件系统是否开启acl功能不同的文件系统查看的方法不一样，ext的文件系统 dumpe2fs -h /dev/sda2 | grep -i acldumpe2fs 1.41.12 (17-May-2010)Default mount options: user_xattr acl# 如果没有，则是[root@test-ceph ~]# dumpe2fs -h /dev/sda1 | grep -i acldumpe2fs 1.42.9 (28-Dec-2013)dumpe2fs: Bad magic number in super-block 当尝试打开 /dev/sda1 对于xfs文件系统来说，默认会开启acl，但是你也可以用dmesg查看 dmesg | grep -i acl [root@test-ceph ~]# dmesg | grep -i acl[ 1.533401] systemd[1]: systemd 219 running in system mode. (+PAM +AUDIT +SELINUX +IMA -APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 -SECCOMP +BLKID +ELFUTILS +KMOD +IDN)[ 2.993939] SGI XFS with ACLs, security attributes, no debug enabled 开启ACL功能后，不代表就使用ACL功能。是否使用该功能，不同文件系统控制方法不一样，对于ext家族来说，通过mount挂载选项来控制，而对于xfs文件系统，mount命令根本不支持acl参数(xfs文件系统如何关闭或启用）—>暂不知道 设置和查看acl设定acl –> setfacl setfacl [option] u:[user]:[rwx] 目录文件 setfacl [option] g:[组列表]:[rwx] 目录文件``` -m 设定acl权限-x：删除指定的ACL权限，可以指定用户、组和文件来删除(remove)-M：写了ACL条目的文件，将从此文件中读取ACL条目，需要配合-m，所以-M指定的是modify file-X：写了ACL条目的文件，将从此文件中读取ACL条目，需要配合-x，所以-X指定的是remove file-n：不重置mask-b：删除所有的ACL权限-d：设定默认ACL权限，只对目录有效，设置后子目录(文件)继承默认ACL，只对未来文件 有效-k：删除默认ACL权限-R：递归设定ACL权限，只对目录有效，只对已有文件有效获取acl --> getfacl```bashgetfacl filename acl中的mask设置mask后会将mask权限与已有的acl权限进行与计算，计算后的结果会成为新的ACL权限。比如之前的hzj用户有rwx的权限，设置mask r– 后你会发现hzj用户只有可读的权限 做与操作如果一个文件有多个用户需要设置权限，这个时候每次授权都会重置mask，这个时候我们可以用-n来避免 # 设置maskgetfacl -m m:[rwx] 目录/文件名# 限制mask变更setfacl -n -m u:hzj:rwx tt.txt 设置递归和默认acl权限递归ACL权限只对目录里已有文件有效，默认权限只对未来目录里的文件有效。 # 递归ACLsetfacl -m u:name:[rwx] -R 目录名 # 默认aclsetfacl -m d:u:name:[rwx] 目录名 删除acl setfacl -x u:name file # 删除指定用户ACLsetfacl -x g:gname file # 删除指定组名aclsetfacl -b file # 指定文件删除acl 特殊权限文件隐藏属性http://www.ha97.com/5172.html chattr [+ - = ][ai] 文件或目录 设置了a参数时，文件中将只能增加内容，不能删除数据，且不能打开文件进行任何编辑，哪怕是追加内容也不可以，所以像sed等需要打开文件的再写入数据的工具也无法操作成功。文件也不能被删除。只有root才能设置。设置了i参数时，文件将被锁定，不能向其中增删改内容，也不能删除修改文件等各种动作。只有root才能设置。可以将其理解为设置了i后，文件将是永恒不变的了，谁都不能动它。 对/etc/shadow文件设置i属性，任何用户包括root将不能修改密码，而且也不能创建用户。 # 添加chattr +i /etc/shadow # 删除chattr -i /etc/shadow suid/sgid/sbit 其他的文章acl权限 https://www.cnblogs.com/ysocean/p/7801329.htmllinux文件权限 https://www.cnblogs.com/zoulongbin/p/7263267.htmllinux权限管理https://www.cnblogs.com/franknihao/p/7346771.html","link":"/posts/af2754a4/"},{"title":"linux实用命令","text":"learn linux linux实用命令查找包含某字符串的文件及位置find . | xargs grep -ri \"要查找的字符串 压缩打包与解压缩打包# 压缩tar -jcv -f filename.tar.bz2 filenametar -cxv -f filename.tar filename# 查询压缩包中的内容tar -jtv -f filename.tar.bz2 # 解压tar -cxv -f filename.tar .tar -jxv -f filename.tar.bz2 -C 预解压缩的目录","link":"/posts/fa4e8e08/"},{"title":"linux目录配置","text":"learn linux linux目录配置依据 – > FHS – > filesystem hierarchy standard 什么是FHS使用者可以了解到已安装软件通常放置于那个目录下， 所以他们希望独立的软件开发商、操作系统制作者、以及想要维护系统的使用者，都能够遵循FHS的标准。 也就是说，FHS的重点在于规范每个特定的目录下应该要放置什么样子的数据而已。 这样做好处非常多，因为Linux操作系统就能够在既有的面貌下（目录架构不变）发展出开发者想要的独特风格。+ 第一层三类文件分别是/ root 根目录，与开机系统有关/usr 与软件安装/执行有关/var 与系统运行过程有关 在根目录下面,FHS定义必须存在的目录/bin 在bin目录下面放置了一些基操的指令文件 在/bin下面的指令可以被root与一般帐号所使用，主要有：cat, chmod, chown, date, mv, mkdir, cp, bash等等常用的指令，在单人模式下也可以被操作 [root@test-ceph bin]# ls -al | grep chmod-rwxr-xr-x. 1 root root 58656 10月 31 2018 chmod /boot 开机时会用到的文件包括Linux核心文件以及开机菜单与开机所需配置文件等等 kernel文件常用vmlinuz命名/dev 硬件设备存放点，以文件形式存在/etc 主要配置文件存放点/lib 开机时用到的函数库， /lib/modules/下面存放一些核心模块/media 可移除设备，不常用/mnt 挂载设备/opt 第三方协力软件放置的目录 不常用/run /sbin 存放指令/srv/tmp 这是让一般使用者或者是正在执行的程序暂时放置文件的地方。/usr/var 建议存在的目录/home 这是系统默认的使用者主文件夹（home directory）/lib* 存放与/lib不同格式的二进制函数库/root 系统管理员（root）的主文件夹 特殊目录 /lost+found 这个目录是使用标准的ext2/ext3/ext4文件系统格式才会产生的一个目录，目的在于当文件系统发生错误时， 将一些遗失的片段放置到这个目录下 xfs系统没有/proc 这个目录本身是一个“虚拟文件系统（virtual filesystem）”喔！他放置的数据都是在内存当中， 例如系统核心、行程信息（process）、周边设备的状态及网络状态等等。因为这个目录下的数据都是在内存当中， 所以本身不占任何硬盘空间啊！/sys 这个目录其实跟/proc非常类似，也是一个虚拟的文件系统，主要也是记录核心与系统硬件信息较相关的信息。 包括目前已载入的核心模块与核心侦测到的硬件设备信息等等。这个目录同样不占硬盘容量 /usr在/usr中存放的是安装和执行的软件/usr/bin/ 所有一般用户能够使用的指令都放在这里 并且/bin 软连接到/usr/bin/usr/lib/ 同/lib一样 软连接/usr/local 系统管理员在本机自行安装自己下载的软件（非distribution默认提供者），建议安装到此目录， 这样会比较便于管理/usr/sbin 非系统正常运行所需要的系统指令。最常见的就是某些网络服务器软件的服务指令（daemon）啰！不过基本功能与 /sbin 也差不多， 因此目前 /sbin 就是链接到此目录中的。 /usr/src 源代码存放点 /var在/var中存放的是运行过程中的文件/var/cache 暂存盘/var/lib 程序本身执行的过程中，需要使用到的数据文件放置的目录。在此目录下各自的软件应该要有各自的目录。 举例来说，MySQL的数据库放置到/var/lib/mysql/而rpm的数据库则放到/var/lib/rpm去！/var/log 登陆文件放置的目录","link":"/posts/af2754a4/"},{"title":"linux扩展软件命令","text":"learn Command linux扩展软件命令json工具json解析工具对于PHP和Python来说，解析json并不是太大的问题，同样的在linux下jq这个json解析工具也是相当完善的。 # 安装sudo yum install jq Centos安装sudo apt-get install jq Ubuntu安装# 使用jq[参数列表] '过滤条件' 文件名或标准输入jq --help 查看帮助文档-compact-output / -c 默认情况下，jq会将json格式化为多树状结构输出，但有时需要将一个json串在一行输出，即可使用该参数 常用操作格式化json格式化json，方便查看,当然如果本身文件不是json的格式，他则会报错 cat xxx.json | jq . # 格式化 报错内容: manu@manu:~/code/php/json$ cat json_err.txt |jq .parse error: Expected separator between values at line 1, column 183 根据key值获取value值{ \"key_1\":\"value_1\", \"key_2\":\"value_2\",}# 根据key值获取vlauecat som_json | jq '.foo' 如果值不存在，则返回null 多层key获取value值cat som_json | jq '.foo.bar'cat som_json | jq '.foo[2].bar' 获取key值cat som_json | jq 'keys' 判断是否存在某keycat som_json | jq 'has(\"key\")' jq更高级的用法http://justcode.ikeepstudying.com/2018/02/shell%EF%BC%9A%E6%97%A0%E6%AF%94%E5%BC%BA%E5%A4%A7%E7%9A%84shell%E4%B9%8Bjson%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7jq-linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%A7%A3%E6%9E%90json-jq%E8%A7%A3%E6%9E%90-json/","link":"/posts/25384ae1/"},{"title":"linux文件系统2","text":"linux文件系统2linux中有许多常用的文件，各自有各自主要的作用 ，怕忘记，这里做些笔记 /etc/hosts文件hosts —— the static table lookup for host name（主机名查询静态表）。hosts文件是Linux系统上一个负责ip地址与域名快速解析的文件，以ascii格式保存在/etc/目录下。hosts文件包含了ip地址与主机名之间的映射，还包括主机的别名。在没有域名解析服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的ip地址，否则就需要使用dns服务程序来解决。通过可以将常用的域名和ip地址映射加入到hosts文件中，实现快速方便的访问。优先级 ： dns缓存 > hosts > dns服务 —> 配置 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.0.5.91 lvs-master10.0.5.93 lvs-slave10.0.5.92 lvs-web1#10.0.5.90 lvs-web210.0.5.90 www.baidu.com# ip地址 主机名/域名 主机别名 相当于本地的域名解析，当你ping www.baidu.com的时候，会默认去ping 10.0.5.90","link":"/posts/cd527bc1/"},{"title":"httpd服务","text":"apache http serverApache HTTP Server（简称Apache）是Apache软件基金会的一个开放源码的网页服务器，可以在大多数计算机操作系统中运行，由于其多平台和安全性被广泛使用，是最流行的Web服务器端软件之一。它快速、可靠并且可通过简单的API扩展，将Perl/Python等解释器编译到服务器中。 在Apache中，其配置文件目录为“/etc/httpd/conf/httpd.conf”，这里面包括设置网站资源的存放目录及一些相关的配置。 # 安装httpyum install httpd # 开启服务systemctl start httpd# 检查httpd服务状态systemctl status httpd# 查看端口状态 netstat -anutp | grep 80 目录介绍配置文件目录为“/etc/httpd/conf/httpd.conf” [root@localhost httpd]# ls -1conf # 存放服务的主配置文件conf.d # 存放apache的主页信息conf.modules.dlogsmodulesrun 配置信息配置文件目录为“/etc/httpd/conf/httpd.conf” [root@localhost httpd]# vi /etc/httpd/conf/httpd.confServerRoot \"/etc/httpd\" #apache配置文件的根目录Timeout 60 #超时时间，即连接服务端在60秒内没有任何操作，即自动断开Listen 80 #监听的端口ServerAdmin root@localhost #设置管理员，e-mail 地址ServerName www.example.com:80 #服务器主机名.DocumentRoot \"/var/www/html\" #网站页面根目录,存放文档的地方 Options Indexes FollowSymLinks #O目录浏览 #Followsymlinks:可以用连接，要是想要禁止显示文件目录，可以直接在‘indexes’前加‘-’。 AllowOverride None Order allow,deny #目录与访问的控制 Allow from all # 别名Alias /icons/ \"/var/www/icons/\" #别名和别名目录 Options Indexes MultiViews FollowSymLinks AllowOverride None Order allow,deny Allow from all# 默认页面 Options Indexes #当一个目录没有默认首页时，允许显示此目录列表 Options FollowSymLinks AllowOverride None--DirectoryIndex index.html index.html.var #指定默认首页AddDefaultCharset UTF-8 #设置服务器的默认编码为： UTF-8 python3构建http服务python3 -m http.server 维护&错误http服务已开启，但是无法访问网站 在本地查看httpd服务curl http://localhost:80 看端口，如果是在公司内部，查看是否有部分ip端口被封 比如80 8080 88 等等如果是以上情况，修改httpd 配置文件中的监听端口，重启http服务即可 永久关闭selinux ,需要重启vi /etc/selinux/configSELINUX=disabled 临时关闭setenforce 0 可能会出现的报错信息(13)Permission denied: make_sock: could not bind to address [::]:88—-> 关闭selinux即可 检测端口是否被开启使用telnet登陆的方式测试服务器端口是否开放 # 未开放状态下的返回情况➜ ~ telnet 10.0.5.92 8888Trying 10.0.5.92...telnet: Unable to connect to remote host: Connection refused# 开放状态下的返回情况➜ ~ telnet 10.0.5.91 8888Trying 10.0.5.91...Connected to 10.0.5.91.Escape character is '^]'. 开放端口端口未被开放———> iptables -I INPUT -p tcp –dport 8888 -j ACCEPT 地址https://www.linuxidc.com/Linux/2017-05/143468.htm","link":"/posts/4982550/"},{"title":"iptables、firewall 防火墙","text":"iptables、firewall防火墙Linux中有两种防火墙软件，ConterOS7.0以上使用的是firewall，ConterOS7.0以下使用的是iptables firewall# 开启防火墙systemctl start firewalld# 关闭防火墙systemctl stop firewalld# 查看状态systemctl status firewalldfirewall-cmd --state# 设置开机启动systemctl enable firewalld# 禁用开机启动systemctl disabled firewalld# 重启防火墙firewall-cmd --reload# 开放端口firewall-cmd --zone=public --add-port=8080/tcp --permanet# 查看已经开放的端口firewall-cmd --list-ports firewall-cmd --list-all# 关闭端口firewall-cmd --zone=public --remove-port=8080/tcp --permanet\\ https://juejin.im/post/5d538326f265da03ce39cf38 iptables# 安装iptables yum install iptables# 安装iptables-servicesyum install iptables-services# 开启防火墙systemctl start iptables# 关闭防火墙systemctl stop iptables.services# 防火墙状态 、开机启动 、 禁用开机启动、status 、 enable 、disable# 查看filter表的几条链规则(INPUT链可以看出开放了哪些端口)：iptables -L -n# 查看连标规则iptables -t nat -L -n # 清除防火墙所有规则iptables -F# 给INPUT链添加规则（开放8080端口）iptables -I INPUT -p tcp --dport 8080 -j ACCEPT# 查找规则所在行iptables -L INPUT --line-numbers -n# 根据行号删除过滤规则(关闭8080)iptables -D INPUT 1 防火墙错误导致的原因 开通httpd后，当前机器下使用curl可访问，但外部机器访问ip+端口则无法访问[root@localhost ~]# curl http://10.0.5.92:8888curl: (7) Failed connect to 10.0.5.92:8888; No route to host curl报如下错误：curl: (7) Failed connect to 172.16.225.43:7001; No route to host 解决办法—-> 在被访问机器下开放8888端口—-> iptables -l INPUT -p tcp –dport 8888 -j ACCEPTt 8888 -j ACCEPT","link":"/posts/60486/"},{"title":"netstat","text":"netstat工具netstat是在内核中访问网络相关信息的程序。 提供TCP连接、TCP和UDP监听、进程内存管理的状态。 监控TCP/IP网络的非常有用的工具，显示路由表、实际网络连接以及每一个网络接口设备的状态信息。 使用netstat可以让用户知道有哪些网络连接正在运作，使用时如果不带参数，netstat显示活动的TCP连接 # 安装yum install net-tools# 使用netstat 选项：常用参数：-a:显示所有的socket，包括监听的以及未监听的。-n:不使用域名和服务名，而使用IP和端口号。-l:仅列出在listen状态的网络服务。-p:显示建立连接的程序名和PID。-e:显示以太网统计。-s:显示每个协议的统计。-t：显示TCP协议连接情况。-u:显示UDP协议连接情况。-c:每隔一个固定时间，执行netstat命令。-r：显示核心路由表。-i:显示所有的网络接口信息 常用指令# 显示建立连接的程序名 PID IP 端口以及监听状态[root@localhost ~]# netstat -pan | grep 8888tcp6 0 0 :::8888 :::* LISTEN 16711/httpd","link":"/posts/4421/"},{"title":"vim快捷键","text":"vim快捷键VIM 是 Linux 系统上一款文本编辑器，它是操作 Linux 的一款利器。当前有很多优秀的 IDE 都支持安装 VIM 插件，原因就是使用它便捷，高效，很爽！主要记录了 VIM 的一些常用使用技巧，方便随时查阅学习 。 快捷键# 跳转到行首 shift+i # 跳转到行尾 esc->shift+a 编辑 清空当前行，并进入编辑模式 cc 清空当前单词，并进入编辑模式 cw 删除特定行数之间的空行:68,121g/^s*$/d # 这里^s*$ 匹配所有的空行","link":"/posts/e47927c/"},{"title":"rpm 与 yum","text":"learn linux 🐧 rpm 与 yumrpmRPM是RedHat Package Manager（RedHat软件包管理工具）类似Windows里面的“添加/删除程序”。rpm 执行安装包二进制包（Binary）以及源代码包（Source）两种。二进制包可以直接安装在计算机中，而源代码包将会由RPM自动编译、安装。源代码包经常以src.rpm作为后缀名。RPM 现在是 Linux Standard Base (LSB) 中采用的包管理系统。 rpm更多的用来做查询 检验，在小部分上做安装，大部分上使用yum安装 RPM工作原理他最大的特点就是将你要安装的软件先编译过， 并且打包成为 RPM 机制的包装文件，通过包装好的软件里头默认的数据库记录， 记录这个软件要安装的时候必须具备的相依属性软件，当安装在你的 Linux 主机时， RPM 会先依照软件里头的数据查询 Linux 主机的相依属性软件是否满足， 若满足则予以安装，若不满足则不予安装。优点: 由于已经编译完成并且打包完毕，所以软件传输与安装上很方便 （不需要再重新编译）； 由于软件的信息都已经记录在 Linux 主机的数据库上，很方便查询、升级与安装 rpm 安装路径一般来说，RPM 类型的文件在安装的时候，会先去读取文件内记载的设置参数内容，然后将该数据用来比对 Linux 系统的环境，以找出是否有属性相依的软件尚未安装的问题。例如 Openssh 这个连线软件需要通过 Openssl 这个加密软件的帮忙，所以得先安装 openssl 才能装 openssh 的意思。那你的环境如果没有 openssl ， 你就无法安装 openssh。若环境检查合格了，那么 RPM 文件就开始被安装到你的 Linux 系统上。安装完毕后，该软件相关的信息就会被写入 /var/lib/rpm/ 目录下的数据库文件中了。 上面这个目录内的数据很重要喔！因为未来如果我们有任何软件升级的需求，版本之间的比较就是来自于这个数据库， 而如果你想要查询系统已经安装的软件，也是从这里查询的！同时，目前的 RPM 也提供数码签章信息， 这些数码签章也是在这个目录内记录的呢！所以说，这个目录得要注意不要被删除了 ll /var/lib/rpm/[root@ops rpm]# lltotal 35212-rw-r--r--. 1 root root 1638400 Feb 24 15:46 Basenames-rw-r--r--. 1 root root 8192 Feb 24 15:45 Conflictname-rw-r--r-- 1 root root 286720 Feb 24 20:27 __db.001-rw-r--r-- 1 root root 90112 Feb 24 20:27 __db.002-rw-r--r-- 1 root root 1318912 Feb 24 20:27 __db.003-rw-r--r--. 1 root root 598016 Feb 24 15:46 Dirnames-rw-r--r--. 1 root root 8192 Feb 24 15:46 Group-rw-r--r--. 1 root root 12288 Feb 24 15:46 Installtid-rw-r--r--. 1 root root 28672 Feb 24 15:46 Name-rw-r--r--. 1 root root 16384 Feb 24 15:46 Obsoletename-rw-r--r--. 1 root root 29913088 Feb 24 15:46 Packages-rw-r--r--. 1 root root 2019328 Feb 24 15:46 Providename-rw-r--r--. 1 root root 155648 Feb 24 15:46 Requirename-rw-r--r--. 1 root root 40960 Feb 24 15:46 Sha1header-rw-r--r--. 1 root root 24576 Feb 24 15:46 Sigmd5-rw-r--r--. 1 root root 8192 Feb 10 16:46 Triggername RPM的指令RPM的指令太多，使用时又经常是组合的形式存在。 rpm -ivh xxx.rpm #安装并 显示进度 --install--verbose--hashrpm -ivh xxx.rpm yyy.rpm # 同时安装多个rpm -Uvh xxx.rpm #升级软件包并 显示进度 --Update--verbose-hashrpm -qpl xxx.rpm #列出RPM软件包内的文件信息rpm -qpi xxx.rpm #列出RPM软件包的描述信息rpm -qf xxx.rpm #查找指定文件属于哪个RPM软件包rpm -Va xxx.rpm #检验所有的RPM软件包，查找丢失的文件rpm -e xxx.rpm #删除包rpm -e --nodeps xxx.rpm #忽略依赖的检查来删除,但最好不要这么做，因为忽略依赖，会变得很杂乱rpm --import RPM-GPG-KEY(签名文件) #导入签名 rpm验证与数码签章(Verify/signature)rpm验证使用 /var/lib/rpm 下面的数据库内容来比对目前 Linux 系统的环境下的所有软件文件,如果存在改动则会列出来 rpm -Va # 检验所有已安装的软件rpm -V + 已安装的软件名称 # 定向检验某个软件rpm -Vp + 某个 RPM 文件的文件名 # 列出该软件内可能被更动过的文件rpm -Vf # 列出某个文件是否被更动过``` 如果和确认文件更新的情况举例```bash[root@ops rpm]# rpm -Vf /etc/logrotate.confS.5....T. c /etc/logrotate.conf c就是配置文件的意思(configuration) SM5DLUGTP c filenameS ：（file Size differs） 文件的容量大小是否被改变M ：（Mode differs） 文件的类型或文件的属性 （rwx） 是否被改变？如是否可执行等参数已被改变5 ：（MD5 sum differs） MD5 这一种指纹码的内容已经不同D ：（Device major/minor number mis-match） 设备的主/次代码已经改变L ：（readLink（2） path mis-match） Link 路径已被改变U ：（User ownership differs） 文件的所属人已被改变G ：（Group ownership differs） 文件的所属群组已被改变T ：（mTime differs） 文件的创建时间已被改变P ：（caPabilities differ） 功能已经被改变 另外c还有其他的几种文件类型 c ：配置文件 （config file）d ：文件数据文件 （documentation）g ：鬼文件～通常是该文件不被某个软件所包含，较少发生！（ghost file）l ：授权文件 （license file）r ：读我文件 （read me） yum既然看了rpm,那么与他紧密相关的yum也值得一看, yum 是通过分析 RPM 的标头数据后， 根据各软件的相关性制作出属性相依时的解决方案，然后可以自动处理软件的相依属性问题，以解决软件安装或移除与升级的问题。 常用命令yum search nginx # 搜寻某个软件名称或者是描述 （description） 的重要关键字；yum list nginx # 列出目前 yum 所管理的所有的软件名称与版本，有点类似 rpm -qa；yum info jq # 查看包信息yum list update # 列出目前服务器上可供本机进行升级的软件有哪些？yum install jq --installroot=/some/path #将该软件安装在 /some/path 而不使用默认路径yum remove jq # 删除yum clean all # 经所有软件库数据删掉，清除缓存yum repolist all # 显示所有仓库yum-config-manager --enable repository... # 打开仓库yum-config-manager --disable repository... # 关闭仓库 yum的配置文件在你的linux生成后，系统会默认给你几个 CentOS 的映射站台，但是这些CentOS 的映射站台可能会选错，或者说速度会很慢，那么我们就要修改我们的yum配置文件 vim /etc/yum.repos.d/CentOS-Base.repo[base]# 代表软件库的名字！中括号一定要存在，里面的名称则可以随意取。但是不能有两个相同的软件库名称， 否则 yum 会不晓得该到哪里去找软件库相关软件清单文件。name=CentOS-$releasever - Base# 只是说明一下这个软件库的意义而已，重要性不高！mirrorlist=http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=os&infra=$infra# 列出这个软件库可以使用的映射站台，如果不想使用，可以注解到这行；baseurl=http://mirror.centos.org/centos/$releasever/os/$basearch/# 这个最重要，因为后面接的就是软件库的实际网址！ mirrorlist 是由 yum 程序自行去捉映射站台， baseurl 则是指定固定的一个软件库网址！我们刚刚找到的网址放到这里来啦！gpgcheck=1# 指定是否需要查阅 RPM 文件内的数码签章gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7# 就是数码签章的公钥档所在位置！使用默认值即可 更新成阿里云的repo [base]name=CentOS-$releasever - Base - mirrors.aliyun.comfailovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/ http://mirrors.cloud.aliyuncs.com/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7 安装mysql实例 添加yum源，为了下载的速度，我们添加一个阿里源wget https://mirrors.tuna.tsinghua.edu.cn/mysql/yum/mysql-connectors-community-el7/mysql-community-release-el7-5.noarch.rpm 安装镜像源rpm -ivh mysql-community-release-el7-5.noarch.rpm 安装后/etc/yum.repos.d/目录下多了两个文件[root@work196 yum.repos.d]# ll grep 'mysql' --color-rw-r--r--. 1 root root 1060 Jan 29 2014 mysql-community-source.repo-rw-r--r--. 1 root root 1209 Jan 29 2014 mysql-community.repo 清理yum缓存，重新建立缓存yum clean allyum makecache 关闭8.0镜像,开启5.7镜像yum-config-manager --disable mysql80-communityyum-config-manager --enable mysql57-community 下载安装yum install mysql-community-server 启动systemctl start mysqld","link":"/posts/fa23aabb/"},{"title":"docker-k8s 基础","text":"learn docker + k8s 🐳 🕸️ docker-k8s基础k8s中的最小调度单元 pod在k8s里面，有很多新的技术概念，其中有一个东西被称之为pod。pod是k8s集群里面运行和部署的最小单元，它的设计理念是，一个pod可以承载多个容器，并且共享网络地址和文件系统，内部的容器通过进程间的通信相互访问。也就是说在k8s中，最小的单位不再是container，而是pod一个pod节点中可以有多个container容器 根据pods yaml文件创建一个nginx容器创建一个pod节点，pod.yml文件 ## pod_nginx.ymlapiVersion: v1kind: Podmetadata: name: nginx labels: ¦ app: nginxspec: containers: - name: nginx ¦ image: nginx ¦ ports: ¦ - containerPort: 80 创建pod节点 # 创建节点[root@ops ~]# kubectl create -f pod_nginx.ymlpod/nginx created# 查看节点[root@ops ~]# kubectl get podsNAME READY STATUS RESTARTS AGEnginx 1/1 Running 0 2m27s# 查看详细信息[root@ops ~]# kubectl get pods -o wideNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATESnginx 1/1 Running 0 4m44s 172.17.0.4 ops.novalocal 查看容器id 如果你本身自己就是linux机器的话，机器本身就是Minikub节点了，查看docker [root@ops ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbe7d61df08ee nginx \"nginx -g 'daemon of…\" 5 minutes ago Up 5 minutes k8s_nginx_nginx_default_3a2d631d-0de5-40fc-969d-1451a2190389_055af5366716a k8s.gcr.io/pause:3.1 \"/pause\" 5 minutes ago Up 5 minutes k8s_POD_nginx_default_3a2d631d-0de5-40fc-969d-1451a2190389_0## 进入容器,查看网络docker exec be7d61df08ee -it /bin/bash 批量创建多个容器 ReplicaSet## rs_nginx.yamlapiVersion: apps/v1kind: ReplicaSetmetadata: name: nginx labels: ¦ tier: frontendspec: replicas: 3 selector: ¦ matchLabels: ¦ ¦ tier: frontend template: ¦ metadata: ¦ ¦ name: nginx ¦ ¦ labels: ¦ ¦ ¦ tier: frontend ¦ spec: ¦ ¦ containers: ¦ ¦ - name: nginx ¦ ¦ ¦ image: nginx ¦ ¦ ¦ ports: ¦ ¦ ¦ - containerPort: 80 创建多节点 kubectl create -f rs_nginx.yml[root@ops ~]# kubectl get podsNAME READY STATUS RESTARTS AGEnginx-df6pr 1/1 Running 0 10snginx-sspd2 0/1 ContainerCreating 0 10snginx-vbjs6 0/1 ContainerCreating 0 10s 使用这个方法创建的内容，会维持容器的数量 ## 删除一个容器[root@ops ~]# kubectl delete pods nginx-df6prpod \"nginx-df6pr\" deleted# 再次查看节点中的容器时，会发现他会再生成一个容器[root@ops ~]# kubectl get podsNAME READY STATUS RESTARTS AGEnginx-pnk4c 0/1 ContainerCreating 0 4snginx-sspd2 1/1 Running 0 5m51snginx-vbjs6 1/1 Running 0 5m51s 横向扩展与缩放将容器减少到2个 [root@ops ~]# kubectl scale rs nginx --replicas=2replicaset.apps/nginx scaled[root@ops ~]# kubectl get rsNAME DESIRED CURRENT READY AGEnginx 2 2 2 21m[root@ops ~]# kubectl get podsNAME READY STATUS RESTARTS AGEnginx-sspd2 1/1 Running 0 21mnginx-vbjs6 1/1 Running 0 21m 将容器增加到5个 [root@ops ~]# kubectl scale rs nginx --replicas=2replicaset.apps/nginx scaled[root@ops ~]# kubectl scale rs nginx --replicas=5replicaset.apps/nginx scaled[root@ops ~]# kubectl get podsNAME READY STATUS RESTARTS AGEnginx-bnnbc 0/1 ContainerCreating 0 3snginx-jh5kn 0/1 ContainerCreating 0 3snginx-skhqq 0/1 ContainerCreating 0 3snginx-sspd2 1/1 Running 0 23mnginx-vbjs6 1/1 Running 0 23m kubectl的使用方法kubectl提供了许多便捷的方法，其帮助命令也很完善，这边举例几个常用的 kubectl get pods -o wide # 查看pods节点上有哪些容器kubectl exec -it CONTAINER-NAME sh # 进入第一个叫CONTAINER-NAME的容器kubectl exec -it -c Container name sh # 指定容器名字进入kubectl describe pods nginx # 查看pods节点详情kubectl get pods # 查看有哪些节点kubectl create -f xx.yml # 根据yml文件创建podskubectl delete -f xx.yml # 删除由xx.yml创建的pods","link":"/posts/b83f2a68/"},{"title":"neovim配置","text":"learn vim 🇺🇬 neovim配置在centos服务器上搭建自己的neovim环境yum upgradeyum install python3 git curl -LO https://github.com/neovim/neovim/releases/download/stable/nvim.appimage## 添加权限chmod 777 ./nvim.appimage./nvim.appimage --appimage-extractln -s ./squashfs-root/usr/bin/nvim /usr/bin/nvim # 下载配置mkdir ~/.configgit clone git://github.com/rafi/vim-config.git ~/.config/nvimcd ~/.config/nvimsh venvs.shmake testmake# 安装deoplete-tabninecd ~/.config/nvimtouch config/local.plugin.yaml# cat > ./local.plugin.yaml < EOF ---> - repo: tbodt/deoplete-tabnine> build: ./install.sh> EOFmake update 错误vim version 8动手编译安装vim 8+ # 安装环境yum install ruby ruby-devel lua lua-devel luajit \\luajit-devel ctags git python python-devel \\python36 python36-devel tcl-devel \\perl perl-devel perl-Extutils-ParseXS \\perl-ExtUtils-XSpp perl-ExtUtils-CBuilder \\perl-ExtUtils-Embed libX* ncurses-devel gtk2-devel \\gcc# 卸载原来不符合版本要求的version vimyum -y remove vim# 获取vimgit clone https://github.com/vim/vim.git# 编译安装cd vim && ./configure --with-features=huge \\--enable-gui=gtk2 \\--with-x \\--enable-fontset \\--enable-cscope \\--enable-multibyte \\--enable-pythoninterp \\--with-python-config-dir=/usr/lib64/python2.7/config \\--enable-python3interp \\--with-python3-config-dir=/usr/lib64/python3.6/config \\--enable-luainterp \\--enable-rubyinterp \\--enable-perlinterp \\--enable-multibyte \\--prefix=/usr/local/vim \\--with-compiledby=\"brooksj\"# 创建makefilemake# 编译make -j 8# 设置系统环境export PATH=/usr/local/vim/bin:$PATH ## 注释# 这里的路径和你vim的安装路径一样，安装路径为创建makefile文件时 指定的--prefix参数 你可能需要的一些网址如何安装neovimhttps://github.com/neovim/neovim/wiki/Installing-Neovimvim 配置文件https://github.com/PegasusWang/vim-config","link":"/posts/8673b365/"},{"title":"python 基础","text":"learn python 🐍 python基础python创建虚拟环境 方法1 使用virtualenvpip install virtualenv# 豆瓣源# pip install -i https://pypi.douban.com/simple virtualenv virtualenv env # 创建虚拟环境virtualenv -p /usr/local/bin/python3 venv # 指定解释器安装source env/bin/active # 激活虚拟环境deactivate # 退出虚拟环境rm -rf ./venv # 删除虚拟环境 使用pipenvhttps://juejin.im/post/5ca4be8bf265da30b160de27 使用slotpython是一门动态语言，创建class的实例之后，我们可以给该实例绑定任何属性和方法 举例: 给类的特定实例绑定属性class student(object): passif __name__ == \"__main__\": # 尝试给实例绑定动态变量 s = student() s.name = 'hzj' print(s.name) 给类的特定实例绑定方法class student(object): passdef set_age(self,age): self.age = ageif __name__ == \"__main__\": s = student() # 创建实例 from types import MethodType s.set_age = MethodType(set_age,s) # 绑定方法 s.set_age(25) print(s.age) 但是给一个实例绑定的方法对另一个实例是不起作用的 class student(object): pass def set_age(self,age): self.age = age if __name__ == \"__main__\": s = student() from types import MethodType s.set_age = MethodType(set_age,s) s.set_age(25) s2 = student() # 新的实例 s2.set_age(50) print(s2.age)# 报错# Traceback (most recent call last):# File \"slots_py.py\", line 15, in # s2.set_age(50)# AttributeError: 'student' object has no attribute 'set_age' 给类的所有实例绑定方法class student(): passdef set_age(self,age): self.age = ageif __name__ == \"__main__\": student.set_age = set_age s = student() s.set_age(10) print(s.age) s2 = student() s2.set_age(20) print(s2.age) 限制实例的属性上来的三例都是给实例扩展属性，在某些情况下我们可以用slots = (‘x’,’y’) 的形式来定义绑定的属性名称 class student(): __slots__ = ('name','age')if __name__ == \"__main__\": s1 = student() # 声明实例 s1.age = 2 print(s1.age) # 声明不允许的变量 s2 = student() s2.hobit = \"swimming\" print(s2.hobit) 出现报错 Traceback (most recent call last): File \"slots_py.py\", line 15, in s2.hobit = \"swimming\"AttributeError: 'student' object has no attribute 'hobit' slots继承在子类当中，他是不具有父类的属性的，除非在子类中也定义slots，这样，子类实例允许定义的属性就是自身的slots加上父类的slots。 class student(): __slots__ = ('name','age') class BadStudent(student): __slots__ = ('name','hobit') if __name__ == \"__main__\": bs = BadStudent() bs.name = \"name\" bs.hobit = \"hobit\" bs.age = \"age\" bs.xx = \"xx\" print(bs.name,bs.hobit,bs.age) print(bs.xx)Traceback (most recent call last): File \"slots_py.py\", line 15, in bs.xx = \"xx\"AttributeError: 'BadStudent' object has no attribute 'xx' 使用@property# 使用property## 在绑定属性时，如果我们直接把属性暴露出去，虽然写起来很简单，但是，没办法检查参数，导致可以把成绩随便改：class student : __slots__ = ('name','age','score')class student2: def get_score(self): return self._score def set_score(self,value): if not isinstance(value,int): raise ValueError(\"score must be an integet!\") if vlaue < 0 or value > 100: raise ValueError(\"some must between 0 ~ 100!\") self._score = valueclass student3(object): @property def score(self): return self._score @score.setter def score(self,value): if not isinstance(value,int): raise ValueError(\"score must be an integet!\") if vlaue < 0 or value > 100: raise ValueError(\"some must between 0 ~ 100!\") self._score = valueif __name__ == \"__main__\": s = student() s.score = 10 print(s.score) s2 = student2() s2.set_score(20) print(s2.get_score()) s3 = student3() s3.score = 30 # @property = set_score print(s3.score) #@score.setter = get_score## 只用了property的话就是只读属性## 用了property和setter的话就是可读写属性","link":"/posts/98b77d55/"},{"title":"linux_command ss","text":"learn linux command linux_command ssss是Socket Statistics的缩写。顾名思义，ss命令可以用来获取socket统计信息，它可以显示和netstat类似的内容。但ss的优势在于它能够显示更多更详细的有关TCP和连接状态的信息，而且比netstat更快速更高效。 查看网络连接你可以是使用netstat 或者 cat /proc/net/tcp但是当你在连接数上万的服务器上使用netstat时候，会出现明显的卡顿 ➜ ~ netstatActive Internet connectionsProto Recv-Q Send-Q Local Address Foreign Address (state)tcp4 0 0 10.0.28.62.63485 117.18.232.200.https ESTABLISHEDtcp4 0 0 10.0.28.62.63467 210.22.248.181.https ESTABLISHEDtcp4 0 0 10.0.28.62.63459 121.51.176.86.https ESTABLISHEDtcp4 0 0 10.0.28.62.63458 121.51.176.86.https FIN_WAIT_2tcp4 0 0 10.0.28.62.63456 121.51.176.86.https FIN_WAIT_2tcp4 0 0 10.0.28.62.63451 121.51.176.86.https FIN_WAIT_2tcp4 0 517 10.0.28.62.63449 121.51.176.86.https FIN_WAIT_1tcp4 0 0 10.0.28.62.63443 121.51.176.86.https FIN_WAIT_1tcp4 0 31 10.0.28.62.63429 52.114.158.91.https FIN_WAIT_1tcp4 0 0 10.0.28.62.63424 10.0.28.58.ssh ESTABLISHEDtcp4 0 0 10.0.28.62.63422 hkg12s13-in-f5.1.https ESTABLISHEDtcp4 0 0 10.0.28.62.63379 13.107.18.11.https ESTABLISHEDtcp4 0 0 10.0.28.62.63378 13.107.18.11.https ESTABLISHED[root@hzj-machine ~]# cat /proc/net/tcp sl local_address rem_address st tx_queue rx_queue tr tm->when retrnsmt uid timeout inode 0: 0100007F:0019 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 22560 1 ffff8840c72e0000 100 0 0 10 0 1: 00000000:0016 00000000:0000 0A 00000000:00000000 00:00000000 00000000 0 0 21768 1 ffff8840c1b18000 100 0 0 10 0 2: 3A1C000A:0016 3E1C000A:F7C0 01 00000000:00000000 02:000A38D8 00000000 0 0 119773 4 ffff8840c72e3640 20 4 27 10 -1 3: 3A1C000A:0016 3E1C000A:F2F2 01 00000000:00000000 02:0002DF3E 00000000 0 0 117281 2 ffff8840c72e64c0 20 4 31 10 25 4: 3A1C000A:0016 3E1C000A:F0A9 01 00000000:00000000 02:0008BF3E 00000000 0 0 70042 2 ffff8840c72e2e80 20 4 31 2 2 但是ss相对于这两种来说在速度上加快了很多,它利用到了TCP协议栈中tcp_diag。tcp_diag是一个用于分析统计的模块，可以获得Linux 内核中第一手的信息，这就确保了ss的快捷高效.当谈如果系统中没有tcp_diag,ss也可以正常运行。速度相对于有tcp_diag较慢 Use命令格式ss [参数]ss [参数] [过滤] 参数 -h, --help 帮助信息-V, --version 程序版本信息-n, --numeric 不解析服务名称-r, --resolve 解析主机名-a, --all 显示所有套接字（sockets）-l, --listening 显示监听状态的套接字（sockets）-o, --options 显示计时器信息-e, --extended 显示详细的套接字（sockets）信息-m, --memory 显示套接字（socket）的内存使用情况-p, --processes 显示使用套接字（socket）的进程-i, --info 显示 TCP内部信息-s, --summary 显示套接字（socket）使用概况-4, --ipv4 仅显示IPv4的套接字（sockets）-6, --ipv6 仅显示IPv6的套接字（sockets）-0, --packet 显示 PACKET 套接字（socket）-t, --tcp 仅显示 TCP套接字（sockets）-u, --udp 仅显示 UCP套接字（sockets）-d, --dccp 仅显示 DCCP套接字（sockets）-w, --raw 仅显示 RAW套接字（sockets）-x, --unix 仅显示 Unix套接字（sockets）-f, --family=FAMILY 显示 FAMILY类型的套接字（sockets），FAMILY可选，支持 unix, inet, inet6, link, netlink-A, --query=QUERY, --socket=QUERY QUERY := {all|inet|tcp|udp|raw|unix|packet|netlink}[,QUERY]-D, --diag=FILE 将原始TCP套接字（sockets）信息转储到文件 -F, --filter=FILE 从文件中都去过滤器信息 FILTER := [ state TCP-STATE ] [ EXPRESSION ] 显示所有的TCP连接 或者 UDP连接## 显示tcpss -t -a## 显示udpss -u -a 显示所有套接字（sockets）的大致情况ss -s 列出所有打开的网络连接端口ss -l 显示进行使用的socketss -pl 找出打开套接字/端口应用程序ss -pl | grep 3306 显示所有状态为etablished的SMTP连接","link":"/posts/d331dcdd/"},{"title":"centos有线网卡配置802.1x上网","text":"learn linux centos有线网卡配置802.1x查看版本 root:~# cat /etc/redhat-releaseCentOS Linux release 7.7.1908 (Core) 取消本机的有线活动网卡 这里举例的是ifcfg-enp3s0 sed -i -r '/ONBOOT/s#ONBOOT.*#ONBOOT=no/g' /etc/sysconfig/network-scripts/ifcfg-enp3s0 chkconfig –list ，查看是否有 network 的服务，如果有，执行 chkconfig –del network 删除 修改 /etc/wpa_supplicant/wpa_supplicant.conf，写入如下内容： ctrl_interface=/var/run/wpa_supplicantap_scan=0network={ key_mgmt=IEEE8021X eap=PEAP identity=\"YOUR_USER_NAME\" password=\"YOUR_PASSWORD\" phase2=\"autheap=MSCHAPV2\"} 做检测是否成功 $ ifdown em1$ wpa_supplicant -B -i em1 -c /etc/wpa_supplicant/wpa_supplicant.conf -D wired$ ifup em1$ dhclient em1$ ip addr # 查看IP地址$ ping baidu.com 设置开机启动 touch /etc/init.d/wpa_network#!/bin/bash# chkconfig: 2345 10 90# description: wpa networkifdown em1wpa_supplicant -B -i em1 -c /etc/wpa_supplicant/wpa_supplicant.conf -D wiredifup em1dhclient em1 chkconfig –add wpa-network，加入到 chkconfig 中 chkconfig wpa-network on，开启 reboot 重启检测是否成功自动联网","link":"/posts/443b0db9/"},{"title":"交换机升级步骤","text":"learn switch 交换机升级步骤如何使用ftp## 建立ftp连接ftp domain.comftp 192.168.0.1ftp user@ftpdomain.com## 获取方法>ftp put file # 上传文件>ftp ls # 列出远程机器上的文件目录>ftp get file # 获取文件 登陆成功 升级步骤存在情况:1.交换机仅内网2.交换机配有外网 第一种解决方法机器在内网,无法使用外网的机器进行文件传输，解决方法。登录同网段的内网机器，用ftp传文件 先使用tftp上传文件到服务器(115.231.100.91)，再登录服务器，使用ftp连接远程交换机 ftp (远程服务器IP)192.168.20.22# 按照提示输入用户名及密码# 登录完成后，传输文件put 绝对路径+要传输的文件# 传输文件到指定目录，先使用ftp登录远程服务器，然后cd到指定目录下，再使用put传输文件ftp xxxipcd test/soft/put xxx.ipe 第二种情况交换机的解决办法PC本地通过winscp传输ipe文件到交换机上并设定主要镜像为所传的ipe文件 下载ipe升级软件下载地址为:http://10.0.8.10/dl/comware/ 下载winscp下载地址为:https://winscp.net/eng/download.php 登录所需要升级的交换机,配置升级交换机的角色，需要密码 # 开启ftp服务ftp server enable# 在本地建立用户system-view local-user abc class managepassword simple 123456# 设定用户的工作地址为 flash:/authorization-attribute user-role network-admin work-directory flash:/# 开通用户权限，与admin保持一致service-type ftpauthorization-attribute user-role level-3authorization-attribute user-role network-adminauthorization-attribute user-role network-operator 使用winscp传输文件形式：ftphostname : 公网IPusername : abcpassword : 123拖入文件，完成传输 设置交换机启动项boot-loader file flash:/xxxx.ipe slot 1 main 后续处理关闭ftpundo ftp server enable删除角色 第二种情况交换机的解决办法(2)直接使用scp传输文件https://docs.google.com/document/d/1TZmYLlFvITRnZdVdnCuakIXoSfXudx_lU09W2mi5NHg/edit","link":"/posts/2c7b0ff4/"}],"tags":[{"name":"工具","slug":"工具","link":"/tags/%E5%B7%A5%E5%85%B7/"},{"name":"code","slug":"code","link":"/tags/code/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"django","slug":"django","link":"/tags/django/"},{"name":"CI-CD","slug":"CI-CD","link":"/tags/CI-CD/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"daily","slug":"daily","link":"/tags/daily/"},{"name":"vue","slug":"vue","link":"/tags/vue/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"vim","slug":"vim","link":"/tags/vim/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"rust","slug":"rust","link":"/tags/rust/"},{"name":"编程","slug":"编程","link":"/tags/%E7%BC%96%E7%A8%8B/"},{"name":"Command","slug":"Command","link":"/tags/Command/"},{"name":"负载均衡","slug":"负载均衡","link":"/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"记事本","slug":"记事本","link":"/tags/%E8%AE%B0%E4%BA%8B%E6%9C%AC/"},{"name":"command","slug":"command","link":"/tags/command/"},{"name":"ansible","slug":"ansible","link":"/tags/ansible/"},{"name":"网络","slug":"网络","link":"/tags/%E7%BD%91%E7%BB%9C/"},{"name":"交换机","slug":"交换机","link":"/tags/%E4%BA%A4%E6%8D%A2%E6%9C%BA/"}],"categories":[{"name":"工具","slug":"工具","link":"/categories/%E5%B7%A5%E5%85%B7/"},{"name":"code","slug":"code","link":"/categories/code/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"编程","slug":"编程","link":"/categories/%E7%BC%96%E7%A8%8B/"},{"name":"checklist","slug":"checklist","link":"/categories/checklist/"},{"name":"docker","slug":"linux/docker","link":"/categories/linux/docker/"},{"name":"架构","slug":"架构","link":"/categories/%E6%9E%B6%E6%9E%84/"},{"name":"记事本","slug":"记事本","link":"/categories/%E8%AE%B0%E4%BA%8B%E6%9C%AC/"},{"name":"CI-CD","slug":"架构/CI-CD","link":"/categories/%E6%9E%B6%E6%9E%84/CI-CD/"},{"name":"扩展","slug":"扩展","link":"/categories/%E6%89%A9%E5%B1%95/"},{"name":"数据结构","slug":"数据结构","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"网络","slug":"网络","link":"/categories/%E7%BD%91%E7%BB%9C/"},{"name":"extra","slug":"网络/extra","link":"/categories/%E7%BD%91%E7%BB%9C/extra/"},{"name":"django","slug":"编程/django","link":"/categories/%E7%BC%96%E7%A8%8B/django/"},{"name":"脚本","slug":"linux/脚本","link":"/categories/linux/%E8%84%9A%E6%9C%AC/"},{"name":"Command","slug":"linux/Command","link":"/categories/linux/Command/"},{"name":"文件系统","slug":"linux/文件系统","link":"/categories/linux/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"故障","slug":"linux/故障","link":"/categories/linux/%E6%95%85%E9%9A%9C/"},{"name":"linux-network","slug":"linux/linux-network","link":"/categories/linux/linux-network/"},{"name":"二层交换机","slug":"网络/二层交换机","link":"/categories/%E7%BD%91%E7%BB%9C/%E4%BA%8C%E5%B1%82%E4%BA%A4%E6%8D%A2%E6%9C%BA/"},{"name":"交换机","slug":"网络/交换机","link":"/categories/%E7%BD%91%E7%BB%9C/%E4%BA%A4%E6%8D%A2%E6%9C%BA/"},{"name":"jwt","slug":"编程/jwt","link":"/categories/%E7%BC%96%E7%A8%8B/jwt/"},{"name":"设备","slug":"设备","link":"/categories/%E8%AE%BE%E5%A4%87/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"python","slug":"python","link":"/categories/python/"},{"name":"ansible","slug":"ansible","link":"/categories/ansible/"}]}